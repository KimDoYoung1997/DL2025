{
 "cells": [
  {
   "cell_type": "raw",
   "id": "aeff2ac3-8f9f-4111-ab0c-7e897c0b0ea5",
   "metadata": {
    "id": "87b5cded-346b-4915-acf5-b5ec93a5207d",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"07wk-1: (합성곱신경망) -- CNN 자랑, CNN 핵심레이어\"\n",
    "author: \"최규빈\"\n",
    "date: \"04/16/2025\"\n",
    "draft: false\n",
    "freeze: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b739324d-6331-47b4-8aae-da740055ff9d",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/guebin/DL2025/blob/main/posts/06wk-2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcaeff1-7791-48ed-9c60-b954ffe6b7f2",
   "metadata": {
    "id": "4d47a7c9",
    "tags": []
   },
   "source": [
    "# 1. 강의영상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854076ca-0234-427b-9a95-147a041cf58f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# {{<video https://youtu.be/playlist?list=PLQqh36zP38-wcPiCEdYML9-6-Xv5RVbso&si=BbNo6mwCHqwOV0FS>}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c59bc1-1a1d-4287-b55a-a26104664fe0",
   "metadata": {},
   "source": [
    "# 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "229dfe04-bb02-4a02-81e4-c6fdd9eb2f91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "758b9fdc-63aa-4526-a12e-42a784516343",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (4.5, 3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a66400-3cdc-42a7-9c81-2ec4eee68ef2",
   "metadata": {},
   "source": [
    "# 3. CNN 자랑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40719670-b070-4639-b689-48e886e8b945",
   "metadata": {},
   "source": [
    "## A. 성능좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4446a9ea-72f1-4a79-955c-73374fdf7c52",
   "metadata": {},
   "source": [
    "*Fashion MNIST*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19ffc154-e4b6-4e09-9c32-73110128d4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True)\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, range(5000))\n",
    "test_dataset = torch.utils.data.Subset(test_dataset, range(1000))\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "X = torch.stack([to_tensor(img) for img, lbl in train_dataset]).to(\"cuda:0\")\n",
    "y = torch.tensor([lbl for img, lbl in train_dataset])\n",
    "y = torch.nn.functional.one_hot(y).float().to(\"cuda:0\")\n",
    "XX = torch.stack([to_tensor(img) for img, lbl in test_dataset]).to(\"cuda:0\")\n",
    "yy = torch.tensor([lbl for img, lbl in test_dataset])\n",
    "yy = torch.nn.functional.one_hot(yy).float().to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653e698e-94d9-4598-a9ae-84ed1044c766",
   "metadata": {},
   "source": [
    "*발악수준으로 설계한 신경망*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f5290e2d-e9d9-4641-92fd-7e6df5b68ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784,2048),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(2048,10)\n",
    ").to(\"cuda\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "963b8ded-f1e7-48be-8975-3ba38bfac4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoc in range(1,500):\n",
    "    #1\n",
    "    logits = net(X)\n",
    "    #2\n",
    "    loss = loss_fn(logits, y) \n",
    "    #3\n",
    "    loss.backward()\n",
    "    #4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0972367a-51bb-47c6-8ee3-cd177c968dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(X).argmax(axis=1) == y.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b95f70ad-2b90-4ecb-9610-90a91c862c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8520, device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(XX).argmax(axis=1) == yy.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0411382b-477e-4aec-888b-d230844df9e1",
   "metadata": {},
   "source": [
    "*대충대충 설계한 합성곱신경망*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "70a00a09-6d44-43de-9395-f68d7ca25b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1,16,2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(2704,10),\n",
    ").to(\"cuda\")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b7b598c9-e55b-4d88-a2a9-1974d20f0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoc in range(1,500):\n",
    "    #1\n",
    "    logits = net(X)\n",
    "    #2\n",
    "    loss = loss_fn(logits, y) \n",
    "    #3\n",
    "    loss.backward()\n",
    "    #4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "84e56cf1-abf9-49f8-82cf-2cd9e739c7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9466, device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(X).argmax(axis=1) == y.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ca554ed-6556-4c13-bf7b-0de533ceb487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8710, device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(XX).argmax(axis=1) == yy.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508ed6f-d728-459d-8faf-95c071e17921",
   "metadata": {},
   "source": [
    "## B. 파라메터적음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f7ea0eee-5dff-4d54-a05b-1b9681d6aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784,2048),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(2048,10)\n",
    ")\n",
    "net2 = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1,16,2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(2704,10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7304bb47-7550-41c5-baae-aa92909d8ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1_params = list(net1.parameters())\n",
    "net2_params = list(net2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0ef7b74d-bff2-4f7b-8ba9-58178603b674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 784])\n",
      "torch.Size([2048])\n",
      "torch.Size([10, 2048])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for params in net1_params:\n",
    "    print(params.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "83ee0d71-65cf-4e41-95c2-26592e2c5b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1628170"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2048*784 + 2048 + 10*2048 + 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3fd0625a-44ca-4a30-9316-dc3cc6c1d85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 2, 2])\n",
      "torch.Size([16])\n",
      "torch.Size([10, 2704])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for params in net2_params:\n",
    "    print(params.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "54d4ed1d-50dc-418a-9f02-c0759855f566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27130"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*1*2*2 + 16 + 10*2704 + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7615fc25-fbb6-47f8-861b-14fa69af4371",
   "metadata": {},
   "source": [
    "## C. 유명함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf82636-e42f-4063-805f-df879b295f9d",
   "metadata": {},
   "source": [
    "`-` <https://brunch.co.kr/@hvnpoet/109> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3724d0-c678-4508-966a-ea26f4638e87",
   "metadata": {},
   "source": [
    "# 4. CNN 핵심레이어 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21d2ce1-1d63-425b-aba5-92f380bc7caa",
   "metadata": {},
   "source": [
    "## A. `torch.nn.Conv2d`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a65cd9-e547-46be-ae42-8c85c58931b1",
   "metadata": {},
   "source": [
    "`-` 우선 연산하는 방법만 살펴보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a913513-8ca2-4bed-91ba-931984be8349",
   "metadata": {},
   "source": [
    "**(예시1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c48566f-65e4-483e-be7e-0d2e65b9a463",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.1733, -0.4235],\n",
       "           [ 0.1802,  0.4668]]]]),\n",
       " tensor([0.2037]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(43052)\n",
    "conv = torch.nn.Conv2d(1,1,(2,2)) # 입력1, 출력1, (2,2) window size\n",
    "conv.weight.data, conv.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c7df93e-3d04-4b08-9948-cbcba3cc82ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 1.],\n",
       "          [2., 3.]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.arange(0,4).reshape(1,1,2,2).float() # 2,2 흑백이미지. \n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "335c606d-9e5f-4670-ab14-9076669dde1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.541"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-0.1733)*0 + (-0.4235)*1 +\\\n",
    "(0.1802)*2 + (0.4668)*3 + 0.2037"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1ea904b-3cd2-4366-93f9-6b4406d67107",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.5410]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1351a868-3291-42e2-97fe-6769291c58d8",
   "metadata": {},
   "source": [
    "**(예시2) 평균**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cbd33a25-85dd-4168-a7a6-e3d4b934b17d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(1,1,(2,2))\n",
    "conv.weight.data = conv.weight.data * 0 + 1/4\n",
    "conv.bias.data = conv.bias.data * 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "408ce6e0-4199-4a73-985e-f738ff4f7e00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e446b2f5-11f0-4d37-bdb2-31cdffa3c6e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.5000,  3.5000,  4.5000],\n",
       "          [ 6.5000,  7.5000,  8.5000],\n",
       "          [10.5000, 11.5000, 12.5000]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6de21e7-e8e3-492c-9050-3c1afafd5435",
   "metadata": {},
   "source": [
    "**(예시3) 이동평균?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c6444d3f-806d-4d83-a2e6-a7614d778d97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "           [ 4.,  5.,  6.,  7.],\n",
       "           [ 8.,  9., 10., 11.],\n",
       "           [12., 13., 14., 15.]]]]),\n",
       " tensor([[[[ 5.0000,  6.0000],\n",
       "           [ 9.0000, 10.0000]]]], grad_fn=<ConvolutionBackward0>))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.arange(16).reshape(1,1,4,4).float()\n",
    "img,conv(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1022142-ccd4-4568-bd7d-25a78da28ed7",
   "metadata": {},
   "source": [
    "**(예시4) window size가 증가한다면? (2d의 이동평균느낌)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8c87eb71-43cb-4881-938d-9f52cfc7986b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = torch.arange(16).reshape(1,1,4,4).float()\n",
    "conv = torch.nn.Conv2d(1,1,(3,3))\n",
    "conv.weight.data = conv.weight.data * 0 + 1/9\n",
    "conv.bias.data = conv.bias.data * 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b6ad76e4-2fa5-49a1-8b69-e495090798cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "           [ 4.,  5.,  6.,  7.],\n",
       "           [ 8.,  9., 10., 11.],\n",
       "           [12., 13., 14., 15.]]]]),\n",
       " tensor([[[[ 5.0000,  6.0000],\n",
       "           [ 9.0000, 10.0000]]]], grad_fn=<ConvolutionBackward0>))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img,conv(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0ea35b-5ae0-4c18-bd1d-db825439be42",
   "metadata": {},
   "source": [
    "**(예시5)** 2개의 이미지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8b4ef185-a9f1-4a9c-8115-b9cd2fae0fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs = torch.arange(32).reshape(2,1,4,4).float()\n",
    "conv = torch.nn.Conv2d(1,1,(3,3))\n",
    "conv.weight.data = conv.weight.data * 0 + 1/9\n",
    "conv.bias.data = conv.bias.data * 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e1d91bd3-773f-40b6-aeb5-23ffea16c162",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "           [ 4.,  5.,  6.,  7.],\n",
       "           [ 8.,  9., 10., 11.],\n",
       "           [12., 13., 14., 15.]]],\n",
       " \n",
       " \n",
       "         [[[16., 17., 18., 19.],\n",
       "           [20., 21., 22., 23.],\n",
       "           [24., 25., 26., 27.],\n",
       "           [28., 29., 30., 31.]]]]),\n",
       " tensor([[[[ 5.0000,  6.0000],\n",
       "           [ 9.0000, 10.0000]]],\n",
       " \n",
       " \n",
       "         [[[21.0000, 22.0000],\n",
       "           [25.0000, 26.0000]]]], grad_fn=<ConvolutionBackward0>))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs, conv(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b08c5b-75f0-4c80-84bc-857b69a91602",
   "metadata": {},
   "source": [
    "**(예시6) 피처뻥튀기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf03413a-b35b-4586-9b66-23c460b3a41e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs = torch.arange(32).reshape(2,1,4,4).float()\n",
    "conv = torch.nn.Conv2d(1,16,(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc59986b-adbd-4f9b-8874-7d0887e58138",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 4, 4]), torch.Size([2, 16, 2, 2]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape,conv(imgs).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97996a6c-0f25-454b-a995-d9b3f86e8ce2",
   "metadata": {},
   "source": [
    "> 질문: `conv(img) = img @ What` 을 만족하는 What을 찾을 수 있을까? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b4625d-6708-4f97-936e-885243738b41",
   "metadata": {},
   "source": [
    "## B. `torch.nn.ReLU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5b41bb3-f3f6-47ae-8e79-4b4fe85210b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.8648,  0.9710,  0.7732,  0.6412,  0.0170],\n",
       "           [ 0.2735, -1.7195, -0.1226, -0.0941,  0.1285],\n",
       "           [ 0.1185,  0.4669, -1.1873, -0.5097, -0.2983],\n",
       "           [-0.1454, -0.0031,  1.0633, -0.3308,  1.1639],\n",
       "           [-2.1129, -0.3902, -1.5113, -1.4605,  0.0812]]]]),\n",
       " tensor([[[[0.0000, 0.9710, 0.7732, 0.6412, 0.0170],\n",
       "           [0.2735, 0.0000, 0.0000, 0.0000, 0.1285],\n",
       "           [0.1185, 0.4669, 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 1.0633, 0.0000, 1.1639],\n",
       "           [0.0000, 0.0000, 0.0000, 0.0000, 0.0812]]]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu = torch.nn.ReLU()\n",
    "img = torch.randn(25).reshape(1,1,5,5)\n",
    "img, relu(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b876b7-6109-497a-895d-4b829f7468a9",
   "metadata": {},
   "source": [
    "## C. `torch.nn.MaxPool2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fcbb9b1d-5690-403b-83a8-d9132858d028",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.3463,  0.8714,  0.3561, -0.6945,  0.8013],\n",
       "           [ 0.6642, -1.1428, -2.1780, -0.2902, -0.0939],\n",
       "           [ 0.2526,  1.0615,  0.0906,  0.5329, -0.4825],\n",
       "           [ 0.0956, -0.2131, -1.4917,  0.3350,  0.6976],\n",
       "           [-0.3294,  0.1037, -1.5099, -0.9487, -1.3825]]]]),\n",
       " tensor([[[[0.8714, 0.3561],\n",
       "           [1.0615, 0.5329]]]]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp = torch.nn.MaxPool2d((2,2))\n",
    "img = torch.randn(25).reshape(1,1,5,5)\n",
    "img,mp(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
