{
 "cells": [
  {
   "cell_type": "raw",
   "id": "20ee4531-eaa2-4d6d-acb8-4cd9edf06ac9",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"13wk-1: 강화학습 (1) -- Bandit\"\n",
    "author: \"최규빈\"\n",
    "date: \"05/28/2024\"\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21686a35-0ef2-4663-971c-f02b8ad79474",
   "metadata": {
    "id": "e67ab8e0"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/guebin/DL2025/blob/main/posts/13wk-1.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b8e653-df6b-41a2-8351-01ad961065bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. 강의영상 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11adab44-8584-4bfa-a4c5-f65d6dfe47c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# {{<video https://youtu.be/playlist?list=PLQqh36zP38-zEjn2m8H8hMCHsQK8udE27&si=Sy-lnw4Kq56SRggu >}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a67f063-a6a4-4296-9680-2d876243c8ad",
   "metadata": {},
   "source": [
    "# 2. Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24822064-5bff-4f2f-99f3-6a9c492061f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a799d45e-eb75-4701-ab34-82760c915cf0",
   "metadata": {},
   "source": [
    "# 3. 강화학습 Intro "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e479024e-9c7a-466a-bcc2-1ec46c76726e",
   "metadata": {},
   "source": [
    "`-` 강화학습(대충설명): 어떠한 \"(게임)환경\"이 있을때 거기서 \"뭘 할지\"를 학습하는 과업"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5477824c-e424-463b-a066-a661b4fe99c8",
   "metadata": {},
   "source": [
    "![그림1: 셔튼(@sutton1998reinforcement)의 교재에서 발췌한 그림, 되게 유명한 그림이에요](https://github.com/guebin/DL2025/blob/main/posts/13wk-1-fig1.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30713925-6e51-4f58-b1a4-6013b5895b6d",
   "metadata": {},
   "source": [
    "`-` 딥마인드: breakout $\\to$ 알파고 \n",
    "\n",
    "- <https://www.youtube.com/watch?v=TmPfTpjtdgg>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab05457e-9665-4f75-a313-0c1b0d2015df",
   "metadata": {},
   "source": [
    "![그림2: 벽돌깨기](https://github.com/guebin/DL2025/blob/main/posts/13wk-1-fig2.png?raw=true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "840d4f25-fcc2-4896-9f1b-67cf305ec8bd",
   "metadata": {},
   "source": [
    "`-` 강화학습에서 \"강화\"는 뭘 강화한다는것일까? \n",
    "\n",
    "- <https://k9connoisseur.com/blogs/news/positive-reinforcement-dog-training> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53923369-d64d-4ec0-a768-3fd2c6597819",
   "metadata": {},
   "source": [
    "`-` 강화학습 미래? (이거 잘하면 먹고 살 수 있을까?) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578300c7-92f8-408b-baab-64a1c7b95670",
   "metadata": {},
   "source": [
    "# 4. Bandit 게임 설명 및 원시코드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7cd2d0-7561-4ab7-8e89-df6bb928564b",
   "metadata": {},
   "source": [
    "`-` 문제설명: 두 개의 버튼이 있다. `버튼0`을 누르면 1의 보상을, `버튼1`을 누르면 10의 보상을 준다고 가정 \n",
    "\n",
    "- Agent: 버튼0을 누르거나,버튼1을 누르는 존재 \n",
    "- Env: Agent의 Action을 바탕으로 Reward를 주는 존재\n",
    "\n",
    "> 주의: 이 문제 상황에서 state는 없음 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8653d111-85df-4b0b-8f9d-5c2d62fb2b50",
   "metadata": {},
   "source": [
    "`-` 생성형AI로 위의 상황을 설명한것 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2faf6f7-03ef-47cf-81de-32a86f7765af",
   "metadata": {},
   "source": [
    "::: {.layout-ncol=3}\n",
    "![그림3(a) 챗지피티로 생성한그림](13wk-1-fig3-gpt.png) \n",
    "![그림3(b) 제미나이로 생성한 그림](13wk-1-fig3-gemini.png)\n",
    "![그림3(c)  퍼플렉시티로 생성한 그림](13wk-1-fig3-perplexity.png)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e0830f-ebad-4d24-8c0a-44c37ad7e6fc",
   "metadata": {},
   "source": [
    "https://claude.ai/public/artifacts/1f52fcb2-ef08-4af1-8cf8-4a497d7bcc5f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b72277-802e-4f80-bad0-8961cc2f6301",
   "metadata": {},
   "source": [
    "`-` 처음에 어떤 행동을 해야 하는가?\n",
    "\n",
    "- 처음에는 아는게 없음\n",
    "- 일단 \"아무거나\" 눌러보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9707fb-b2ce-4cf7-8f53-8ce45df90508",
   "metadata": {},
   "source": [
    "`-` 버튼을 아무거나 누르는 코드를 작성해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b99fadba-0ac5-41fa-8d96-cf2cf176f94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'버튼1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_space = ['버튼0','버튼1']\n",
    "action = np.random.choice(action_space,p=[0.5,0.5])\n",
    "action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee68dea-5c18-4e66-8280-b311c1add329",
   "metadata": {},
   "source": [
    "`-` 버튼을 누른 행위에 따른 보상을 구현하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc135a81-4b30-41c6-be95-ee8426c3ba1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward = 1 if action == \"버튼0\" else 10 \n",
    "reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba0475b-1dba-4c6c-8e00-f61e7a4daace",
   "metadata": {},
   "source": [
    "`-` 아무버튼이나 10번정도 눌러보면서 데이터를 쌓아보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16a64047-a67e-40e7-90d8-06c8d7728a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "버튼1 10\n",
      "버튼1 10\n",
      "버튼1 10\n",
      "버튼1 10\n",
      "버튼0 1\n",
      "버튼1 10\n",
      "버튼0 1\n",
      "버튼0 1\n",
      "버튼1 10\n",
      "버튼0 1\n"
     ]
    }
   ],
   "source": [
    "action_space = ['버튼0','버튼1']\n",
    "for _ in range(10):\n",
    "    action = np.random.choice(action_space)\n",
    "    reward = 1 if action == \"버튼0\" else 10\n",
    "    print(action,reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8779cfa0-124c-4b2a-bd2e-b1cc08650647",
   "metadata": {},
   "source": [
    "`-` 깨달았음: `버튼0`을 누르면 1점을 받고, `버튼1`을 누르면 10점을 받는 \"환경(environment)\"이구나? $\\to$ `버튼1`을 누르는 \"동작(=action)\"을 해야하는 상황이구나? \n",
    "\n",
    "- 여기에서 $\\to$의 과정을 체계화 시킨 학문이 강화학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "869388fb-5f2b-49d2-be75-3b57ae230ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "버튼1 10\n",
      "버튼1 10\n",
      "버튼1 10\n",
      "버튼1 10\n",
      "버튼1 10\n",
      "버튼1 10\n",
      "버튼1 10\n",
      "버튼1 10\n",
      "버튼1 10\n",
      "버튼1 10\n"
     ]
    }
   ],
   "source": [
    "action_space = ['버튼0','버튼1']\n",
    "for _ in range(10):\n",
    "    action = '버튼1'\n",
    "    reward = 1 if action == \"버튼0\" else 10\n",
    "    print(action,reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f62d30-b90b-4270-8328-57f5a5c2126c",
   "metadata": {},
   "source": [
    "`-` 강화학습: 환경(environment)을 이해 $\\to$ 에이전트(agent)가 행동(action)을 결정 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca73f6b-7d4e-4b7f-a21b-73a084a46df3",
   "metadata": {
    "tags": []
   },
   "source": [
    "> `agent`라는 용어를 기억할 것 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871ada95-ccec-43bd-9e42-29b5aee92c4c",
   "metadata": {},
   "source": [
    "***위의 과정이 잘 되었다는 의미로 사용하는 문장들*** \n",
    "\n",
    "- 강화학습이 성공적으로 잘 되었다. \n",
    "- 에이전트가 환경의 과제를 완료했다. \n",
    "- 에이전트가 환경에서 성공적으로 학습했다. \n",
    "- 에이전트가 올바른 행동을 학습했다. \n",
    "- 게임 클리어 (비공식) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2634400c-880b-4e36-893e-df2e385325b0",
   "metadata": {},
   "source": [
    "`-` 게임이 클리어 되었다는 것을 의미하는 지표를 정하고 싶다. \n",
    "\n",
    "- 단순한 생각: `버튼1`을 누르는 순간 게임클리어로 보면 되지 않나?\n",
    "- 게임클리어조건: (1) 20번은 그냥 진행 (2) 최근 20번의 보상의 평균이 9.5점 이상이면 게임이 클리어 되었다고 생각하자.^[`버튼1`을 눌러야 하는건 맞지만 몇번의 실수는 눈감아 주자는 의미]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411c38ae-be38-4e2e-9b96-5abc22bc23bc",
   "metadata": {},
   "source": [
    "`-` 원시코드1: 환경을 이해하지 못한 에이전트 -- 게임을 클리어할 수 없다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcb6ea7f-f4c2-4930-9930-23cc5bc82faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시도:1\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:2\t행동:0\t보상:1\t최근20번보상평균:5.5000\t\n",
      "시도:3\t행동:0\t보상:1\t최근20번보상평균:4.0000\t\n",
      "시도:4\t행동:0\t보상:1\t최근20번보상평균:3.2500\t\n",
      "시도:5\t행동:0\t보상:1\t최근20번보상평균:2.8000\t\n",
      "시도:6\t행동:0\t보상:1\t최근20번보상평균:2.5000\t\n",
      "시도:7\t행동:1\t보상:10\t최근20번보상평균:3.5714\t\n",
      "시도:8\t행동:1\t보상:10\t최근20번보상평균:4.3750\t\n",
      "시도:9\t행동:0\t보상:1\t최근20번보상평균:4.0000\t\n",
      "시도:10\t행동:1\t보상:10\t최근20번보상평균:4.6000\t\n",
      "시도:11\t행동:1\t보상:10\t최근20번보상평균:5.0909\t\n",
      "시도:12\t행동:1\t보상:10\t최근20번보상평균:5.5000\t\n",
      "시도:13\t행동:1\t보상:10\t최근20번보상평균:5.8462\t\n",
      "시도:14\t행동:1\t보상:10\t최근20번보상평균:6.1429\t\n",
      "시도:15\t행동:1\t보상:10\t최근20번보상평균:6.4000\t\n",
      "시도:16\t행동:1\t보상:10\t최근20번보상평균:6.6250\t\n",
      "시도:17\t행동:0\t보상:1\t최근20번보상평균:6.2941\t\n",
      "시도:18\t행동:1\t보상:10\t최근20번보상평균:6.5000\t\n",
      "시도:19\t행동:0\t보상:1\t최근20번보상평균:6.2105\t\n",
      "시도:20\t행동:0\t보상:1\t최근20번보상평균:5.9500\t\n",
      "--\n",
      "시도:21\t행동:0\t보상:1\t최근20번보상평균:5.5000\t\n",
      "시도:22\t행동:0\t보상:1\t최근20번보상평균:5.5000\t\n",
      "시도:23\t행동:1\t보상:10\t최근20번보상평균:5.9500\t\n",
      "시도:24\t행동:1\t보상:10\t최근20번보상평균:6.4000\t\n",
      "시도:25\t행동:0\t보상:1\t최근20번보상평균:6.4000\t\n",
      "시도:26\t행동:0\t보상:1\t최근20번보상평균:6.4000\t\n",
      "시도:27\t행동:0\t보상:1\t최근20번보상평균:5.9500\t\n",
      "시도:28\t행동:1\t보상:10\t최근20번보상평균:5.9500\t\n",
      "시도:29\t행동:0\t보상:1\t최근20번보상평균:5.9500\t\n",
      "시도:30\t행동:0\t보상:1\t최근20번보상평균:5.5000\t\n",
      "시도:31\t행동:1\t보상:10\t최근20번보상평균:5.5000\t\n",
      "시도:32\t행동:1\t보상:10\t최근20번보상평균:5.5000\t\n",
      "시도:33\t행동:0\t보상:1\t최근20번보상평균:5.0500\t\n",
      "시도:34\t행동:1\t보상:10\t최근20번보상평균:5.0500\t\n",
      "시도:35\t행동:0\t보상:1\t최근20번보상평균:4.6000\t\n",
      "시도:36\t행동:1\t보상:10\t최근20번보상평균:4.6000\t\n",
      "시도:37\t행동:0\t보상:1\t최근20번보상평균:4.6000\t\n",
      "시도:38\t행동:0\t보상:1\t최근20번보상평균:4.1500\t\n",
      "시도:39\t행동:1\t보상:10\t최근20번보상평균:4.6000\t\n",
      "시도:40\t행동:1\t보상:10\t최근20번보상평균:5.0500\t\n",
      "시도:41\t행동:1\t보상:10\t최근20번보상평균:5.5000\t\n",
      "시도:42\t행동:0\t보상:1\t최근20번보상평균:5.5000\t\n",
      "시도:43\t행동:1\t보상:10\t최근20번보상평균:5.5000\t\n",
      "시도:44\t행동:0\t보상:1\t최근20번보상평균:5.0500\t\n",
      "시도:45\t행동:0\t보상:1\t최근20번보상평균:5.0500\t\n",
      "시도:46\t행동:0\t보상:1\t최근20번보상평균:5.0500\t\n",
      "시도:47\t행동:1\t보상:10\t최근20번보상평균:5.5000\t\n",
      "시도:48\t행동:0\t보상:1\t최근20번보상평균:5.0500\t\n",
      "시도:49\t행동:0\t보상:1\t최근20번보상평균:5.0500\t\n",
      "시도:50\t행동:0\t보상:1\t최근20번보상평균:5.0500\t\n"
     ]
    }
   ],
   "source": [
    "action_space = [0,1]\n",
    "actions = []\n",
    "rewards = []\n",
    "for t in range(1,51):\n",
    "    action = np.random.choice(action_space)\n",
    "    reward = 1 if action == 0 else 10\n",
    "    actions.append(action)\n",
    "    rewards.append(reward)\n",
    "    #--#\n",
    "    print(\n",
    "        f\"시도:{t}\\t\"\n",
    "        f\"행동:{action}\\t\"\n",
    "        f\"보상:{reward}\\t\"\n",
    "        f\"최근20번보상평균:{np.mean(rewards[-20:]):.4f}\\t\"\n",
    "    )\n",
    "    if t<20:\n",
    "        pass \n",
    "    elif t==20:\n",
    "        print(\"--\")\n",
    "    else: \n",
    "        if np.mean(rewards[-20:]) > 9.5:\n",
    "            print(\"Game Clear\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b619eab5-a2c8-4fcd-b371-536a36e9f5fe",
   "metadata": {},
   "source": [
    "`-` 원시코드2: 환경을 깨달은 에이전트 -- 게임클리어 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37445159-472e-4b10-9cf9-0bd88e7267a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시도:1\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:2\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:3\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:4\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:5\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:6\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:7\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:8\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:9\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:10\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:11\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:12\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:13\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:14\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:15\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:16\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:17\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:18\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:19\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:20\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "--\n",
      "시도:21\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "Game Clear\n"
     ]
    }
   ],
   "source": [
    "action_space = [0,1]\n",
    "actions = []\n",
    "rewards = []\n",
    "for t in range(1,51):\n",
    "    action = 1\n",
    "    reward = 1 if action == 0 else 10\n",
    "    actions.append(action)\n",
    "    rewards.append(reward)\n",
    "    #--#\n",
    "    print(\n",
    "        f\"시도:{t}\\t\"\n",
    "        f\"행동:{action}\\t\"\n",
    "        f\"보상:{reward}\\t\"\n",
    "        f\"최근20번보상평균:{np.mean(rewards[-20:]):.4f}\\t\"\n",
    "    )\n",
    "    if t<20:\n",
    "        pass \n",
    "    elif t==20:\n",
    "        print(\"--\")\n",
    "    else: \n",
    "        if np.mean(rewards[-20:]) > 9.5:\n",
    "            print(\"Game Clear\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145bea96-4131-4c2f-8b90-48876df8b291",
   "metadata": {},
   "source": [
    "# 5.  `Env` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c3018-4b7c-4fba-8e9c-e5574a5bc746",
   "metadata": {},
   "source": [
    "`-` `Bandit` 클래스 선언 + `.step()` 구현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b793e30-e99f-4baf-9ba8-98e73e0af173",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bandit:\n",
    "    def step(self,agent_action):\n",
    "        reward = 1 if agent_action == 0 else 10\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9d8956f-57f5-4c25-b5a1-57c7ab6920c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시도:1\t행동:0\t보상:1\t최근20번보상평균:1.0000\t\n",
      "시도:2\t행동:0\t보상:1\t최근20번보상평균:1.0000\t\n",
      "시도:3\t행동:0\t보상:1\t최근20번보상평균:1.0000\t\n",
      "시도:4\t행동:0\t보상:1\t최근20번보상평균:1.0000\t\n",
      "시도:5\t행동:1\t보상:10\t최근20번보상평균:2.8000\t\n",
      "시도:6\t행동:1\t보상:10\t최근20번보상평균:4.0000\t\n",
      "시도:7\t행동:1\t보상:10\t최근20번보상평균:4.8571\t\n",
      "시도:8\t행동:1\t보상:10\t최근20번보상평균:5.5000\t\n",
      "시도:9\t행동:0\t보상:1\t최근20번보상평균:5.0000\t\n",
      "시도:10\t행동:1\t보상:10\t최근20번보상평균:5.5000\t\n",
      "시도:11\t행동:1\t보상:10\t최근20번보상평균:5.9091\t\n",
      "시도:12\t행동:0\t보상:1\t최근20번보상평균:5.5000\t\n",
      "시도:13\t행동:1\t보상:10\t최근20번보상평균:5.8462\t\n",
      "시도:14\t행동:1\t보상:10\t최근20번보상평균:6.1429\t\n",
      "시도:15\t행동:1\t보상:10\t최근20번보상평균:6.4000\t\n",
      "시도:16\t행동:0\t보상:1\t최근20번보상평균:6.0625\t\n",
      "시도:17\t행동:1\t보상:10\t최근20번보상평균:6.2941\t\n",
      "시도:18\t행동:1\t보상:10\t최근20번보상평균:6.5000\t\n",
      "시도:19\t행동:0\t보상:1\t최근20번보상평균:6.2105\t\n",
      "시도:20\t행동:0\t보상:1\t최근20번보상평균:5.9500\t\n",
      "--\n",
      "시도:21\t행동:0\t보상:1\t최근20번보상평균:5.9500\t\n",
      "시도:22\t행동:1\t보상:10\t최근20번보상평균:6.4000\t\n",
      "시도:23\t행동:0\t보상:1\t최근20번보상평균:6.4000\t\n",
      "시도:24\t행동:1\t보상:10\t최근20번보상평균:6.8500\t\n",
      "시도:25\t행동:1\t보상:10\t최근20번보상평균:6.8500\t\n",
      "시도:26\t행동:1\t보상:10\t최근20번보상평균:6.8500\t\n",
      "시도:27\t행동:0\t보상:1\t최근20번보상평균:6.4000\t\n",
      "시도:28\t행동:1\t보상:10\t최근20번보상평균:6.4000\t\n",
      "시도:29\t행동:0\t보상:1\t최근20번보상평균:6.4000\t\n",
      "시도:30\t행동:0\t보상:1\t최근20번보상평균:5.9500\t\n",
      "시도:31\t행동:0\t보상:1\t최근20번보상평균:5.5000\t\n",
      "시도:32\t행동:1\t보상:10\t최근20번보상평균:5.9500\t\n",
      "시도:33\t행동:1\t보상:10\t최근20번보상평균:5.9500\t\n",
      "시도:34\t행동:0\t보상:1\t최근20번보상평균:5.5000\t\n",
      "시도:35\t행동:1\t보상:10\t최근20번보상평균:5.5000\t\n",
      "시도:36\t행동:1\t보상:10\t최근20번보상평균:5.9500\t\n",
      "시도:37\t행동:0\t보상:1\t최근20번보상평균:5.5000\t\n",
      "시도:38\t행동:1\t보상:10\t최근20번보상평균:5.5000\t\n",
      "시도:39\t행동:1\t보상:10\t최근20번보상평균:5.9500\t\n",
      "시도:40\t행동:0\t보상:1\t최근20번보상평균:5.9500\t\n",
      "시도:41\t행동:1\t보상:10\t최근20번보상평균:6.4000\t\n",
      "시도:42\t행동:1\t보상:10\t최근20번보상평균:6.4000\t\n",
      "시도:43\t행동:0\t보상:1\t최근20번보상평균:6.4000\t\n",
      "시도:44\t행동:1\t보상:10\t최근20번보상평균:6.4000\t\n",
      "시도:45\t행동:1\t보상:10\t최근20번보상평균:6.4000\t\n",
      "시도:46\t행동:1\t보상:10\t최근20번보상평균:6.4000\t\n",
      "시도:47\t행동:1\t보상:10\t최근20번보상평균:6.8500\t\n",
      "시도:48\t행동:1\t보상:10\t최근20번보상평균:6.8500\t\n",
      "시도:49\t행동:1\t보상:10\t최근20번보상평균:7.3000\t\n",
      "시도:50\t행동:1\t보상:10\t최근20번보상평균:7.7500\t\n"
     ]
    }
   ],
   "source": [
    "env = Bandit()\n",
    "action_space = [0,1]\n",
    "actions = []\n",
    "rewards = []\n",
    "for t in range(1,51):\n",
    "    action = np.random.choice(action_space)\n",
    "    reward = env.step(action)\n",
    "    actions.append(action)\n",
    "    rewards.append(reward)\n",
    "    #--#\n",
    "    print(\n",
    "        f\"시도:{t}\\t\"\n",
    "        f\"행동:{action}\\t\"\n",
    "        f\"보상:{reward}\\t\"\n",
    "        f\"최근20번보상평균:{np.mean(rewards[-20:]):.4f}\\t\"\n",
    "    )\n",
    "    if t<20:\n",
    "        pass \n",
    "    elif t==20:\n",
    "        print(\"--\")\n",
    "    else: \n",
    "        if np.mean(rewards[-20:]) > 9.5:\n",
    "            print(\"Game Clear\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aefb2ff-5262-4df3-bacf-a6ae2fe246a4",
   "metadata": {},
   "source": [
    "# 6. `Agent`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b720b8f-6d87-420b-977e-67494b219d19",
   "metadata": {},
   "source": [
    "## A. action을 인간이정함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0153317c-5675-4b75-8dd5-20318bc2684c",
   "metadata": {},
   "source": [
    "`-` Agent 클래스 설계\n",
    "\n",
    "- 액션을 하고, 본인의 행동과 환경에서 받은 reward를 기억 \n",
    "- `.act()`함수와 `.save_experience()`함수 구현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7afc5a50-c15c-47fb-a9d0-717c98a66620",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.action_space = [0,1]\n",
    "        self.action = None \n",
    "        self.reward = None\n",
    "        self.actions = []\n",
    "        self.rewards = [] \n",
    "    def act(self):\n",
    "        prob = [0.5, 0.5]\n",
    "        self.action = 1 #np.random.choice(self.action_space,p=prob)\n",
    "    def save_experience(self):\n",
    "        self.actions.append(self.action)\n",
    "        self.rewards.append(self.reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e950fef-37f6-4903-acd5-07c7e7e57291",
   "metadata": {},
   "source": [
    "--- 대충 아래와 같은 느낌으로 코드가 돌아가요 ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0416ebaa-3d6f-4479-9da5-28afa6ce3c6d",
   "metadata": {},
   "source": [
    "**시점0**: init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f4cb7c4-6cfb-495f-ae4d-a827d7d7dc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent()\n",
    "env = Bandit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f275263-e72b-4df0-a116-202362ded3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, [], [])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action, agent.reward, agent.actions, agent.rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490bdcc8-1c84-4047-ab33-f1e57cf8f0ac",
   "metadata": {},
   "source": [
    "**시점1**: agent 가 acition을 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e72a91df-5039-49e8-a5b8-8e7cbb5c3ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.act()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb869109-81c5-4632-b313-87e1da62913f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, None, [], [])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action, agent.reward, agent.actions, agent.rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6899a720-f624-47b0-bed6-7e148a40a2ac",
   "metadata": {},
   "source": [
    "**시점2**: env가 agent에게 보상을 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f05d67e-4081-4429-aad4-3fa087891b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.reward = env.step(agent.action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d2df5e6-42dd-4535-935b-31a4f95000da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, [], [])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action, agent.reward, agent.actions, agent.rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b24e00-32a2-4d12-807e-3449b65dcc4a",
   "metadata": {},
   "source": [
    "**시점3**: 경험을 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f14a60a3-9e8f-4386-b753-ab6258399c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save_experience()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10cb693a-b83f-4278-840f-1e724053348f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, [1], [10])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action, agent.reward, agent.actions, agent.rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b251b5f-b2c9-486f-b4a6-50bf8f82659d",
   "metadata": {},
   "source": [
    "-- 전체코드 -- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e811bfa0-8af0-43a1-a068-99a8195e94a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시도:1\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:2\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:3\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:4\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:5\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:6\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:7\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:8\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:9\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:10\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:11\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:12\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:13\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:14\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:15\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:16\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:17\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:18\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:19\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "시도:20\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "--\n",
      "시도:21\t행동:1\t보상:10\t최근20번보상평균:10.0000\t\n",
      "Game Clear\n"
     ]
    }
   ],
   "source": [
    "env = Bandit()\n",
    "agent = Agent()\n",
    "for t in range(1,51):\n",
    "    agent.act()\n",
    "    agent.reward = env.step(agent.action)\n",
    "    agent.save_experience()\n",
    "    #--#\n",
    "    print(\n",
    "        f\"시도:{t}\\t\"\n",
    "        f\"행동:{agent.action}\\t\"\n",
    "        f\"보상:{agent.reward}\\t\"\n",
    "        f\"최근20번보상평균:{np.mean(agent.rewards[-20:]):.4f}\\t\"\n",
    "    )\n",
    "    if t<20:\n",
    "        pass \n",
    "    elif t==20:\n",
    "        print(\"--\")\n",
    "    else: \n",
    "        if np.mean(agent.rewards[-20:]) > 9.5:\n",
    "            print(\"Game Clear\")\n",
    "            break    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0649d4c-959a-4310-8fb7-3ce78fcf8270",
   "metadata": {},
   "source": [
    "## B.  `q_table` $\\to$ action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9018af5a-2d51-4916-81d1-2d64c8ba716a",
   "metadata": {},
   "source": [
    "`-` 지금까지 풀이의 한계\n",
    "\n",
    "- 사실 강화학습은 \"환경을 이해 $\\to$ 행동을 결정\" 의 과정에서 \"$\\to$\"의 과정을 수식화 한 것이다.\n",
    "- 그런데 지금까지 했던 코드는 환경(environment)를 이해하는 순간 에이전트(agent)가 최적의 행동(action)^[`버튼1`을 누른다]을 **\"직관적으로\"** 결정하였으므로 기계가 스스로 학습을 했다고 볼 수 없다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8fcc05-a5e6-4a16-a196-0bd715fe20b0",
   "metadata": {},
   "source": [
    "`-` 에이전트가 데이터를 보고 스스로 학습할 수 있도록 설계 -- 부제: `agent.learn()`을 설계하자. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f58afe5-82bd-4718-ab1f-557fe71cba6f",
   "metadata": {},
   "source": [
    "1. 데이터를 모아서 `q_table` 를 만든다. `q_table`은 아래와 같은 내용을 포함한다. \n",
    "\n",
    "|행동|보상(추정값)|\n",
    "|:--:|:--:|\n",
    "|버튼0 ($=a_0$)|1 ($=q_0$)|\n",
    "|버튼1 ($=a_1$)|10 ($=q_1$)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86eaa536-9087-45b5-9885-82f81980b860",
   "metadata": {},
   "source": [
    "2. `q_table`을 바탕으로 적절한 정책(=`policy`)을 설정한다. \n",
    "\n",
    "- $q_1>q_0$ 이므로 그냥 버튼1을 누르면 될듯 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aaf2a9-5f8b-4a0d-ac1d-89d1a61e78c6",
   "metadata": {},
   "source": [
    "> 여기에서 `q_table`, `policy`라는 용어를 기억하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10e6227-274e-4aea-8fc1-5397311bafa8",
   "metadata": {},
   "source": [
    "`-` `q_table`을 계산하는 코드 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9cf34aa8-f3ff-4237-bb5c-a98854b37e77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.actions = [0, 1, 1,  0, 1,   0, 0] \n",
    "agent.rewards = [1, 9, 10, 1, 9.5, 1, 1.2] \n",
    "actions = np.array(agent.actions)\n",
    "rewards = np.array(agent.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "977688a4-5992-4ca6-8703-308ff81c7e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "q0,q1 = rewards[actions==0].mean(), rewards[actions==1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "76c92a0b-d55f-4133-a057-5911b4f87888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.05, 9.5 ])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table = np.array([q0,q1])\n",
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3403eb3a-87e0-42f3-99a7-9d1677317c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da576b5e-3086-426a-9f71-ea2b78893842",
   "metadata": {},
   "source": [
    "`-` 최종코드정리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b4fcb863-994d-4a94-abd4-dcd96c82d703",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.action_space = [0,1]\n",
    "        self.action = None \n",
    "        self.reward = None\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.q_table = np.array([0,0])\n",
    "        self.n_experiences = 0 \n",
    "    def act(self):\n",
    "        if self.n_experiences <= 20:\n",
    "            self.action = np.random.choice(self.action_space)\n",
    "        else: \n",
    "            self.action = self.q_table.argmax()\n",
    "    def save_experience(self):\n",
    "        self.actions.append(self.action)\n",
    "        self.rewards.append(self.reward)\n",
    "        self.n_experiences = self.n_experiences + 1 \n",
    "    def learn(self):\n",
    "        if self.n_experiences < 20:\n",
    "            pass \n",
    "        else: \n",
    "            actions = np.array(self.actions)\n",
    "            rewards = np.array(self.rewards)      \n",
    "            q0,q1 = rewards[actions==0].mean(), rewards[actions==1].mean()\n",
    "            self.q_table = np.array([q0,q1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1ff8e30b-c94e-4f1f-b35a-0b6e718643b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시도:1\t행동:0\t보상:1\t최근20번보상평균:1.0000\t\n",
      "시도:2\t행동:0\t보상:1\t최근20번보상평균:1.0000\t\n",
      "시도:3\t행동:0\t보상:1\t최근20번보상평균:1.0000\t\n",
      "시도:4\t행동:1\t보상:10\t최근20번보상평균:3.2500\t\n",
      "시도:5\t행동:1\t보상:10\t최근20번보상평균:4.6000\t\n",
      "시도:6\t행동:0\t보상:1\t최근20번보상평균:4.0000\t\n",
      "시도:7\t행동:0\t보상:1\t최근20번보상평균:3.5714\t\n",
      "시도:8\t행동:0\t보상:1\t최근20번보상평균:3.2500\t\n",
      "시도:9\t행동:1\t보상:10\t최근20번보상평균:4.0000\t\n",
      "시도:10\t행동:0\t보상:1\t최근20번보상평균:3.7000\t\n",
      "시도:11\t행동:0\t보상:1\t최근20번보상평균:3.4545\t\n",
      "시도:12\t행동:0\t보상:1\t최근20번보상평균:3.2500\t\n",
      "시도:13\t행동:0\t보상:1\t최근20번보상평균:3.0769\t\n",
      "시도:14\t행동:1\t보상:10\t최근20번보상평균:3.5714\t\n",
      "시도:15\t행동:1\t보상:10\t최근20번보상평균:4.0000\t\n",
      "시도:16\t행동:0\t보상:1\t최근20번보상평균:3.8125\t\n",
      "시도:17\t행동:0\t보상:1\t최근20번보상평균:3.6471\t\n",
      "시도:18\t행동:0\t보상:1\t최근20번보상평균:3.5000\t\n",
      "시도:19\t행동:1\t보상:10\t최근20번보상평균:3.8421\t\n",
      "시도:20\t행동:0\t보상:1\t최근20번보상평균:3.7000\t\n",
      "--\n",
      "시도:21\t행동:1\t보상:10\t최근20번보상평균:4.1500\t\n",
      "시도:22\t행동:1\t보상:10\t최근20번보상평균:4.6000\t\n",
      "시도:23\t행동:1\t보상:10\t최근20번보상평균:5.0500\t\n",
      "시도:24\t행동:1\t보상:10\t최근20번보상평균:5.0500\t\n",
      "시도:25\t행동:1\t보상:10\t최근20번보상평균:5.0500\t\n",
      "시도:26\t행동:1\t보상:10\t최근20번보상평균:5.5000\t\n",
      "시도:27\t행동:1\t보상:10\t최근20번보상평균:5.9500\t\n",
      "시도:28\t행동:1\t보상:10\t최근20번보상평균:6.4000\t\n",
      "시도:29\t행동:1\t보상:10\t최근20번보상평균:6.4000\t\n",
      "시도:30\t행동:1\t보상:10\t최근20번보상평균:6.8500\t\n",
      "시도:31\t행동:1\t보상:10\t최근20번보상평균:7.3000\t\n",
      "시도:32\t행동:1\t보상:10\t최근20번보상평균:7.7500\t\n",
      "시도:33\t행동:1\t보상:10\t최근20번보상평균:8.2000\t\n",
      "시도:34\t행동:1\t보상:10\t최근20번보상평균:8.2000\t\n",
      "시도:35\t행동:1\t보상:10\t최근20번보상평균:8.2000\t\n",
      "시도:36\t행동:1\t보상:10\t최근20번보상평균:8.6500\t\n",
      "시도:37\t행동:1\t보상:10\t최근20번보상평균:9.1000\t\n",
      "시도:38\t행동:1\t보상:10\t최근20번보상평균:9.5500\t\n",
      "Game Clear\n"
     ]
    }
   ],
   "source": [
    "env = Bandit()\n",
    "agent = Agent()\n",
    "for t in range(1,51):\n",
    "    # step1: 행동\n",
    "    agent.act()\n",
    "    # step2: 보상\n",
    "    agent.reward = env.step(agent.action)\n",
    "    # step3: 저장 & 학습\n",
    "    agent.save_experience()\n",
    "    agent.learn()    \n",
    "    #--#\n",
    "    print(\n",
    "        f\"시도:{t}\\t\"\n",
    "        f\"행동:{agent.action}\\t\"\n",
    "        f\"보상:{agent.reward}\\t\"\n",
    "        f\"최근20번보상평균:{np.mean(agent.rewards[-20:]):.4f}\\t\"\n",
    "    )\n",
    "    if t<20:\n",
    "        pass \n",
    "    elif t==20:\n",
    "        print(\"--\")\n",
    "    else: \n",
    "        if np.mean(agent.rewards[-20:]) > 9.5:\n",
    "            print(\"Game Clear\")\n",
    "            break    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
