{
 "cells": [
  {
   "cell_type": "raw",
   "id": "20ee4531-eaa2-4d6d-acb8-4cd9edf06ac9",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"13wk-1: 강화학습 (1) -- Bandit\"\n",
    "author: \"최규빈\"\n",
    "date: \"05/28/2024\"\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21686a35-0ef2-4663-971c-f02b8ad79474",
   "metadata": {
    "id": "e67ab8e0"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/guebin/DL2025/blob/main/posts/13wk-1.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3237b5b0-69a8-44e3-b444-58261c5ba538",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. 강의영상 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7c171ef0-8493-471d-aa90-e4861180057c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# {{<video https://youtu.be/playlist?list=PLQqh36zP38-zEjn2m8H8hMCHsQK8udE27&si=Sy-lnw4Kq56SRggu >}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a085d66-8267-451a-8bf3-a3aca3e5c976",
   "metadata": {},
   "source": [
    "# 2. Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "52b823e1-9736-49c1-a19b-5257423b91e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858fcdc0-7ada-4785-ab9d-65bdd9edda48",
   "metadata": {},
   "source": [
    "# 3. 강화학습 Intro "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ca10ce-0bff-41ba-b0e1-1623d05e2f7b",
   "metadata": {},
   "source": [
    "`-` 강화학습(대충설명): 어떠한 \"(게임)환경\"이 있을때 거기서 \"뭘 할지\"를 학습하는 과업"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9f18c5f-53b6-4cff-a38c-851ba686c095",
   "metadata": {},
   "source": [
    "![그림1: 셔튼(@sutton1998reinforcement)의 교재에서 발췌한 그림, 되게 유명한 그림이에요](https://github.com/guebin/DL2025/blob/main/posts/13wk-1-fig1.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c79f64f-0a04-468f-8662-61b59ffcc623",
   "metadata": {},
   "source": [
    "`-` 딥마인드: breakout $\\to$ 알파고 \n",
    "\n",
    "- <https://www.youtube.com/watch?v=TmPfTpjtdgg>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c726bb5a-2497-4e1a-85c2-27d177176392",
   "metadata": {},
   "source": [
    "![그림2: 벽돌깨기](https://github.com/guebin/DL2025/blob/main/posts/13wk-1-fig2.png?raw=true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7f81fc4-4682-4088-b641-a7d2c6c0eff6",
   "metadata": {},
   "source": [
    "`-` 강화학습에서 \"강화\"는 뭘 강화한다는것일까? \n",
    "\n",
    "- <https://k9connoisseur.com/blogs/news/positive-reinforcement-dog-training> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3554431a-7c67-4669-b0de-583814a7f2e6",
   "metadata": {},
   "source": [
    "`-` 강화학습 미래? (이거 잘하면 먹고 살 수 있을까?) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5faefc2-5f76-47a2-8c6d-b731341b1e6a",
   "metadata": {},
   "source": [
    "# 4. Bandit 게임 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e7c2d4-0e6b-466d-b6df-ce7e25f42f6c",
   "metadata": {},
   "source": [
    "`-` 문제설명: 두 개의 버튼이 있다. `버튼0`을 누르면 1의 보상을, `버튼1`을 누르면 10의 보상을 준다고 가정 \n",
    "\n",
    "- Agent: 버튼0을 누르거나,버튼1을 누르는 존재 \n",
    "- Env: Agent의 Action을 바탕으로 Reward를 주는 존재\n",
    "\n",
    "> 주의: 이 문제 상황에서 state는 없음 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cda09e-9d14-46fc-bb02-e1d209222bba",
   "metadata": {},
   "source": [
    "`-` 생성형AI로 위의 상황을 설명한것 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835b33e9-db69-4600-ab3f-b93292cc1a24",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between; gap: 10px;\">\n",
    "  <div style=\"flex: 1; text-align: center;\">\n",
    "    <img src=\"https://github.com/guebin/DL2025/blob/main/posts/13wk-1-fig3-gpt.png?raw=true\" style=\"width: 100%;\">\n",
    "    <p>(a) 챗지피티로 생성한 그림</p>\n",
    "  </div>\n",
    "  <div style=\"flex: 1; text-align: center;\">\n",
    "    <img src=\"https://github.com/guebin/DL2025/blob/main/posts/13wk-1-fig3-gemini.png?raw=true\" style=\"width: 100%;\">\n",
    "    <p>(b) 제미나이로 생성한 그림</p>\n",
    "  </div>\n",
    "  <div style=\"flex: 1; text-align: center;\">\n",
    "    <img src=\"https://github.com/guebin/DL2025/blob/main/posts/13wk-1-fig3-perplexity.png?raw=true\" style=\"width: 100%;\">\n",
    "    <p>(c) 퍼플렉시티로 생성한 그림</p>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3187e124-a50f-4b8c-bba9-741ced1c8c69",
   "metadata": {},
   "source": [
    "- 클로드로 생성: <https://claude.ai/public/artifacts/1f52fcb2-ef08-4af1-8cf8-4a497d7bcc5f>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14261b7-b3a2-4820-97a6-40430fbf47ed",
   "metadata": {},
   "source": [
    "`-` 게임진행양상\n",
    "\n",
    "- 처음에는 아는게 없음. 일단 \"아무거나\" 눌러보자. (\"에이전트가 랜덤액션을 한다\" 고 표현함 )\n",
    "- 한 20번 정도 눌러보면서 결과를 관찰함 (\"에이전트가 경험을 축적한다\"고 표현함) \n",
    "- 버튼0을 누를때는 1점, 버튼1을 누를때는 10점을 준다는 사실을 깨달음. (\"에이전트가 환경을 이해했다\"고 표현함)\n",
    "- 버튼1을 누르는게 나한테 이득이 라는 사실을 깨달음. (\"에이전트가 최적의 정책을 학습했다\" 고 표현함)\n",
    "- 이제부터 무조건 버튼1만 누름 $\\to$ 게임 클리어 (\"강화학습 성공\"이라 표현할 수 있음)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001f7fa9-b70f-4a13-a729-c8b0d7c52c2f",
   "metadata": {},
   "source": [
    "`-` 어떻게 버튼1을 누르는게 이득이라는 사실을 아는거지? $\\to$ 아래와 같은 테이블을 만들면 된다. (`q_table`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fcf554-cca6-4bc4-bbfe-a97e30d6c618",
   "metadata": {},
   "source": [
    "|| Action0 | Action1 | \n",
    "|:-:|:-:|:-:|\n",
    "|State0 | mean(Reward \\| State0, Action0) |mean(Reward \\| State0, Action1)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed7d45a-9978-445c-836a-7ef166efd831",
   "metadata": {},
   "source": [
    "# 5. Bandit 환경 설계 및 풀이 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa80f633-de3a-4ac3-af5f-aaf68def12de",
   "metadata": {},
   "source": [
    "## A. 대충 개념만 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "0c101a0d-249d-4c58-836c-89a06dcf44cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = [0,1] \n",
    "actions_deque = collections.deque(maxlen=200)\n",
    "rewards_deque = collections.deque(maxlen=200)\n",
    "#---#\n",
    "for _ in range(10):\n",
    "    action = np.random.choice(action_space)\n",
    "    if action ==0: \n",
    "        reward = 1\n",
    "    else:\n",
    "        reward = 10\n",
    "    actions_deque.append(action)\n",
    "    rewards_deque.append(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "a75d37f3-44cb-4da6-b2ba-ae9d8481a9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([1, 0, 1, 0, 0, 1, 1, 0, 1, 1], maxlen=200)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "a6116391-36b0-480e-8569-e51f887bbefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([10, 1, 10, 1, 1, 10, 10, 1, 10, 10], maxlen=200)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards_deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "b3e60e33-3071-448e-adf8-7fbb9208edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_numpy = np.array(actions_deque)\n",
    "rewards_numpy = np.array(rewards_deque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "4d5cfcae-5a9f-42f1-a0c6-132c031e58b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., 10.])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q0 = rewards_numpy[actions_numpy==0].mean()\n",
    "q1 = rewards_numpy[actions_numpy==1].mean()\n",
    "q_table = np.array([q0,q1])\n",
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "1fe97354-3fcc-4ea4-b624-f29e5990476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---#\n",
    "for _ in range(5):\n",
    "    #action = np.random.choice(action_space)\n",
    "    action = q_table.argmax()\n",
    "    if action ==0: \n",
    "        reward = 1\n",
    "    else:\n",
    "        reward = 10\n",
    "    actions_deque.append(action)\n",
    "    rewards_deque.append(reward)\n",
    "    actions_numpy = np.array(actions_deque)\n",
    "    rewards_numpy = np.array(rewards_deque)\n",
    "    q0 = rewards_numpy[actions_numpy==0].mean()\n",
    "    q1 = rewards_numpy[actions_numpy==1].mean()\n",
    "    q_table = np.array([q0,q1])\n",
    "    q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "a07df6bc-913e-45af-8d02-174a98477194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GameClear\n"
     ]
    }
   ],
   "source": [
    "if rewards_numpy[-5:].mean() > 9:\n",
    "    print(\"GameClear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaca4a0-993a-49ff-b8ab-beb0f43c4668",
   "metadata": {},
   "source": [
    "## B. 클래스를 이용한 설계 및 풀이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "194c0fe9-f423-4716-a39c-87ccbdd5e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batdit():\n",
    "    def __init__(self):\n",
    "        self.reward = None \n",
    "    def step(self,action):\n",
    "        if action == 0:\n",
    "            self.reward = 1\n",
    "        elif action == 1:\n",
    "            self.reward = 10\n",
    "        return self.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "225dbe6e-41c0-4a9e-b92f-1e253f82c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self):\n",
    "        self.n_experiences = 0 \n",
    "        self.action_space = [0,1]\n",
    "        self.action = None \n",
    "        self.actions_deque = collections.deque(maxlen=500)\n",
    "        self.actions_numpy = np.array(self.actions_deque)\n",
    "        self.reward = None \n",
    "        self.rewards_deque = collections.deque(maxlen=500)\n",
    "        self.rewards_numpy = np.array(self.rewards_deque)\n",
    "        self.q_table = None\n",
    "    def act(self):\n",
    "        if self.n_experiences < 20:\n",
    "            self.action = np.random.choice(self.action_space)\n",
    "        else: \n",
    "            self.action = self.q_table.argmax()\n",
    "        print(f\"버튼{self.action}누름\")\n",
    "    def save_experience(self):\n",
    "        self.n_experiences = self.n_experiences + 1\n",
    "        self.actions_deque.append(self.action)\n",
    "        self.rewards_deque.append(self.reward)\n",
    "        self.actions_numpy = np.array(self.actions_deque)\n",
    "        self.rewards_numpy = np.array(self.rewards_deque)\n",
    "    def learn(self):\n",
    "        if self.n_experiences < 20:\n",
    "            pass\n",
    "        else: \n",
    "            q0 = self.rewards_numpy[self.actions_numpy == 0].mean()\n",
    "            q1 = self.rewards_numpy[self.actions_numpy == 1].mean()\n",
    "            self.q_table = np.array([q0,q1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "52a9b2d9-34b1-432d-bad1-262b95ffb99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Batdit()\n",
    "agent = Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "8fbc3e05-de44-4bde-aaee-d78b374c37f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "버튼0누름\n"
     ]
    }
   ],
   "source": [
    "agent.act()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "9278cfce-cf25-4d46-bcba-17b43a92bc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "버튼0누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼0누름\n",
      "버튼0누름\n",
      "버튼1누름\n",
      "버튼0누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼0누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼0누름\n",
      "버튼0누름\n",
      "버튼0누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "버튼1누름\n",
      "게임클리어\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    #1. 행동\n",
    "    agent.act()\n",
    "    #2. 보상\n",
    "    agent.reward = env.step(agent.action)\n",
    "    #3. 저장 & 학습 \n",
    "    agent.save_experience()\n",
    "    agent.learn()\n",
    "    #---#\n",
    "    if (agent.n_experiences > 20) and (agent.rewards_numpy[-20:].mean() >9):\n",
    "        print(\"게임클리어\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
