{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e0cf9e49-e6ba-4ac9-a207-36a7eb78d768",
   "metadata": {
    "id": "87b5cded-346b-4915-acf5-b5ec93a5207d",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"08wk-1: (합성곱신경망) -- MNIST, CIFAR10, XAI란?\"\n",
    "author: \"최규빈\"\n",
    "date: \"04/23/2025\"\n",
    "draft: false\n",
    "freeze: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e6f192-e141-433b-97b0-78a5aff9e627",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/guebin/DL2025/blob/main/posts/08wk-1.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471831e9-47b7-4d0e-986b-923806f90d84",
   "metadata": {
    "id": "4d47a7c9",
    "tags": []
   },
   "source": [
    "# 1. 강의영상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8af761c-b80e-4795-980a-e76ae3b7061a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#{{<video https://youtu.be/playlist?list=PLQqh36zP38-z7s7FppJtYXFUnJzw88qWg&si=3TuaJ7IiiIG6QT7X>}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ac0063-e34a-456e-9e05-91d9ac4e2ff7",
   "metadata": {},
   "source": [
    "# 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94cf31c0-2cee-4a18-82da-3380f21e28f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e051a46-f5b5-4bdd-b236-6f6b9c62d7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (4.5, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32b497c2-3d41-4aa1-99c2-d3e7e4d972bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN \n",
    "# net = 2d --> 1d\n",
    "# 1d: (linr -> relu)\n",
    "# 2d: (conv -> relu -> mp) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb4b685-5d73-49fe-a748-67f3ec471d4f",
   "metadata": {},
   "source": [
    "# 3. MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e8ec5b1-d78d-4696-8bf5-b26c3d2e7eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True,transform=torchvision.transforms.ToTensor())\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True,transform=torchvision.transforms.ToTensor())\n",
    "X,y = next(iter(torch.utils.data.DataLoader(train_dataset,batch_size=6000,shuffle=True)))\n",
    "XX,yy = next(iter(torch.utils.data.DataLoader(train_dataset,batch_size=1000,shuffle=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e591dce-9fdc-4f52-9054-9dcca8031a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1,32,kernel_size=5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2),\n",
    "    torch.nn.Conv2d(32,32,kernel_size=3),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Flatten(),\n",
    "    #---#\n",
    "    torch.nn.Linear(3200,10)\n",
    ")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "#---#\n",
    "net.to(\"cuda:0\")\n",
    "X = X.to(\"cuda:0\")\n",
    "y = y.to(\"cuda:0\")\n",
    "XX = XX.to(\"cuda:0\")\n",
    "yy = yy.to(\"cuda:0\")\n",
    "#---#\n",
    "for epoc in range(100):\n",
    "    #1\n",
    "    netout = net(X)\n",
    "    #2\n",
    "    loss = loss_fn(netout,y)\n",
    "    #3\n",
    "    loss.backward()\n",
    "    #4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "addb1431-ad1b-49d8-929d-c4c72d9dd46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9790, device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(X).argmax(axis=1) == y).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79eed0fc-3b22-4817-b83f-85000fa2de78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9690, device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(XX).argmax(axis=1) == yy).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6c374d2-2f4a-4b50-b9c0-daa2ba491ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da98d950-3b33-4efd-94f6-d3431e136dff",
   "metadata": {},
   "source": [
    "# 4. CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "876bf56a-a932-420a-8dff-f50514577a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True,transform=torchvision.transforms.ToTensor())\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True,transform=torchvision.transforms.ToTensor())\n",
    "X,y = next(iter(torch.utils.data.DataLoader(train_dataset,batch_size=10000,shuffle=True)))\n",
    "XX,yy = next(iter(torch.utils.data.DataLoader(train_dataset,batch_size=2000,shuffle=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aad4f7-b0a0-4318-9783-675abf2323a2",
   "metadata": {},
   "source": [
    "## A. 직접설계 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a63c9951-e0aa-4a89-ae8a-d6339a315345",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3,32,kernel_size=5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2),\n",
    "    torch.nn.Conv2d(32,32,kernel_size=3),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Flatten(),\n",
    "    #---#\n",
    "    torch.nn.Linear(4608,10)\n",
    ")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "#---#\n",
    "net.to(\"cuda:0\")\n",
    "X = X.to(\"cuda:0\")\n",
    "y = y.to(\"cuda:0\")\n",
    "XX = XX.to(\"cuda:0\")\n",
    "yy = yy.to(\"cuda:0\")\n",
    "#---#\n",
    "for epoc in range(500):\n",
    "    #1\n",
    "    netout = net(X)\n",
    "    #2\n",
    "    loss = loss_fn(netout,y)\n",
    "    #3\n",
    "    loss.backward()\n",
    "    #4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c7812e9-f130-4301-a1d8-16e8bebdab07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7025, device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(X).argmax(axis=1) == y).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82b4bb58-0037-4114-a7a6-8a3c9dcf032f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6050, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(XX).argmax(axis=1) == yy).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6375b1-452c-409c-b962-21d0a0259fef",
   "metadata": {},
   "source": [
    "- 표현력자체에 문제가 있어보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9f4b803-fdc2-4085-abc2-44f59bf44a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c472ddc-b3f8-4d1a-af1d-f6db005c6c56",
   "metadata": {},
   "source": [
    "## B. 알렉스넷? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20b66ca-f54d-4aff-a2f6-c052c1e623bc",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Comparison_image_neural_networks.svg/960px-Comparison_image_neural_networks.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a434dae6-0bb9-4aee-82bb-635a74ef7b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.zeros(1,3*224*224).reshape(1,3,224,224)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdd5f796-6695-480b-8ed6-df39a04ea845",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3,96,kernel_size=(11,11),stride=4),\n",
    "    torch.nn.ReLU(),    \n",
    "    torch.nn.MaxPool2d((3,3),stride=2), # default stride는 3\n",
    "    torch.nn.Conv2d(96,256,kernel_size=(5,5),padding=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d((3,3),stride=2), # default stride는 3\n",
    "    torch.nn.Conv2d(256,384,kernel_size=(3,3),padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(384,384,kernel_size=(3,3),padding=1),\n",
    "    torch.nn.ReLU(),    \n",
    "    torch.nn.Conv2d(384,256,kernel_size=(3,3),padding=1),\n",
    "    torch.nn.ReLU(),    \n",
    "    torch.nn.MaxPool2d((3,3),stride=2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(6400,4096),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(4096,4096),        \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),    \n",
    "    torch.nn.Linear(4096,1000),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652af543-0312-47fa-a01e-2443e25219bc",
   "metadata": {},
   "source": [
    "## C. 알렉스넷으로 ImageNet 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1bdd05a-983c-49cf-8744-53d66a8cde67",
   "metadata": {},
   "outputs": [],
   "source": [
    "net[-1] = torch.nn.Linear(4096,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3da9a06-0a65-409c-b7a5-0dfb0d32709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn(1,3,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85102866-e15c-4631-810d-8930776d662a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (256x2x2). Calculated output size: (256x0x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/pooling.py:213\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/_jit_internal.py:624\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/functional.py:830\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[0;32m--> 830\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given input size: (256x2x2). Calculated output size: (256x0x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "net(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be13c5e5-9740-4944-9b5d-28f60f101536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 2, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[:5](img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a79108d-e1cb-4d88-9a8b-45191123e300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7174bc-9ece-4007-9af3-49715ab537f1",
   "metadata": {},
   "source": [
    "실패 ㅠㅠ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d9e5fd-4bff-4a94-983e-6b9b8652f989",
   "metadata": {},
   "source": [
    "## D. renset18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276bffe0-ecc9-4b56-a73c-3de756f0de93",
   "metadata": {},
   "source": [
    "`-` res: <https://arxiv.org/pdf/1512.03385>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b06789ab-b33e-44f6-9fe5-92cedf343eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torchvision.models.resnet18()\n",
    "# net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6118b8b-f5fb-4747-b593-748d5804d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.fc = torch.nn.Linear(512,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1c6c4f9-7ca7-47b1-8811-3f0a688f2d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "#---#\n",
    "net.to(\"cuda:0\")\n",
    "X = X.to(\"cuda:0\")\n",
    "y = y.to(\"cuda:0\")\n",
    "XX = XX.to(\"cuda:0\")\n",
    "yy = yy.to(\"cuda:0\")\n",
    "#---#\n",
    "for epoc in range(500):\n",
    "    #1\n",
    "    netout = net(X)\n",
    "    #2\n",
    "    loss = loss_fn(netout,y)\n",
    "    #3\n",
    "    loss.backward()\n",
    "    #4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbc4d1e5-7085-459f-bdad-de4f40b3655d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(X).argmax(axis=1) == y).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1893378f-1d83-45e0-a1e9-ce6d8740050f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6215, device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(XX).argmax(axis=1) == yy).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a986bc9-fa6f-4ce0-8758-9a17a0a1fcc7",
   "metadata": {},
   "source": [
    "- 오버피팅이 있어보긴하지만 표현력자체는 올라감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8efb6544-fc12-4706-89b7-49ee01f3dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27f89a6-22fd-4e02-9a4a-de6ff7a4b7e8",
   "metadata": {},
   "source": [
    "## E. resnet18, pretrained=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eeed69-a000-43b8-bbba-d87500e605e7",
   "metadata": {},
   "source": [
    "`-` 아이디어: 하나를 잘하는 모델은 다른것도 잘하지 않을까? <-- transfer learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1adf2e13-49d4-4ba9-88ac-a9d726ccc8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torchvision.models.resnet18(pretrained=True) # 아키텍처 + 학습된 가중치까지 \n",
    "net.fc = torch.nn.Linear(512,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d3816c2-d1d7-4c8e-9f74-094ffd5432db",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "#---#\n",
    "net.to(\"cuda:0\")\n",
    "X = X.to(\"cuda:0\")\n",
    "y = y.to(\"cuda:0\")\n",
    "XX = XX.to(\"cuda:0\")\n",
    "yy = yy.to(\"cuda:0\")\n",
    "#---#\n",
    "for epoc in range(500):\n",
    "    #1\n",
    "    netout = net(X)\n",
    "    #2\n",
    "    loss = loss_fn(netout,y)\n",
    "    #3\n",
    "    loss.backward()\n",
    "    #4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9205ed86-30b2-47e4-bb80-1438559b0405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(X).argmax(axis=1) == y).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e2819ae-9aa6-4165-aae3-51a63977376c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8035, device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net(XX).argmax(axis=1) == yy).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04881eb5-873c-4f43-a4fa-d32f6566cf30",
   "metadata": {},
   "source": [
    "- 잘함 (오버피팅은 여전히 있음) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f05922b6-7336-4f87-99e5-f2f312e31900",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe03457-0c91-4e97-b082-917c97458781",
   "metadata": {},
   "source": [
    "# 5. XAI 란? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb35480-3908-44ec-b89b-f1539f93ca6b",
   "metadata": {},
   "source": [
    "<https://brunch.co.kr/@hvnpoet/140>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
