{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a38c22cf-74ca-41d2-95ba-b973a0263535",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"lecture\"\n",
    "author: \"최규빈\"\n",
    "date: \"05/19/2025\"\n",
    "draft: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b27a7a-19b0-4cf3-bcf4-8db99f55036d",
   "metadata": {
    "id": "e67ab8e0"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/guebin/DL2025/blob/main/posts/09wk-2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041ac616-02e3-4d7c-ac6e-3d90eaca2029",
   "metadata": {},
   "source": [
    "# 1. 강의영상 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c312ab0b-05da-4723-b350-83e344abc5e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#{{<video https://youtu.be/playlist?list=PLQqh36zP38-yfHwkWM_aHLQKTfKtoA7Oy&si=sgzwOEtflO1POup0 >}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ea632c-108b-4ffe-ab8e-831ac513f399",
   "metadata": {},
   "source": [
    "# 2. Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1faf4c40-64d2-4fd5-b89f-e08f6c0aa6bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cec14ee-2fe4-4c02-949f-2ad08c0fc616",
   "metadata": {},
   "source": [
    "# 3. Data -- `AbAcAd`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac66d4dc-33d9-4b01-96ca-d4595048724c",
   "metadata": {
    "tags": []
   },
   "source": [
    "`-` 데이터정리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b481b28-ac17-404e-97a6-2791382d8a99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = list('AbAcAd'*50)\n",
    "txt[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f56d4e2-3a1a-4d02-8940-6f5e43d52ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x  y\n",
       "0  A  b\n",
       "1  b  A\n",
       "2  A  c\n",
       "3  c  A\n",
       "4  A  d"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame({'x':txt[:-1], 'y':txt[1:]})\n",
    "df_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba1915dd-4936-4501-8261-f9a662d52352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(df_train.x.map({'A':0,'b':1,'c':2,'d':3}))\n",
    "y = torch.tensor(df_train.y.map({'A':0,'b':1,'c':2,'d':3}))\n",
    "X = torch.nn.functional.one_hot(x).float()\n",
    "y = torch.nn.functional.one_hot(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e72bc52-1188-4177-8def-6616a819db22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([299, 4]), torch.Size([299, 4]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d30958d-5ddc-41ef-b0bd-286cbad8804b",
   "metadata": {},
   "source": [
    "# 4. `rNNCell` -- 복습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8a481-24bf-41f9-a1bd-b582a87e7e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3782abb3-c805-4d1c-b147-fb2d292d18a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af3ce85e-97bb-4178-a574-9f2def521472",
   "metadata": {},
   "source": [
    "# 5. `torch.nn.RNNCell`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47851815-84a3-4fa8-93ea-3b9818d3b87e",
   "metadata": {},
   "source": [
    "ref: <https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaf9282-9e73-4321-83f4-3bf8d40c6621",
   "metadata": {},
   "source": [
    "`-` `torch.nn.RNNCell`을 이용하여 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f7354-e5d9-4aef-8eaa-ec44b1e1f1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3333173-35a0-4d4b-9e98-471eb0d2971d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0208feb-81ca-4820-b2eb-b4e77f8a6fdf",
   "metadata": {},
   "source": [
    "`-` `torch.nn.RNNCell`의 가중치를 이전에 직접 설계한 `rNNCell`와 동일하게 설정한 이후 학습  \n",
    "\n",
    "- 왜 이런것을 하지? 우리가 직접만들어본 클래스 `rNNCell`이 torch에서 기본제공하는 `torch.nn.RNNCell`와 동일기능을 수행한다는 것을 확인하기 위함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e7fe0c-8e1b-49b9-8ac0-712419846731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e82734d-9b76-4e45-a128-fed2d755e191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c760018-0a97-4413-acff-6dbb30c08da3",
   "metadata": {},
   "source": [
    "# 6. `torch.nn.RNN`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ca12fd-86dd-40bb-a8c3-7eb33de1f1b6",
   "metadata": {},
   "source": [
    "ref: <https://docs.pytorch.org/docs/stable/generated/torch.nn.RNN.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d3266a-e2e3-4ae0-a404-dbab618ad39a",
   "metadata": {},
   "source": [
    "||`RNNCell`, 배치사용 X | `RNNCell`, 배치사용 O  |\n",
    "|:-:|:-:|:-:|\n",
    "|X|$(L,H_{in})$|$(L, N, H_{in})$|\n",
    "|h|$(L,H_{out})$|$(L, N, H_{out})$|\n",
    "|y|$(L,Q)$|$(L, N, Q)$|\n",
    "|Xt|$(H_{in},)$|$(N, H_{in})$|\n",
    "|ht|$(H_{out},)$|$(N, H_{out})$|\n",
    "|yt|$(Q,)$|$(N,Q)$|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef2eb9c-fff0-4b0a-86df-b455f203176c",
   "metadata": {},
   "source": [
    "||`RNN`, 배치사용 X | `RNN`, 배치사용 O | \n",
    "|:-:|:-:|:-:|\n",
    "|X|$(L,H_{in})$|$(L, N, H_{in})$|\n",
    "|h|$(L,H_{out})$|$(L, N, H_{out})$|\n",
    "|y|$(L,Q)$|$(L, N, Q)$|\n",
    "|hx|$(D\\times {\\tt num\\_layers},H_{out})$|$(D\\times {\\tt num\\_layers},N,H_{out})$|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b453e7-1237-484b-bb58-fe072c58e7a3",
   "metadata": {},
   "source": [
    "`-` `torch.nn.RNN`을 활용한 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defdaaff-acda-4358-8271-8f390dae60fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc41905-6428-4081-8345-39def5dc0afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b32f3713-ebf7-453a-9a52-b746f6c7b5f5",
   "metadata": {},
   "source": [
    "`-` `torch.nn.RNN`의 가중치를 이전에 직접 설계한 `rNNCell`와 동일하게 설정한 이후 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20750c8-afdc-4dce-8271-852b0059f33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2419d591-4bf7-453a-ac01-bf0892d11f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ebeb5c9-8c61-466c-8f93-4a6bdadc2fa6",
   "metadata": {},
   "source": [
    "# 7. `torch.nn.LSTM`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cd174e-3c23-4733-b5bd-eb3b1ae896b3",
   "metadata": {},
   "source": [
    "`-` `torch.nn.LSTM`을 이용하여 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4c7ec2-d69c-4b8f-a1de-dbe3d9b41c27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317f2aa2-78b7-403e-b002-45542514b42a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4422632-cc9f-4bb6-aa81-0723ef93cc34",
   "metadata": {
    "tags": []
   },
   "source": [
    "# A1. 자잘한 용어 정리 ($\\star$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b393b-9da2-429c-a8bc-53ae16dba416",
   "metadata": {},
   "source": [
    "## A. ${\\bf X}$, ${\\bf y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670f43e0-e82f-4368-b271-bfb56423f1f6",
   "metadata": {},
   "source": [
    "`-` X, y를 지칭하는 이름 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f149ac33-7b50-4ecd-a560-76bf2f7c374a",
   "metadata": {},
   "source": [
    "| 구분 | 용어                                | 설명 |\n",
    "|------|-------------------------------------|------|\n",
    "| X    | 설명변수                             | 종속변수(반응변수)를 설명하거나 예측하는 데 사용되는 변수로, 전통 통계 및 머신러닝에서의 입력 역할 |\n",
    "|      | 독립변수 (Independent Variable)     | 전통적인 통계학 및 회귀 분석 문맥에서 사용됨 |\n",
    "|      | 입력변수 (Input Variable)           | 머신러닝 모델에서 입력 데이터로 사용되며, 특히 신경망 구조 등에서 많이 쓰임 |\n",
    "|      | 특징 / 특성 (Feature)               | 머신러닝, 데이터마이닝, 딥러닝 등에서 데이터를 구성하는 속성 또는 설명 변수로 사용됨 |\n",
    "|      | 예측 변수 (Predictor)               | 예측 모델 설계 시 독립변수를 지칭하는 용어로, 모델링/통계 분석 문맥에서 흔히 사용됨 |\n",
    "|      | 공변량 (Covariate)                  | 실험 디자인, 특히 임상연구나 사회과학 연구에서 제어 변수로 사용됨 |\n",
    "| y    | 반응변수                             | 독립변수의 영향을 받는 결과 변수로, 모델링이나 인과 추론에서 핵심적인 대상 |\n",
    "|      | 종속변수 (Dependent Variable)       | 전통 통계학과 회귀분석에서 사용되며, 독립변수의 영향을 받는 변수로 정의됨 |\n",
    "|      | 출력변수 (Output Variable)          | 머신러닝 및 딥러닝에서 모델의 예측 결과로 출력되는 값으로 사용됨 |\n",
    "|      | 타겟 / 정답 (Target / Label)        | 지도학습에서 모델이 학습해야 하는 실제 정답값을 의미하며, 분류/회귀 문제에 공통적으로 사용됨 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890d3be3-4380-463f-9c5d-df1955b7f8e1",
   "metadata": {},
   "source": [
    "`-` 더 다양함: <https://ko.wikipedia.org/wiki/독립변수와_종속변수>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9351cd32-339f-442f-b5ef-cd7ea120e301",
   "metadata": {
    "tags": []
   },
   "source": [
    "## B. 지도학습 \n",
    "\n",
    "`-` 우리가 수업에서 다루는 데이터는 주로 아래와 같은 느낌이다. \n",
    "\n",
    "1.  데이터는 $(X,y)$의 형태로 정리되어 있다. \n",
    "\n",
    "2.  $y$는 우리가 관심이 있는 변수이다. 즉 우리는 $y$를 적절하게 추정하는 것에 관심이 있다.\n",
    "\n",
    "3.  $X$는 $y$를 추정하기 위해 필요한 정보이다.\n",
    "\n",
    "|       $X$        |         $y$         |     비고     |     순서    |           예시           |\n",
    "|:----------------:|:-------------------:|:-------------:|:-------------:|:------------------------:|\n",
    "|     기온(온도)    |  아이스 아메리카노 판매량  | 회귀 |   상관없음   | 날씨가 판매량에 미치는 영향 분석 |\n",
    "|      스펙        |     합격 여부       | 로지스틱        |   상관없음   | 입사 지원자의 합격 예측      |\n",
    "|     이미지       |      카테고리       | 합성곱신경망 (CNN) |   상관없음   |    개/고양이 이미지 구분     |\n",
    "| 유저, 아이템 정보 |        평점         |  추천시스템        |   상관없음   |     넷플릭스 영화 추천       |\n",
    "| 처음 $m$개의 단어(문장) | 이후 1개의 단어(문장) | 순환신경망 (RNN) | 순서 상관 있음 | 챗봇, 문장 생성, 언어 모델링 |\n",
    "| 처음 $m$개의 단어(문장) |      카테고리       | 순환신경망 (RNN) | 순서 상관 있음 | 영화리뷰 감정 분류           |\n",
    "\n",
    "`-` 이러한 문제상황, 즉 $(X,y)$가 주어졌을때 $X \\to y$를 추정하는 문제를 supervised learning 이라한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a49cbf7-582a-432d-ae51-99f0261ca03c",
   "metadata": {},
   "source": [
    "## C. 모델이란? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0d15bb-cd67-4551-888a-e8107cc8801c",
   "metadata": {},
   "source": [
    "`-` 통계학에서 모델은 y와 x의 관계를 의미하며 오차항의 설계를 포함하는 개념이다. 이는 통계학이 \"데이터 = 정보 + 오차\"의 관점을 유지하기 때문이다. 따라서 통계학에서 모델링이란 \n",
    "\n",
    "$$y_i = net(x_i) + \\epsilon_i$$\n",
    "\n",
    "에서 (1) 적절한 함수 $net$를 선택하는 일 (2) 적절한 오차항 $\\epsilon_i$ 을 설계하는일 모두를 포함한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9f31b1-5c13-43b8-819f-42b9dbe6dcc8",
   "metadata": {},
   "source": [
    "`-` 딥러닝 혹은 머신러닝에서 모델은 단순히\n",
    "\n",
    "$$y_i \\approx net(x_i)$$\n",
    "\n",
    "를 의미하는 경우가 많다. 즉 \"model=net\"라고 생각해도 무방하다. 이 경우 \"모델링\"이란 단순히 적절한 $net$을 설계하는 것만을 의미할 경우가 많다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aff737-7fa2-42d9-b4ce-6e1d71fb7375",
   "metadata": {},
   "source": [
    "`-` 그래서 생긴일\n",
    "\n",
    "- 통계학교재 특징: 분류문제와 회귀문제를 엄밀하게 구분하지 않는다. 사실 오차항만 다를뿐이지 크게보면 같은 회귀모형이라는 관점이다. 그래서 일반화선형모형(GLM)이라는 용어를 쓴다. \n",
    "- 머신러닝/딥러닝교재 특징: 회귀문제와 분류문제를 구분해서 설명한다. (표도 만듦) 이는 오차항에 대한 기술을 모호하게 하여 생기는 현상이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d002890e-c45a-46f8-b7fc-b4fe4bb1cb4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## D. 학습이란? \n",
    "\n",
    "`-` 학습이란 주어진 자료 $(X,y)$를 잘 분석하여 $X$에서 $y$로 가는 어떠한 “규칙” 혹은 “원리”를 찾는 것이다.\n",
    "\n",
    "-   학습이란 주어진 자료 $(X,y)$를 잘 분석하여 $X$에서 $y$로 가는 어떠한 “맵핑”을 찾는 것이다.\n",
    "-   학습이란 주어진 자료 $(X,y)$를 잘 분석하여 $X$에서 $y$로 가는 어떠한 \"함수”을 찾는 것이다. 즉 $y\\approx f(X)$가 되도록 만드는 $f$를 잘 찾는 것이다. (이 경우 \"함수를 추정한다\"라고 표현)\n",
    "-   학습이란 주어진 자료 $(X,y)$를 잘 분석하여 $X$에서 $y$로 가는 어떠한 “모델” 혹은 \"모형\"을 찾는 것이다. 즉 $y\\approx model(X)$가 되도록 만드는 $model$을 잘 찾는 것이다. (이 경우 \"모형을 학습시킨다\"라고 표현)\n",
    "-   **학습이란 주어진 자료 $(X,y)$를 잘 분석하여 $X$에서 $y$로 가는 어떠한 “네트워크”을 찾는 것이다. 즉 $y\\approx net(X)$가 되도록 만드는 $net$을 잘 찾는 것이다. (이 경우 \"네트워크를 학습시킨다\"라고 표현)**\n",
    "\n",
    "`-` prediction이란 학습과정에서 찾은 “규칙” 혹은 “원리”를 $X$에 적용하여 $\\hat{y}$을 구하는 과정이다. 학습과정에서 찾은 규칙 혹은 원리는 $f$,$model$,$net$ 으로 생각가능한데 이에 따르면 아래가 성립한다.\n",
    "\n",
    "-   $\\hat{y} = f(X)$\n",
    "-   $\\hat{y} = model(X)$\n",
    "-   $\\hat{y} = net(X)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328631e5-1f00-4303-bffe-20c6e4f8de16",
   "metadata": {
    "tags": []
   },
   "source": [
    "## E. $\\hat{y}$를 부르는 다양한 이름\n",
    "\n",
    "`-` $\\hat{y}$는 $X$가 주어진 자료에 있는 값인지 아니면 새로운 값 인지에 따라 지칭하는 이름이 미묘하게 다르다.\n",
    "\n",
    "1.  $X \\in data$: $\\hat{y}=net(X)$ 는 predicted value, fitted value 라고 부른다.\n",
    "\n",
    "2.  $X \\notin data$: $\\hat{y}=net(X)$ 는 predicted value, predicted\n",
    "    value with new data 라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308c8ec3-6d80-4ab3-8416-a1a4007dd978",
   "metadata": {
    "tags": []
   },
   "source": [
    "## F. 다양한 코드들 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b50c254-7ddc-4977-93ff-d9f0d994f964",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "`-` 파이썬 코드..\n",
    "\n",
    "```Python\n",
    "#Python\n",
    "predictor.fit(X,y) # autogluon 에서 \"학습\"을 의미하는 과정\n",
    "model.fit(X,y) # sklearn 에서 \"학습\"을 의미하는 과정\n",
    "trainer.train() # huggingface 에서 \"학습\"을 의미하는 과정\n",
    "trainer.predict(dataset) # huggingface 에서 \"예측\"을 의미하는 과정\n",
    "model.fit(x, y, batch_size=32, epochs=10) # keras에서 \"학습\"을 의미하는 과정\n",
    "model.predict(test_img) # keras에서 \"예측\"을 의미하는 과정 \n",
    "```\n",
    "\n",
    "`-` R 코드..\n",
    "\n",
    "```r\n",
    "# R\n",
    "ols <- lm(y~x) # 선형회귀분석에서 학습을 의미하는 함수\n",
    "ols$fitted.values # 선형회귀분석에서 yhat을 출력 \n",
    "predict(ols, newdata=test) # 선형회귀분석에서 test에 대한 예측값을 출력하는 함수\n",
    "ols$coef # 선형회귀분석에서 weight를 확인하는 방법\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b3bc2f-fe7d-48a8-8158-6afd44ff84e9",
   "metadata": {},
   "source": [
    "# A2. 신경망관련 용어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fd894d-1cc8-4a28-bcad-7b9d6938d1cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "`-` 은근히 용어가 헷갈리는데, 뜻을 좀 살펴보자. \n",
    "\n",
    "- ANN: 인공신경망 \n",
    "- MLP: 다층퍼셉트론 (레이어가 여러개 있어요) \n",
    "- DNN: 깊은신경망, 심층신경망 \n",
    "- CNN: 합성곱신경망 \n",
    "- RNN: 순환신경망 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0accc4f4-4acd-4a0b-ba74-902470218481",
   "metadata": {
    "tags": []
   },
   "source": [
    "`# 예시1` -- MLP, DNN\n",
    "\n",
    "```Python\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=1,out_features=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=2,out_features=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=2,out_features=1),    \n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13d96a2-c80d-4938-8069-720d9ddca7bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "- ANN: O\n",
    "- MLP: O \n",
    "- DNN: O\n",
    "- CNN: X (합성곱레이어가 없으므로) \n",
    "- RNN: X (순환구조가 없으므로)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fe888d-669f-4cae-83fd-e9487659345e",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfb5b11-2f56-4a31-9779-ca45cdb5acd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "`# 예시2` -- MLP, Shallow Network\n",
    "\n",
    "```Python\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=1,out_features=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=2,out_features=1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da850f72-bce5-424c-b319-2d3ce6e034bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "- ANN: O\n",
    "- MLP: O \n",
    "- DNN: X (깊은 신경망으로 생각하려면 더 많은 레이어가 필요함. 합의된 기준은 히든레이어 2장이상, 이걸 설명하기 위해서 얕은 신경망이란 용어도 씀) \n",
    "- CNN: X (합성곱레이어가 없으므로) \n",
    "- RNN: X (순환구조가 없으므로)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc54673a-219a-475f-91b6-c2743080712a",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e930ce-7f1d-4736-a347-180ad5ca66a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "`# 예시3` -- MLP, DNN, Wide NN\n",
    "\n",
    "```Python\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=1,out_features=1048576),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=1048576,out_features=1048576),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=1048576,out_features=1),\n",
    "    torch.nn.Sigmoid(),    \n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb553fc-f364-4d69-8721-57c8b4fb2e66",
   "metadata": {
    "tags": []
   },
   "source": [
    "- ANN: O\n",
    "- MLP: O \n",
    "- DNN: O (깊긴한데 이정도면 모양이 깊다기 보다는 넓은 신경망임, 그래서 어떤 연구에서는 이걸 넓은 신경망이라 부르기도 함) \n",
    "- CNN: X (합성곱레이어가 없으므로) \n",
    "- RNN: X (순환구조가 없으므로)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbea0e6-bf78-4b68-bfc8-3844d426ff8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "`# 예시4` -- CNN\n",
    "\n",
    "```Python\n",
    "net = torch.nn.Sequential(\n",
    "    # Layer1\n",
    "    torch.nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    torch.nn.LeakyReLU(0.2),\n",
    "    # Layer2\n",
    "    torch.nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    torch.nn.BatchNorm2d(128),\n",
    "    torch.nn.LeakyReLU(0.2),\n",
    "    # Layer3\n",
    "    torch.nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    torch.nn.BatchNorm2d(256),\n",
    "    torch.nn.LeakyReLU(0.2),\n",
    "    # Layer4\n",
    "    torch.nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    torch.nn.BatchNorm2d(512),\n",
    "    torch.nn.LeakyReLU(0.2),\n",
    "    # Layer5\n",
    "    torch.nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Flatten()\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769c7fc8-6dd1-455e-b475-f850f0054450",
   "metadata": {
    "tags": []
   },
   "source": [
    "- ANN: O\n",
    "- MLP: X (합성곱연결이 포함되어있으므로, MLP가 아님, 완전연결만 포함해야 MLP임)  \n",
    "- DNN: O\n",
    "- CNN: O (합성곱레이어를 포함하고 있으므로) \n",
    "- RNN: X (순환구조가 없으므로)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d329320-0afb-4196-ad62-0c84b22e0410",
   "metadata": {},
   "source": [
    "`# `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c20184-9246-4b8f-adf6-7eca7efd40cb",
   "metadata": {},
   "source": [
    "`# 예시5` -- CNN \n",
    "\n",
    "```Python\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1,16,(5,5)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d((2,2)),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(2304,1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39f10a6-7181-4617-945f-8743d6652f14",
   "metadata": {
    "tags": []
   },
   "source": [
    "- ANN: O\n",
    "- MLP: X \n",
    "- DNN: X? (히든레이어가 1장이므로..)\n",
    "- CNN: O (합성곱레이어를 포함하고 있으므로) \n",
    "- RNN: X (순환구조가 없으므로)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c77caa-6a89-4f11-955d-c71199b6abbb",
   "metadata": {},
   "source": [
    "> 근데 대부분의 문서에서는 CNN, RNN은 DNN의 한 종류로 설명하고 있어서요.. 이런 네트워크에서는 개념충돌이 옵니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b489f6f9-1109-4831-8f60-8cf5dbc58801",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a612f6dc-62e4-4860-8ab1-307e396e711d",
   "metadata": {},
   "source": [
    "`# 예시6` -- RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec50aa1-f0a6-4ca2-9b72-fec06020cf54",
   "metadata": {},
   "source": [
    "```Python\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = torch.nn.RNN(4,2)\n",
    "        self.linr = torch.nn.Linear(2,2) \n",
    "    def forward(self,X):\n",
    "        h,_ = self.rnn(X) \n",
    "        netout = self.linr(h)\n",
    "        return netout \n",
    "net = Net()     \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9706b2f9-3070-446d-ba2c-f253d5cdef08",
   "metadata": {
    "tags": []
   },
   "source": [
    "- ANN: O\n",
    "- MLP: X \n",
    "- DNN: X? (히든레이어가 1장이므로..)\n",
    "- CNN: X (합성곱레이어가 없으므로) \n",
    "- RNN: O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24d4636-f6cb-45b6-ab8d-f80e89f3f5b9",
   "metadata": {},
   "source": [
    "> 이것도 비슷한 개념충돌 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4900271-d097-4d01-9c39-0596e2b96d73",
   "metadata": {},
   "source": [
    "`#`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b60468-a8ab-4d6c-8c4b-b422ffa08a59",
   "metadata": {},
   "source": [
    "# A3. 학습 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1255ff62-4803-4556-a96d-599d31c68eeb",
   "metadata": {},
   "source": [
    "`-` 모든 인공지능 관련 알고리즘은 아래의 분류로 가능함. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40d5109-8f7c-4858-8379-2771ab6f700b",
   "metadata": {},
   "source": [
    "| **특징**            | **지도학습 (Supervised Learning)** | **비지도학습 (Unsupervised Learning)** | **강화학습 (Reinforcement Learning)** |\n",
    "|:---------------------:|:-------------------------------------:|:----------------------------------------:|:---------------------------------------:|\n",
    "| **정의**            | 입력 데이터와 정답(레이블)을 사용   | 입력 데이터만 사용                      | 에이전트가 환경과 상호작용하며 학습   |\n",
    "| **목표**            | 입력에 대한 정확한 출력을 예측      | 데이터의 숨겨진 구조나 패턴 발견       | 최대 보상을 얻기 위한 최적의 정책 학습 |\n",
    "| **예시**            | 이미지 분류, 스팸 필터링            | 군집화, 차원 축소                       | 게임 플레이, 로봇 제어                 |\n",
    "| **주요 알고리즘**   | 선형 회귀, 로지스틱 회귀, SVM       | K-평균, PCA, 오토인코더                | Q-러닝, DQN          |\n",
    "| **활용**            | 분류, 예측              | 데이터의 숨겨진 패턴 발견               | 복잡한 의사결정 문제 해결 가능         |\n",
    "| **데이터 요구사항** | 레이블링이 반드시 필요           | 많은 양의 데이터 필요                  | 시뮬레이션 또는 실제 환경 필요         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62640895-66bd-4f32-a998-fbdafe1372ed",
   "metadata": {},
   "source": [
    "`-` 그런데 분류가 애매한 것들이 점점 많아짐."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
