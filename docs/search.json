[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "딥러닝 (2025)",
    "section": "",
    "text": "질문하는 방법\n\n이메일: guebin@jbnu.ac.kr\n직접방문: 자연과학대학 본관 205호\nZoom: 이메일로 미리 시간을 정할 것\n카카오톡: http://pf.kakao.com/_txeIFG/chat\n\n오늘의 강의노트\n\n코랩사용자서버사용자\n\n\n아래의 링크 클릭\n\n\n\n주피터에서 아래를 실행 (주소 오류 수정했음!)\n!wget https://raw.githubusercontent.com/guebin/DL2025/refs/heads/main/posts/lecture.ipynb\n\n\n\n강의노트\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nApr 9, 2025\n\n\n06wk-1: (신경망) – 데이터분석 코딩패턴, 다중클래스 분류\n\n\n최규빈 \n\n\n\n\nApr 7, 2025\n\n\n05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법\n\n\n최규빈 \n\n\n\n\nApr 2, 2025\n\n\n05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃\n\n\n최규빈 \n\n\n\n\nMar 31, 2025\n\n\n04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST\n\n\n최규빈 \n\n\n\n\nMar 26, 2025\n\n\n04wk-1: (신경망) – 로지스틱의 한계 극복\n\n\n최규빈 \n\n\n\n\nMar 24, 2025\n\n\n03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계\n\n\n최규빈 \n\n\n\n\nMar 19, 2025\n\n\n03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형\n\n\n최규빈 \n\n\n\n\nMar 17, 2025\n\n\n02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)\n\n\n최규빈 \n\n\n\n\nMar 10, 2025\n\n\n01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정\n\n\n최규빈 \n\n\n\n\nMar 5, 2025\n\n\n01wk-1: (토치) – 강의소개, 파이토치 기본\n\n\n최규빈 \n\n\n\n\nJan 1, 2025\n\n\nA2: Exam Guidelines\n\n\n최규빈 \n\n\n\n\nJan 1, 2025\n\n\nA1: Exercise\n\n\n최규빈 \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/05wk-1.html#a.-데이터",
    "href": "posts/05wk-1.html#a.-데이터",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "A. 데이터",
    "text": "A. 데이터\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\ny = x * 4 + 2.5 + eps\nx,y = x.reshape(-1,1), y.reshape(-1,1)\n\n\nplt.plot(x,y,'o')"
  },
  {
    "objectID": "posts/05wk-1.html#b.-학습",
    "href": "posts/05wk-1.html#b.-학습",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "B. 학습",
    "text": "B. 학습\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1)\n## \nfor epoc in range(200):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n\nnet[0].weight, net[0].bias\n\n(Parameter containing:\n tensor([[4.0042]], requires_grad=True),\n Parameter containing:\n tensor([2.4459], requires_grad=True))"
  },
  {
    "objectID": "posts/05wk-1.html#c.-예측",
    "href": "posts/05wk-1.html#c.-예측",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "C. 예측",
    "text": "C. 예측\n온도가 0.1 도일때, 커피를 얼마나 팔까?\n\n0.1 * 4.0042 + 2.4459 \n\n2.84632\n\n\n\nxx = torch.tensor([[0.1]])\nnet(xx)\n\ntensor([[2.8463]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n온도가 0.2도일때 커피를 얼마나 팔까?\n\n0.2 * 4.0042 + 2.4459 \n\n3.24674\n\n\n\nxx = torch.tensor([[0.2]])\nnet(xx)\n\ntensor([[3.2467]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n온도가 [0.1, 0.2] 일때의 예측값을 한번에 보고 싶다면?\n\nxx = torch.tensor([[0.1],\n                   [0.2]])\nnet(xx)\n\ntensor([[2.8463],\n        [3.2467]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\n\n\n\n\n\nNote\n\n\n\n이거 질문이 와서 좀 더 자세히 설명하겠습니다. (아직 net(x)의 계산 과정을 선형 변환 관점에서 수식으로 정리하는 데 익숙하지 않으셔서 그럴 수 있습니다. 이건 단순 산수라서 하나씩 차근차근 따라가다 보면 충분히 이해하실 수 있어요. 처음부터 바로 이해되지 않더라도 전혀 걱정하실 필요 없습니다.)\n하나의 값 \\(x\\)에 대하여 \\(net(x)\\)는 아래를 의미하는 연산을 합니다.\nnet(x) = 4.0042 * x + 2.4459  = net[0].weight * x + net[0].bias\n사실 위의 과정을 수식으로 엄밀하게 쓰면 아래와 같습니다.\n\\[net(\\begin{bmatrix} x \\end{bmatrix}) = 2.4459 + \\begin{bmatrix} x \\end{bmatrix} \\begin{bmatrix} 4.0042 \\end{bmatrix}\\]\n여기에서 \\(\\begin{bmatrix} x \\end{bmatrix}\\) 와 \\(\\begin{bmatrix} 4.0042  \\end{bmatrix}\\) 는 모두 \\(1\\times 1\\) matrix를 의미합니다. 만약에 \\(2 \\times 1\\) matrix \\({\\bf x} = \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}\\)를 네트워크의 입력으로 고려한다면 아래와 같이 됩니다.\n\\[net({\\bf x})=net\\left(\\begin{bmatrix}x_1 \\\\ x_2 \\end{bmatrix}\\right) = 2.4459 + \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\begin{bmatrix} 4.0042 \\end{bmatrix} = \\begin{bmatrix} 2.4459 + 4.0042 x_1 \\\\ 2.4459 + 4.0042 x_2\\end{bmatrix} \\]\n따라서 \\({\\bf xx} = \\begin{bmatrix} 0.1 \\\\ 0.2 \\end{bmatrix}\\) 를 네트워크의 입력으로 넣으면\n\\[net({\\bf xx})= \\begin{bmatrix} 2.4459 + 4.0042 \\times 0.1 \\\\ 2.4459 + 4.0042 \\times 0.2\\end{bmatrix}= \\begin{bmatrix} 2.8463 \\\\ 3.2467 \\end{bmatrix}\\]\n와 같이 계산되겠죠."
  },
  {
    "objectID": "posts/05wk-1.html#a.-오버피팅",
    "href": "posts/05wk-1.html#a.-오버피팅",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "A. 오버피팅",
    "text": "A. 오버피팅\n- 오버피팅이란?\n\n위키: In mathematical modeling, overfitting is “the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit to additional data or predict future observations reliably”. (수학적 모델링에서 과적합이란 “어떤 모델이 주어진 데이터에 너무 꼭 맞춰져 있어서, 새로운 데이터나 미래의 결과를 잘 예측하지 못할 수 있는 상태”를 의미한다.)\n제 개념: 데이터를 “데이터 = 언더라잉 + 오차”라고 생각할때 우리가 데이터로부터 적합할 것은 언더라잉인데 오차항을 적합하고 있는 현상."
  },
  {
    "objectID": "posts/05wk-1.html#b.-오버피팅-예시",
    "href": "posts/05wk-1.html#b.-오버피팅-예시",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "B. 오버피팅 예시",
    "text": "B. 오버피팅 예시\n- \\(m\\)이 매우 클때 아래의 네트워크 거의 무엇이든 맞출 수 있다고 보면 된다.\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n- 그런데 종종 맞추지 말아야 할 것들도 맞춘다.\n\\[\\text{model:} \\quad y_i = (0\\times x_i) + \\epsilon_i,~~ \\text{where}~ \\epsilon_i \\sim N(0,0.01^2)\\]\n\ntorch.manual_seed(5) \nx = torch.linspace(0,1,100).reshape(100,1)\ny = torch.randn(100).reshape(100,1)*0.01\nplt.plot(x,y,'--o',alpha=0.5)\n\n\n\n\n\n\n\n\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'--o',alpha=0.5)\nplt.plot(x,net(x).data,'--')"
  },
  {
    "objectID": "posts/05wk-1.html#c.-오버피팅이라는-뚜렷한-증거-train-test",
    "href": "posts/05wk-1.html#c.-오버피팅이라는-뚜렷한-증거-train-test",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "C. 오버피팅이라는 뚜렷한 증거! (train / test)",
    "text": "C. 오버피팅이라는 뚜렷한 증거! (train / test)\n- 데이터의 분리하여 보자.\n\ntorch.manual_seed(5) \nx_all = torch.linspace(0,1,100).reshape(100,1)\ny_all = torch.randn(100).reshape(100,1)*0.01\nx,xx = x_all[:80], x_all[80:]\ny,yy = y_all[:80], y_all[80:]\nplt.plot(x,y,'--o',alpha=0.5,label=\"training\")\nplt.plot(xx,yy,'--o',alpha=0.5,label=\"test\")\nplt.legend()\n\n\n\n\n\n\n\n\n- train만 학습\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- training data로 학습한 net를 training data 에 적용\n\nplt.plot(x_all,y_all,'--o',alpha=0.5,color=\"gray\")\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n\ntraining에서는 그럭저럭 잘 맞춤\n\n- training data로 학습한 net를 test data 에 적용\n\nplt.plot(x_all,y_all,'--o',alpha=0.5,color=\"gray\")\nplt.plot(x,net(x).data,'--')\nplt.plot(xx,net(xx).data,'--')\n\n\n\n\n\n\n\n\n\ntrain에서는 그럭저럭 잘 맞추는데 test에서는 엉망이다 = overfit"
  },
  {
    "objectID": "posts/05wk-1.html#d.-시벤코정리의-올바른-이해",
    "href": "posts/05wk-1.html#d.-시벤코정리의-올바른-이해",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "D. 시벤코정리의 올바른 이해",
    "text": "D. 시벤코정리의 올바른 이해\n\n\n\n\n\n\nNote\n\n\n\n시벤코의 항변(?) (Cybenko 1989)\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크 \\(net: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\)는\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(), ## &lt;-- 여기에 렐루를 써도 된다. \n    torch.nn.Linear(???,q)\n)\n모든 보렐가측함수\n\\[f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\]\n를 원하는 정확도로 “근사”시킬 수 있다. 쉽게 말하면 \\({\\bf X} \\to {\\bf y}\\) 인 어떠한 복잡한 규칙라도 하나의 은닉층을 가진 신경망이 원하는 정확도로 근사시킨다는 의미이다. 그렇지만 이러한 규칙이 네크워크가 학습하지 못했던 자료 (처음 보는 자료, unseen data) \\({\\bf XX}_{m \\times p}\\), \\({\\bf yy}_{m \\times q}\\) 에 대하여서도 올바르게 적용된다라는 보장은 없다. 시벤코는 단지 net가 가지는 표현력의 한계를 수학적으로 밝혔을 뿐이다.\n\n\n\nCybenko, George. 1989. “Approximation by Superpositions of a Sigmoidal Function.” Mathematics of Control, Signals and Systems 2 (4): 303–14."
  },
  {
    "objectID": "posts/05wk-1.html#a.-오버피팅의-해결",
    "href": "posts/05wk-1.html#a.-오버피팅의-해결",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "A. 오버피팅의 해결",
    "text": "A. 오버피팅의 해결\n- 오버피팅의 해결책: 드랍아웃\n- 데이터\n\ntorch.manual_seed(5) \nx_all = torch.linspace(0,1,100).reshape(100,1)\ny_all = torch.randn(100).reshape(100,1)*0.01\n#plt.plot(x_all,y_all,'--o',alpha=0.5)\nx,y = x_all[:80], y_all[:80]\nxx,yy = x_all[80:], y_all[80:]\nplt.plot(x,y,'--o',color=\"C0\")\nplt.plot(xx,yy,'--o',color=\"C1\")\n\n\n\n\n\n\n\n\n- 학습\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.8),\n    torch.nn.Linear(512,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화 (잘못된 사용)\n\nplt.plot(x_all,y_all,'--o',alpha=0.5,color=\"gray\")\nplt.plot(x,net(x).data,'--')\nplt.plot(xx,net(xx).data,'--')\n\n\n\n\n\n\n\n\n- 결과시각화 (올바른 사용)\n\nnet.training \n\nTrue\n\n\n\nnet.eval()\n\nSequential(\n  (0): Linear(in_features=1, out_features=512, bias=True)\n  (1): ReLU()\n  (2): Dropout(p=0.8, inplace=False)\n  (3): Linear(in_features=512, out_features=1, bias=True)\n)\n\n\n\nnet.training\n\nFalse\n\n\n\nplt.plot(x_all,y_all,'--o',alpha=0.5,color=\"gray\")\nplt.plot(x,net(x).data,'--')\nplt.plot(xx,net(xx).data,'--')"
  },
  {
    "objectID": "posts/05wk-1.html#b.-드랍아웃-레이어",
    "href": "posts/05wk-1.html#b.-드랍아웃-레이어",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "B. 드랍아웃 레이어",
    "text": "B. 드랍아웃 레이어\n- 드랍아웃의 성질1: 드랍아웃의 계산방식을 이해해보자.\n\nu = torch.randn(10,2)\nd = torch.nn.Dropout(0.9)\nu\n\ntensor([[ 0.2325, -0.2137],\n        [-1.1099,  0.1651],\n        [-0.6292, -0.6375],\n        [-0.7331, -0.4100],\n        [ 0.3024,  0.1195],\n        [ 1.6408,  0.9799],\n        [ 0.6248, -0.6950],\n        [-0.4911, -1.5387],\n        [ 0.3758,  0.2701],\n        [ 1.5462, -0.1872]])\n\n\n\nd(u)\n\ntensor([[ 0.0000, -0.0000],\n        [-0.0000,  0.0000],\n        [-6.2916, -0.0000],\n        [-7.3306, -4.0995],\n        [ 0.0000,  0.0000],\n        [ 0.0000,  0.0000],\n        [ 0.0000, -0.0000],\n        [-0.0000, -0.0000],\n        [ 0.0000,  0.0000],\n        [ 0.0000, -0.0000]])\n\n\n\n90%의 드랍아웃: 드랍아웃층의 입력 중 임의로 90%를 골라서 결과를 0으로 만든다. + 그리고 0이 되지않고 살아남은 값들은 10배 만큼 값이 커진다.\n남은값을 10배 키우는 이유? 출력의 평균값을 보정하기 위해서\n\n- 드랍아웃의 성질2: 드랍아웃을 on/off 하는 방법을 이해해보자.\n\nu = torch.randn(10,2)\nu\n\ntensor([[ 1.5448,  0.6084],\n        [-0.2335, -0.0364],\n        [ 0.2034,  1.2170],\n        [-0.3361,  0.2241],\n        [ 1.7618,  0.2731],\n        [-0.5324, -1.4465],\n        [-1.0775,  1.2933],\n        [ 0.8029, -1.0636],\n        [-0.6346, -0.7101],\n        [ 0.9358, -0.2241]])\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Dropout(0.9)\n)\nnet\n\nSequential(\n  (0): Dropout(p=0.9, inplace=False)\n)\n\n\n\nu,net(u)\n\n(tensor([[ 1.5448,  0.6084],\n         [-0.2335, -0.0364],\n         [ 0.2034,  1.2170],\n         [-0.3361,  0.2241],\n         [ 1.7618,  0.2731],\n         [-0.5324, -1.4465],\n         [-1.0775,  1.2933],\n         [ 0.8029, -1.0636],\n         [-0.6346, -0.7101],\n         [ 0.9358, -0.2241]]),\n tensor([[0.0000, 0.0000],\n         [-0.0000, -0.0000],\n         [0.0000, 0.0000],\n         [-0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [-0.0000, -0.0000],\n         [-0.0000, 0.0000],\n         [0.0000, -0.0000],\n         [-0.0000, -0.0000],\n         [9.3584, -0.0000]]))\n\n\n\nnet.training\n\nTrue\n\n\n\nnet.eval() # 드랍아웃이 무력화\n\nSequential(\n  (0): Dropout(p=0.9, inplace=False)\n)\n\n\n\nu,net(u)\n\n(tensor([[ 1.5448,  0.6084],\n         [-0.2335, -0.0364],\n         [ 0.2034,  1.2170],\n         [-0.3361,  0.2241],\n         [ 1.7618,  0.2731],\n         [-0.5324, -1.4465],\n         [-1.0775,  1.2933],\n         [ 0.8029, -1.0636],\n         [-0.6346, -0.7101],\n         [ 0.9358, -0.2241]]),\n tensor([[ 1.5448,  0.6084],\n         [-0.2335, -0.0364],\n         [ 0.2034,  1.2170],\n         [-0.3361,  0.2241],\n         [ 1.7618,  0.2731],\n         [-0.5324, -1.4465],\n         [-1.0775,  1.2933],\n         [ 0.8029, -1.0636],\n         [-0.6346, -0.7101],\n         [ 0.9358, -0.2241]]))\n\n\n- 드랍아웃레이어 정리\n\n계산: (1) 입력의 일부를 임의로 0으로 만드는 역할 (2) 0이 안된것들은 스칼라배하여 드랍아웃을 통과한 모든 숫자들의 총합이 대체로 일정하게 되도록 조정\non/off: 학습시에는 dropout on / 학습을 하지 않을 경우는 dropout off\n느낌: 일부러 패널티를 안고 학습하는 느낌..\n효과: 오버피팅을 억제하는 효과가 있음\n\n\n참고: 오버피팅을 잡는 방법은 드랍아웃만 있는게 아니다.."
  },
  {
    "objectID": "posts/05wk-1.html#c.-드랍아웃-레이어의-위치",
    "href": "posts/05wk-1.html#c.-드랍아웃-레이어의-위치",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "C. 드랍아웃 레이어의 위치",
    "text": "C. 드랍아웃 레이어의 위치\n- ReLU,dropout의 특이한 성질: \\(\\text{dropout}(\\text{relu}({\\bf x}))=\\text{relu}(\\text{dropout}({\\bf x}))\\)\n\nu = torch.randn(10,2)\nr = torch.nn.ReLU()\nd = torch.nn.Dropout()\n\n\ntorch.manual_seed(0)\nd(r(u))\n\ntensor([[2.8004, 0.0000],\n        [0.0000, 1.4576],\n        [4.3925, 0.0000],\n        [0.0000, 1.4472],\n        [0.0000, 2.3459],\n        [0.0000, 0.0000],\n        [0.0000, 0.4245],\n        [0.0000, 1.8586],\n        [0.0000, 0.1394],\n        [0.0000, 0.0000]])\n\n\n\ntorch.manual_seed(0)\nr(d(u))\n\ntensor([[2.8004, 0.0000],\n        [-0.0000, 1.4576],\n        [4.3925, -0.0000],\n        [-0.0000, 1.4472],\n        [0.0000, 2.3459],\n        [0.0000, 0.0000],\n        [0.0000, 0.4245],\n        [0.0000, 1.8586],\n        [-0.0000, 0.1394],\n        [-0.0000, 0.0000]])\n\n\n- 다른 활성화함수는 성립안함\n\nu = torch.randn(10,2)\ns = torch.nn.Sigmoid()\nd = torch.nn.Dropout()\n\n\ntorch.manual_seed(0)\nd(s(u))\n\ntensor([[0.4801, 0.0000],\n        [0.0000, 1.4006],\n        [0.3487, 0.0000],\n        [0.0000, 1.2299],\n        [0.9213, 1.6180],\n        [1.1322, 0.0000],\n        [0.0000, 1.4407],\n        [0.6015, 1.4349],\n        [0.0000, 1.7626],\n        [0.0000, 0.0000]])\n\n\n\ntorch.manual_seed(0)\ns(d(u))\n\ntensor([[0.0907, 0.5000],\n        [0.5000, 0.8452],\n        [0.0427, 0.5000],\n        [0.5000, 0.7183],\n        [0.4218, 0.9472],\n        [0.6300, 0.5000],\n        [0.5000, 0.8691],\n        [0.1561, 0.8657],\n        [0.5000, 0.9822],\n        [0.5000, 0.5000]])\n\n\n- 결론: 드랍아웃은 활성화 함수 바로 뒤에 오는게 맞음. (그렇지 않다면 0을 만들 수 없는걸?) 그렇지만 ReLU의 경우 활성화 함수 직전에 취하기도 함."
  },
  {
    "objectID": "posts/05wk-1.html#d.-평균보정의-필요성-선택학습",
    "href": "posts/05wk-1.html#d.-평균보정의-필요성-선택학습",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "D. 평균보정의 필요성 (선택학습)",
    "text": "D. 평균보정의 필요성 (선택학습)\n\n\n\n\n\n\nNote\n\n\n\n90%의 드랍아웃에서 출력결과에 왜 x10하는지 좀 더 자세히 설명한 챕터입니다. 궁금하시다면 읽어보시고 아니라면 넘어가셔도 무방합니다.\n\n\n- 아래의 데이터를 관찰하자.\n\nx,_ = torch.randn(300).sort()\ny = relu(20*x) + torch.randn(300)\nx,y = x.reshape(-1,1), y.reshape(-1,1)\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n- 적합해보자.\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1000),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.1),\n    torch.nn.Linear(1000,1,bias=False),\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(5000):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nnet.eval()\n\nSequential(\n  (0): Linear(in_features=1, out_features=1000, bias=True)\n  (1): ReLU()\n  (2): Dropout(p=0.1, inplace=False)\n  (3): Linear(in_features=1000, out_features=1, bias=False)\n)\n\n\n\nnet.training\n\nFalse\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n- 주황색선이나오는 이유 설명해보자.\n\nU = net[:-1](x).data \nW = net[-1].weight.T \n\n아래3개는 동일한코드임\n\nnet(x).reshape(-1)[:10] # 코드1\n\ntensor([-0.9858, -0.5127, -0.4687,  0.0514,  0.0558,  0.2089,  0.2213,  0.2619,\n         0.2691,  0.2823], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n(U@W).reshape(-1)[:10] # 코드2\n\ntensor([-0.9858, -0.5127, -0.4687,  0.0514,  0.0558,  0.2089,  0.2213,  0.2619,\n         0.2691,  0.2823], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n((U*W.reshape(-1)).sum(axis=1))[:10] # 코드3\n\ntensor([-0.9858, -0.5127, -0.4687,  0.0514,  0.0558,  0.2089,  0.2213,  0.2619,\n         0.2691,  0.2823], grad_fn=&lt;SliceBackward0&gt;)\n\n\n따라서 아래의 주황색선들의 .sum(axis=1) 하기만 하면 net(x)의 결과가 된다.\n\nplt.plot(x,U*W.reshape(-1).data,color=\"C1\",alpha=0.02);\n\n\n\n\n\n\n\n\n- 즉 왼쪽의 주황색선1이 모두 합쳐져서 오른쪽의 점선이된다.\n1 1000개가 있음\nfig,ax = plt.subplots(1,2,figsize=(9,3))\nax[0].plot(x,U*W.reshape(-1).data,color=\"C1\",alpha=0.02);\nax[0].set_title(\"1,000 ReLUs\")\nax[1].plot(x,net(x).data,'--',color=\"C1\")\nax[1].set_title(r\"$net({\\bf x})$=sum(1,000 ReLUs)\");\n\n\n\n\n\n\n\n\n\n만약에 왼쪽의 주황색선이 10%만 사용되어서 100개의 렐루만 사용되었다면? 대충 x10을 해줘야 net(x) 가 나오지 않겠어요?"
  },
  {
    "objectID": "posts/04wk-2.html#a.-step은-표현-불가능하지-않나",
    "href": "posts/04wk-2.html#a.-step은-표현-불가능하지-않나",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "A. Step은 표현 불가능하지 않나?",
    "text": "A. Step은 표현 불가능하지 않나?\n# 예제1 – 일부러 이상하게 만든 취업합격률 곡선\n\ntorch.manual_seed(43052)\nx = torch.linspace(-1,1,2000).reshape(-1,1)\nu = 0*x-3\nu[x&lt;-0.2] = (15*x+6)[x&lt;-0.2]\nu[(-0.2&lt;x)&(x&lt;0.4)] = (0*x-1)[(-0.2&lt;x)&(x&lt;0.4)]\nsig = torch.nn.Sigmoid()\nv = π = sig(u)\ny = torch.bernoulli(v)\n\n\nplt.plot(x,y,'.',alpha=0.03, label=\"observed\")\nplt.plot(x,v,'--', label=\"unobserved\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03, label=\"observed\")\nplt.plot(x,v, label=\"true\")\nplt.plot(x,net(x).data,'--', label=\"estimated\")\nplt.legend()\n\n\n\n\n\n\n\n\n#"
  },
  {
    "objectID": "posts/04wk-2.html#b.-곡선은-표현-불가능하지-않나",
    "href": "posts/04wk-2.html#b.-곡선은-표현-불가능하지-않나",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "B. 곡선은 표현 불가능하지 않나?",
    "text": "B. 곡선은 표현 불가능하지 않나?\n# 예제2 – 2024년 수능 미적30번 문제에 나온 곡선\n\\[y_i = e^{-x_i} \\times  |\\cos(5x_i)| \\times \\sin(5x) + \\epsilon_i, \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\]\n\ntorch.manual_seed(43052)\nx = torch.linspace(0,2,2000).reshape(-1,1)\neps = torch.randn(2000).reshape(-1,1)*0.05\nfx = torch.exp(-1*x)* torch.abs(torch.cos(3*x))*(torch.sin(3*x))\ny = fx + eps\n\n\nplt.plot(x,y,label=\"observed\",alpha=0.5)\nplt.plot(x,fx,label=\"true\")\n\n\n\n\n\n\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048), # 꺽이지않은 1024개의 직선\n    torch.nn.ReLU(), # 꺽인(렐루된) 1024개의 직선 \n    torch.nn.Linear(2048,1), # 합쳐진 하나의 꺽인 직선 \n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n## \nfor epoc in range(1000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,label=\"observed\",alpha=0.5)\nplt.plot(x,fx,label=\"true\")\nplt.plot(x,net(x).data,'--',label=\"estimated\")\nplt.legend()\n\n\n\n\n\n\n\n\n#"
  },
  {
    "objectID": "posts/04wk-2.html#a.-시벤코정리-소개",
    "href": "posts/04wk-2.html#a.-시벤코정리-소개",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "A. 시벤코정리 소개",
    "text": "A. 시벤코정리 소개\n\n\n\n\n\n\nUniversal Approximation Thm (Cybenko 1989)\n\n\n\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크 \\(net: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\)는\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n모든 보렐 가측함수 (Borel measurable function)\n\\[f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\]\n를 원하는 정확도로 “근사”시킬 수 있다. 쉽게 말하면 \\({\\bf X} \\to {\\bf y}\\) 인 어떠한 복잡한 규칙라도 하나의 은닉층을 가진 신경망이 원하는 정확도로 근사시킨다는 의미이다. 예를들면 아래와 같은 문제를 해결할 수 있다.\n\n\\({\\bf X}_{n\\times 2}\\)는 토익점수, GPA 이고 \\({\\bf y}_{n\\times 1}\\)는 취업여부일 경우 \\({\\bf X} \\to {\\bf y}\\)인 규칙을 신경망은 항상 찾을 수 있다.\n\\({\\bf X}_{n \\times p}\\)는 주택이미지, 지역정보, 주택면적, 주택에 대한 설명 이고 \\({\\bf y}_{n\\times 1}\\)는 주택가격일 경우 \\({\\bf X} \\to {\\bf y}\\)인 규칙을 신경망은 항상 찾을 수 있다.\n\n즉 하나의 은닉층을 가진 신경망의 표현력은 거의 무한대라 볼 수 있다.\n\n\n\nCybenko, George. 1989. “Approximation by Superpositions of a Sigmoidal Function.” Mathematics of Control, Signals and Systems 2 (4): 303–14.\n\n보렐가측함수에 대한 정의는 측도론에 대한 이해가 있어야 가능함. 측도론에 대한 내용이 궁금하다면 https://guebin.github.io/SS2024/ 을 공부해보세요"
  },
  {
    "objectID": "posts/04wk-2.html#b.-왜-가능한가",
    "href": "posts/04wk-2.html#b.-왜-가능한가",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "B. 왜 가능한가??",
    "text": "B. 왜 가능한가??\n- 준비\n\nx = torch.linspace(-10,10,200).reshape(-1,1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(in_features=2,out_features=1)\n)\nl1,a1,l2 = net\n\n\nnet\n\nSequential(\n  (0): Linear(in_features=1, out_features=2, bias=True)\n  (1): Sigmoid()\n  (2): Linear(in_features=2, out_features=1, bias=True)\n)\n\n\n# 생각1 – 2개의 시그모이드를 우연히 잘 조합하면 하나의 계단함수를 만들 수 있다.\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+10.00,+10.00])\n\n\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\n\n\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x)[:,[0]].data,label=r\"$-5x+10$\")\nax[0].plot(x,l1(x)[:,[1]].data,label=r\"$5x+10$\")\nax[0].set_title('$l_1(x)$')\nax[0].legend()\nax[1].plot(x,a1(l1(x))[:,[0]].data,label=r\"$v_1=sig(-5x+10)$\")\nax[1].plot(x,a1(l1(x))[:,[1]].data,label=r\"$v_2=sig(5x+10)$\")\nax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[1].legend()\nax[2].plot(x,l2(a1(l1(x))).data,color='C2',label=r\"$v_1+v_2-1$\")\nax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$')\nax[2].legend()\n\n\n\n\n\n\n\n\n#\n# 생각2 – 계단함수의 모양이 꼭 생각1과 같을 필요는 없다. 중심은 이동가능하고, 높이도 조절가능하다.\n가능한 예시1\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+0.00,+20.00])\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data.numpy(),'--',color='C0'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C0'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C0'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nax[2].set_ylim(-0.1,2.6)\n\n\n\n\n\n\n\n\n가능한 예시2\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+20.00,+00.00])\nl2.weight.data = torch.tensor([[2.50,2.50]])\nl2.bias.data = torch.tensor([-2.50])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data.numpy(),'--',color='C1'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C1'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C1'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nax[2].set_ylim(-0.1,2.6)\n\n\n\n\n\n\n\n\n#\n# 생각3: 첫번째 선형변환(=\\(l_1\\))에서 out_features=4로 하고 적당한 가중치를 조정하면 \\((l_2\\circ a_1 \\circ l_1)(x)\\)의 결과로 생각2의 예시1,2를 조합한 형태도 가능할 것 같다. 즉 4개의 시그모이드를 잘 조합하면 2단계 계단함수를 만들 수 있다.\n\nl1 = torch.nn.Linear(in_features=1,out_features=4)\na1 = torch.nn.Sigmoid()\nl2 = torch.nn.Linear(in_features=4,out_features=1)\n\n\nl1.weight.data = torch.tensor([[-5.00],[5.00],[-5.00],[5.00]])\nl1.bias.data = torch.tensor([0.00, 20.00, 20.00, 0])\nl2.weight.data = torch.tensor([[1.00,  1.00, 2.50,  2.50]])\nl2.bias.data = torch.tensor([-1.0-2.5])\n\n\nplt.plot(l2(a1(l1(x))).data,'--')\nplt.title(r\"$(l_2 \\circ a_1 \\circ l_1)(x)$\")\n\nText(0.5, 1.0, '$(l_2 \\\\circ a_1 \\\\circ l_1)(x)$')\n\n\n\n\n\n\n\n\n\n\n이러한 함수는 계단모양이며, 0을 제외한 서로다른 계단의 높이는 2개가 된다. 이를 간단히 “2단계-계단함수”라고 칭하자.\n\n#\n# 생각4 – \\(2m\\)개의 시그모이드를 우연히 잘 조합하면 \\(m\\)단계 계단함수를 만들 수 있다.\n- 정리1: 2개의 시그모이드를 우연히 잘 결합하면 아래와 같은 “1단계-계단함수” 함수 \\(h\\)를 만들 수 있다.\n\ndef h(x):\n    sig = torch.nn.Sigmoid()\n    v1 = -sig(200*(x-0.5))\n    v2 = sig(200*(x+0.5))\n    return v1+v2 \n\n\nplt.plot(x,h(x))\nplt.title(\"$h(x)$\")\n\nText(0.5, 1.0, '$h(x)$')\n\n\n\n\n\n\n\n\n\n- 정리2: 위와 같은 함수 \\(h\\)를 이용한 아래의 네트워크를 고려하자. 이는 “m단계-계단함수”를 만든다.\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n그리고 위의 네트워크와 동일한 효과를 주는 아래의 네트워크가 항상 존재함.\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,2m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n#\n# 생각5 – 그런데 어지간한 함수형태는 구불구불한 “m단계-계단함수”로 다 근사할 수 있지 않나?\n그렇다면 아래의 네트워크에서 (1) ?? 를 충분히 키우고 (2) 적절하게 학습만 잘 된다면\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n위의 네트워크는 거의 무한한 표현력을 가진다. –&gt; 이런식으로 증명하면 됩니당\n#"
  },
  {
    "objectID": "posts/04wk-2.html#c.-h의-위력",
    "href": "posts/04wk-2.html#c.-h의-위력",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "C. \\(h\\)의 위력",
    "text": "C. \\(h\\)의 위력\n- 소망: 아래와 같이 net을 설계해서, 그 위력을 체감해보고 싶은데..\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,??),\n    torch.nn.H(),\n    torch.nn.Linear(??,1)\n)\n- \\(h(x)\\)를 생성하는 클래스를 만들어보자.\n\nclass H(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,x):\n        def h(x):\n            sig = torch.nn.Sigmoid()\n            v1 = -sig(200*(x-0.5))\n            v2 = sig(200*(x+0.5))\n            return v1+v2 \n        out = h(x)\n        return out \n\n\nh = H()\n\n- \\(h\\)의 위력을 체감해보자.\n# 예제1 – 스펙의 역설\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/ironyofspec.csv\")\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    H(),\n    torch.nn.Linear(2048,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(200):\n    ## 1 \n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,prob)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n#\n# 예제2 – 수능곡선\n\ntorch.manual_seed(43052)\nx = torch.linspace(0,2,2000).reshape(-1,1)\neps = torch.randn(2000).reshape(-1,1)*0.05\nfx = torch.exp(-1*x)* torch.abs(torch.cos(3*x))*(torch.sin(3*x))\ny = fx + eps\n\n\nplt.plot(x,y,alpha=0.5)\nplt.plot(x,fx)\n\n\n\n\n\n\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    H(),\n    torch.nn.Linear(2048,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(200):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,alpha=0.5)\nplt.plot(x,fx)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n#"
  },
  {
    "objectID": "posts/04wk-2.html#d.-의문점",
    "href": "posts/04wk-2.html#d.-의문점",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "D. 의문점",
    "text": "D. 의문점\n- 이 수업을 잘 이해한 사람: 그냥 활성화함수를 \\(h\\)로 쓰면 끝 아니야? 뭐하러 relu 를 쓰는거지?\n- 딥러닝을 좀 공부해본사람1: 왜 딥러닝이 2010년이 지나서야 떳지? 1989년에 세상의 모든 문제가 풀려야 하는것 아닌가?\n- 딥러닝을 좀 공부해본사람2: 하나의 은닉층을 가진 네크워크는 잘 안쓰지 않나? 은닉층이 깊을수록 좋다고 들었는데?\n- 약간의 의구심이 있지만 아무튼 우리는 아래의 무기를 가진 꼴이 되었다.\n\n\n\n\n\n\n우리의 무기\n\n\n\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크로,\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n\\(f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\) 인 모든 보렐 가측 함수 \\(f\\) 을 원하는 정확도로 “근사”시킬 수 있다."
  },
  {
    "objectID": "posts/04wk-2.html#a.-예비학습-plt.imshow",
    "href": "posts/04wk-2.html#a.-예비학습-plt.imshow",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "A. 예비학습 – plt.imshow()",
    "text": "A. 예비학습 – plt.imshow()\n- plt.imshow(..., cmap=\"gray\") 에서 ...이 shape이 (??,??)이면 흑백이미지를 출력\n\nimg = torch.tensor([[255,100],\n                    [255,0]])\nplt.imshow(img,cmap=\"gray\")\n\n\n\n\n\n\n\n\n- plt.imshow(...) 에서 ...의 shape이 (??,??,3)이면 칼라이미지를 출력\n\nr = torch.tensor([[255,0],\n                  [255,0]])\ng = torch.tensor([[0,255],\n                  [0,0]])\nb = torch.tensor([[0,0],\n                  [0,255]])\nimg = torch.stack([r,g,b],axis=-1)\nplt.imshow(img)\n\n\n\n\n\n\n\n\n- plt.imshow(...) 에서 ...의 자료형이 int인지 float인지에 따라서 인식이 다름\n\nr = torch.tensor([[1,0],\n                  [1,0]])\ng = torch.tensor([[0,1],\n                  [0,0]])\nb = torch.tensor([[0,0],\n                  [0,1]])\nimg = torch.stack([r,g,b],axis=-1)\nplt.imshow(img)\n\n\n\n\n\n\n\n\n\nr = torch.tensor([[255,0],\n                  [255,0]])/255\ng = torch.tensor([[0,255],\n                  [0,0]])/255\nb = torch.tensor([[0,0],\n                  [0,255]])/255\nimg = torch.stack([r,g,b],axis=-1)\nplt.imshow(img)"
  },
  {
    "objectID": "posts/04wk-2.html#b.-데이터",
    "href": "posts/04wk-2.html#b.-데이터",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "B. 데이터",
    "text": "B. 데이터\n- 데이터 정리코드\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX3 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==3])\nX7 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==7])\nX = torch.concat([X3,X7],axis=0)\ny = torch.tensor([0.0]*len(X3) + [1.0]*len(X7))\n\n\nplt.plot(y,'.')\n\n\n\n\n\n\n\n\n- 우리는 \\({\\bf X}: (n,1,28,28)\\) 에서 \\({\\bf y}: (n,1)\\)으로 가는 맵핑을 배우고 싶음. \\(\\to\\) 이런건 배운적이 없는데?.. \\(\\to\\) 그렇다면 \\({\\bf X}:(n,784) \\to {\\bf y}:(n,1)\\) 으로 가는 맵핑을 학습하자.\n\nX = torch.stack([img.reshape(-1) for img in X])\ny = y.reshape(-1,1)\n\n\nX.shape,y.shape\n\n(torch.Size([12396, 784]), torch.Size([12396, 1]))"
  },
  {
    "objectID": "posts/04wk-2.html#c.-학습",
    "href": "posts/04wk-2.html#c.-학습",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "C. 학습",
    "text": "C. 학습\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(200):\n    ## 1 \n    yhat = net(X) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y,'.')\nplt.plot(net(X).data,'.',alpha=0.2)\n\n\n\n\n\n\n\n\n\n((y == (net(X).data &gt; 0.5))*1.0).mean()\n\ntensor(0.9901)\n\n\n\n\n\n\n\n\nNote\n\n\n\n이미지자료의 차원\n\n칼라이미지데이터 \\({\\bf X}\\)는 (n,3,h,w) 의 차원을 가지거나 (n,h,w,3)의 차원을 가진다.\n흑백이미지데이터 \\({\\bf X}\\)는 (n,h,w) 의 차원을 가지거나 (n,1,h,w)의 차원을 가지거나 (n,h,w,1)의 차원을 가진다."
  },
  {
    "objectID": "posts/01wk-2.html#a.-아이스-아메리카노-가짜자료",
    "href": "posts/01wk-2.html#a.-아이스-아메리카노-가짜자료",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "A. 아이스 아메리카노 (가짜자료)",
    "text": "A. 아이스 아메리카노 (가짜자료)\n- 카페주인인 박혜원씨는 온도와 아이스아메리카노 판매량이 관계가 있다는 것을 알았다. 구체적으로는\n\n“온도가 높아질 수록 (=날씨가 더울수록) 아이스아메리카노의 판매량이 증가”\n\n한다는 사실을 알게 되었다. 이를 확인하기 위해서 아래와 같이 100개의 데이터를 모았다.\n\ntemp = [-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632]\n\n\nsales= [-8.5420, -6.5767, -5.9496, -4.4794, -4.2516, -3.1326, -4.0239, -4.1862,\n        -3.3403, -2.2027, -2.0262, -2.5619, -1.3353, -2.0466, -0.4664, -1.3513,\n        -1.6472, -0.1089, -0.3071, -0.6299, -0.0438,  0.4163,  0.4166, -0.0943,\n         0.2662,  0.4591,  0.8905,  0.8998,  0.6314,  1.3845,  0.8085,  1.2594,\n         1.1211,  1.9232,  1.0619,  1.3552,  2.1161,  1.1437,  1.6245,  1.7639,\n         1.6022,  1.7465,  0.9830,  1.7824,  2.1116,  2.8621,  2.1165,  1.5226,\n         2.5572,  2.8361,  3.3956,  2.0679,  2.8140,  3.4852,  3.6059,  2.5966,\n         2.8854,  3.9173,  3.6527,  4.1029,  4.3125,  3.4026,  3.2180,  4.5686,\n         4.3772,  4.3075,  4.4895,  4.4827,  5.3170,  5.4987,  5.4632,  6.0328,\n         5.2842,  5.0539,  5.4538,  6.0337,  5.7250,  5.7587,  6.2020,  6.5992,\n         6.4621,  6.5140,  6.6846,  7.3497,  8.0909,  7.0794,  6.8667,  7.4229,\n         7.2544,  7.1967,  9.5006,  9.0339,  7.4887,  9.0759, 11.0946, 10.3260,\n        12.2665, 13.0983, 12.5468, 13.8340]\n\n여기에서 temp는 평균기온이고, sales는 아이스아메리카노 판매량이다. 평균기온과 판매량의 그래프를 그려보면 아래와 같다.\n\nplt.plot(temp,sales,'o')\n\n\n\n\n\n\n\n\n오늘 바깥의 온도는 0.5도 이다. 아이스 아메라카노를 몇잔정도 만들어 두면 좋을까?"
  },
  {
    "objectID": "posts/01wk-2.html#b.-가짜자료를-만든-방법",
    "href": "posts/01wk-2.html#b.-가짜자료를-만든-방법",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "B. 가짜자료를 만든 방법",
    "text": "B. 가짜자료를 만든 방법\n- 방법1: \\(y_i= w_0+w_1 x_i +\\epsilon_i = 2.5 + 4x_i +\\epsilon_i, \\quad i=1,2,\\dots,n\\)\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\ny = x * 4 + 2.5 + eps\n\n\nx[:5], y[:5]\n\n(tensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792]),\n tensor([-8.5420, -6.5767, -5.9496, -4.4794, -4.2516]))\n\n\n- 방법2: \\({\\bf y}={\\bf X}{\\bf W} +\\boldsymbol{\\epsilon}\\)\n\n\\({\\bf y}=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\dots \\\\ y_n\\end{bmatrix}, \\quad {\\bf X}=\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots \\\\ 1 & x_n\\end{bmatrix}, \\quad {\\bf W}=\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}, \\quad \\boldsymbol{\\epsilon}= \\begin{bmatrix} \\epsilon_1 \\\\ \\dots \\\\ \\epsilon_n\\end{bmatrix}\\)\n\n\nX = torch.stack([torch.ones(100),x],axis=1)\nW = torch.tensor([[2.5],[4.0]])\ny = X@W + eps.reshape(100,1)\nx = X[:,[1]]\n\n\nX[:5,:], y[:5,:]\n\n(tensor([[ 1.0000, -2.4821],\n         [ 1.0000, -2.3621],\n         [ 1.0000, -1.9973],\n         [ 1.0000, -1.6239],\n         [ 1.0000, -1.4792]]),\n tensor([[-8.5420],\n         [-6.5767],\n         [-5.9496],\n         [-4.4794],\n         [-4.2516]]))\n\n\n- ture와 observed data를 동시에 시각화\n\nplt.plot(x,y,'o',label=r\"observed data: $(x_i,y_i)$\")\n#plt.plot(x,2.5+4*x,'--',label=r\"true: $(x_i, 4x_i+2.5)$ // $y=4x+2.5$ \")\nplt.legend()"
  },
  {
    "objectID": "posts/01wk-2.html#c.-회귀분석이란",
    "href": "posts/01wk-2.html#c.-회귀분석이란",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "C. 회귀분석이란?",
    "text": "C. 회귀분석이란?\n- 클리셰: 관측한 자료 \\((x_i,y_i)\\) 가 있음 \\(\\to\\) 우리는 \\((x_i,y_i)\\)의 관계를 파악하여 새로운 \\(x\\)가 왔을때 그것에 대한 예측값(predicted value) \\(\\hat{y}\\)을 알아내는 법칙을 알고 싶음 \\(\\to\\) 관계를 파악하기 위해서 \\((x_i, y_i)\\)의 산점도를 그려보니 \\(x_i\\)와 \\(y_i\\)는 선형성을 가지고 있다는 것이 파악됨 \\(\\to\\) 오차항이 등분산성을 가지고 어쩌고 저쩌고… \\(\\to\\) 하여튼 \\((x_i,y_i)\\) 를 “적당히 잘 관통하는” 어떠한 하나의 추세선을 잘 추정하면 된다.\n- 회귀분석이란 산점도를 보고 적당한 추세선을 찾는 것이다. 좀 더 정확하게 말하면 \\((x_1,y_1) \\dots (x_n,y_n)\\) 으로 \\(\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\) 를 최대한 \\(\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}\\)와 비슷하게 찾는 것.\n\ngiven data : \\(\\big\\{(x_i,y_i) \\big\\}_{i=1}^{n}\\)\nparameter: \\({\\bf W}=\\begin{bmatrix} w_0 \\\\ w_1 \\end{bmatrix}\\)\nestimated parameter: \\({\\bf \\hat{W}}=\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\)\n\n- 더 쉽게 말하면 아래의 그림을 보고 “적당한” 추세선을 찾는 것이다.\n\nplt.plot(x,y,'o',label=r\"observed data: $(x_i,y_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 추세선을 그리는 행위 = \\((w_0,w_1)\\)을 선택하는일"
  },
  {
    "objectID": "posts/01wk-2.html#a.-1단계-최초의-점선",
    "href": "posts/01wk-2.html#a.-1단계-최초의-점선",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "A. 1단계 – 최초의 점선",
    "text": "A. 1단계 – 최초의 점선\n\nWhat = torch.tensor([[-5.0],[10.0]])\nWhat\n\ntensor([[-5.],\n        [10.]])\n\n\n\nyhat = X@What \n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')"
  },
  {
    "objectID": "posts/01wk-2.html#b.-2단계-update",
    "href": "posts/01wk-2.html#b.-2단계-update",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "B. 2단계 – update",
    "text": "B. 2단계 – update\n- ’적당한 정도’를 판단하기 위한 장치: loss function 도입!\n\\[loss=\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2=({\\bf y}-{\\bf\\hat{y}})^\\top({\\bf y}-{\\bf\\hat{y}})=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\]\n- loss 함수의 특징: 위 그림의 주황색 점선이 ‘적당할 수록’ loss값이 작다.\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat)\n\n\n\n\n\n\n\n\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875)\n\n\n- 우리의 목표: 이 loss(=8587.6275)을 더 줄이자.\n\n궁극적으로는 아예 모든 조합 \\((\\hat{w}_0,\\hat{w}_1)\\)에 대하여 가장 작은 loss를 찾으면 좋겠다.\n\n- 문제의 치환: 생각해보니까 우리의 문제는 아래와 같이 수학적으로 단순화 되었다.\n\n가장 적당한 주황색 선을 찾자 \\(\\to\\) \\(loss(\\hat{w}_0,\\hat{w}_1)\\)를 최소로하는 \\((\\hat{w}_0,\\hat{w}_1)\\)의 값을 찾자.\n\n- 수정된 목표: \\(loss(\\hat{w}_0,\\hat{w}_1)\\)를 최소로 하는 \\((\\hat{w}_0,\\hat{w}_1)\\)을 구하라.\n\n단순한 수학문제가 되었다. 이것은 마치 \\(f(x,y)\\)를 최소화하는 \\((x,y)\\)를 찾으라는 것임.\n함수의 최대값 혹은 최소값을 컴퓨터를 이용하여 찾는것을 “최적화”라고 하며 이는 산공교수님들이 가장 잘하는 분야임. (산공교수님들에게 부탁하면 잘해줌, 산공교수님들은 보통 최적화해서 어디에 쓸지보다 최적화 자체에 더 관심을 가지고 연구하심)\n최적화를 하는 방법? 경사하강법\n\n# 경사하강법 아이디어 (1차원)\n\n임의의 점을 찍는다.\n그 점에서 순간기울기를 구한다. (접선) &lt;– 미분\n순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 움직인다.\n\n\n팁: 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 조절한다. \\(\\to\\) \\(\\alpha\\)를 도입\n\n\n최종수식: \\(\\hat{w} \\leftarrow \\hat{w} - \\alpha \\times \\frac{\\partial}{\\partial w}loss(w)\\)\n\n#\n# 경사하강법 아이디어 (2차원)\n\n\n임의의 점을 찍는다.\n그 점에서 순간기울기를 구한다. (접평면) &lt;– 편미분\n순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 각각 움직인다.\n\n\n팁: 여기서도 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 각각 조절한다. \\(\\to\\) \\(\\alpha\\)를 도입.\n\n#\n- 경사하강법 = loss를 줄이도록 \\({\\bf \\hat{W}}\\)를 개선하는 방법\n\n업데이트 공식: 수정값 = 원래값 - \\(\\alpha\\) \\(\\times\\) 기울어진크기(=미분계수)\n여기에서 \\(\\alpha\\)는 전체적인 보폭의 크기를 결정한다. 즉 \\(\\alpha\\)값이 클수록 한번의 update에 움직이는 양이 크다.\n\n- loss는 \\(\\hat{\\bf W} =\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\) 에 따라서 값이 바뀌는 함수로 해석가능하고 구체적인 형태는 아래와 같음.\n\\[ loss(\\hat{w}_0,\\hat{w}_1) := loss(\\hat{\\bf W})=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\]\n따라서 구하고 싶은것은 아래와 같음\n\\[\\hat{\\bf W}^{LSE} = \\underset{\\bf \\hat{W}}{\\operatorname{argmin}} ~ loss(\\hat{\\bf W})\\]\n\n\n\n\n\n\nWarning\n\n\n\n아래의 수식\n\\[\\hat{\\bf W}^{LSE} = \\underset{\\bf \\hat{W}}{\\operatorname{argmin}} ~ loss(\\hat{\\bf W})\\]\n은 아래와 같이 표현해도 무방합니다.\n\\[\\hat{\\bf W} = \\underset{\\bf W}{\\operatorname{argmin}} ~ loss({\\bf W})\\]\n마치 함수 \\(f(\\hat{x})=({\\hat x}-1)^2\\) 을 \\(f(x)=(x-1)^2\\) 이라고 표현할 수 있는 것 처럼요..\n\n\n여기까지 01wk-2에서 수업했습니다~\n\n여기부터는 02wk-1에서..\n# 지난시간 복습\n\n# x,X,W,y // X = [1 x], W = [w0, w1]' # 회귀분석에서는 W=β\n# 회귀모형: y=X@W+ϵ = X@β+ϵ\n# true: E(y)=X@W\n# observed: (x,y)\n# estimated W = What = [w0hat, w1hat]' &lt;-- 아무값이나넣었음.. \n# estimated y = yhat = X@What = X@β̂ \n# loss = yhat이랑 y랑 얼마나 비슷한지 = sum((y-yhat)^2)\n# (x,y) 보고 최적의 선분을 그리는것 = loss를 가장 작게 만드는 What = [w0hat, w1hat] 를 찾는것\n# 전략: (1) 아무 What나 찍는다 (2) 그거보다 더 나은 What을 찾는다. (3) 1-2를 반복한다. \n# 전략2가 어려운데, 이를 수행하는 방법이 경사하강법 \n# 경사하강법 알고리즘: 더나은What = 원래What - 0.1*미분값\n\n\nWhat = torch.tensor([[-5.0],[10.0]])\nWhat\n\ntensor([[-5.],\n        [10.]])\n\n\n\nyhat = X@What \nplt.plot(x,y,'o')\nplt.plot(x,yhat,'--')\n\n\n\n\n\n\n\n\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875)\n\n\n복습끝~\n#\n- 더 나은 선으로 업데이트하기 위해서는 공식 “더나은What = 원래What - 0.1*미분값” 를 적용해야하고 이를 위해서는 미분값을 계산할 수 있어야 함.\n\n\n\n\n\n\nImportant\n\n\n\n경사하강법을 좀 더 엄밀하게 써보자. 경사하강법은 \\(loss(\\hat{\\bf W})\\)를 최소로 만드는 \\(\\hat{\\bf W}\\)를 컴퓨터로 구하는 방법인데, 구체적으로는 아래와 같다.\n1. 임의의 점 \\(\\hat{\\bf W}\\)를 찍는다.\n2. 그 점에서 순간기울기를 구한다. 즉 \\(\\left.\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\right|_{{\\bf W}=\\hat{\\bf W}}\\) 를 계산한다.\n3. \\(\\hat{\\bf W}\\)에서의 순간기울기의 부호를 살펴보고 부호와 반대방향으로 움직인다. 이때 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 각각 조절한다. 즉 아래의 수식에 따라 업데이트 한다.\n\\[\\hat{\\bf W} \\leftarrow \\hat{\\bf W} - \\alpha \\times \\left.\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\right|_{{\\bf W}=\\hat{\\bf W}}\\]\n여기에서 맨 마지막 수식을 간단하게 쓴 것이 더나은What = 원래What - 0.1*미분값 이다.\n\n\n- 미분값을 계산하는 방법1\n\n# 손실 8587.6875 를 계산하는 또 다른 방식\ndef l(w0,w1):\n    yhat = w0 + w1*x\n    return torch.sum((y-yhat)**2)\n\n\nl(-5,10)\n\ntensor(8587.6875)\n\n\n\nh=0.001\nprint((l(-5+h,10) - l(-5,10))/h)\nprint((l(-5,10+h) - l(-5,10))/h)\n\ntensor(-1341.7968)\ntensor(1190.4297)\n\n\n일단 이거로 업데이트해볼까?\n\n# 더나은What = 원래What - 0.1*미분값\n# [-5,10] - 0.001 * [-1341.7968,1190.4297]\n\n\nsssss = What - 0.001 * torch.tensor([[-1341.7968],[1190.4297]])\nsssss\n\ntensor([[-3.6582],\n        [ 8.8096]])\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What,'-') # 원래What: 주황색\nplt.plot(x,X@sssss,'-') # 더나은What: 초록색\n\n\n\n\n\n\n\n\n\n잘 된 것 같긴한데..\n미분구하는게 너무 어려워..\n다른 방법 없을까?\n\n\n\n\n\n\n\nImportant\n\n\n\n사실 이 방법은\n\n\\(\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\approx \\frac{loss(w_0+h,w_1)-loss(w_0,w_1)}{h}\\)\n\\(\\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\approx \\frac{loss(w_0,w_1+h)-loss(w_0,w_1)}{h}\\)\n\n이 계산을 이용하여\n\\[\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W}):= \\begin{bmatrix} \\frac{\\partial}{\\partial w_0} \\\\ \\frac{\\partial}{\\partial w_1}\\end{bmatrix}loss({\\bf W}) =  \\begin{bmatrix} \\frac{\\partial}{\\partial w_0}loss({\\bf W}) \\\\ \\frac{\\partial}{\\partial w_1}loss({\\bf W})\\end{bmatrix}  =  \\begin{bmatrix} \\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\\\ \\frac{\\partial}{\\partial w_1}loss(w_0,w_1)\\end{bmatrix}\\]\n를 계산한 것이라 볼 수 있죠\n\n\n- 미분값을 계산하는 방법2\n\n## 약간의 지식이 필요함. \n# loss = (y-XWhat)'(y-XWhat)\n# = (y'-What'X')(y-XWhat)\n# = y'y-y'XWhat -What'X'y + What'X'XWhat \n# loss를 What으로 미분\n# loss' = -X'y - X'y + 2X'XWhat\n\n\n-2*X.T@y + 2*X.T@X@What\n\ntensor([[-1342.2524],\n        [ 1188.9302]])\n\n\n\n\n\n\n\n\nImportant\n\n\n\n이 방법은 \\(loss({\\bf W})\\)의 미분을 구할수 있어야 사용가능합니다. 즉\n\\[\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})= -2{\\bf X}^\\top {\\bf y} + 2{\\bf X}^\\top {\\bf X}{\\bf W}\\]\n를 계산할 수 있어야 합니다.\n\n\n- 미분값을 계산하는 방법3 – 이 패턴을 외우세여\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875, grad_fn=&lt;SumBackward0&gt;)\n\n\n\nloss.backward() # loss를 미분하라.. 꼬리표가 있게 한 What으로.. \n\n\nWhat.grad\n\ntensor([[-1342.2524],\n        [ 1188.9305]])\n\n\n- 위의 코드를 다시 복습해보자.\n– loss.backward()실행전 –\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\n\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n None)\n\n\n– loss.backward()실행후 –\n\nloss.backward()\n\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-1342.2524],\n         [ 1188.9305]]))\n\n\n# 1회 업데이트 과정을 차근차근 시각화하며 정리해보자.\n\nalpha = 0.001 \nprint(f\"{What.data} -- 수정전\")\nprint(f\"{-alpha*What.grad} -- 수정하는폭\")\nprint(f\"{What.data-alpha*What.grad} -- 수정후\")\nprint(f\"{torch.tensor([[2.5],[4]])} -- 참값(이건 비밀~~)\")\n\ntensor([[-5.],\n        [10.]]) -- 수정전\ntensor([[ 1.3423],\n        [-1.1889]]) -- 수정하는폭\ntensor([[-3.6577],\n        [ 8.8111]]) -- 수정후\ntensor([[2.5000],\n        [4.0000]]) -- 참값(이건 비밀~~)\n\n\n\nWbefore = What.data\nWafter = What.data - alpha * What.grad \nWbefore, Wafter\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-3.6577],\n         [ 8.8111]]))\n\n\n\nplt.plot(x,y,'o',label=r'observed data')\nplt.plot(x,X@Wbefore,'--', label=r\"$\\hat{\\bf y}_{before}={\\bf X}@\\hat{\\bf W}_{before}$\")\nplt.plot(x,X@Wafter,'--', label=r\"$\\hat{\\bf y}_{after}={\\bf X}@\\hat{\\bf W}_{after}$\")\nplt.legend()\n\n\n\n\n\n\n\n\n#"
  },
  {
    "objectID": "posts/01wk-2.html#c.-3단계-iteration-learn-estimate-bfhat-w",
    "href": "posts/01wk-2.html#c.-3단계-iteration-learn-estimate-bfhat-w",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "C. 3단계 – iteration (=learn = estimate \\(\\bf{\\hat W}\\))",
    "text": "C. 3단계 – iteration (=learn = estimate \\(\\bf{\\hat W}\\))\n- 이제 1단계와 2단계를 반복만하면된다. 그래서 아래와 같은 코드를 작성하면 될 것 같은데…\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True) # 최초의 직선을 만드는 값\nfor epoc in range(30):\n    yhat = X@What \n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n돌려보면 잘 안된다.\n- 아래와 같이 해야한다.\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True) # 최초의 직선을 만드는 값\nfor epoc in range(30):\n    yhat = X@What \n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    What.grad = None \n\n\nplt.plot(x,y,'o',label=r\"observed: $(x_i,y_i)$\")\nplt.plot(x,X@What.data,'--o', label=r\"estimated: $(x_i,\\hat{y}_i)$ -- after 30 iterations (=epochs)\", alpha=0.4 )\nplt.legend()\n\n\n\n\n\n\n\n\n- 왜? loss.backward() 는 아래의 역할을 하는것 처럼 이해되었지만\n\nWhat.grad \\(\\leftarrow\\) What에서미분값\n\n실제로는 아래의 역할을 수행하기 때문이다. (컴퓨터공학적인 이유로..)\n\nWhat.grad \\(\\leftarrow\\) What.grad + What에서미분값\n\n\n\n\n\n\n\nNote\n\n\n\nWhat.grad \\(\\leftarrow\\) What.grad + What에서미분값 임을 확인하기 위해서.. 약간의 테스트를 했습니다.\n먼저\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True) # 최초의 직선을 만드는 값\nprint(What.data)\nprint(What.grad)\n를 확인한뒤 아래를 반복실행해봤을때\nyhat = X@What \nloss = torch.sum((y-yhat)**2)\nloss.backward() # \nprint(What.data)\nprint(What.grad)\nWhat.data와 What.grad 값이 계속 일정하게 나온다면\n\nWhat.grad \\(\\leftarrow\\) What에서미분값\n\n이와 같은 계산이 진행되는 것이겠고, What.grad의 값이 자꾸 커진다면\n\nWhat.grad \\(\\leftarrow\\) What.grad + What에서미분값\n\n이와 같은 계산이 진행되는 것이겠죠?"
  },
  {
    "objectID": "posts/examguidelines.html",
    "href": "posts/examguidelines.html",
    "title": "A2: Exam Guidelines",
    "section": "",
    "text": "총 30분 (미정)\n\n\n\n\n\n답안지 (.ipynb)\n시험 장면 영상 촬영본\n\n\n\n\n\n답안지와 영상촬영본 모두 LMS에 업로드\n\n\n\n\n\n\n\nZoom 실행 후 로그인하여 새 회의 시작\n카메라와 마이크를 켠 상태로 시험 환경 세팅\n하단의 녹화 버튼 클릭 (또는 단축키 Alt + R)\n시험 종료 후 회의 종료 → 영상이 자동 저장됨\n\n기본 저장 위치: 내 PC &gt; 문서 &gt; Zoom 폴더\n\n\n※ Zoom 무료 계정은 40분 제한이 있으므로 시간 초과 주의\n※ 본 시험은 40분이므로 한 번에 녹화 가능\n\n\n\n\nCommand + Shift + 5 키 입력\n화면 하단 도구에서 전체 화면 또는 원하는 영역 지정 후 녹화 시작\n시험 종료 후 메뉴 막대에서 정지 버튼 클릭\n영상은 기본적으로 바탕화면에 저장됨\n\n\n기타 OBS Studio 등 녹화 프로그램을 활용해도 무방함. 녹화본은 반드시 시험 시작부터 종료까지 전 과정을 포함해야 하며 LMS 업로드 마감 시간 내 제출할 것"
  },
  {
    "objectID": "posts/examguidelines.html#시험-시간",
    "href": "posts/examguidelines.html#시험-시간",
    "title": "A2: Exam Guidelines",
    "section": "",
    "text": "총 30분 (미정)"
  },
  {
    "objectID": "posts/examguidelines.html#제출물",
    "href": "posts/examguidelines.html#제출물",
    "title": "A2: Exam Guidelines",
    "section": "",
    "text": "답안지 (.ipynb)\n시험 장면 영상 촬영본"
  },
  {
    "objectID": "posts/examguidelines.html#제출-방법",
    "href": "posts/examguidelines.html#제출-방법",
    "title": "A2: Exam Guidelines",
    "section": "",
    "text": "답안지와 영상촬영본 모두 LMS에 업로드"
  },
  {
    "objectID": "posts/examguidelines.html#영상-촬영-방법",
    "href": "posts/examguidelines.html#영상-촬영-방법",
    "title": "A2: Exam Guidelines",
    "section": "",
    "text": "Zoom 실행 후 로그인하여 새 회의 시작\n카메라와 마이크를 켠 상태로 시험 환경 세팅\n하단의 녹화 버튼 클릭 (또는 단축키 Alt + R)\n시험 종료 후 회의 종료 → 영상이 자동 저장됨\n\n기본 저장 위치: 내 PC &gt; 문서 &gt; Zoom 폴더\n\n\n※ Zoom 무료 계정은 40분 제한이 있으므로 시간 초과 주의\n※ 본 시험은 40분이므로 한 번에 녹화 가능\n\n\n\n\nCommand + Shift + 5 키 입력\n화면 하단 도구에서 전체 화면 또는 원하는 영역 지정 후 녹화 시작\n시험 종료 후 메뉴 막대에서 정지 버튼 클릭\n영상은 기본적으로 바탕화면에 저장됨\n\n\n기타 OBS Studio 등 녹화 프로그램을 활용해도 무방함. 녹화본은 반드시 시험 시작부터 종료까지 전 과정을 포함해야 하며 LMS 업로드 마감 시간 내 제출할 것"
  },
  {
    "objectID": "posts/06wk-1.html#a.-일반적인-trainvaltest-셋팅",
    "href": "posts/06wk-1.html#a.-일반적인-trainvaltest-셋팅",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴, 다중클래스 분류",
    "section": "A. 일반적인 train/val/test 셋팅",
    "text": "A. 일반적인 train/val/test 셋팅\n- Step1: 데이터정리\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\ntest_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX0 = torch.stack([to_tensor(img) for img, lbl in train_dataset if lbl==0])\nX1 = torch.stack([to_tensor(img) for img, lbl in train_dataset if lbl==1])\nX = torch.concat([X0,X1],axis=0).reshape(-1,784)\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\nXX0 = torch.stack([to_tensor(img) for img, lbl in test_dataset if lbl==0])\nXX1 = torch.stack([to_tensor(img) for img, lbl in test_dataset if lbl==1])\nXX = torch.concat([XX0,XX1],axis=0).reshape(-1,784)\nyy = torch.tensor([0.0]*len(XX0) + [1.0]*len(XX1)).reshape(-1,1)\n\n- Step2: 학습가능한 오브젝트들의 설정 (모델링과정 포함)\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n- Step3: 학습 (=적합)\n\nfor epoc in range(1,501):\n    #----에폭시작-----#\n    # step1 \n    yhat = net(X)\n    # step2 \n    loss = loss_fn(yhat,y)\n    # step3     \n    loss.backward()\n    # step4 \n    optimizr.step()\n    optimizr.zero_grad()\n    #-----에폭끝-----#\n    # 에폭별로 살펴보고 싶은 뭔가들.. \n    if (epoc % 50) == 0:\n        acc = ((net(X.data) &gt; 0.5) == y.data).float().mean()\n        print(f\"# of epochs = {epoc},\\t acc={acc.item(): .2f}\")\n\n# of epochs = 50,    acc= 0.45\n# of epochs = 100,   acc= 0.66\n# of epochs = 150,   acc= 0.85\n# of epochs = 200,   acc= 0.94\n# of epochs = 250,   acc= 0.97\n# of epochs = 300,   acc= 0.98\n# of epochs = 350,   acc= 0.99\n# of epochs = 400,   acc= 0.99\n# of epochs = 450,   acc= 0.99\n# of epochs = 500,   acc= 0.99\n\n\n- Step4: 예측 & 결과분석\ntrain acc\n\n((net(X) &gt; 0.5)*1.0 ==  y).float().mean()\n\ntensor(0.9936)\n\n\ntest acc\n\n((net(XX) &gt; 0.5)*1.0 ==  yy).float().mean()\n\ntensor(0.9986)"
  },
  {
    "objectID": "posts/06wk-1.html#b.-dropout-사용",
    "href": "posts/06wk-1.html#b.-dropout-사용",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴, 다중클래스 분류",
    "section": "B. Dropout 사용",
    "text": "B. Dropout 사용\n- Step1: 데이터정리\n\npass\n\n- Step2: 학습가능한 오브젝트들의 설정 (모델링과정 포함)\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.Dropout(0.5),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n- Step3: 학습 (=적합)\n\nfor epoc in range(1,501):\n    net.train()\n    #----에폭시작-----#\n    # step1 \n    yhat = net(X)\n    # step2 \n    loss = loss_fn(yhat,y)\n    # step3     \n    loss.backward()\n    # step4 \n    optimizr.step()\n    optimizr.zero_grad()\n    #-----에폭끝-----#\n    net.eval()\n    # 에폭별로 살펴보고 싶은 뭔가들.. \n    if (epoc % 50) == 0:\n        acc = ((net(X.data) &gt; 0.5) == y.data).float().mean()\n        print(f\"# of epochs = {epoc},\\t acc={acc.item(): .2f}\")\n\n# of epochs = 50,    acc= 0.45\n# of epochs = 100,   acc= 0.66\n# of epochs = 150,   acc= 0.84\n# of epochs = 200,   acc= 0.94\n# of epochs = 250,   acc= 0.97\n# of epochs = 300,   acc= 0.98\n# of epochs = 350,   acc= 0.99\n# of epochs = 400,   acc= 0.99\n# of epochs = 450,   acc= 0.99\n# of epochs = 500,   acc= 0.99\n\n\n- Step4: 예측 & 결과분석\ntrain acc\n\n((net(X) &gt; 0.5)*1.0 ==  y).float().mean()\n\ntensor(0.9935)\n\n\ntest acc\n\n((net(XX) &gt; 0.5)*1.0 ==  yy).float().mean()\n\ntensor(0.9986)"
  },
  {
    "objectID": "posts/06wk-1.html#c.-gpu도-사용",
    "href": "posts/06wk-1.html#c.-gpu도-사용",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴, 다중클래스 분류",
    "section": "C. GPU도 사용",
    "text": "C. GPU도 사용\n- Step1: 데이터정리\n\npass\n\n- Step2: 학습가능한 오브젝트들의 설정 (모델링과정 포함)\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.Dropout(0.5),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n).to(\"cuda:0\")\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n- Step3: 학습 (=적합)\n\nfor epoc in range(1,501):\n    net.train()\n    #----에폭시작-----#\n    X = X.to(\"cuda:0\")\n    y = y.to(\"cuda:0\")\n    # step1 \n    yhat = net(X)\n    # step2 \n    loss = loss_fn(yhat,y)\n    # step3     \n    loss.backward()\n    # step4 \n    optimizr.step()\n    optimizr.zero_grad()\n    #-----에폭끝-----#\n    net.eval()\n    # 에폭별로 살펴보고 싶은 뭔가들.. \n    if (epoc % 50) == 0:\n        acc = ((net(X.data) &gt; 0.5) == y.data).float().mean()\n        print(f\"# of epochs = {epoc},\\t acc={acc.item(): .2f}\")\n\n# of epochs = 50,    acc= 0.45\n# of epochs = 100,   acc= 0.66\n# of epochs = 150,   acc= 0.84\n# of epochs = 200,   acc= 0.94\n# of epochs = 250,   acc= 0.97\n# of epochs = 300,   acc= 0.98\n# of epochs = 350,   acc= 0.99\n# of epochs = 400,   acc= 0.99\n# of epochs = 450,   acc= 0.99\n# of epochs = 500,   acc= 0.99\n\n\n- Step4: 예측 & 결과분석\ntrain acc\n\n((net(X) &gt; 0.5) ==  y).float().mean()\n\ntensor(0.9934, device='cuda:0')\n\n\ntest acc\n\n#((net(XX) &gt; 0.5) ==  yy).float().mean() -- 오류나요\n\n\n방법1 – net을 cpu로 내림\n방법2 – net를 cuda에 유지 (=XX,yy를 cuda로 올림)\n\n\n# net를 쿠다에 유지하는 방법으로 해보자..\nXX = XX.to(\"cuda:0\")\nyy = yy.to(\"cuda:0\")\n((net(XX) &gt; 0.5) ==  yy).float().mean()\n\ntensor(0.9986, device='cuda:0')"
  },
  {
    "objectID": "posts/06wk-1.html#d.-미니배치도-사용",
    "href": "posts/06wk-1.html#d.-미니배치도-사용",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴, 다중클래스 분류",
    "section": "D. 미니배치도 사용",
    "text": "D. 미니배치도 사용\n- Step1: 데이터정리\n\nX = X.to(\"cpu\")\ny = y.to(\"cpu\")\nXX = XX.to(\"cpu\")\nyy = yy.to(\"cpu\")\n\n\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds, batch_size=16)\n\n- Step2: 학습가능한 오브젝트들의 설정 (모델링과정 포함)\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.Dropout(0.5),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n).to(\"cuda:0\")\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n- Step3: 학습 (=적합)\n\nfor epoc in range(1,3):\n    net.train()\n    #----에폭시작-----#\n    for Xm,ym in dl:\n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # step1 \n        ym_hat = net(Xm)\n        # step2 \n        loss = loss_fn(ym_hat,ym)\n        # step3     \n        loss.backward()\n        # step4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #-----에폭끝-----#\n    net.eval()\n    # 에폭별로 살펴보고 싶은 뭔가들..\n        # ## 방법1 -- net를 cpu로 내림\n        # net.to(\"cpu\")\n        # acc = ((net(X.data) &gt; 0.5) == y.data).float().mean()\n        # print(f\"# of epochs = {epoc},\\t acc={acc.item(): .4f}\")    \n        # net.to(\"cuda:0\")\n    ## 방법2 -- net을 cuda에 유지 \n    s = 0 \n    for Xm,ym in dl:\n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        ym_hat = net(Xm)\n        s = s + ((net(Xm.data) &gt; 0.5) == ym.data).float().sum()\n    acc = s/12665\n    print(f\"# of epochs = {epoc},\\t acc={acc.item(): .4f}\")\n\n# of epochs = 1,     acc= 0.9738\n# of epochs = 2,     acc= 0.9886\n\n\n- Step4: 예측 & 결과분석\n\nnet.to(\"cpu\")\n\nSequential(\n  (0): Linear(in_features=784, out_features=32, bias=True)\n  (1): Dropout(p=0.5, inplace=False)\n  (2): ReLU()\n  (3): Linear(in_features=32, out_features=1, bias=True)\n  (4): Sigmoid()\n)\n\n\ntrain acc\n\n((net(X) &gt; 0.5)*1.0 ==  y).float().mean()\n\ntensor(0.9886)\n\n\ntest acc\n\n((net(XX) &gt; 0.5)*1.0 ==  yy).float().mean()\n\ntensor(0.9953)\n\n\n\n점점 비본질적인 코드가 늘어남 (=코드가 드럽다는 소리에요) –&gt; Trainer의 개념 등장"
  },
  {
    "objectID": "posts/06wk-1.html#a.-이항분류와-bcewithlogitsloss",
    "href": "posts/06wk-1.html#a.-이항분류와-bcewithlogitsloss",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴, 다중클래스 분류",
    "section": "A. 이항분류와 BCEWithLogitsLoss",
    "text": "A. 이항분류와 BCEWithLogitsLoss\n- 데이터\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n# test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX0_train = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\nX1_train = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\n# X0_test = torch.stack([to_tensor(Xi) for Xi, yi in test_dataset if yi==0])\n# X1_test = torch.stack([to_tensor(Xi) for Xi, yi in test_dataset if yi==1])\nX = torch.concat([X0_train,X1_train],axis=0).reshape(-1,784)\ny = torch.tensor([0.0]*len(X0_train) + [1.0]*len(X1_train)).reshape(-1,1)\n# XX = torch.concat([X0_test,X1_test],axis=0).reshape(-1,784)\n# yy = torch.tensor([0.0]*len(X0_test) + [1.0]*len(X1_test)).reshape(-1,1)\n\n\n굳이 테스트는 필요없어서..\n\n- 예전코드는 아래와 같음 (sig는 수동처리함)\n\ntorch.manual_seed(0)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1)\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1,11):\n    # step1 \n    netout = net(X) # netout = logits \n    yhat = torch.exp(netout) / (1 + torch.exp(netout)) # yhat = prob \n    # step2\n    loss = loss_fn(yhat,y) \n    # step3     \n    loss.backward()\n    # step4 \n    optimizr.step()\n    optimizr.zero_grad()\n    #---에폭끝나고 확인할 것들---#\n    acc = ((net(X).data &gt; 0)  == y).float().mean()\n    print(f\"epoch = {epoc}\\t acc = {acc:.4f}\")\n\nepoch = 1    acc = 0.4677\nepoch = 2    acc = 0.4677\nepoch = 3    acc = 0.4745\nepoch = 4    acc = 0.5572\nepoch = 5    acc = 0.6995\nepoch = 6    acc = 0.8175\nepoch = 7    acc = 0.8904\nepoch = 8    acc = 0.9255\nepoch = 9    acc = 0.9444\nepoch = 10   acc = 0.9577\n\n\n# netout(= logits) 의 특징\n\n\\(netout &gt; 0 \\Leftrightarrow sig(netout) &gt;0.5\\)\n\\(netout &lt; 0 \\Leftrightarrow sig(netout) &lt;0.5\\)\n\n- 그런데 위의 코드는 아래의 코드와 같음\n\ntorch.manual_seed(0)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1)\n)\nloss_fn = torch.nn.BCEWithLogitsLoss() # &lt;--- 여기를 바꾸고 \noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1,11):\n    # step1 \n    netout = net(X) # netout = logits \n    # yhat = torch.exp(netout) / (1 + torch.exp(netout))  # yhat = prob \n    # step2\n    loss = loss_fn(netout,y) \n    # step3     \n    loss.backward()\n    # step4 \n    optimizr.step()\n    optimizr.zero_grad()\n    #---에폭끝나고 확인할 것들---#\n    acc = ((net(X).data &gt; 0)  == y).float().mean()\n    print(f\"epoch = {epoc}\\t acc = {acc:.4f}\")\n\nepoch = 1    acc = 0.4677\nepoch = 2    acc = 0.4677\nepoch = 3    acc = 0.4745\nepoch = 4    acc = 0.5572\nepoch = 5    acc = 0.6995\nepoch = 6    acc = 0.8175\nepoch = 7    acc = 0.8904\nepoch = 8    acc = 0.9255\nepoch = 9    acc = 0.9444\nepoch = 10   acc = 0.9577"
  },
  {
    "objectID": "posts/06wk-1.html#b.-범주형자료의-변환",
    "href": "posts/06wk-1.html#b.-범주형자료의-변환",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴, 다중클래스 분류",
    "section": "B. 범주형자료의 변환",
    "text": "B. 범주형자료의 변환\n- 범주형자료를 숫자로 어떻게 바꿀까?\n\n실패 / 성공 \\(\\to\\) 0 / 1\n숫자0그림 / 숫자1그림 \\(\\to\\) 0 / 1\n강아지그림 / 고양이그림 \\(\\to\\) 0 / 1\n강아지그림 / 고양이그림 / 토끼그림 \\(\\to\\) 0 / 1 / 2 ?????\n\n- 주입식교육: 강아지그림/고양이그림/토끼그림일 경우 숫자화시키는 방법\n\n잘못된방식: 강아지그림 = 0, 고양이그림 = 1, 토끼그림 = 2\n올바른방식: 강아지그림 = [1,0,0], 고양이그림 = [0,1,0], 토끼그림 = [0,0,1] ### &lt;– 이런방식을 원핫인코딩이라함\n\n- 왜?\n\n설명1: 강아지그림, 고양이그림, 토끼그림은 서열측도가 아니라 명목척도임. 그래서 범주를 0,1,2 로 숫자화하면 평균등의 의미가 없음 (사회조사분석사 2급 스타일)\n설명2: 범주형은 원핫인코딩으로 해야함 (“30일만에 끝내는 실전머신러닝” 이런 책에 나오는 스타일)\n설명3: 동전을 한번 던져서 나오는 결과는 \\(n=1\\)인 이항분포를 따름. 주사위 한번 던져서 나오는 눈금의 숫자는 \\(n=1\\)인 다항분포를 따름. \\(n=1\\)인 이항분포의 실현값은 0,1 이고, \\(n=1\\)인 다항분포의 실현값은 [1,0,0], [0,1,0], [0,0,1] 이므로 당연히 \\(y_i\\) 는 [1,0,0], [0,1,0], [0,0,1] 중 하나의 형태를 가진다고 가정하는게 바람직함 (이 설명이 이 중에서 가장 정확한 설명임)"
  },
  {
    "objectID": "posts/06wk-1.html#c.-실습-3개의-클래스를-구분",
    "href": "posts/06wk-1.html#c.-실습-3개의-클래스를-구분",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴, 다중클래스 분류",
    "section": "C. 실습: 3개의 클래스를 구분¶",
    "text": "C. 실습: 3개의 클래스를 구분¶\n- 데이터준비\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX0 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\nX1 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\nX2 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==2])\nX = torch.concat([X0,X1,X2]).reshape(-1,1*28*28)\ny = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2)).reshape(-1,1).float()\n\n\ny = torch.nn.functional.one_hot(y.flatten().long()).float()\n\n- 적합\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,3),\n)\nloss_fn = torch.nn.CrossEntropyLoss() # 이름이 좀 그래.. 나같으면 CEWithLogitsLoss 라고 했을듯 \noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(100):\n    ## step1 \n    netout = net(X)\n    ## step2 \n    loss = loss_fn(netout,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\n(net(X).argmax(axis=1)  == y.argmax(axis=1)).float().mean()\n\ntensor(0.9827)"
  },
  {
    "objectID": "posts/06wk-1.html#d.-결론-외우세여",
    "href": "posts/06wk-1.html#d.-결론-외우세여",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴, 다중클래스 분류",
    "section": "D. 결론 – 외우세여",
    "text": "D. 결론 – 외우세여\n- 파이토치버전 // 코딩용\n\n\n\n분류\nnetout의 의미\n손실함수\n\n\n\n\n이항분류\nprob\nBCELoss\n\n\n이항분류\nlogits\nBCEWithLogitsLoss\n\n\n다항분류\nprob\nNA\n\n\n다항분류\nlogits\nCrossEntropyLoss\n\n\n\n\nCrossEntropyLoss 이거 이름이 완전 마음에 안들어요.. CEWithLogitsLoss 라고 하는게 더 좋을 것 같습니다.\n\n- 일반적개념 // 이론용\n\n\n\n\n\n\n\n\n\n분류\n오차항의가정\n마지막활성화함수\n손실함수\n\n\n\n\n이항분류\n이항분포\nsigmoid1\nBinary Cross Entropy\n\n\n다항분류\n다항분포\nsoftmax2\nCross Entropy\n\n\n\n\n\n1 prob=sig(logit)2 probs=soft(logits)"
  },
  {
    "objectID": "posts/01wk-1.html#a.-torch",
    "href": "posts/01wk-1.html#a.-torch",
    "title": "01wk-1: (토치) – 강의소개, 파이토치 기본",
    "section": "A. torch",
    "text": "A. torch\n- 벡터\n\ntorch.tensor([1,2,3])\n\ntensor([1, 2, 3])\n\n\n- 벡터의 덧셈\n\ntorch.tensor([1,2,3]) + torch.tensor([2,2,2])\n\ntensor([3, 4, 5])\n\n\n- 브로드캐스팅\n\ntorch.tensor([1,2,3]) + 2\n\ntensor([3, 4, 5])"
  },
  {
    "objectID": "posts/01wk-1.html#b.-벡터와-매트릭스",
    "href": "posts/01wk-1.html#b.-벡터와-매트릭스",
    "title": "01wk-1: (토치) – 강의소개, 파이토치 기본",
    "section": "B. 벡터와 매트릭스",
    "text": "B. 벡터와 매트릭스\n- \\(3 \\times 2\\) matrix\n\ntorch.tensor([[1,2],[3,4],[5,6]]) \n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n- \\(3 \\times 1\\) matrix = \\(3 \\times 1\\) column vector\n\ntorch.tensor([[1],[3],[5]]) \n\ntensor([[1],\n        [3],\n        [5]])\n\n\n- \\(1 \\times 2\\) matrix = \\(1 \\times 2\\) row vector\n\ntorch.tensor([[1,2]]) \n\ntensor([[1, 2]])\n\n\n- 더하기\n브로드캐스팅(편한거)\n\ntorch.tensor([[1,2],[3,4],[5,6]]) - 1\n\ntensor([[0, 1],\n        [2, 3],\n        [4, 5]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-3],[-5]])\n\ntensor([[0, 1],\n        [0, 1],\n        [0, 1]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-2]])\n\ntensor([[0, 0],\n        [2, 2],\n        [4, 4]])\n\n\n잘못된 브로드캐스팅\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-3,-5]])\n\nRuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-2]])\n\nRuntimeError: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0\n\n\n이상한 것\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-2])\n\ntensor([[0, 0],\n        [2, 2],\n        [4, 4]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-3,-5])\n\nRuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\n\n\n- 행렬곱\n정상적인 행렬곱\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1],[2]])\n\ntensor([[ 5],\n        [11],\n        [17]])\n\n\n\ntorch.tensor([[1,2,3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\ntensor([[22, 28]])\n\n\n잘못된 행렬곱\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1,2]])\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 1x2)\n\n\n\ntorch.tensor([[1],[2],[3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (3x1 and 3x2)\n\n\n이상한 것\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([1,2]) # 이게 왜 가능..\n\ntensor([ 5, 11, 17])\n\n\n\ntorch.tensor([1,2,3]) @ torch.tensor([[1,2],[3,4],[5,6]]) # 이건 왜 가능?\n\ntensor([22, 28])"
  },
  {
    "objectID": "posts/01wk-1.html#c.-transpose-reshape",
    "href": "posts/01wk-1.html#c.-transpose-reshape",
    "title": "01wk-1: (토치) – 강의소개, 파이토치 기본",
    "section": "C. transpose, reshape",
    "text": "C. transpose, reshape\n- transpose\n\ntorch.tensor([[1,2],[3,4]]).T \n\ntensor([[1, 3],\n        [2, 4]])\n\n\n\ntorch.tensor([[1],[3]]).T \n\ntensor([[1, 3]])\n\n\n\ntorch.tensor([[1,2]]).T \n\ntensor([[1],\n        [2]])\n\n\n- reshape\n일반적인 사용\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(2,3)\n\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]])\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(1,6)\n\ntensor([[1, 2, 3, 4, 5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(6)\n\ntensor([1, 2, 3, 4, 5, 6])\n\n\n편한 것\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(2,-1)\n\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(6,-1)\n\ntensor([[1],\n        [2],\n        [3],\n        [4],\n        [5],\n        [6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(-1,6)\n\ntensor([[1, 2, 3, 4, 5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(-1)\n\ntensor([1, 2, 3, 4, 5, 6])"
  },
  {
    "objectID": "posts/01wk-1.html#d.-concat-stack-starstarstar",
    "href": "posts/01wk-1.html#d.-concat-stack-starstarstar",
    "title": "01wk-1: (토치) – 강의소개, 파이토치 기본",
    "section": "D. concat, stack \\((\\star\\star\\star)\\)",
    "text": "D. concat, stack \\((\\star\\star\\star)\\)\n- concat\n\na = torch.tensor([[1],[3],[5]])\nb = torch.tensor([[2],[4],[6]])\ntorch.concat([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n\ntorch.concat([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n- stack\n\na = torch.tensor([1,3,5])\nb = torch.tensor([2,4,6])\ntorch.stack([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n\ntorch.concat([a.reshape(3,1),b.reshape(3,1)],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n\n\n\n\n\n\nWarning\n\n\n\nconcat과 stack을 지금 처음본다면 아래를 복습하시는게 좋습니다.\nhttps://guebin.github.io/PP2024/posts/06wk-2.html#numpy와-축axis"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/04wk-1.html",
    "href": "posts/04wk-1.html",
    "title": "04wk-1: (신경망) – 로지스틱의 한계 극복",
    "section": "",
    "text": "1. 강의영상\n\n\n\n2. Imports\n\nimport torch\nimport matplotlib.pyplot as plt \nimport pandas as pd\n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n\n3. 꺽인직선을 만드는 방법\n지난시간복습\n\n# 오늘의 잔소리.. \n## 회귀(카페예제): yhat=직선=linr(x), 정규분포, MSEloss\n## 로지스틱(스펙과취업): yhat=곡선=sig(직선)=sig(linr(x)), 베르누이, BCELoss\n## 이름없음(스펙의역설): yhat=꺽인곡선=sig(꺽인직선)=sig(??), 베르누이, BCELOss\n\n- 로지스틱의 한계를 극복하기 위해서는 시그모이드를 취하기 전에 꺽인 그래프 모양을 만드는 기술이 있어야겠음.\n- 아래와 같은 벡터 \\({\\bf x}\\)를 가정하자.\n\nx = torch.linspace(-1,1,1001).reshape(-1,1)\nx\n\ntensor([[-1.0000],\n        [-0.9980],\n        [-0.9960],\n        ...,\n        [ 0.9960],\n        [ 0.9980],\n        [ 1.0000]])\n\n\n- 목표: 아래와 같은 벡터 \\({\\bf y}\\)를 만들어보자.\n\\[{\\bf y} = [y_1,y_2,\\dots,y_{n}]^\\top, \\quad y_i = \\begin{cases} 9x_i +4.5& x_i &lt;0 \\\\ -4.5x_i + 4.5& x_i &gt;0 \\end{cases}\\]\n\n\n\n\n\n\nCaution\n\n\n\n일반적으로 제 강의노트에서\n\n독립변수 = 설명변수 = \\({\\bf x}\\), \\({\\bf X}\\)\n종속변수 = 반응변수 = \\({\\bf y}\\)\n\n를 의미하는데요, 여기에서 \\(({\\bf x},{\\bf y})\\) 는 (독립변수,종속변수) 혹은 (설명변수,반응변수) 를 의미하는게 아닙니다.\n\n\n# 방법1 – 수식 그대로 구현\n\nplt.plot(x,9*x+4.5,color=\"blue\",alpha=0.1)\nplt.plot(x[x&lt;0], (9*x+4.5)[x&lt;0],color=\"blue\")\nplt.plot(x,-4.5*x+4.5,color=\"orange\",alpha=0.1)\nplt.plot(x[x&gt;0], (-4.5*x+4.5)[x&gt;0],color=\"orange\")\n\n\n\n\n\n\n\n\n\ny = x*0\ny[x&lt;0] = (9*x+4.5)[x&lt;0]\ny[x&gt;0] = (-4.5*x+4.5)[x&gt;0]\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n#\n# 방법2 – 렐루이용\n\nrelu = torch.nn.ReLU()\n#plt.plot(x,-4.5*relu(x),color=\"red\")\n#plt.plot(x,-9*relu(-x),color=\"blue\")\ny = -4.5*relu(x) + -9*relu(-x) + 4.5\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n- 좀 더 중간과정을 시각화 – (강의때 설명안했음)\n\nfig = plt.figure(figsize=(6, 4))\nspec = fig.add_gridspec(4, 3)\nax1 = fig.add_subplot(spec[:2,0]); ax1.set_title(r'$x$'); ax1.set_ylim(-1,1)\nax2 = fig.add_subplot(spec[2:,0]); ax2.set_title(r'$-x$'); ax2.set_ylim(-1,1)\nax3 = fig.add_subplot(spec[:2,1]); ax3.set_title(r'$relu(x)$'); ax3.set_ylim(-1,1)\nax4 = fig.add_subplot(spec[2:,1]); ax4.set_title(r'$relu(-x)$'); ax4.set_ylim(-1,1)\nax5 = fig.add_subplot(spec[1:3,2]); ax5.set_title(r'$-4.5 relu(x)-9 relu(-x)+4.5$')\n#---#\nax1.plot(x,'--',color='C0')\nax2.plot(-x,'--',color='C1')\nax3.plot(relu(x),'--',color='C0')\nax4.plot(relu(-x),'--',color='C1')\nax5.plot(-4.5*relu(x)-9*relu(-x)+4.5,'--',color='C2')\nfig.tight_layout()\n\n\n\n\n\n\n\n\n#\n# 방법3 – relu의 브로드캐스팅 활용\n- 우리가 하고 싶은 것\n\n# y = -4.5*relu(x) + -9*relu(-x) + 4.5\n\n- 아래와 같은 아이디어로 y를 계산해도 된다.\n\nx, relu 준비\nu = [x -x]\nv = relu(u) = [relu(x), relu(-x)] = [v1 v2]\ny = -4.5*v1 + -9*v2 + 4.5\n\n\nu = torch.concat([x,-x],axis=1)\nv = relu(u)\nv1 = v[:,[0]]\nv2 = v[:,[1]]\ny = -4.5*v1 -9*v2 + 4.5 \nplt.plot(x,y)\n\n\n\n\n\n\n\n\n#\n# 방법4 – y = linr(v)\n\n# 4. y = -4.5*v1 + -9*v2 + 4.5 = [v1 v2] @ [[-4.5],[-9]] + 4.5 \n# y = -4 + 3*x = [1 x] @ [[-4],[3]]\n\n\nx \nu = torch.concat([x,-x],axis=1)\nv = relu(u) \ny = v @ torch.tensor([[-4.5],[-9]]) + 4.5 \n\n\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n#\n# 방법5 – u = linr(x)\n\n# x \n# u = torch.concat([x,-x],axis=1)\n# v = relu(u) \n# y = v @ torch.tensor([[-4.5],[-9]]) + 4.5 \n\n\nx \nu = x @ torch.tensor([[1.0, -1.0]])\nv = relu(u) \ny = v @ torch.tensor([[-4.5],[-9]]) + 4.5 \n\n\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n#\n# 방법6 – torch.nn.Linear()를 이용\n\n# x \n# u = x @ torch.tensor([[1.0, -1.0]]) = l1(x) \n# v = relu(u) = a1(u)\n# y = v @ torch.tensor([[-4.5],[-9]]) + 4.5 = l2(v) \n\n\n# u = l1(x) # l1은 x-&gt;u인 선형변환: (n,1) -&gt; (n,2) 인 선형변환\nl1 = torch.nn.Linear(1,2,bias=False)\nl1.weight.data = torch.tensor([[1.0, -1.0]]).T \na1 = relu \nl2 = torch.nn.Linear(2,1,bias=True)\nl2.weight.data = torch.tensor([[-4.5],[-9]]).T \nl2.bias.data = torch.tensor([4.5])\n#---#\nx\nu = l1(x)\nv = a1(u) \ny = l2(v) \n\n\nplt.plot(x,y.data)\n\n\n\n\n\n\n\n\n\npwlinr = torch.nn.Sequential(l1,a1,l2)\nplt.plot(x,pwlinr(x).data)\n\n\n\n\n\n\n\n\n#\n\n\n\n\n\n\nNote\n\n\n\n수식표현\n(1) \\({\\bf X}=\\begin{bmatrix} x_1 \\\\ \\dots \\\\ x_n \\end{bmatrix}\\)\n(2) \\(l_1({\\bf X})={\\bf X}{\\bf W}^{(1)}\\overset{bc}{+} {\\boldsymbol b}^{(1)}=\\begin{bmatrix} x_1 & -x_1 \\\\ x_2 & -x_2 \\\\ \\dots & \\dots \\\\ x_n & -x_n\\end{bmatrix}\\)\n\n\\({\\bf W}^{(1)}=\\begin{bmatrix} 1 & -1 \\end{bmatrix}\\)\n\\({\\boldsymbol b}^{(1)}=\\begin{bmatrix} 0 & 0 \\end{bmatrix}\\)\n\n(3) \\((a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big)=\\begin{bmatrix} \\text{relu}(x_1) & \\text{relu}(-x_1) \\\\ \\text{relu}(x_2) & \\text{relu}(-x_2) \\\\ \\dots & \\dots \\\\ \\text{relu}(x_n) & \\text{relu}(-x_n)\\end{bmatrix}\\)\n(4) \\((l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\)\n\\(\\quad=\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)\n\n\\({\\bf W}^{(2)}=\\begin{bmatrix} -4.5 \\\\ -9 \\end{bmatrix}\\)\n\\(b^{(2)}=4.5\\)\n\n(5) \\(\\textup{pwlinr}({\\bf X})=(l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\)\n\\(\\quad =\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)\n\n\n\n\n4. 스펙의역설 적합\n- 다시한번 데이터 정리\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/ironyofspec.csv\")\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\n\n\n\n\n\n\n\n\n- Step1에 대한 생각: 네트워크를 어떻게 만들까? = 아키텍처를 어떻게 만들까? = 모델링\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n\n\\(l_1\\): torch.nn.Linear(1,2,bias=False)\n\\(a_1\\): torch.nn.ReLU()\n\\(l_2\\): torch.nn.Linear(2,1,bias=True)\n\\(a_2\\): torch.nn.Sigmoid()\n\n- Step1-4\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2,bias=False),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2,1,bias=True),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss() \noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## step1\n    yhat = net(x)\n    ## step2\n    loss = loss_fn(yhat,y)\n    ## step3\n    loss.backward()\n    ## step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\nplt.plot(x,yhat.data,'--')\n\n\n\n\n\n\n\n\n한번더~\n\nfor epoc in range(5000):\n    ## step1\n    yhat = net(x)\n    ## step2\n    loss = loss_fn(yhat,y)\n    ## step3\n    loss.backward()\n    ## step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\nplt.plot(x,yhat.data,'--')"
  },
  {
    "objectID": "posts/03wk-2.html#a.-로지스틱-모형",
    "href": "posts/03wk-2.html#a.-로지스틱-모형",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 로지스틱 모형",
    "text": "A. 로지스틱 모형\n- \\(x\\)가 커질수록 (혹은 작아질수록) \\(y=1\\)이 잘나오는 모형은 아래와 같이 설계할 수 있음 &lt;— 외우세요!!!\n\n\\(y_i \\sim {\\cal B}(\\pi_i),\\quad\\) where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)} = \\frac{1}{1+\\exp(-w_0-w_1x_i)}\\)\n\\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\n- 회귀모형과 로지스틱 모형의 비교\n\n회귀모형: \\(y_i \\sim {\\cal N}(w_0+w_1x_i, \\sigma^2)\\)1\n로지스틱: \\(y_i \\sim {\\cal B}\\big(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\big)\\)\n\n1 원래는 이렇게 썼었지.. \\(y_i = w_0 + w_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim {\\cal N}(0,\\sigma^2)\\)- 우리가 예측하고 싶은것\n\n회귀모형: 정규분포의 평균을 예측하고 싶음. 즉 \\(w_0+w_1x_i\\)를 예측하고 싶음. 예측값으로는 \\(\\hat{w}_0 + \\hat{w}_1x_i\\)를 사용!\n로지스틱: 베르누이의 평균을 예측하고 싶음. 즉 \\(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)를 예측하고 싶음. 예측값으로는 \\(\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}\\)를 사용!"
  },
  {
    "objectID": "posts/03wk-2.html#b.-데이터-스펙과-취업",
    "href": "posts/03wk-2.html#b.-데이터-스펙과-취업",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 데이터 – 스펙과 취업",
    "text": "B. 데이터 – 스펙과 취업\n\ntorch.manual_seed(43052)\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nw0,w1 = -1, 5\nprob = torch.exp(w0+w1*x) / (1+torch.exp(w0+w1*x)) \ny = torch.bernoulli(prob)\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'.',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.legend()"
  },
  {
    "objectID": "posts/03wk-2.html#c.-step1-net-설계-모델링",
    "href": "posts/03wk-2.html#c.-step1-net-설계-모델링",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "C. Step1: net 설계 (모델링)",
    "text": "C. Step1: net 설계 (모델링)\n- 최초의 곡선을 그려보자.\n\n최초의직선: \\(\\hat{y}_i= \\hat{w}_0+\\hat{w}_1x_i\\) 에서 아무 \\(\\hat{w}_0\\), \\(\\hat{w}_1\\) 을 설정하면 된다.\n최초의곡선: \\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\) 에서 아무 \\(\\hat{w}_0\\), \\(\\hat{w}_1\\) 을 설정하면 된다.\n\n\n\n\n\n\n\nNote\n\n\n\n일단은 초기 설정값을 \\(\\hat{w}_0 = -0.8\\), \\(\\hat{w}_1 = -0.3\\) 으로 하자. (실제값은 \\(w_0=-1\\), \\(w_1=5\\) 이다)\n\n\n# 방법1 – l1, sigmoid\n\nl1 = torch.nn.Linear(1,1)\nl1(x) # w0hat + w1hat*x \n\ntensor([[ 0.6311],\n        [ 0.6304],\n        [ 0.6297],\n        ...,\n        [-0.6902],\n        [-0.6909],\n        [-0.6916]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n\n\ndef sigmoid(x):\n    return torch.exp(x)/(1+torch.exp(x))\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.plot(x,sigmoid(l1(x)).data,'--b', label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$ -- first curve\")\nplt.legend()\n\n\n\n\n\n\n\n\n#\n# 방법2 – l1, a1\n\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n\n\na1 = torch.nn.Sigmoid()\n\n\nsigmoid(l1(x)), a1(l1(x)) # 똑같아요\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;DivBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;))\n\n\n- 지금까지의 구현 확인\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.plot(x,a1(l1(x)).data,'--b', label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$ -- first curve with $(a_1 \\circ l_1)(x)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n#\n# 방법3 - l1, a1 만들고 \\(\\to\\) net\n- 관찰: 지금 아래의 구조이다.\n\\[{\\bf x} \\overset{l_1}{\\to} {\\bf u} \\overset{a_1}{\\to} {\\bf v} = \\hat{\\bf y}\\]\n- 소망: 함수 \\(l_1, a_1\\) 의 합성을 하나로 묶어서\n\\[(a_1\\circ l_1)({\\bf x}) := net({\\bf x})\\]\n이러한 기능을 하는 하나의 함수 \\(net\\)을 만들 수 없을까?\n\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\na1 = torch.nn.Sigmoid()\n\n\nnet = torch.nn.Sequential(l1,a1) #l1을 취하고 그다음에 a1을 취하라는 의미\n\n\nnet(x), a1(l1(x)), sigmoid(l1(x))\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;DivBackward0&gt;))\n\n\n* net 구조 잠깐 살펴보기\n\nnet[0], net[1]\n\n(Linear(in_features=1, out_features=1, bias=True), Sigmoid())\n\n\n\nl1 is net[0]\n\nTrue\n\n\n\na1 is net[1]\n\nTrue\n\n\n#\n# 방법4 – net을 바로 만들기\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nnet[0].weight.data = torch.tensor([[-0.3]])\nnet[0].bias.data = torch.tensor([-0.8])\nyhat = net(x)\n\n\nnet(x)\n\ntensor([[0.3775],\n        [0.3775],\n        [0.3774],\n        ...,\n        [0.2499],\n        [0.2498],\n        [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n#"
  },
  {
    "objectID": "posts/03wk-2.html#d.-step14",
    "href": "posts/03wk-2.html#d.-step14",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "D. Step1~4",
    "text": "D. Step1~4\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net \nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n\nfor epoc in range(4900):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 5000 epochs')\n\nText(0.5, 1.0, 'after 5000 epochs')"
  },
  {
    "objectID": "posts/03wk-2.html#a.-시각화를-위한-준비",
    "href": "posts/03wk-2.html#a.-시각화를-위한-준비",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 시각화를 위한 준비",
    "text": "A. 시각화를 위한 준비\n\ndef plot_loss(loss_fn, ax=None, Wstar=[-1,5]):\n    w0hat,w1hat =torch.meshgrid(torch.arange(-10,3,0.1),torch.arange(-1,10,0.1),indexing='ij')\n    w0hat = w0hat.reshape(-1)\n    w1hat = w1hat.reshape(-1)\n    def l(w0hat,w1hat):\n        yhat = torch.exp(w0hat+w1hat*x)/(1+torch.exp(w0hat+w1hat*x))\n        return loss_fn(yhat,y) \n    loss = list(map(l,w0hat,w1hat))\n    #---#\n    if ax is None: \n        fig = plt.figure()\n        ax = fig.add_subplot(1,1,1,projection='3d')\n    ax.scatter(w0hat,w1hat,loss,s=0.001) \n    ax.scatter(w0hat[::20],w1hat[::20],loss[::20],s=0.1,color='C0') \n    w0star,w1star = np.array(Wstar).reshape(-1)\n    ax.scatter(w0star,w1star,l(w0star,w1star),s=200,marker='*',color='red',label=f\"W=[{w0star:.1f},{w1star:.1f}]\")\n    #---#\n    ax.elev = 15\n    ax.dist = -20\n    ax.azim = 75    \n    ax.legend()\n    ax.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax.set_xticks([-10,-5,0])  # x축 틱 간격 설정\n    ax.set_yticks([-10,0,10])  # y축 틱 간격 설정\n\n\ndef _learn_and_record(net, loss_fn, optimizr):\n    yhat_history = [] \n    loss_history = []\n    What_history = []\n    Whatgrad_history = []\n    What_history.append([net[0].bias.data.item(), net[0].weight.data.item()])\n    for epoc in range(100): \n        ## step1 \n        yhat = net(x)\n        ## step2 \n        loss = loss_fn(yhat,y)\n        ## step3\n        loss.backward() \n        ## step4 \n        optimizr.step()\n        ## record \n        if epoc % 5 ==0: \n            yhat_history.append(yhat.reshape(-1).data.tolist())\n            loss_history.append(loss.item())\n            What_history.append([net[0].bias.data.item(), net[0].weight.data.item()])\n            Whatgrad_history.append([net[0].bias.grad.item(), net[0].weight.grad.item()])\n        optimizr.zero_grad() \n        \n    return yhat_history, loss_history, What_history, Whatgrad_history\n    \ndef show_animation(net, loss_fn, optimizr):\n    yhat_history,loss_history,What_history,Whatgrad_history = _learn_and_record(net,loss_fn,optimizr)\n    \n    fig = plt.figure(figsize=(7.5,3.5))\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n    ## ax1: 왼쪽그림 \n    ax1.scatter(x,y,alpha=0.01)\n    ax1.scatter(x[0],y[0],color='C0',label=r\"observed data = $(x_i,y_i)$\")\n    ax1.plot(x,prob,'--',label=r\"prob (true) = $(x_i,\\frac{exp(-1+5x_i)}{1+exp(-1+5x_i)})$\")    \n    line, = ax1.plot(x,yhat_history[0],'--',label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$\") \n    ax1.legend()\n    ## ax2: 오른쪽그림 \n    plot_loss(loss_fn,ax2)\n    ax2.scatter(np.array(What_history)[0,0],np.array(What_history)[0,1],loss_history[0],color='blue',s=200,marker='*')    \n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        w0hat = np.array(What_history)[epoc,0]\n        w1hat = np.array(What_history)[epoc,1]\n        w0hatgrad = np.array(Whatgrad_history)[epoc,0]\n        w1hatgrad = np.array(Whatgrad_history)[epoc,1]\n        ax2.scatter(w0hat,w1hat,loss_history[epoc],color='grey')\n        ax2.set_title(f\"What.grad=[{w0hatgrad:.4f},{w1hatgrad:.4f}]\",y=0.8)\n        fig.suptitle(f\"epoch={epoc*5} // What=[{w0hat:.2f},{w1hat:.2f}] // Loss={loss_fn.__class__.__name__} // Opt={optimizr.__class__.__name__}\")\n        return line\n    ani = animation.FuncAnimation(fig, animate, frames=20)    \n    plt.close()\n    return ani\n\n\nfrom matplotlib import animation\nplt.rcParams[\"animation.html\"] = \"jshtml\"\n\n함수사용법\n\nloss_fn = torch.nn.MSELoss()\nplot_loss(loss_fn)\n\n\n\n\n\n\n\n\n\ntorch.manual_seed(42)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-2.html#b.-좋은-초기값",
    "href": "posts/03wk-2.html#b.-좋은-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 좋은 초기값",
    "text": "B. 좋은 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-2.html#c.-가능성-있는-초기값",
    "href": "posts/03wk-2.html#c.-가능성-있는-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 가능성 있는 초기값",
    "text": "C. 가능성 있는 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-2.html#d.-최악의-초기값",
    "href": "posts/03wk-2.html#d.-최악의-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 최악의 초기값",
    "text": "D. 최악의 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n해결하는 접근법:\n\n컴공스타일: 에폭을 늘려볼까?\n산공스타일: 옵티마이저를 바꿔볼까?\n통계스타일: Loss를 바꿔볼까?"
  },
  {
    "objectID": "posts/03wk-2.html#a.-bce-loss를-사용하여-학습",
    "href": "posts/03wk-2.html#a.-bce-loss를-사용하여-학습",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "A. BCE Loss를 사용하여 학습",
    "text": "A. BCE Loss를 사용하여 학습\n- BCE loss라는게 있음.\n\n\\(loss= - \\sum_{i=1}^{n} \\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\)\nhttps://en.wikipedia.org/wiki/Cross-entropy\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net \nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    #loss = torch.mean((y-yhat)**2) # loss_fn(yhat,y)\n    loss = -torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat))\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n같은 100 에폭인데 훨씬 잘맞춤..\n- loss수식을 못외우겠다면?\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net \nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) # yhat부터 써야함\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')"
  },
  {
    "objectID": "posts/03wk-2.html#b.-loss-function-시각화",
    "href": "posts/03wk-2.html#b.-loss-function-시각화",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "B. Loss Function 시각화",
    "text": "B. Loss Function 시각화\n\nplot_loss(torch.nn.MSELoss())\n\n\n\n\n\n\n\n\n\nplot_loss(torch.nn.BCELoss())\n\n\n\n\n\n\n\n\n- 비교해보자.\n\nfig = plt.figure()\nax1 = fig.add_subplot(1,2,1,projection='3d')\nax2 = fig.add_subplot(1,2,2,projection='3d')\nplot_loss(torch.nn.MSELoss(),ax1)\nplot_loss(torch.nn.BCELoss(),ax2)"
  },
  {
    "objectID": "posts/03wk-2.html#c.-학습과정-시각화-좋은-초기값",
    "href": "posts/03wk-2.html#c.-학습과정-시각화-좋은-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 학습과정 시각화 – 좋은 초기값",
    "text": "C. 학습과정 시각화 – 좋은 초기값\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-2.html#d.-학습과정-시각화-가능성-있는-초기값",
    "href": "posts/03wk-2.html#d.-학습과정-시각화-가능성-있는-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 학습과정 시각화 – 가능성 있는 초기값",
    "text": "D. 학습과정 시각화 – 가능성 있는 초기값\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-2.html#e.-학습과정-시각화-최악의-초기값",
    "href": "posts/03wk-2.html#e.-학습과정-시각화-최악의-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "E. 학습과정 시각화 – 최악의 초기값",
    "text": "E. 학습과정 시각화 – 최악의 초기값\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-2.html#a.-학습과정-시각화-좋은-초기값",
    "href": "posts/03wk-2.html#a.-학습과정-시각화-좋은-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 학습과정 시각화 – 좋은 초기값",
    "text": "A. 학습과정 시각화 – 좋은 초기값\n- MSELoss + SGD\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8470])\nnet[0].weight.data = torch.tensor([[-0.3467]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-2.html#b.-학습과정-시각화-가능성-있는-초기값",
    "href": "posts/03wk-2.html#b.-학습과정-시각화-가능성-있는-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 학습과정 시각화 – 가능성 있는 초기값",
    "text": "B. 학습과정 시각화 – 가능성 있는 초기값\n- MSELoss + SGD\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-2.html#c.-학습과정-시각화-최악의-초기값",
    "href": "posts/03wk-2.html#c.-학습과정-시각화-최악의-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 학습과정 시각화 – 최악의 초기값",
    "text": "C. 학습과정 시각화 – 최악의 초기값\n- MSELoss + SGD\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-2.html#d.-참고자료",
    "href": "posts/03wk-2.html#d.-참고자료",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 참고자료",
    "text": "D. 참고자료\nhttps://www.youtube.com/watch?v=MD2fYip6QsQ\n\n11:50 – Momentum\n12:30 – RMSprop\n15:55 – Adam"
  },
  {
    "objectID": "posts/03wk-2.html#a.-신문기사-데이터의-모티브",
    "href": "posts/03wk-2.html#a.-신문기사-데이터의-모티브",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 신문기사 (데이터의 모티브)",
    "text": "A. 신문기사 (데이터의 모티브)\n- 스펙이 높아도 취업이 안된다고 합니다..\n중소·지방 기업 “뽑아봤자 그만두니까”\n중소기업 관계자들은 고스펙 지원자를 꺼리는 이유로 높은 퇴직률을 꼽는다. 여건이 좋은 대기업으로 이직하거나 회사를 관두는 경우가 많다는 하소연이다. 고용정보원이 지난 3일 공개한 자료에 따르면 중소기업 청년취업자 가운데 49.5%가 2년 내에 회사를 그만두는 것으로 나타났다.\n중소 IT업체 관계자는 “기업 입장에서 가장 뼈아픈 게 신입사원이 그만둬서 새로 뽑는 일”이라며 “명문대 나온 스펙 좋은 지원자를 뽑아놔도 1년을 채우지 않고 그만두는 사원이 대부분이라 우리도 눈을 낮춰 사람을 뽑는다”고 말했다."
  },
  {
    "objectID": "posts/03wk-2.html#b.-가짜데이터-스펙의-역설",
    "href": "posts/03wk-2.html#b.-가짜데이터-스펙의-역설",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 가짜데이터 – 스펙의 역설",
    "text": "B. 가짜데이터 – 스펙의 역설\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/ironyofspec.csv\")\ndf\n\n\n\n\n\n\n\n\nx\nprob\ny\n\n\n\n\n0\n-1.000000\n0.000045\n0.0\n\n\n1\n-0.998999\n0.000046\n0.0\n\n\n2\n-0.997999\n0.000047\n0.0\n\n\n3\n-0.996998\n0.000047\n0.0\n\n\n4\n-0.995998\n0.000048\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n0.995998\n0.505002\n0.0\n\n\n1996\n0.996998\n0.503752\n0.0\n\n\n1997\n0.997999\n0.502501\n0.0\n\n\n1998\n0.998999\n0.501251\n1.0\n\n\n1999\n1.000000\n0.500000\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.legend()"
  },
  {
    "objectID": "posts/03wk-2.html#c.-로지스틱으로-적합",
    "href": "posts/03wk-2.html#c.-로지스틱으로-적합",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 로지스틱으로 적합",
    "text": "C. 로지스틱으로 적합\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---# \nfor epoc in range(5000):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.plot(x,net(x).data, '--', label= r\"prob (estimated) = $(x_i,\\hat{y}_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- Epoch을 10억번으로 설정해도 이건 못 맞출것 같음."
  },
  {
    "objectID": "posts/03wk-2.html#d.-로지스틱-한계극복-아이디어만",
    "href": "posts/03wk-2.html#d.-로지스틱-한계극복-아이디어만",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 로지스틱 한계극복 – 아이디어만",
    "text": "D. 로지스틱 한계극복 – 아이디어만\n- sigmoid를 넣기 전의 상태가 직선이 아니라 꺽이는 직선이야 한다.\n\na = torch.nn.Sigmoid()\n\n\nfig,ax = plt.subplots(4,2,figsize=(8,8))\nu1 = torch.tensor([-6,-4,-2,0,2,4,6])\nu2 = torch.tensor([6,4,2,0,-2,-4,-6])\nu3 = torch.tensor([-6,-2,2,6,2,-2,-6])\nu4 = torch.tensor([-6,-2,2,6,4,2,0])\nax[0,0].plot(u1,'--o',color='C0',label = r\"$u_1$\")\nax[0,0].legend()\nax[0,1].plot(a(u1),'--o',color='C0',label = r\"$a(u_1)=\\frac{exp(u_1)}{exp(u_1)+1}$\")\nax[0,1].legend()\nax[1,0].plot(u2,'--o',color='C1',label = r\"$u_2$\")\nax[1,0].legend()\nax[1,1].plot(a(u2),'--o',color='C1',label = r\"$a(u_2)=\\frac{exp(u_2)}{exp(u_2)+1}$\")\nax[1,1].legend()\nax[2,0].plot(u3,'--o',color='C2', label = r\"$u_3$\")\nax[2,0].legend()\nax[2,1].plot(a(u3),'--o',color='C2', label = r\"$a(u_3)=\\frac{exp(u_3)}{exp(u_3)+1}$\")\nax[2,1].legend()\nax[3,0].plot(u4,'--o',color='C3', label = r\"$u_4$\")\nax[3,0].legend()\nax[3,1].plot(a(u4),'--o',color='C3', label = r\"$a(u_4)=\\frac{exp(u_4)}{exp(u_4)+1}$\")\nax[3,1].legend()"
  },
  {
    "objectID": "posts/02wk-2.html#a.-print",
    "href": "posts/02wk-2.html#a.-print",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "A. print",
    "text": "A. print\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nprint(f\"시작값 = {What.data.reshape(-1)}\")\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - alpha * What.grad\n    print(f'loss = {loss:.2f} \\t 업데이트폭 = {-alpha * What.grad.reshape(-1)} \\t 업데이트결과: {What.data.reshape(-1)}')\n    What.grad = None\n\n시작값 = tensor([-5., 10.])\nloss = 8587.69   업데이트폭 = tensor([ 1.3423, -1.1889])      업데이트결과: tensor([-3.6577,  8.8111])\nloss = 5675.21   업데이트폭 = tensor([ 1.1029, -0.9499])      업데이트결과: tensor([-2.5548,  7.8612])\nloss = 3755.64   업데이트폭 = tensor([ 0.9056, -0.7596])      업데이트결과: tensor([-1.6492,  7.1016])\nloss = 2489.58   업데이트폭 = tensor([ 0.7431, -0.6081])      업데이트결과: tensor([-0.9061,  6.4935])\nloss = 1654.04   업데이트폭 = tensor([ 0.6094, -0.4872])      업데이트결과: tensor([-0.2967,  6.0063])\nloss = 1102.32   업데이트폭 = tensor([ 0.4995, -0.3907])      업데이트결과: tensor([0.2028, 5.6156])\nloss = 737.84    업데이트폭 = tensor([ 0.4091, -0.3136])      업데이트결과: tensor([0.6119, 5.3020])\nloss = 496.97    업데이트폭 = tensor([ 0.3350, -0.2519])      업데이트결과: tensor([0.9469, 5.0501])\nloss = 337.71    업데이트폭 = tensor([ 0.2742, -0.2025])      업데이트결과: tensor([1.2211, 4.8477])\nloss = 232.40    업데이트폭 = tensor([ 0.2243, -0.1629])      업데이트결과: tensor([1.4454, 4.6848])\nloss = 162.73    업데이트폭 = tensor([ 0.1834, -0.1311])      업데이트결과: tensor([1.6288, 4.5537])\nloss = 116.63    업데이트폭 = tensor([ 0.1500, -0.1056])      업데이트결과: tensor([1.7787, 4.4480])\nloss = 86.13     업데이트폭 = tensor([ 0.1226, -0.0851])      업데이트결과: tensor([1.9013, 4.3629])\nloss = 65.93     업데이트폭 = tensor([ 0.1001, -0.0687])      업데이트결과: tensor([2.0014, 4.2942])\nloss = 52.57     업데이트폭 = tensor([ 0.0818, -0.0554])      업데이트결과: tensor([2.0832, 4.2388])\nloss = 43.72     업데이트폭 = tensor([ 0.0668, -0.0447])      업데이트결과: tensor([2.1500, 4.1941])\nloss = 37.86     업데이트폭 = tensor([ 0.0545, -0.0361])      업데이트결과: tensor([2.2045, 4.1579])\nloss = 33.97     업데이트폭 = tensor([ 0.0445, -0.0292])      업데이트결과: tensor([2.2490, 4.1287])\nloss = 31.40     업데이트폭 = tensor([ 0.0363, -0.0236])      업데이트결과: tensor([2.2853, 4.1051])\nloss = 29.70     업데이트폭 = tensor([ 0.0296, -0.0191])      업데이트결과: tensor([2.3150, 4.0860])\nloss = 28.57     업데이트폭 = tensor([ 0.0242, -0.0155])      업데이트결과: tensor([2.3392, 4.0705])\nloss = 27.83     업데이트폭 = tensor([ 0.0197, -0.0125])      업데이트결과: tensor([2.3589, 4.0580])\nloss = 27.33     업데이트폭 = tensor([ 0.0161, -0.0101])      업데이트결과: tensor([2.3750, 4.0479])\nloss = 27.00     업데이트폭 = tensor([ 0.0131, -0.0082])      업데이트결과: tensor([2.3881, 4.0396])\nloss = 26.79     업데이트폭 = tensor([ 0.0107, -0.0067])      업데이트결과: tensor([2.3988, 4.0330])\nloss = 26.64     업데이트폭 = tensor([ 0.0087, -0.0054])      업데이트결과: tensor([2.4075, 4.0276])\nloss = 26.55     업데이트폭 = tensor([ 0.0071, -0.0044])      업데이트결과: tensor([2.4146, 4.0232])\nloss = 26.48     업데이트폭 = tensor([ 0.0058, -0.0035])      업데이트결과: tensor([2.4204, 4.0197])\nloss = 26.44     업데이트폭 = tensor([ 0.0047, -0.0029])      업데이트결과: tensor([2.4251, 4.0168])\nloss = 26.41     업데이트폭 = tensor([ 0.0038, -0.0023])      업데이트결과: tensor([2.4290, 4.0144])"
  },
  {
    "objectID": "posts/02wk-2.html#b.-시각화-yhat의-관점에서",
    "href": "posts/02wk-2.html#b.-시각화-yhat의-관점에서",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "B. 시각화 – yhat의 관점에서!",
    "text": "B. 시각화 – yhat의 관점에서!\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nplt.plot(x,y,'o',label = \"observed\")\nfig = plt.gcf()\nax = fig.gca()\nax.plot(x,X@What.data,'--',color=\"C1\")\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - alpha * What.grad\n    ax.plot(x,X@What.data,'--',color=\"C1\",alpha=0.1)\n    What.grad = None"
  },
  {
    "objectID": "posts/02wk-2.html#c.-시각화-loss의-관점에서",
    "href": "posts/02wk-2.html#c.-시각화-loss의-관점에서",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "C. 시각화 – loss의 관점에서!!",
    "text": "C. 시각화 – loss의 관점에서!!\n\ndef plot_loss():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    w0 = np.arange(-6, 11, 0.5) \n    w1 = np.arange(-6, 11, 0.5)\n    W1,W0 = np.meshgrid(w1,w0)\n    LOSS=W0*0\n    for i in range(len(w0)):\n        for j in range(len(w1)):\n            LOSS[i,j]=torch.sum((y-w0[i]-w1[j]*x)**2)\n    ax.plot_surface(W0, W1, LOSS, rstride=1, cstride=1, color='b',alpha=0.1)\n    ax.azim = 30  ## 3d plot의 view 조절 \n    ax.dist = 8   ## 3d plot의 view 조절 \n    ax.elev = 5   ## 3d plot의 view 조절 \n    ax.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax.set_xticks([-5,0,5,10])  # x축 틱 간격 설정\n    ax.set_yticks([-5,0,5,10])  # y축 틱 간격 설정\n    plt.close(fig)  # 자동 출력 방지\n    return fig\n\n\n# 손실 8587.6875 를 계산하는 또 다른 방식\ndef l(w0hat,w1hat):\n    yhat = w0hat + w1hat*x\n    return torch.sum((y-yhat)**2)\n\n\nfig = plot_loss()\nax = fig.gca()\nax.scatter(2.5, 4, l(2.5,4), s=200, marker='*', color='red', label=r\"${\\bf W}=[2.5, 4]'$\")\nax.scatter(-5, 10, l(-5,10), s=200, marker='*', color='blue', label=r\"initial $\\hat{\\bf W}=[-5, 10]'$\")\nax.legend()\nfig\n\n\n\n\n\n\n\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    w0,w1 = What.data.reshape(-1) \n    ax.scatter(w0,w1,l(w0,w1),s=5,marker='o',color='blue')\n    What.grad = None\n\n\nfig"
  },
  {
    "objectID": "posts/02wk-2.html#d.-애니메이션",
    "href": "posts/02wk-2.html#d.-애니메이션",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "D. 애니메이션",
    "text": "D. 애니메이션\n\nfrom matplotlib import animation\n\n\nplt.rcParams['figure.figsize'] = (7.5,2.5)\nplt.rcParams[\"animation.html\"] = \"jshtml\" \n\n\ndef show_animation(alpha=0.001):\n    ## 1. 히스토리 기록을 위한 list 초기화\n    loss_history = [] \n    yhat_history = [] \n    What_history = [] \n\n    ## 2. 학습 + 학습과정기록\n    What= torch.tensor([[-5.0],[10.0]],requires_grad=True)\n    What_history.append(What.data.tolist())\n    for epoc in range(30): \n        yhat=X@What ; yhat_history.append(yhat.data.tolist())\n        loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n        loss.backward() \n        What.data = What.data - alpha * What.grad; What_history.append(What.data.tolist())\n        What.grad = None    \n\n    ## 3. 시각화 \n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\n    #### ax1: yhat의 관점에서.. \n    ax1.plot(x,y,'o',label=r\"$(x_i,y_i)$\")\n    line, = ax1.plot(x,yhat_history[0],label=r\"$(x_i,\\hat{y}_i)$\") \n    ax1.legend()\n    #### ax2: loss의 관점에서.. \n    w0 = np.arange(-6, 11, 0.5) \n    w1 = np.arange(-6, 11, 0.5)\n    W1,W0 = np.meshgrid(w1,w0)\n    LOSS=W0*0\n    for i in range(len(w0)):\n        for j in range(len(w1)):\n            LOSS[i,j]=torch.sum((y-w0[i]-w1[j]*x)**2)\n    ax2.plot_surface(W0, W1, LOSS, rstride=1, cstride=1, color='b',alpha=0.1)\n    ax2.azim = 30  ## 3d plot의 view 조절 \n    ax2.dist = 8   ## 3d plot의 view 조절 \n    ax2.elev = 5   ## 3d plot의 view 조절 \n    ax2.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax2.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax2.set_xticks([-5,0,5,10])  # x축 틱 간격 설정\n    ax2.set_yticks([-5,0,5,10])  # y축 틱 간격 설정\n    ax2.scatter(2.5, 4, l(2.5,4), s=200, marker='*', color='red', label=r\"${\\bf W}=[2.5, 4]'$\")\n    ax2.scatter(-5, 10, l(-5,10), s=200, marker='*', color='blue')\n    ax2.legend()\n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        ax2.scatter(np.array(What_history)[epoc,0],np.array(What_history)[epoc,1],loss_history[epoc],color='grey')\n        fig.suptitle(f\"alpha = {alpha} / epoch = {epoc}\")\n        return line\n\n    ani = animation.FuncAnimation(fig, animate, frames=30)\n    plt.close()\n    return ani\n\n\nani = show_animation(alpha=0.001)\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/02wk-2.html#e.-학습률에-따른-시각화",
    "href": "posts/02wk-2.html#e.-학습률에-따른-시각화",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "E. 학습률에 따른 시각화",
    "text": "E. 학습률에 따른 시각화\n- \\(\\alpha\\)가 너무 작다면 비효율적임\n\nshow_animation(alpha=0.0001)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- \\(\\alpha\\)가 크다고 무조건 좋은건 또 아님\n\nshow_animation(alpha=0.0083)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 수틀리면 수렴안할수도??\n\nshow_animation(alpha=0.0085)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 그냥 망할수도??\n\nshow_animation(alpha=0.01)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nplt.rcdefaults()\nplt.rcParams['figure.figsize'] = 4.5,3.0"
  },
  {
    "objectID": "posts/02wk-2.html#a.-기본패턴",
    "href": "posts/02wk-2.html#a.-기본패턴",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "A. 기본패턴",
    "text": "A. 기본패턴\n\n## -- 외우세요!!! -- ##\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    loss = torch.sum((y-yhat)**2)/100\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.1 * What.grad\n    What.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')\nplt.title(f'What={What.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/02wk-2.html#b.-step2의-수정-loss_fn-이용",
    "href": "posts/02wk-2.html#b.-step2의-수정-loss_fn-이용",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "B. Step2의 수정 – loss_fn 이용",
    "text": "B. Step2의 수정 – loss_fn 이용\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nloss_fn = torch.nn.MSELoss()\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    #loss = torch.sum((y-yhat)**2)/100\n    loss = loss_fn(yhat,y) # 여기서는 큰 상관없지만 습관적으로 yhat을 먼저넣는 연습을 하자!!\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.1 * What.grad\n    What.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')\nplt.title(f'What={What.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/02wk-2.html#c.-step1의-수정-net-이용",
    "href": "posts/02wk-2.html#c.-step1의-수정-net-이용",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "C. Step1의 수정 – net 이용",
    "text": "C. Step1의 수정 – net 이용\n# net – net 오브젝트란?\n원래 yhat을 이런식으로 구했는데 ~\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nyhat= X@What\nyhat[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n아래와 같은 방식으로 코드를 짜고 싶음..\nyhat = net(X) # \n위와 같은 코드를 가능하게 하는 net은 torch에서 지원하고 아래와 같이 사용할 수 있음.\n\n# yhat = net(X) \nnet = torch.nn.Linear(\n    in_features=2, # X:(n,2) --&gt; 2 \n    out_features=1, # yhat:(n,1) --&gt; 1 \n    bias=False \n)\n\n\nnet.weight.data = torch.tensor([[-5.0], [10.0]]).T # .T 를 해야함. 외우세요 \nnet.weight\n\nParameter containing:\ntensor([[-5., 10.]], requires_grad=True)\n\n\n\nnet(X)[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n(X@What)[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n(X@net.weight.T)[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n#\n- 수정된코드\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\nfor epoc in range(30):\n    # step1: yhat\n    # yhat = X@What \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    net.weight.data = net.weight.data - 0.1 * net.weight.grad\n    net.weight.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/02wk-2.html#d.-step4의-수정-optimizer의-이용",
    "href": "posts/02wk-2.html#d.-step4의-수정-optimizer의-이용",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "D. Step4의 수정 – optimizer의 이용",
    "text": "D. Step4의 수정 – optimizer의 이용\n- 소망: 아래의 과정을 좀 더 편하게 했으면..\nnet.weight.data = net.weight.data - 0.1 * net.weight.grad\nnet.weight.data = None \n# optimizer – 이걸 이용하면 update 과정을 손쉽게 할 수 있음\n기존코드\n\n## -- 준비과정 -- ## \n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n\n\n## -- 1에폭진행 -- ## \n# step1: \nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\nnet.weight.data = net.weight.data - 0.1 * net.weight.grad\nprint(net.weight.data)\nnet.weight.grad = None\n\ntensor([[-5., 10.]])\ntensor([[-3.6577,  8.8111]])\n\n\n\n## -- 2에폭진행 -- ## \n# step1: 2에폭진행\nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\nnet.weight.data = net.weight.data - 0.1 * net.weight.grad\nprint(net.weight.data)\nnet.weight.grad = None\n\ntensor([[-3.6577,  8.8111]])\ntensor([[-2.5548,  7.8612]])\n\n\n새로운코드 – optimizer 이용\n\n## -- 준비과정 -- ## \n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비\noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\n\n\n## -- 1에폭진행 -- ## \nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\n#net.weight.data = net.weight.data - 0.1 * net.weight.grad\noptimizr.step()\nprint(net.weight.data)\n#net.weight.grad = None\noptimizr.zero_grad()\n\ntensor([[-5., 10.]])\ntensor([[-3.6577,  8.8111]])\n\n\n\n## -- 2에폭진행 -- ## \nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\n#net.weight.data = net.weight.data - 0.1 * net.weight.grad\noptimizr.step()\nprint(net.weight.data)\n#net.weight.grad = None\noptimizr.zero_grad()\n\ntensor([[-3.6577,  8.8111]])\ntensor([[-2.5548,  7.8612]])\n\n\n#\n- 수정된코드\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비 \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/exercise.html#벡터와-행렬",
    "href": "posts/exercise.html#벡터와-행렬",
    "title": "A1: Exercise",
    "section": "$. 벡터와 행렬",
    "text": "$. 벡터와 행렬\n(1) 아래와 같이 length 5 인 vector를 torch.tensor로 선언하는 코드를 작성하라.\n\\[{\\bf x} = [1,2,3,4,5]\\]\n(풀이)\n\nx = torch.tensor([1,2,3,4,5])\nx\n\ntensor([1, 2, 3, 4, 5])\n\n\n(2) 아래와 같은 2x2 matrix 를 torch.tensor로 선언하는 코드를 작성하라.\n\\[{\\bf A} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}\\]\n(3) 아래와 같은 matrix 를 torch.tensor로 선언하는 코드를 작성하라.\n\\[{\\bf W} = \\begin{bmatrix} 2.5  \\\\  4 \\end{bmatrix}\\]\n(4) 아래와 같은 matrix 를 torch.tensor로 선언하는 코드를 작성하라.\n\\[{\\bf x} = \\begin{bmatrix} 2.5  & 4 \\end{bmatrix}\\]"
  },
  {
    "objectID": "posts/exercise.html#concat-stack",
    "href": "posts/exercise.html#concat-stack",
    "title": "A1: Exercise",
    "section": "$. concat, stack",
    "text": "$. concat, stack\na,b가 아래와 같이 주어졌다고 하자.\n\na = torch.tensor([1]*10)\nb = torch.tensor([2]*10)\n\n아래를 잘 읽고 물음에 답하라.\n(1) 주어진 a,b와 torch.concat를 이용하여 아래와 같은 배열을 만들어라.\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n\ntorch.concat([a.reshape(-1,1), b.reshape(-1,1)])\n\ntensor([[1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2]])\n\n\n(2) 주어진 a,b 와 torch.concat,.reshape를 이용하여 아래와 같은 배열을 만들어라.\ntensor([[1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2]])\n(3) 주어진 a,b 와 torch.concat,.reshape를 이용하여 아래와 같은 배열을 만들어라.\ntensor([[1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2]])\n(4) 주어진 a,b와 torch.stack 을 이용하여 아래와 같은 배열을 만들어라.\ntensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]\n(5) 주어진 a,b와 torch.stack을 이용하여 아래와 같은 배열을 만들어라.\ntensor([[1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2]])"
  },
  {
    "objectID": "posts/exercise.html#행렬곱",
    "href": "posts/exercise.html#행렬곱",
    "title": "A1: Exercise",
    "section": "$. 행렬곱",
    "text": "$. 행렬곱\n(1) 아래와 같은 텐서를 고려하자.\n\na = torch.tensor([1,2,3,4,5]).reshape(-1,1)\nb = torch.tensor([3,2,1,1,2]).reshape(-1,1)\n\n@ 연산자를 이용하여 \\(\\sum_{i=1}^{5}a_ib_i\\)를 계산하라.\n(풀이)\n\na.T @ b\n\ntensor([[24]])\n\n\n(2) 아래와 같은 텐서를 고려하자.\n\ntorch.manual_seed(0)\nx = torch.randn(100).reshape(-1,1)\n\n@연산자를 이용하여 \\(\\sum_{i=1}^{100}x_i^2\\)을 계산하라."
  },
  {
    "objectID": "posts/exercise.html#인덱싱",
    "href": "posts/exercise.html#인덱싱",
    "title": "A1: Exercise",
    "section": "$. 인덱싱",
    "text": "$. 인덱싱\n아래와 같은 배열을 선언하라.\n\ntorch.manual_seed(1)\nx = torch.randn(12).reshape(3,4)\nx\n\ntensor([[ 0.6614,  0.2669,  0.0617,  0.6213],\n        [-0.4519, -0.1661, -1.5228,  0.3817],\n        [-1.0276, -0.5631, -0.8923, -0.0583]])\n\n\n(1) 1열을 추출하는 코드를 작성하라. 즉 결과가 아래와 같이 나오도록 하라.\ntensor([[ 0.6614],\n        [-0.4519],\n        [-1.0276]])\n(2) 2-3열을 추출하는 코드를 작성하라. 즉 결과가 아래와 같이 나오도록 하라.\ntensor([[ 0.2669,  0.0617],\n        [-0.1661, -1.5228],\n        [-0.5631, -0.8923]])\n(3) 2-3행을 추출하는 코드를 작성하라. 즉 결과가 아래와 같이 나오도록 하라.\ntensor([[-0.4519, -0.1661, -1.5228,  0.3817],\n        [-1.0276, -0.5631, -0.8923, -0.0583]])"
  },
  {
    "objectID": "posts/exercise.html#회귀dl2024-mid-3",
    "href": "posts/exercise.html#회귀dl2024-mid-3",
    "title": "A1: Exercise",
    "section": "$. 회귀(DL2024-MID-3)",
    "text": "$. 회귀(DL2024-MID-3)\n\n이 문제의 경우 풀이가 https://guebin.github.io/DL2024/posts/09wk-2.html#%EB%8B%A8%EC%88%9C%ED%9A%8C%EA%B7%80%EB%AC%B8%EC%A0%9C-10%EC%A0%90 에 있습니다.\n\n주어진 자료가 아래와 같다고 하자.\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\nx = x.reshape(-1,1)\nϵ = torch.randn(100).reshape(-1,1)*0.5\ny = 2.5+ 4*x + ϵ\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n(1) torch.nn.Linear를 이용하여 아래와 같은 최초의 직선을 생성하는 네트워크를 설계하라.\n\\[\\hat{y}_i = -5.0 + 10.0 x_i \\]\n(2) 아래의 수식에 대응하는 loss를 계산하라. 여기에서 \\(\\hat{y}_i\\)은 (1)의 결과로 얻은 값을 사용하라.\n\\[loss = \\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2\\]\n(3) 적당한 matrix \\({\\bf X}_{n\\times 2}\\) 와 \\(\\hat{\\bf W}_{2\\times 1}\\)을 정의하여 아래와 같이 \\(\\hat{y}_i\\)을 구하라.\n\\[\\hat{y}_i = -5.0 + 5.0 x_i \\]\n(4) 아래의 수식에 대응하는 loss를 계산하라. 여기에서 \\(\\hat{y}_i\\)은 (3)의 결과로 얻은 값을 사용하라.\n\\[loss = \\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2\\]\n(5) (2)에서 얻은 \\(\\hat{y}_i\\) (4)에서 얻은 \\(\\hat{y}_i\\) 중 무엇이 더 적절하다고 생각하는가? 이유는 무엇인가? 손실(=loss)에 근거하여 설명하라.\n(6) .backward() 를 이용하여 (2)와 (4)에 해당하는 미분값을 계산하라. 학습률이 0.01인 경사하강법을 이용하여 (1),(3) 에 대응하는 가중치를 update 하라."
  },
  {
    "objectID": "posts/exercise.html#회귀5obs",
    "href": "posts/exercise.html#회귀5obs",
    "title": "A1: Exercise",
    "section": "$. 회귀(5obs)",
    "text": "$. 회귀(5obs)\n아래와 같은 5개의 자료를 관측하였다고 가정하자.\n\n\n\n\nx\ny\n\n\n\n\n0\n11\n17.7\n\n\n1\n12\n18.5\n\n\n2\n13\n21.2\n\n\n3\n14\n23.6\n\n\n4\n15\n24.2\n\n\n\n\\(x\\)에서 \\(y\\)로 향하는 규칙을 찾기 위해 아래와 같은 모형을 고려하였다. (\\(\\beta_0, \\beta_1\\) 대신에 \\(w_0, w_1\\) 이라 생각해도 무방)\n\\[y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i, \\quad i =1,2,\\dots, n\\]\n(1) \\(\\hat{\\beta}_0=3, \\hat{\\beta}_1=3\\) 일 경우의 loss를 계산하라. 단, 손실함수는 MSELoss로 설정한다.\n(2) \\(\\hat{\\beta}_0=3, \\hat{\\beta}_1=3\\) 에서 손실함수의 미분계수를 계산하라.\n(3) 아래의 제약사항을 준수하여 추정값 \\(\\hat{\\beta}_0=3, \\hat{\\beta}_1=3\\) 의 값을 1회 update하라.\n제약사항\n\nyhat = X@Bhat 을 만족하는 적당한 X, Bhat을 선언하여 문제를 풀 것. (즉 torch.nn.Linear() 를 사용하지 말 것)\n손실함수는 torch.nn.MSELoss()를 사용하지 말고 직접 손실을 구할 것\n(확률적)경사하강법을 이용하여 update 하되 직접 수식을 입력할 것. 즉 torch.optim.SGD()를 사용하지 말 것.\n학습률은 0.001로 설정할 것\n\n(4) 아래의 제약사항을 준수하여 추정값 \\(\\hat{\\beta}_0=3, \\hat{\\beta}_1=3\\) 의 값을 다시 1회 update하라. 결과를 (3)과 비교하라 (동일결과가 나와야함)\n제약사항\n\nyhat = net(X) 을 만족하는 적당한 X, net을 선언하여 문제를 풀 것. 이때 net는 torch.nn.Linear(??,??,bias=False) 를 사용하여 선언할 것.\n손실함수는 torch.nn.MSELoss()를 사용하지 말고 직접 손실을 구할 것\n(확률적)경사하강법을 이용하여 update 하되 직접 수식을 입력할 것. 즉 torch.optim.SGD()를 사용하지 말 것.\n학습률은 0.001로 설정할 것\n\n(5) 아래의 제약사항을 준수하여 추정값 \\(\\hat{\\beta}_0=3, \\hat{\\beta}_1=3\\) 의 값을 다시 1회 update하라. 결과를 (3)-(4)와 비교하라 (모두 동일결과가 나와야함)\n제약사항\n\nyhat = net(X) 을 만족하는 적당한 X, net을 선언하여 문제를 풀 것. 이때 net는 torch.nn.Linear(??,??,bias=False) 를 사용하여 선언할 것.\n손실함수는 torch.nn.MSELoss()를 사용하지 말고 직접 손실을 구할 것\ntorch.optim.SGD()를 이용하여 update할 것\n학습률은 0.001로 설정할 것\n\n(6) 아래의 제약사항을 준수하여 추정값 \\(\\hat{\\beta}_0=3, \\hat{\\beta}_1=3\\) 의 값을 다시 1회 update하라. 결과를 (3)-(5)와 비교하라 (모두 동일결과가 나와야함)\n제약사항\n\nyhat = net(x) 을 만족하는 적당한 x, net을 선언하여 문제를 풀 것. 이때 net는 torch.nn.Linear(??,??,bias=True) 를 사용하여 선언할 것.\n손실함수는 torch.nn.MSELoss()를 사용하지 말고 직접 손실을 구할 것\n(확률적)경사하강법을 이용하여 update 하되 직접 수식을 입력할 것. 즉 torch.optim.SGD()를 사용하지 말 것.\n학습률은 0.001로 설정할 것"
  },
  {
    "objectID": "posts/exercise.html#회귀2d",
    "href": "posts/exercise.html#회귀2d",
    "title": "A1: Exercise",
    "section": "$. 회귀(2d)",
    "text": "$. 회귀(2d)\n아래의 데이터를 고려하자.\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/regression_2d.csv\")\nx1 = torch.tensor(df.x1).float().reshape(-1,1)\nx2 = torch.tensor(df.x2).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\n\n\\(x_1, x_2\\) 에서 \\(y\\)로 향하는 규칙을 찾기 위해 아래와 같은 모형을 고려하였다. (\\(\\beta_0,\\beta_1,\\beta_2\\) 대신에 \\(w_0, w_1, w_2\\) 라고 생각해도 무방)\n\\[y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\epsilon_i \\quad i = 1, 2, \\ldots, n\\]\n(1) 아래의 제약사항에 맞추어서 \\(\\beta_0,\\beta_1,\\beta_2\\)의 값을 추정하라.\n제약사항\n\nyhat = X@Bhat 을 만족하는 적당한 X, Bhat을 선언하여 문제를 풀 것. (즉 torch.nn.Linear() 를 사용하지 말 것)\n손실함수는 MSE로 설정하되 torch.nn.MSELoss()를 사용하지 말고 직접 손실을 구할 것\n(확률적)경사하강법을 이용하여 update 하되 직접 수식을 입력할 것. 즉 torch.optim.SGD()를 사용하지 말 것.\n\nhint: 참값은 \\(\\beta_0=2.5, \\beta_1=4 , \\beta_2= -2\\) 임\n(2) (1)에서 구한 X에 대하여 아래의 수식을 이용하여 추정값을 구하여라.\n\\[\\hat{\\boldsymbol \\beta}^{LSE} = \\begin{bmatrix} \\hat{\\beta}_0^{LSE} \\\\  \\hat{\\beta}_1^{LSE} \\\\  \\hat{\\beta}_2^{LSE}\\end{bmatrix} = ({\\bf X}^\\top {\\bf X})^{-1}{\\bf X}^\\top {\\bf y}\\]\n(1)에서 추정한 값과 비교하라. 비슷한가?\nhint: (1)과 (2)의 추정값은 거의 같아야합니다..\n(3) 이 문제에서 모수의 참값은 \\(\\beta_0=2.5, \\beta_1=4 , \\beta_2= -2\\) 이다. epoch을 증가할수록 (1)에서 추정된 값은 참값에 근접해갈까? (epoch을 무한대로 하면 결국 참값에 수렴할까?)\n(4) 아래의 제약사항에 맞추어서 \\(\\beta_0,\\beta_1,\\beta_2\\)의 값을 다시 추정하라.\n제약사항\n\nyhat = net(X) 을 만족하는 적당한 X, net을 선언하여 문제를 풀 것. 이때 net는 torch.nn.Linear(??,??,bias=False) 를 사용하여 선언할 것.\ntorch.nn.MSELoss()를 이용하여 손실을 구할 것\ntorch.optim.SGD()를 이용하여 update할 것\n\n(5) 아래의 제약사항에 맞추어서 \\(\\beta_0,\\beta_1,\\beta_2\\)의 값을 다시 추정하라.\n제약사항\n\nyhat = net(X) 을 만족하는 적당한 X, net을 선언하여 문제를 풀 것. 이때 net는 torch.nn.Linear(??,??,bias=True) 를 사용하여 선언할 것.\ntorch.nn.MSELoss()를 이용하여 손실을 구할 것\ntorch.optim.SGD()를 이용하여 update할 것"
  },
  {
    "objectID": "posts/exercise.html#회귀dl2022-mid-2",
    "href": "posts/exercise.html#회귀dl2022-mid-2",
    "title": "A1: Exercise",
    "section": "$. 회귀(DL2022-MID-2)",
    "text": "$. 회귀(DL2022-MID-2)\n\n이 문제의 경우 풀이가 https://guebin.github.io/DL2022/posts/2022-10-28-9wk-1-midsol.html 에 있습니다.\n\n주어진 자료가 아래와 같다고 하자.\n\ntorch.manual_seed(7676)\nx = torch.randn(100).sort().values\nϵ = torch.randn(100)*0.5\ny = 2.5+ 4*x + ϵ\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n아래와 같은 모형을 가정하고 물음에 답하라.\n\\[y_i = w_0+w_1 x_i +\\epsilon_i, \\quad \\epsilon_i \\overset{iid}{\\sim} N(0,\\sigma^2)\\]\n(1) ??를 적당하게 채워 아래와 같은 네트워크를 설정하고 최초의 예측값이 \\(\\hat{y}_i=-5+10x_i\\)가 출력되도록 net의 가중치를 조정하라.\nnet = torch.nn.Linear(in_features=2,out_features=??,bias=??)\n(2) 학습률은 0.1로 설정하고 torch.optim.Adam을 이용하여 optimizer를 선언하라. \\((\\hat{w}_0,\\hat{w}_1)=(-5,10)\\)에서 MSELoss의 미분계수 \\(\\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1) ~\\Big|_{~\\hat{w}_0,\\hat{w}_1}\\)를 구하고 이를 바탕으로 \\((\\hat{w}_0,\\hat{w}_1)\\)의 값을 1회 갱신하라. 계산된 미분계수값과 갱신된 \\((\\hat{w}_0,\\hat{w}_1)\\)의 값을 출력하라.\n(3) (2)에서 설정한 optimizer를 이용하여 \\((\\hat{w}_0, \\hat{w}_1)\\)의 값을 5회 갱신한 값을 구하여라. - 문제(2)에 갱신한 1회를 포함하여 5회임.\n(4) 학습률을 0.2로 설정하고 torch.optim.SGD를 이용하여 새로운 optimizr를 선언하라. (3)의 결과로 총 5회 갱신된 값에 이어서 10회 추가로 학습하라. 학습된 값은 얼마인가?\n(5) (4)의 수렴값이 학습이 잘 되었다고 생각하는가? 잘 되었다고 생각하면 그 근거는 무엇인가? (단, \\((w_0,w_1)\\)의 참값은 모른다고 가정한다)\n\nhint: 미분값을 근거로 대답할 것"
  },
  {
    "objectID": "posts/exercise.html#과잉매개변수dl2022-ass-2",
    "href": "posts/exercise.html#과잉매개변수dl2022-ass-2",
    "title": "A1: Exercise",
    "section": "$. 과잉매개변수(DL2022-ASS-2)",
    "text": "$. 과잉매개변수(DL2022-ASS-2)\n\n이 내용은 overparameterized model에 대한 내용을 다루고 있습니다. 이 문제의 경우는 풀이가 https://guebin.github.io/DL2022/posts/II.%20DNN/2022-10-26-Assignment2.html 에 제공되어있습니다.\n\n\nOverparameterized model은 03wk-1, 3-B 의 내용과도 관련 있습니다.\n\n아래와 같은 자료가 있다고 가정하자.\n\nx = torch.rand([1000,1])*2-1\ny = 3.14 + 6.28*x + torch.randn([1000,1]) \n\n\nplt.plot(x,y,'o',alpha=0.1)\n\n\n\n\n\n\n\n\n(1) 아래의 모형을 가정하고 \\(\\beta_0,\\beta_1\\)을 파이토치를 이용하여 추정하라.\n\n\\(y_i = \\beta_0  + \\beta_1 x_i + \\epsilon_i,\\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n(2) 아래의 모형을 가정하고 \\(\\beta_0\\)를 파이토치를 이용하여 추정하라.\n\n\\(y_i = \\beta_0  + \\epsilon_i,\\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n(3) 아래의 모형을 가정하고 \\(\\beta_1\\)을 파이토치를 이용하여 추정하라.\n\n\\(y_i = \\beta_1x_i  + \\epsilon_i \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n(4) 아래의 모형을 가정하고 \\(\\alpha_0,\\beta_0,\\beta_1\\)을 파이토치를 이용하여 추정하라.\n\n\\(y_i = \\alpha_0+\\beta_0+ \\beta_1x_i  + \\epsilon_i \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n\\(\\hat{\\alpha}_0+\\hat{\\beta}_0\\)은 얼마인가? 이 값과 문제 (1)에서 추정된 \\(\\hat{\\beta_0}\\)의 값과 비교하여 보라.\n(5) 아래의 모형을 가정하고 \\(\\alpha_0,\\alpha_1,\\beta_0,\\beta_1\\)을 파이토치를 이용하여 추정하라.\n\n\\(y_i = \\alpha_0+\\beta_0+ \\beta_1x_i + \\alpha_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n\\(\\hat{\\alpha}_0+\\hat{\\beta}_0\\), \\(\\hat{\\alpha}_1 + \\hat{\\beta}_1\\)의 값은 각각 얼마인가? 이 값들을 (1) 에서 추정된 \\(\\hat{\\beta}_0\\), \\(\\hat{\\beta}_1\\) 값들과 비교하라.\n(6) 다음은 위의 모형에 대하여 학생들이 discussion한 결과이다. 올바르게 해석한 학생을 모두 골라라.\n민정: \\((x_i,y_i)\\)의 산점도는 직선모양이고 직선의 절펴과 기울기 모두 유의미해 보이므로 \\(y_i = \\beta_0 + \\beta_1 x_i\\) 꼴을 적합하는게 좋겠다.\n슬기: 나도 그렇게 생각해. 그래서 (2)-(3)과 같이 기울기를 제외하고 적합하거나 절편을 제외하고 적합하면 underfitting의 상황에 빠질 수 있어.\n성재: (2)의 경우 사실상 \\(\\bar{y}=\\frac{1}{n}\\sum_{i=1}^{n}y_i\\)를 추정하는 것과 같아지게 되지.\n세민: (4)의 경우 \\({\\bf X}=\\begin{bmatrix} 1  & x_1 \\\\ 1 & x_2 \\\\ \\dots & \\dots \\\\ 1 & x_n \\end{bmatrix}\\) 와 같이 설정하고 네트워크를 아래와 같이 설정할 경우 얻어지는 모형이야.\nnet = torch.nn.Linear(in_features=2,out_features=1,bias=True)\n구환: 모델 (4)-(5)는 표현력은 (1)과 동일하지만 추정할 파라메터는 (1)보다 많으므로 효율적인 모델이라고 볼 수 없어."
  },
  {
    "objectID": "posts/05wk-2.html#a.-로지스틱",
    "href": "posts/05wk-2.html#a.-로지스틱",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "A. 로지스틱",
    "text": "A. 로지스틱\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(1)}} =\\underset{(n,1)}{\\hat{\\bf y}}\\]\n- 모든 observation과 가중치를 명시한 버전\n(표현1)\n\n\n단점: 똑같은 그림의 반복이 너무 많음\n\n- observation 반복을 생략한 버전들\n(표현2) 모든 \\(i\\)에 대하여 아래의 그림을 반복한다고 하면 (표현1)과 같다.\n\n(표현3) 그런데 (표현2)에서 아래와 같이 \\(x_i\\), \\(y_i\\) 대신에 간단히 \\(x\\), \\(y\\)로 쓰는 경우도 많음\n\n- 1을 생략한 버전들\n(표현4) bais=False 대신에 bias=True를 주면 1을 생략할 수 있음\n\n(표현4의 수정) \\(\\hat{w}_1\\)대신에 \\(\\hat{w}\\)를 쓰는 것이 더 자연스러움\n\n(표현5) 선형변환의 결과는 아래와 같이 \\(u\\)로 표현하기도 한다.\n\n\n다이어그램은 그리는 사람의 취향에 따라 그리는 방법이 조금씩 다릅니다. 즉 교재마다 달라요."
  },
  {
    "objectID": "posts/05wk-2.html#b.-스펙의역설",
    "href": "posts/05wk-2.html#b.-스펙의역설",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "B. 스펙의역설",
    "text": "B. 스펙의역설\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\bf y}}\\]\n참고: 코드로 표현\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=2,out_features=1),\n    torch.nn.Sigmoid()\n)\n- 이해를 위해서 예젠에 다루었던 아래의 상황을 고려하자.\n\n(강의노트의 표현)\n\n(좀 더 일반화된 표현) 상황을 일반화하면 아래와 같다.\n\n* Layer의 개념: \\({\\bf X}\\)에서 \\(\\hat{\\boldsymbol y}\\)로 가는 과정은 “선형변환+비선형변환”이 반복되는 구조이다. “선형변환+비선형변환”을 하나의 세트로 보면 아래와 같이 표현할 수 있다.\n\n\\(\\underset{(n,1)}{\\bf X}  \\overset{l_1}{\\to} \\left( \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\right) \\overset{l_2}{\\to} \\left(\\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}\\right), \\quad  \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{net({\\bf X})}=\\underset{(n,1)}{\\hat{\\bf y}}\\)\n\n이것을 다이어그램으로 표현한다면 아래와 같다.\n(선형+비선형을 하나의 Layer로 묶은 표현)\n\nLayer를 세는 방법\n\n제 방식: 학습가능한 파라메터가 몇층으로 있는지… &lt;– 이것만 기억하세여\n일부 교재 설명: 입력층은 계산하지 않음, activation layer는 계산하지 않음. &lt;– 무시하세요.. 이러면 헷갈립니다..\n위의 예제의 경우 number of layer = 2 이다.\n\nHidden Layer의 수를 세는 방법\n\n제 방식: Hidden Layer의 수 = Layer의 수 -1 &lt;– 이걸 기억하세여..\n\n일부 교재 설명: Layer의 수 = Hidden Layer의 수 + 출력층의 수 = Hidden Layer의 수 + 1 &lt;– 기억하지 마세여\n위의 예제의 경우 number of hidden layer = 1 이다.\n\n\n\n\n\n\n\nImportant\n\n\n\n무조건 학습가능한 파라메터가 몇겹으로 있는지만 판단하세요. 딴거 아무것도 생각하지마세여\n## 예시1 -- 2층 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n)\n## 예시2 -- 2층 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid(),\n)\n## 예시3 -- 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n) \n## 예시4 -- 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n) \n## 예시5 -- 3층 (히든레이어는 2층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층    \n) \n## 예시6 -- 3층 (히든레이어는 2층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU()\n    torch.nn.Dropout(??)\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU()\n    torch.nn.Dropout(??)\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층  \n    torch.nn.Sigmoid()\n) \n\n\n\n\n\n\n\n\nImportant\n\n\n\n문헌에 따라서 레이어를 세는 개념이 제가 설명한 방식과 다른경우가 있습니다. 제가 설명한 방식보다 1씩 더해서 셉니다. 즉 아래의 경우 레이어를 3개로 카운트합니다.\n## 예시1 -- 문헌에 따라 3층으로 세는 경우가 있음 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n)\n예를 들어 여기에서는 위의 경우 레이어는 3개라고 설명하고 있습니다. 이러한 카운팅은 “무시”하세요. 제가 설명한 방식이 맞아요. 이 링크 잘못(?) 나와있는 이유는 아래와 같습니다.\n- 진짜 예전에 MLP를 소개할 초창기에서는 위의 경우 Layer를 3개로 셌음. (Rosenblatt et al. 1962)\n- 그런데 요즘은 그렇게 안셈.. (그리고 애초에 MLP라는 용어도 잘 안쓰죠..)\n참고로 히든레이어의 수는 예전방식이나 지금방식이나 동일하게 카운트하므로 히든레이어만 세면 혼돈이 없습니다.\n\n\n\nRosenblatt, Frank et al. 1962. Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanisms. Vol. 55. Spartan books Washington, DC.\n* node의 개념: \\(u\\to v\\)로 가는 쌍을 간단히 노드라는 개념을 이용하여 나타낼 수 있음.\n(노드의 개념이 포함된 그림)\n\n여기에서 node의 숫자 = feature의 숫자와 같이 이해할 수 있다. 즉 아래와 같이 이해할 수 있다.\n(“number of nodes = number of features”로 이해한 그림)\n\n\n다이어그램의 표현방식은 교재마다 달라서 모든 예시를 달달 외울 필요는 없습니다. 다만 임의의 다이어그램을 보고 대응하는 네트워크를 pytorch로 구현하는 능력은 매우 중요합니다."
  },
  {
    "objectID": "posts/05wk-2.html#c.-mnist",
    "href": "posts/05wk-2.html#c.-mnist",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "C. MNIST",
    "text": "C. MNIST\n\\[\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n(다이어그램표현)\n\n\nLayer0,1,2 대신에 Input Layer, Hidden Layer, Output Layer로 표현함\n\n- 위의 다이어그램에 대응하는 코드\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=28*28*1,out_features=32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=32,out_features=1),\n    torch.nn.Sigmoid() \n)"
  },
  {
    "objectID": "posts/05wk-2.html#a.-gpu-사용방법",
    "href": "posts/05wk-2.html#a.-gpu-사용방법",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "A. GPU 사용방법",
    "text": "A. GPU 사용방법\n- cpu 연산이 가능한 메모리에 데이터 저장\n\ntorch.manual_seed(43052)\nx_cpu = torch.tensor([0.0,0.1,0.2]).reshape(-1,1) \ny_cpu = torch.tensor([0.0,0.2,0.4]).reshape(-1,1) \nnet_cpu = torch.nn.Linear(1,1) \n\n\nnet_cpu(x_cpu)\n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nx_cpu\n\ntensor([[0.0000],\n        [0.1000],\n        [0.2000]])\n\n\n- gpu 연산이 가능한 메모리에 데이터 저장\n\n!nvidia-smi # before\n\nMon Apr  7 09:48:42 2025       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA GeForce RTX 3090        Off | 00000000:09:00.0 Off |                  N/A |\n|  0%   29C    P8              27W / 420W |     26MiB / 24576MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|    0   N/A  N/A      1152      G   /usr/lib/xorg/Xorg                            9MiB |\n|    0   N/A  N/A      1471      G   /usr/bin/gnome-shell                          8MiB |\n+---------------------------------------------------------------------------------------+\n\n\n\ntorch.manual_seed(43052)\nx_gpu = x_cpu.to(\"cuda:0\")\ny_gpu = y_cpu.to(\"cuda:0\")\nnet_gpu = torch.nn.Linear(1,1).to(\"cuda:0\") \n\n\n!nvidia-smi\n\nMon Apr  7 09:48:43 2025       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA GeForce RTX 3090        Off | 00000000:09:00.0 Off |                  N/A |\n|  0%   34C    P2              65W / 420W |    287MiB / 24576MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|    0   N/A  N/A      1152      G   /usr/lib/xorg/Xorg                            9MiB |\n|    0   N/A  N/A      1471      G   /usr/bin/gnome-shell                          8MiB |\n|    0   N/A  N/A    140211      C   ...b3/anaconda3/envs/dl2025/bin/python      256MiB |\n+---------------------------------------------------------------------------------------+\n\n\n\nGPU에 메모리를 올리면 GPU메모리가 점유된다! (26MiB -&gt; 287MiB)\n\n- cpu 혹은 gpu 연산이 가능한 메모리에 저장된 값들을 확인\n\nx_cpu, y_cpu, net_cpu.weight, net_cpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]]),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]]),\n Parameter containing:\n tensor([[0.3604]], requires_grad=True),\n Parameter containing:\n tensor([0.9336], requires_grad=True))\n\n\n\nx_gpu, y_gpu, net_gpu.weight, net_gpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]], device='cuda:0'),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]], device='cuda:0'),\n Parameter containing:\n tensor([[-0.3467]], device='cuda:0', requires_grad=True),\n Parameter containing:\n tensor([-0.8470], device='cuda:0', requires_grad=True))\n\n\n- gpu는 gpu끼리 연산가능하고 cpu는 cpu끼리 연산가능함\n(예시1)\n\nnet_cpu(x_cpu) \n\ntensor([[0.9336],\n        [0.9696],\n        [1.0057]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시2)\n\nnet_gpu(x_gpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시3)\n\nnet_cpu(x_gpu) \n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)\n\n\n(예시4)\n\nnet_gpu(x_cpu)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)\n\n\n(예시5)\n\ntorch.mean((y_cpu-net_cpu(x_cpu))**2)\n\ntensor(0.6102, grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시6)\n\ntorch.mean((y_gpu-net_gpu(x_gpu))**2)\n\ntensor(1.2068, device='cuda:0', grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시7)\n\ntorch.mean((y_gpu-net_cpu(x_cpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n\n\n(예시8)\n\ntorch.mean((y_cpu-net_gpu(x_gpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
  },
  {
    "objectID": "posts/05wk-2.html#b.-시간측정-예비학습",
    "href": "posts/05wk-2.html#b.-시간측정-예비학습",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "B. 시간측정 (예비학습)",
    "text": "B. 시간측정 (예비학습)\n\nimport time \n\n\nt1 = time.time()\n\n\nt2 = time.time()\n\n\nt2-t1\n\n5.440181732177734"
  },
  {
    "objectID": "posts/05wk-2.html#c.-cpu-vs-gpu-500-nodes",
    "href": "posts/05wk-2.html#c.-cpu-vs-gpu-500-nodes",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "C. CPU vs GPU (500 nodes)",
    "text": "C. CPU vs GPU (500 nodes)\n- CPU (500 nodes)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,500),\n    torch.nn.ReLU(),\n    torch.nn.Linear(500,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.36923766136169434\n\n\n- GPU (500 nodes)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,500),\n    torch.nn.ReLU(),\n    torch.nn.Linear(500,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.5803208351135254\n\n\n\nCPU가 더 빠르다??"
  },
  {
    "objectID": "posts/05wk-2.html#d.-cpu-vs-gpu-200000-nodes",
    "href": "posts/05wk-2.html#d.-cpu-vs-gpu-200000-nodes",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "D. CPU vs GPU (200,000 nodes)",
    "text": "D. CPU vs GPU (200,000 nodes)\n- CPU (200,000)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,200000),\n    torch.nn.ReLU(),\n    torch.nn.Linear(200000,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n84.05620455741882\n\n\n- GPU (204,800)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,200000),\n    torch.nn.ReLU(),\n    torch.nn.Linear(200000,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n1.373826026916504\n\n\n\n왜 이런 차이가 나는가?\n연산을 하는 주체는 코어인데 CPU는 수는 적지만 일을 잘하는 코어들을 가지고 있고 GPU는 일은 못하지만 다수의 코어를 가지고 있기 때문"
  },
  {
    "objectID": "posts/05wk-2.html#e.-주의점",
    "href": "posts/05wk-2.html#e.-주의점",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "E. 주의점",
    "text": "E. 주의점\n- tensor 일 경우\n\nx = torch.tensor([1,2,3])\nx.to(\"cuda:0\"), x\n\n(tensor([1, 2, 3], device='cuda:0'), tensor([1, 2, 3]))\n\n\n- net일 경우\n\nnet = torch.nn.Linear(1,1).to(\"cuda:0\")\nnet.weight, net.bias\n\n(Parameter containing:\n tensor([[-0.5348]], device='cuda:0', requires_grad=True),\n Parameter containing:\n tensor([-0.3825], device='cuda:0', requires_grad=True))"
  },
  {
    "objectID": "posts/05wk-2.html#a.-의문-좀-이상하지-않아요",
    "href": "posts/05wk-2.html#a.-의문-좀-이상하지-않아요",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "A. 의문: 좀 이상하지 않아요?",
    "text": "A. 의문: 좀 이상하지 않아요?\n- 국민상식: GPU 비싸요.. https://bbs.ruliweb.com/community/board/300143/read/61066881\n\nGPU 메모리 많아봐야 24GB, 그래도 비싸요.. http://shop.danawa.com/virtualestimate/?controller=estimateMain&methods=index&marketPlaceSeq=16\nGPU 메모리가 80GB일 경우 가격: https://prod.danawa.com/info/?pcode=21458333\n\n- 우리가 분석하는 데이터\n\nx = torch.linspace(-10,10,100000).reshape(-1,1)\neps = torch.randn(100000).reshape(-1,1)\ny = x*2 + eps \n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,2*x,'--')\n\n\n\n\n\n\n\n\n- 데이터의 크기가 커지는 순간 x.to(\"cuda:0\"), y.to(\"cuda:0\") 쓰면 난리나겠는걸? \\(\\to\\) 이런식이면 GPU를 이용하여 아무런 분석도 못할것 같은데?? 뭔가 좀 이상한데??\n- 아이디어: 데이터를 100개중에 1개 꼴로만 쓰면 어떨까?\n\nplt.plot(x[::100],y[::100],'o',alpha=0.05)\nplt.plot(x,2*x,'--')\n\n\n\n\n\n\n\n\n\n대충 이거만 가지고 적합해도 충분히 정확할것 같은데?"
  },
  {
    "objectID": "posts/05wk-2.html#b.-xy-데이터를-굳이-모두-gpu에-넘겨야-하는가",
    "href": "posts/05wk-2.html#b.-xy-데이터를-굳이-모두-gpu에-넘겨야-하는가",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "B. X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?",
    "text": "B. X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?\n- 데이터셋을 짝홀로 나누어서 번갈아가면서 GPU에 올렸다 내렸다하면 안되나?\n- 아래의 알고리즘을 생각해보자.\n\n데이터를 반으로 나눈다.\n짝수obs의 x,y 그리고 net의 모든 파라메터를 GPU에 올린다.\nyhat, loss, grad, update 수행\n짝수obs의 x,y를 GPU메모리에서 내린다. 그리고 홀수obs의 x,y를 GPU메모리에 올린다.\nyhat, loss, grad, update 수행\n홀수obs의 x,y를 GPU메모리에서 내린다. 그리고 짝수obs의 x,y를 GPU메모리에 올린다.\n반복\n\n\n이러면 되는거아니야???? —&gt; 맞아요"
  },
  {
    "objectID": "posts/05wk-2.html#c.-경사하강법-확률적경사하강법-미니배치-경사하강법",
    "href": "posts/05wk-2.html#c.-경사하강법-확률적경사하강법-미니배치-경사하강법",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "C. 경사하강법, 확률적경사하강법, 미니배치 경사하강법",
    "text": "C. 경사하강법, 확률적경사하강법, 미니배치 경사하강법\n10개의 샘플이 있다고 가정. \\(\\{(x_i,y_i)\\}_{i=1}^{10}\\)\n# ver1 – 모든 샘플을 이용하여 slope 계산\n(epoch 1) \\(loss=\\sum_{i=1}^{10}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2 \\to slope  \\to update\\)\n(epoch 2) \\(loss=\\sum_{i=1}^{10}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2 \\to slope  \\to update\\)\n…\n\n우리가 항상 이렇게 했죠!\n\n# ver2 – 하나의 샘플만을 이용하여 slope 계산\n(epoch 1)\n\n\\(loss=(y_1-\\hat{w}_0-\\hat{w}_1x_1)^2 \\to slope \\to update\\)\n\\(loss=(y_2-\\hat{w}_0-\\hat{w}_1x_2)^2 \\to slope \\to update\\)\n…\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n(epoch 2)\n\n\\(loss=(y_1-\\hat{w}_0-\\hat{w}_1x_1)^2  \\to slope  \\to  update\\)\n\\(loss=(y_2-\\hat{w}_0-\\hat{w}_1x_2)^2  \\to slope  \\to  update\\)\n…\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n…\n# ver3 – \\(m (\\leq n)\\) 개의 샘플을 이용하여 slope 계산\n\\(m=3\\)이라고 하자.\n(epoch 1)\n\n\\(loss=\\sum_{i=1}^{3}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=4}^{6}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=7}^{9}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n(epoch 2)\n\n\\(loss=\\sum_{i=1}^{3}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=4}^{6}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=7}^{9}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n…"
  },
  {
    "objectID": "posts/05wk-2.html#d.-용어의-정리",
    "href": "posts/05wk-2.html#d.-용어의-정리",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "D. 용어의 정리",
    "text": "D. 용어의 정리\n옛날\n- ver1(모든): gradient descent, batch gradient descent\n- ver2(하나만): stochastic gradient descent\n- ver3(몇개만): mini-batch gradient descent, mini-batch stochastic gradient descent\n요즘\n- ver1(모든): gradient descent\n- ver2(하나만): stochastic gradient descent with batch size = 1\n- ver3(몇개만): stochastic gradient descent - https://www.deeplearningbook.org/contents/optimization.html, 알고리즘 8-1 참고."
  },
  {
    "objectID": "posts/05wk-2.html#e.-datasetds-dataloaderdl",
    "href": "posts/05wk-2.html#e.-datasetds-dataloaderdl",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "E. Dataset(ds), DataLoader(dl)",
    "text": "E. Dataset(ds), DataLoader(dl)\n\n취지는 알겠으나, C의 과정을 실제 구현하려면 진짜 어려움.. (입코딩과 손코딩의 차이) –&gt; 이걸 해결하기 위해서 파이토치에서는 DataLoader라는 오브젝트를 준비했음!\n\n- 데이터\n\nx=torch.tensor(range(10)).float().reshape(-1,1)\ny=torch.tensor([1.0]*5+[0.0]*5).reshape(-1,1)\ntorch.concat([x,y],axis=1)\n\ntensor([[0., 1.],\n        [1., 1.],\n        [2., 1.],\n        [3., 1.],\n        [4., 1.],\n        [5., 0.],\n        [6., 0.],\n        [7., 0.],\n        [8., 0.],\n        [9., 0.]])\n\n\n- ds오브젝트\n\nds = torch.utils.data.TensorDataset(x,y)\nds\n\n&lt;torch.utils.data.dataset.TensorDataset at 0x750d76514d30&gt;\n\n\n\nds.tensors \n# 생긴건 ds.tensors = (x,y) 임\n\n(tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]),\n tensor([[1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.]]))\n\n\n\nds[0],(x,y)[0] # (x,y) 튜플자체는 아님.. 인덱싱이 다르게 동작\n\n((tensor([0.]), tensor([1.])),\n tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]))\n\n\n- dl 오브젝트\n\ndl = torch.utils.data.DataLoader(ds, batch_size=3)\n\n\nfor x_mbatch,y_mbatch in dl:\n    print(f\"x_mini_batch:{x_mbatch.tolist()} \\t y_mini_batch:{y_mbatch.tolist()}\")\n\nx_mini_batch:[[0.0], [1.0], [2.0]]   y_mini_batch:[[1.0], [1.0], [1.0]]\nx_mini_batch:[[3.0], [4.0], [5.0]]   y_mini_batch:[[1.0], [1.0], [0.0]]\nx_mini_batch:[[6.0], [7.0], [8.0]]   y_mini_batch:[[0.0], [0.0], [0.0]]\nx_mini_batch:[[9.0]]     y_mini_batch:[[0.0]]\n\n\n- 마지막관측치는 뭔데 단독으로 업데이트하냐?? –&gt; shuffle True 같이 자잘한 옵션도 있음..\n\ndl = torch.utils.data.DataLoader(ds,batch_size=3,shuffle=True)\nfor x_mbatch,y_mbatch in dl:\n    print(f\"x_mini_batch:{x_mbatch.tolist()} \\t y_mini_batch:{y_mbatch.tolist()}\")\n\nx_mini_batch:[[5.0], [2.0], [9.0]]   y_mini_batch:[[0.0], [1.0], [0.0]]\nx_mini_batch:[[0.0], [7.0], [8.0]]   y_mini_batch:[[1.0], [0.0], [0.0]]\nx_mini_batch:[[1.0], [6.0], [4.0]]   y_mini_batch:[[1.0], [0.0], [1.0]]\nx_mini_batch:[[3.0]]     y_mini_batch:[[1.0]]"
  },
  {
    "objectID": "posts/05wk-2.html#f.-성능체크",
    "href": "posts/05wk-2.html#f.-성능체크",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "F. 성능체크",
    "text": "F. 성능체크\n- 목표: 확률적경사하강법과 그냥 경사하강법의 성능을 “동일 반복횟수”로 비교해보자.\n- MNIST자료를 그냥 경사하강법으로 적합해보자.\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX0 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\nX1 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\nX = torch.concat([X0,X1],axis=0).reshape(-1,784)\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n\nfor epoc in range(700):\n    # step1 \n    yhat = net(X)\n    # step2 \n    loss = loss_fn(yhat,y)\n    # step3     \n    loss.backward()\n    # step4 \n    optimizr.step()\n    optimizr.zero_grad()    \n\n\n((yhat &gt; 0.5) ==  y).float().mean()\n\ntensor(0.9953)\n\n\n- MNIST자료를 확률적 경사하강법으로 적합해보자. – 미니배치 쓰는 학습\n\n# train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n# to_tensor = torchvision.transforms.ToTensor()\n# X0 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\n# X1 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\n# X = torch.concat([X0,X1],axis=0).reshape(-1,784)\n# y = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=2048)\n\n\nlen(X)/2048\n\n6.18408203125\n\n\n\n따라서 (mini) batchsize 가 2048 이라면 한 epoch당 7회 update\n\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n\nfor epoc in range(100): \n    for xm,ym in dl:        \n        # step1 \n        ym_hat = net(xm)\n        # step2 \n        loss = loss_fn(ym_hat,ym)\n        # step3     \n        loss.backward()\n        # step4 \n        optimizr.step()\n        optimizr.zero_grad()\n\n\n((net(X) &gt; 0.5) ==  y).float().mean()\n\ntensor(0.9931)"
  },
  {
    "objectID": "posts/03wk-1.html#a.-bias의-사용",
    "href": "posts/03wk-1.html#a.-bias의-사용",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "A. bias의 사용",
    "text": "A. bias의 사용\nnet에서 bias를 사용\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=1,\n    out_features=1,\n    bias=True\n) # net(x) = x@net.weight.T + net.bias \nnet.bias.data = torch.tensor([-5.0])\nnet.weight.data = torch.tensor([[10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비 \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(x)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nnet.bias.data, net.weight.data\n\n(tensor([2.4290]), tensor([[4.0144]]))\n\n\n#"
  },
  {
    "objectID": "posts/03wk-1.html#b.-잘못된-코드",
    "href": "posts/03wk-1.html#b.-잘못된-코드",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "B. 잘못된(?) 코드",
    "text": "B. 잘못된(?) 코드\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비 \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');\n\n\n\n\n\n\n\n\n- 나쁘지 않은 이유?\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n)\nyhat = net(X) = X@net.weight.T + net.bias\n\n\nnet.weight\n\nParameter containing:\ntensor([[-1.0241,  4.0080]], requires_grad=True)\n\n\n\nnet.bias\n\nParameter containing:\ntensor([3.4689], requires_grad=True)"
  },
  {
    "objectID": "posts/03wk-1.html#a.-hatbf-y",
    "href": "posts/03wk-1.html#a.-hatbf-y",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "A. \\(\\hat{\\bf y} = ??\\)",
    "text": "A. \\(\\hat{\\bf y} = ??\\)\n- \\({\\bf X}\\)를 가지고 \\({\\bf y}\\)를 맞추는 아래와 같은 문제\n\nx = torch.tensor([-6,-5,-4,-3,-2,-1, 0, 1, 2, 3, 4, 5, 6.0]).reshape(-1,1)\ny = torch.tensor([ 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1]).reshape(-1,1)\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n- 아래와 같이 모형화 하면?\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(x)/(1+torch.exp(x)),'o--', label = \"underlying (without error)\")\nplt.legend()"
  },
  {
    "objectID": "posts/03wk-1.html#b.-hatbf-y-fracexptextlinrbf-x1exptextlinrbf-x",
    "href": "posts/03wk-1.html#b.-hatbf-y-fracexptextlinrbf-x1exptextlinrbf-x",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "B. \\(\\hat{\\bf y} = \\frac{\\exp(\\text{linr}({\\bf X}))}{1+\\exp(\\text{linr}({\\bf X}))}\\)",
    "text": "B. \\(\\hat{\\bf y} = \\frac{\\exp(\\text{linr}({\\bf X}))}{1+\\exp(\\text{linr}({\\bf X}))}\\)\n- 걱정: 산점도가 꼭 아래와 같은 방식이 아니라면 어쩌지?\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n\n\\(x\\)가 증가할수록 \\(y\\)가 0이 된다면?\n0근처에서 변화가 일어나지 않고 2근처에서 변화가 일어난다면?\n변화가 좀 더 급하게 (혹은 완만하게 일어난다면?)\n\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(5*x+3)/(1+torch.exp(5*x+3)),'o--', label = \"underlying (without error)\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 걱정해결\n\n#plt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(x)/(1+torch.exp(x)),'o--', label = \"underlying type1 (without error)\", color=\"C1\")\nplt.plot(x,torch.exp(5*x)/(1+torch.exp(5*x)),'o--', label = \"underlying type2 (without error)\", color=\"C2\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n회귀 vs 로지스틱\n\n\\({\\bf X} \\to {\\bf y}\\) 에 대한 패턴이 \\(\\text{linr}({\\bf X}) \\approx {\\bf y}\\) 이라면 회귀!\n\\({\\bf X} \\to {\\bf y}\\) 에 대한 패턴이 \\(\\frac{\\exp(\\text{linr}({\\bf X}))}{1+\\exp(\\text{linr}({\\bf X}))} \\approx {\\bf y}\\) 이라면 로지스틱!"
  },
  {
    "objectID": "posts/03wk-1.html#c.-로지스틱-모형",
    "href": "posts/03wk-1.html#c.-로지스틱-모형",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "C. 로지스틱 모형",
    "text": "C. 로지스틱 모형\n- \\(x\\)가 커질수록 (혹은 작아질수록) \\(y=1\\)이 잘나오는 모형은 아래와 같이 설계할 수 있음 &lt;— 외우세요!!!\n\n\\(y_i \\sim {\\cal B}(\\pi_i),\\quad\\) where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)} = \\frac{1}{1+\\exp(-w_0-w_1x_i)}\\)\n\\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\n- 회귀모형과 로지스틱 모형의 비교\n\n회귀모형: \\(y_i \\sim {\\cal N}(w_0+w_1x_i, \\sigma^2)\\)1\n로지스틱: \\(y_i \\sim {\\cal B}\\big(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\big)\\)\n\n1 원래는 이렇게 썼었지.. \\(y_i = w_0 + w_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim {\\cal N}(0,\\sigma^2)\\)- 우리가 예측하고 싶은것\n\n회귀모형: 정규분포의 평균을 예측하고 싶음. 즉 \\(w_0+w_1x_i\\)를 예측하고 싶음. 예측값으로는 \\(\\hat{w}_0 + \\hat{w}_1x_i\\)를 사용!\n로지스틱: 베르누이의 평균을 예측하고 싶음. 즉 \\(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)를 예측하고 싶음. 예측값으로는 \\(\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}\\)를 사용!"
  }
]