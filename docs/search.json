[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/04wk-1.html",
    "href": "posts/04wk-1.html",
    "title": "04wk-1: (신경망) – 로지스틱의 한계 극복",
    "section": "",
    "text": "1. 강의영상\n\n\n\n2. Imports\n\nimport torch\nimport matplotlib.pyplot as plt \nimport pandas as pd\n\n\nplt.rcParams['figure.figsize'] = (4.5, 3.0)\n\n\n\n3. 꺽인직선을 만드는 방법\n지난시간복습\n\n# 오늘의 잔소리.. \n## 회귀(카페예제): yhat=직선=linr(x), 정규분포, MSEloss\n## 로지스틱(스펙과취업): yhat=곡선=sig(직선)=sig(linr(x)), 베르누이, BCELoss\n## 이름없음(스펙의역설): yhat=꺽인곡선=sig(꺽인직선)=sig(??), 베르누이, BCELOss\n\n- 로지스틱의 한계를 극복하기 위해서는 시그모이드를 취하기 전에 꺽인 그래프 모양을 만드는 기술이 있어야겠음.\n- 아래와 같은 벡터 \\({\\bf x}\\)를 가정하자.\n\nx = torch.linspace(-1,1,1001).reshape(-1,1)\nx\n\ntensor([[-1.0000],\n        [-0.9980],\n        [-0.9960],\n        ...,\n        [ 0.9960],\n        [ 0.9980],\n        [ 1.0000]])\n\n\n- 목표: 아래와 같은 벡터 \\({\\bf y}\\)를 만들어보자.\n\\[{\\bf y} = [y_1,y_2,\\dots,y_{n}]^\\top, \\quad y_i = \\begin{cases} 9x_i +4.5& x_i &lt;0 \\\\ -4.5x_i + 4.5& x_i &gt;0 \\end{cases}\\]\n\n\n\n\n\n\nCaution\n\n\n\n일반적으로 제 강의노트에서\n\n독립변수 = 설명변수 = \\({\\bf x}\\), \\({\\bf X}\\)\n종속변수 = 반응변수 = \\({\\bf y}\\)\n\n를 의미하는데요, 여기에서 \\(({\\bf x},{\\bf y})\\) 는 (독립변수,종속변수) 혹은 (설명변수,반응변수) 를 의미하는게 아닙니다.\n\n\n# 방법1 – 수식 그대로 구현\n\nplt.plot(x,9*x+4.5,color=\"blue\",alpha=0.1)\nplt.plot(x[x&lt;0], (9*x+4.5)[x&lt;0],color=\"blue\")\nplt.plot(x,-4.5*x+4.5,color=\"orange\",alpha=0.1)\nplt.plot(x[x&gt;0], (-4.5*x+4.5)[x&gt;0],color=\"orange\")\n\n\n\n\n\n\n\n\n\ny = x*0\ny[x&lt;0] = (9*x+4.5)[x&lt;0]\ny[x&gt;0] = (-4.5*x+4.5)[x&gt;0]\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n#\n# 방법2 – 렐루이용\n\nrelu = torch.nn.ReLU()\n#plt.plot(x,-4.5*relu(x),color=\"red\")\n#plt.plot(x,-9*relu(-x),color=\"blue\")\ny = -4.5*relu(x) + -9*relu(-x) + 4.5\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n- 좀 더 중간과정을 시각화 – (강의때 설명안했음)\n\nfig = plt.figure(figsize=(6, 4))\nspec = fig.add_gridspec(4, 3)\nax1 = fig.add_subplot(spec[:2,0]); ax1.set_title(r'$x$'); ax1.set_ylim(-1,1)\nax2 = fig.add_subplot(spec[2:,0]); ax2.set_title(r'$-x$'); ax2.set_ylim(-1,1)\nax3 = fig.add_subplot(spec[:2,1]); ax3.set_title(r'$relu(x)$'); ax3.set_ylim(-1,1)\nax4 = fig.add_subplot(spec[2:,1]); ax4.set_title(r'$relu(-x)$'); ax4.set_ylim(-1,1)\nax5 = fig.add_subplot(spec[1:3,2]); ax5.set_title(r'$-4.5 relu(x)-9 relu(-x)+4.5$')\n#---#\nax1.plot(x,'--',color='C0')\nax2.plot(-x,'--',color='C1')\nax3.plot(relu(x),'--',color='C0')\nax4.plot(relu(-x),'--',color='C1')\nax5.plot(-4.5*relu(x)-9*relu(-x)+4.5,'--',color='C2')\nfig.tight_layout()\n\n\n\n\n\n\n\n\n#\n# 방법3 – relu의 브로드캐스팅 활용\n- 우리가 하고 싶은 것\n\n# y = -4.5*relu(x) + -9*relu(-x) + 4.5\n\n- 아래와 같은 아이디어로 y를 계산해도 된다.\n\nx, relu 준비\nu = [x -x]\nv = relu(u) = [relu(x), relu(-x)] = [v1 v2]\ny = -4.5*v1 + -9*v2 + 4.5\n\n\nu = torch.concat([x,-x],axis=1)\nv = relu(u)\nv1 = v[:,[0]]\nv2 = v[:,[1]]\ny = -4.5*v1 -9*v2 + 4.5 \nplt.plot(x,y)\n\n\n\n\n\n\n\n\n#\n# 방법4 – y = linr(v)\n\n# 4. y = -4.5*v1 + -9*v2 + 4.5 = [v1 v2] @ [[-4.5],[-9]] + 4.5 \n# y = -4 + 3*x = [1 x] @ [[-4],[3]]\n\n\nx \nu = torch.concat([x,-x],axis=1)\nv = relu(u) \ny = v @ torch.tensor([[-4.5],[-9]]) + 4.5 \n\n\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n#\n# 방법5 – u = linr(x)\n\n# x \n# u = torch.concat([x,-x],axis=1)\n# v = relu(u) \n# y = v @ torch.tensor([[-4.5],[-9]]) + 4.5 \n\n\nx \nu = x @ torch.tensor([[1.0, -1.0]])\nv = relu(u) \ny = v @ torch.tensor([[-4.5],[-9]]) + 4.5 \n\n\nplt.plot(x,y)\n\n\n\n\n\n\n\n\n#\n# 방법6 – torch.nn.Linear()를 이용\n\n# x \n# u = x @ torch.tensor([[1.0, -1.0]]) = l1(x) \n# v = relu(u) = a1(u)\n# y = v @ torch.tensor([[-4.5],[-9]]) + 4.5 = l2(v) \n\n\n# u = l1(x) # l1은 x-&gt;u인 선형변환: (n,1) -&gt; (n,2) 인 선형변환\nl1 = torch.nn.Linear(1,2,bias=False)\nl1.weight.data = torch.tensor([[1.0, -1.0]]).T \na1 = relu \nl2 = torch.nn.Linear(2,1,bias=True)\nl2.weight.data = torch.tensor([[-4.5],[-9]]).T \nl2.bias.data = torch.tensor([4.5])\n#---#\nx\nu = l1(x)\nv = a1(u) \ny = l2(v) \n\n\nplt.plot(x,y.data)\n\n\n\n\n\n\n\n\n\npwlinr = torch.nn.Sequential(l1,a1,l2)\nplt.plot(x,pwlinr(x).data)\n\n\n\n\n\n\n\n\n#\n\n\n\n\n\n\nNote\n\n\n\n수식표현\n(1) \\({\\bf X}=\\begin{bmatrix} x_1 \\\\ \\dots \\\\ x_n \\end{bmatrix}\\)\n(2) \\(l_1({\\bf X})={\\bf X}{\\bf W}^{(1)}\\overset{bc}{+} {\\boldsymbol b}^{(1)}=\\begin{bmatrix} x_1 & -x_1 \\\\ x_2 & -x_2 \\\\ \\dots & \\dots \\\\ x_n & -x_n\\end{bmatrix}\\)\n\n\\({\\bf W}^{(1)}=\\begin{bmatrix} 1 & -1 \\end{bmatrix}\\)\n\\({\\boldsymbol b}^{(1)}=\\begin{bmatrix} 0 & 0 \\end{bmatrix}\\)\n\n(3) \\((a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big)=\\begin{bmatrix} \\text{relu}(x_1) & \\text{relu}(-x_1) \\\\ \\text{relu}(x_2) & \\text{relu}(-x_2) \\\\ \\dots & \\dots \\\\ \\text{relu}(x_n) & \\text{relu}(-x_n)\\end{bmatrix}\\)\n(4) \\((l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\)\n\\(\\quad=\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)\n\n\\({\\bf W}^{(2)}=\\begin{bmatrix} -4.5 \\\\ -9 \\end{bmatrix}\\)\n\\(b^{(2)}=4.5\\)\n\n(5) \\(\\textup{pwlinr}({\\bf X})=(l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\)\n\\(\\quad =\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)\n\n\n\n\n4. 스펙의역설 적합\n- 다시한번 데이터 정리\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/ironyofspec.csv\")\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\n\n\n\n\n\n\n\n\n- Step1에 대한 생각: 네트워크를 어떻게 만들까? = 아키텍처를 어떻게 만들까? = 모델링\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n\n\\(l_1\\): torch.nn.Linear(1,2,bias=False)\n\\(a_1\\): torch.nn.ReLU()\n\\(l_2\\): torch.nn.Linear(2,1,bias=True)\n\\(a_2\\): torch.nn.Sigmoid()\n\n- Step1-4\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2,bias=False),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2,1,bias=True),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss() \noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## step1\n    yhat = net(x)\n    ## step2\n    loss = loss_fn(yhat,y)\n    ## step3\n    loss.backward()\n    ## step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\nplt.plot(x,yhat.data,'--')\n\n\n\n\n\n\n\n\n한번더~\n\nfor epoc in range(5000):\n    ## step1\n    yhat = net(x)\n    ## step2\n    loss = loss_fn(yhat,y)\n    ## step3\n    loss.backward()\n    ## step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x,prob,'--')\nplt.plot(x,yhat.data,'--')"
  },
  {
    "objectID": "posts/07wk-2.html#a.-torch.nn.relu",
    "href": "posts/07wk-2.html#a.-torch.nn.relu",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "A. torch.nn.ReLU",
    "text": "A. torch.nn.ReLU"
  },
  {
    "objectID": "posts/07wk-2.html#b.-torch.nn.maxpool2d",
    "href": "posts/07wk-2.html#b.-torch.nn.maxpool2d",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "B. torch.nn.MaxPool2d",
    "text": "B. torch.nn.MaxPool2d"
  },
  {
    "objectID": "posts/07wk-2.html#c.-torch.nn.conv2d",
    "href": "posts/07wk-2.html#c.-torch.nn.conv2d",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "C. torch.nn.Conv2d",
    "text": "C. torch.nn.Conv2d\n(예시1) 연산방법, stride=2\n\nimg = torch.rand(1,1,4,4)\nconv = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=2,stride=2)\n\n\nimg\n\ntensor([[[[0.3041, 0.9222, 0.4187, 0.7885],\n          [0.7488, 0.5487, 0.7938, 0.0053],\n          [0.5002, 0.8596, 0.9975, 0.7992],\n          [0.7594, 0.3295, 0.9948, 0.2643]]]])\n\n\n\nconv(img)\n\ntensor([[[[0.4708, 0.6137],\n          [0.5387, 0.6470]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n??\n\nconv.weight.data, conv.bias.data\n\n(tensor([[[[-0.2970, -0.3377],\n           [ 0.0756, -0.1169]]]]),\n tensor([0.4719]))\n\n\n\n(img[:,  :,  :2,  :2] * conv.weight.data).sum()+conv.bias.data, conv(img)\n\n(tensor([0.1281]),\n tensor([[[[0.1281, 0.0595],\n           [0.1877, 0.0775]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n\n(img[:,  :,  :2,  2:] * conv.weight.data).sum()+conv.bias.data, conv(img)\n\n(tensor([0.0595]),\n tensor([[[[0.1281, 0.0595],\n           [0.1877, 0.0775]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n\n(img[:,  :,  :2,  2:] * conv.weight.data).sum()+conv.bias.data, conv(img)\n\n(tensor([0.0595]),\n tensor([[[[0.1281, 0.0595],\n           [0.1877, 0.0775]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n\n(img[:,  :,  2:,  2:] * conv.weight.data).sum()+conv.bias.data, conv(img)\n\n(tensor([0.0775]),\n tensor([[[[0.1281, 0.0595],\n           [0.1877, 0.0775]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n\n\n\n\n\n\nNote\n\n\n\n입력이 1장의 흑백이미지이고 출력도 1장의 흑백이미지일 경우 컨볼루션 계산과정 요약1\n\n윈도우생성: kernel_size = (?,?) 인 윈도우를 만듦\nsub-img생성: 입력 이미지에 윈도우를 통과시켜 (?,?) 크기의 sub-img를 만듦.\n연산: sub-img의 각 원소에 conv.weight의 값을 원소별로 (=element-wisely) 곱하고 결과를 더함. (만약에 conv.bias가 있다면 최종결과에 bias를 더함)\n이동&반복: 윈도우를 stride 만큼 이동하여 반복. (stride=1 이라면 한칸씩, stride=2 라면 두칸씩 이동)\n\n\n\n1 입력shape=(1,1,?,?) 이고 출력의shape=(1,1,?,?)일 경우(예시2) – 재현\n“A guide to convolution arithmetic for deep learning” (Dumoulin and Visin 2016) 에 나온 그림재현\n\nDumoulin, Vincent, and Francesco Visin. 2016. “A Guide to Convolution Arithmetic for Deep Learning.” arXiv Preprint arXiv:1603.07285.\n\nref: https://arxiv.org/abs/1603.07285\n\n\n\n\nFig: conv2d 계산과정시각화\n\n\n\nimg = torch.tensor([\n    [3,3,2,1,0],\n    [0,0,1,3,1],\n    [3,1,2,2,3],\n    [2,0,0,2,2],\n    [2,0,0,0,1]\n]).reshape(1,1,5,5).float()\nimg\n\ntensor([[[[3., 3., 2., 1., 0.],\n          [0., 0., 1., 3., 1.],\n          [3., 1., 2., 2., 3.],\n          [2., 0., 0., 2., 2.],\n          [2., 0., 0., 0., 1.]]]])\n\n\n\nconv = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,bias=False)\nconv.weight.data = torch.tensor([[[\n    [ 0.0, 1.0, 2.0],\n    [ 2.0, 2.0, 0.0],\n    [ 0.0, 1.0, 2.0]\n]]])\n\n\nconv(img)\n\ntensor([[[[12., 12., 17.],\n          [10., 17., 19.],\n          [ 9.,  6., 14.]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n(예시3) 이동평균\n\nimg = torch.arange(1,17).float().reshape(1,1,4,4)\nimg\n\ntensor([[[[ 1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.],\n          [ 9., 10., 11., 12.],\n          [13., 14., 15., 16.]]]])\n\n\n\nconv = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=2,stride=1,bias=False)\nconv.weight.data = conv.weight.data*0 + 1/4\nconv.weight.data\n\ntensor([[[[0.2500, 0.2500],\n          [0.2500, 0.2500]]]])\n\n\n\nconv(img)\n\ntensor([[[[ 3.5000,  4.5000,  5.5000],\n          [ 7.5000,  8.5000,  9.5000],\n          [11.5000, 12.5000, 13.5000]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n(예시4) 2개의 이미지\n- 개념: (1,1,?,?) \\(\\to\\) (1,1,?,?) 의 conv를 observation 별로 적용\n\nconv 에 포함된 파라메터 수는 (1,1,?,?) \\(\\to\\) (1,1,?,?) 인 경우와 (n,1,?,?) \\(\\to\\) (n,1,?,?)인 경우가 동일\n\n\nimgs = torch.arange(1,33).float().reshape(2,1,4,4)\nconv = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=2,stride=1,bias=False)\nconv.weight.data = conv.weight.data*0 + 1/4\n\n\nimgs\n\ntensor([[[[ 1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.],\n          [ 9., 10., 11., 12.],\n          [13., 14., 15., 16.]]],\n\n\n        [[[17., 18., 19., 20.],\n          [21., 22., 23., 24.],\n          [25., 26., 27., 28.],\n          [29., 30., 31., 32.]]]])\n\n\n\nconv(imgs)\n\ntensor([[[[ 3.5000,  4.5000,  5.5000],\n          [ 7.5000,  8.5000,  9.5000],\n          [11.5000, 12.5000, 13.5000]]],\n\n\n        [[[19.5000, 20.5000, 21.5000],\n          [23.5000, 24.5000, 25.5000],\n          [27.5000, 28.5000, 29.5000]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n(예시5) 2개의 이미지, 2개의 out_channels\n- 개념: (1,1,?,?) \\(\\to\\) (1,1,?,?) 의 conv를 한번 적용, 그것과 별개로 (1,1,?,?) \\(\\to\\) (1,1,?,?) 인 다른 conv를 적용함. (즉 하나의 observation당 2번 conv변환) 이것을 observation별로 반복\n\n(1,1,?,?) \\(\\to\\) (1,2,?,?) 인 경우는 (1,1,?,?) \\(\\to\\) (1,1,?,?)인 경우보다 conv에 포함된 파라메터 수가 2배 많음\n그런데 (1,1,?,?) \\(\\to\\) (1,2,?,?) 인 경우와 (n,1,?,?) \\(\\to\\) (n,2,?,?)인 경우는 conv에 포함된 파라메터 수가 같음.\n따라서 (n,1,?,?) \\(\\to\\) (n,2,?,?) 인 경우는 (1,1,?,?) \\(\\to\\) (1,1,?,?)인 경우보다 conv에 포함된 파라메터 수가 2배 많음\n\n\nimg = torch.arange(1,33).float().reshape(2,1,4,4)\nconv = torch.nn.Conv2d(in_channels=1,out_channels=2,kernel_size=2,stride=1,bias=False)\n\n\nimg\n\ntensor([[[[ 1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.],\n          [ 9., 10., 11., 12.],\n          [13., 14., 15., 16.]]],\n\n\n        [[[17., 18., 19., 20.],\n          [21., 22., 23., 24.],\n          [25., 26., 27., 28.],\n          [29., 30., 31., 32.]]]])\n\n\n\nconv.weight.data[0] = conv.weight.data[0]*0 +1/4\nconv.weight.data[1] = conv.weight.data[0]*0\n\n\nconv(img)\n\ntensor([[[[ 3.5000,  4.5000,  5.5000],\n          [ 7.5000,  8.5000,  9.5000],\n          [11.5000, 12.5000, 13.5000]],\n\n         [[ 0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000]]],\n\n\n        [[[19.5000, 20.5000, 21.5000],\n          [23.5000, 24.5000, 25.5000],\n          [27.5000, 28.5000, 29.5000]],\n\n         [[ 0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n\nconv(img)\n\ntensor([[[[ 1.2309,  1.2712,  1.3115],\n          [ 1.3920,  1.4322,  1.4725],\n          [ 1.5530,  1.5933,  1.6335]],\n\n         [[ 3.9083,  4.5405,  5.1728],\n          [ 6.4372,  7.0695,  7.7017],\n          [ 8.9662,  9.5984, 10.2307]]],\n\n\n        [[[ 1.8751,  1.9154,  1.9556],\n          [ 2.0362,  2.0764,  2.1167],\n          [ 2.1972,  2.2375,  2.2777]],\n\n         [[14.0241, 14.6563, 15.2886],\n          [16.5530, 17.1853, 17.8175],\n          [19.0820, 19.7142, 20.3465]]]], grad_fn=&lt;ConvolutionBackward0&gt;)"
  },
  {
    "objectID": "posts/07wk-2.html#a.-data",
    "href": "posts/07wk-2.html#a.-data",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "A. data",
    "text": "A. data\n아래의 4개의 이미지를 생각하자 .\n\nimg0 = torch.tensor([\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n]).reshape(1, 1, 16, 16) \nimg1 = 0.1-torch.einsum('nchw-&gt;ncwh', img0.clone())\nimg2 = torch.zeros((1, 1, 16, 16))\nfor i in range(16):\n    for j in range(16):\n        if j &lt;= i:  # 대각선 아래 삼각형\n            img2[0, 0, i, j] = 0.1\n# 빈 이미지\nimg3 = torch.zeros((1, 1, 16, 16))\nblock_size = 2\n# 블록 단위로 채우기\nfor i in range(0, 16, block_size):\n    for j in range(0, 16, block_size):\n        if ((i // block_size) + (j // block_size)) % 2 == 0:\n            img3[0, 0, i:i+block_size, j:j+block_size] = 0.1\n\n\nfig, axs = plt.subplots(2,2)\nfig.set_figheight(8)\nfig.set_figwidth(8)\naxs[0][0].imshow(img0.squeeze(),cmap=\"gray\")\naxs[0][1].imshow(img1.squeeze(),cmap=\"gray\")\naxs[1][0].imshow(img2.squeeze(),cmap=\"gray\")\naxs[1][1].imshow(img3.squeeze(),cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nimgs = torch.concat([img0,img1,img2,img3],axis=0)\nimgs.shape\n\ntorch.Size([4, 1, 16, 16])"
  },
  {
    "objectID": "posts/07wk-2.html#b.-vertical-edge",
    "href": "posts/07wk-2.html#b.-vertical-edge",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "B. vertical edge",
    "text": "B. vertical edge\n\nv_conv = torch.nn.Conv2d(\n    in_channels=1,\n    out_channels=1,\n    kernel_size=4,\n    bias=False\n)\n\n\nv_conv.weight.data = torch.tensor([[[\n    [ 0, 0, 0, 0],\n    [ 0, 1.0, -1.0, 0],\n    [0, 1.0, -1.0, 0],\n    [ 0, 0, 0, 0]\n]]])\n\n\n이 v_conv는 좌우방향의 픽셀변화, 즉 수직 방향의 엣지(vertical edge)를 감지하는데 적절하다.\n\n\nfig, axs = plt.subplots(2,2)\nfig.set_figheight(8)\nfig.set_figwidth(8)\naxs[0][0].imshow(v_conv(imgs)[0].squeeze().data,cmap=\"gray\")\naxs[0][1].imshow(v_conv(imgs)[1].squeeze().data,cmap=\"gray\")\naxs[1][0].imshow(v_conv(imgs)[2].squeeze().data,cmap=\"gray\")\naxs[1][1].imshow(v_conv(imgs)[3].squeeze().data,cmap=\"gray\")"
  },
  {
    "objectID": "posts/07wk-2.html#c.-horizontal-edge",
    "href": "posts/07wk-2.html#c.-horizontal-edge",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "C. horizontal edge",
    "text": "C. horizontal edge\n\nh_conv = torch.nn.Conv2d(\n    in_channels=1,\n    out_channels=1,\n    kernel_size=4,\n    bias=False\n)\n\n\nh_conv.weight.data = torch.tensor([[[\n    [ 0, 0, 0, 0],\n    [ 0, -1.0, -1.0, 0],\n    [0, 1.0, 1.0, 0],\n    [ 0, 0, 0, 0]\n]]])\n\n\n이 h_conv는 위아레 방향의 픽셀변화, 즉 수평엣지(horizontal edge)를 감지하는데 적절하다.\n\n\nfig, axs = plt.subplots(2,2)\nfig.set_figheight(8)\nfig.set_figwidth(8)\naxs[0][0].imshow(h_conv(imgs)[0].squeeze().data,cmap=\"gray\")\naxs[0][1].imshow(h_conv(imgs)[1].squeeze().data,cmap=\"gray\")\naxs[1][0].imshow(h_conv(imgs)[2].squeeze().data,cmap=\"gray\")\naxs[1][1].imshow(h_conv(imgs)[3].squeeze().data,cmap=\"gray\")"
  },
  {
    "objectID": "posts/07wk-2.html#d.-이동평균",
    "href": "posts/07wk-2.html#d.-이동평균",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "D. 이동평균",
    "text": "D. 이동평균\n\nm_conv = torch.nn.Conv2d(\n    in_channels=1,\n    out_channels=1,\n    kernel_size=4,\n)\nm_conv.weight.data = m_conv.weight.data*0 + 1/16\nm_conv.bias.data = m_conv.bias.data*0 - 0.05\n\n\nfig, axs = plt.subplots(2,2)\nfig.set_figheight(8)\nfig.set_figwidth(8)\naxs[0][0].imshow(m_conv(imgs)[0].squeeze().data,cmap=\"gray\")\naxs[0][1].imshow(m_conv(imgs)[1].squeeze().data,cmap=\"gray\")\naxs[1][0].imshow(m_conv(imgs)[2].squeeze().data,cmap=\"gray\")\naxs[1][1].imshow(m_conv(imgs)[3].squeeze().data,cmap=\"gray\")"
  },
  {
    "objectID": "posts/07wk-2.html#e.-cde-relu-mp",
    "href": "posts/07wk-2.html#e.-cde-relu-mp",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "E. (C,D,E) + relu + mp",
    "text": "E. (C,D,E) + relu + mp\n\nrelu = torch.nn.ReLU()\nmp = torch.nn.MaxPool2d(kernel_size=13)\n\n\nmp(relu(v_conv(imgs)))\n\ntensor([[[[0.200000]]],\n\n\n        [[[0.000000]]],\n\n\n        [[[0.100000]]],\n\n\n        [[[0.200000]]]], grad_fn=&lt;MaxPool2DWithIndicesBackward0&gt;)\n\n\n\nmp(relu(h_conv(imgs)))\n\ntensor([[[[0.000000]]],\n\n\n        [[[0.200000]]],\n\n\n        [[[0.100000]]],\n\n\n        [[[0.200000]]]], grad_fn=&lt;MaxPool2DWithIndicesBackward0&gt;)\n\n\n\nmp(relu(m_conv(imgs)))\n\ntensor([[[[2.000000e-01]]],\n\n\n        [[[2.000000e-01]]],\n\n\n        [[[2.000000e-01]]],\n\n\n        [[[3.725290e-09]]]], grad_fn=&lt;MaxPool2DWithIndicesBackward0&gt;)"
  },
  {
    "objectID": "posts/07wk-2.html#f.-대충-이런-구조",
    "href": "posts/07wk-2.html#f.-대충-이런-구조",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "F. 대충 이런 구조",
    "text": "F. 대충 이런 구조\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(in_channels=1,out_channels=3,kernel_size=4),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=13),\n    torch.nn.Flatten()\n)\nnet[0].weight.data = torch.concat(\n    [v_conv.weight.data,\n     h_conv.weight.data,\n     m_conv.weight.data],axis=0)\nnet[0].bias.data = torch.tensor([0.0,0.0, -0.05])\n\n\nplt.matshow(net(imgs).data,cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nnet(imgs).shape\n\ntorch.Size([4, 3])\n\n\n\n출력은 (n,3)으로 정리되어서 나온다. 이 시점부터는 더 이상 이미지가 입력이라고 생각하지 않아도 되고, 단순히 (n, 3) 크기의 숫자 데이터가 입력으로 주어진 것처럼 보면 된다. 즉 이제부터는 이 (n,3) 데이터를 입력으로 받는 신경망을 설계하면 된다."
  },
  {
    "objectID": "posts/07wk-2.html#g.-mp의-역할",
    "href": "posts/07wk-2.html#g.-mp의-역할",
    "title": "07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST",
    "section": "G. mp의 역할?",
    "text": "G. mp의 역할?\n- 샘플이미지\n\nimg = torch.zeros((1, 1, 16, 16))\ntriangle_size = 4\nfor i in range(triangle_size):\n    for j in range(triangle_size):\n        if j &lt;= i:  # 아래 방향 직각삼각형 (왼쪽 위 꼭짓점 기준)\n            img[0, 0, i, j] = 1.0\n\n\nplt.imshow(img.squeeze(),cmap=\"gray\")\n\n\n\n\n\n\n\n\n- mp1 회\n\nmp = torch.nn.MaxPool2d(kernel_size=2)\nplt.imshow(mp(img).squeeze(),cmap=\"gray\")\n\n\n\n\n\n\n\n\n- mp 2~4회\n\nmp = torch.nn.MaxPool2d(kernel_size=2)\nplt.imshow(mp(mp(img)).squeeze(),cmap=\"gray\")\n\n\n\n\n\n\n\n\n\nmp = torch.nn.MaxPool2d(kernel_size=2)\nplt.imshow(mp(mp(mp(img))).squeeze(),cmap=\"gray\")\n\n\n\n\n\n\n\n\n- maxpooling은 이미지를 “캐리커처화” 한다고 비유할 수 있음. 디테일은 버리고, 중요한 특징만 뽑아서 과장되게 요약한다."
  },
  {
    "objectID": "posts/02wk-2.html#a.-print",
    "href": "posts/02wk-2.html#a.-print",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "A. print",
    "text": "A. print\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nprint(f\"시작값 = {What.data.reshape(-1)}\")\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - alpha * What.grad\n    print(f'loss = {loss:.2f} \\t 업데이트폭 = {-alpha * What.grad.reshape(-1)} \\t 업데이트결과: {What.data.reshape(-1)}')\n    What.grad = None\n\n시작값 = tensor([-5., 10.])\nloss = 8587.69   업데이트폭 = tensor([ 1.3423, -1.1889])      업데이트결과: tensor([-3.6577,  8.8111])\nloss = 5675.21   업데이트폭 = tensor([ 1.1029, -0.9499])      업데이트결과: tensor([-2.5548,  7.8612])\nloss = 3755.64   업데이트폭 = tensor([ 0.9056, -0.7596])      업데이트결과: tensor([-1.6492,  7.1016])\nloss = 2489.58   업데이트폭 = tensor([ 0.7431, -0.6081])      업데이트결과: tensor([-0.9061,  6.4935])\nloss = 1654.04   업데이트폭 = tensor([ 0.6094, -0.4872])      업데이트결과: tensor([-0.2967,  6.0063])\nloss = 1102.32   업데이트폭 = tensor([ 0.4995, -0.3907])      업데이트결과: tensor([0.2028, 5.6156])\nloss = 737.84    업데이트폭 = tensor([ 0.4091, -0.3136])      업데이트결과: tensor([0.6119, 5.3020])\nloss = 496.97    업데이트폭 = tensor([ 0.3350, -0.2519])      업데이트결과: tensor([0.9469, 5.0501])\nloss = 337.71    업데이트폭 = tensor([ 0.2742, -0.2025])      업데이트결과: tensor([1.2211, 4.8477])\nloss = 232.40    업데이트폭 = tensor([ 0.2243, -0.1629])      업데이트결과: tensor([1.4454, 4.6848])\nloss = 162.73    업데이트폭 = tensor([ 0.1834, -0.1311])      업데이트결과: tensor([1.6288, 4.5537])\nloss = 116.63    업데이트폭 = tensor([ 0.1500, -0.1056])      업데이트결과: tensor([1.7787, 4.4480])\nloss = 86.13     업데이트폭 = tensor([ 0.1226, -0.0851])      업데이트결과: tensor([1.9013, 4.3629])\nloss = 65.93     업데이트폭 = tensor([ 0.1001, -0.0687])      업데이트결과: tensor([2.0014, 4.2942])\nloss = 52.57     업데이트폭 = tensor([ 0.0818, -0.0554])      업데이트결과: tensor([2.0832, 4.2388])\nloss = 43.72     업데이트폭 = tensor([ 0.0668, -0.0447])      업데이트결과: tensor([2.1500, 4.1941])\nloss = 37.86     업데이트폭 = tensor([ 0.0545, -0.0361])      업데이트결과: tensor([2.2045, 4.1579])\nloss = 33.97     업데이트폭 = tensor([ 0.0445, -0.0292])      업데이트결과: tensor([2.2490, 4.1287])\nloss = 31.40     업데이트폭 = tensor([ 0.0363, -0.0236])      업데이트결과: tensor([2.2853, 4.1051])\nloss = 29.70     업데이트폭 = tensor([ 0.0296, -0.0191])      업데이트결과: tensor([2.3150, 4.0860])\nloss = 28.57     업데이트폭 = tensor([ 0.0242, -0.0155])      업데이트결과: tensor([2.3392, 4.0705])\nloss = 27.83     업데이트폭 = tensor([ 0.0197, -0.0125])      업데이트결과: tensor([2.3589, 4.0580])\nloss = 27.33     업데이트폭 = tensor([ 0.0161, -0.0101])      업데이트결과: tensor([2.3750, 4.0479])\nloss = 27.00     업데이트폭 = tensor([ 0.0131, -0.0082])      업데이트결과: tensor([2.3881, 4.0396])\nloss = 26.79     업데이트폭 = tensor([ 0.0107, -0.0067])      업데이트결과: tensor([2.3988, 4.0330])\nloss = 26.64     업데이트폭 = tensor([ 0.0087, -0.0054])      업데이트결과: tensor([2.4075, 4.0276])\nloss = 26.55     업데이트폭 = tensor([ 0.0071, -0.0044])      업데이트결과: tensor([2.4146, 4.0232])\nloss = 26.48     업데이트폭 = tensor([ 0.0058, -0.0035])      업데이트결과: tensor([2.4204, 4.0197])\nloss = 26.44     업데이트폭 = tensor([ 0.0047, -0.0029])      업데이트결과: tensor([2.4251, 4.0168])\nloss = 26.41     업데이트폭 = tensor([ 0.0038, -0.0023])      업데이트결과: tensor([2.4290, 4.0144])"
  },
  {
    "objectID": "posts/02wk-2.html#b.-시각화-yhat의-관점에서",
    "href": "posts/02wk-2.html#b.-시각화-yhat의-관점에서",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "B. 시각화 – yhat의 관점에서!",
    "text": "B. 시각화 – yhat의 관점에서!\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nplt.plot(x,y,'o',label = \"observed\")\nfig = plt.gcf()\nax = fig.gca()\nax.plot(x,X@What.data,'--',color=\"C1\")\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - alpha * What.grad\n    ax.plot(x,X@What.data,'--',color=\"C1\",alpha=0.1)\n    What.grad = None"
  },
  {
    "objectID": "posts/02wk-2.html#c.-시각화-loss의-관점에서",
    "href": "posts/02wk-2.html#c.-시각화-loss의-관점에서",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "C. 시각화 – loss의 관점에서!!",
    "text": "C. 시각화 – loss의 관점에서!!\n\ndef plot_loss():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    w0 = np.arange(-6, 11, 0.5) \n    w1 = np.arange(-6, 11, 0.5)\n    W1,W0 = np.meshgrid(w1,w0)\n    LOSS=W0*0\n    for i in range(len(w0)):\n        for j in range(len(w1)):\n            LOSS[i,j]=torch.sum((y-w0[i]-w1[j]*x)**2)\n    ax.plot_surface(W0, W1, LOSS, rstride=1, cstride=1, color='b',alpha=0.1)\n    ax.azim = 30  ## 3d plot의 view 조절 \n    ax.dist = 8   ## 3d plot의 view 조절 \n    ax.elev = 5   ## 3d plot의 view 조절 \n    ax.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax.set_xticks([-5,0,5,10])  # x축 틱 간격 설정\n    ax.set_yticks([-5,0,5,10])  # y축 틱 간격 설정\n    plt.close(fig)  # 자동 출력 방지\n    return fig\n\n\n# 손실 8587.6875 를 계산하는 또 다른 방식\ndef l(w0hat,w1hat):\n    yhat = w0hat + w1hat*x\n    return torch.sum((y-yhat)**2)\n\n\nfig = plot_loss()\nax = fig.gca()\nax.scatter(2.5, 4, l(2.5,4), s=200, marker='*', color='red', label=r\"${\\bf W}=[2.5, 4]'$\")\nax.scatter(-5, 10, l(-5,10), s=200, marker='*', color='blue', label=r\"initial $\\hat{\\bf W}=[-5, 10]'$\")\nax.legend()\nfig\n\n\n\n\n\n\n\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    w0,w1 = What.data.reshape(-1) \n    ax.scatter(w0,w1,l(w0,w1),s=5,marker='o',color='blue')\n    What.grad = None\n\n\nfig"
  },
  {
    "objectID": "posts/02wk-2.html#d.-애니메이션",
    "href": "posts/02wk-2.html#d.-애니메이션",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "D. 애니메이션",
    "text": "D. 애니메이션\n\nfrom matplotlib import animation\n\n\nplt.rcParams['figure.figsize'] = (7.5,2.5)\nplt.rcParams[\"animation.html\"] = \"jshtml\" \n\n\ndef show_animation(alpha=0.001):\n    ## 1. 히스토리 기록을 위한 list 초기화\n    loss_history = [] \n    yhat_history = [] \n    What_history = [] \n\n    ## 2. 학습 + 학습과정기록\n    What= torch.tensor([[-5.0],[10.0]],requires_grad=True)\n    What_history.append(What.data.tolist())\n    for epoc in range(30): \n        yhat=X@What ; yhat_history.append(yhat.data.tolist())\n        loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n        loss.backward() \n        What.data = What.data - alpha * What.grad; What_history.append(What.data.tolist())\n        What.grad = None    \n\n    ## 3. 시각화 \n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\n    #### ax1: yhat의 관점에서.. \n    ax1.plot(x,y,'o',label=r\"$(x_i,y_i)$\")\n    line, = ax1.plot(x,yhat_history[0],label=r\"$(x_i,\\hat{y}_i)$\") \n    ax1.legend()\n    #### ax2: loss의 관점에서.. \n    w0 = np.arange(-6, 11, 0.5) \n    w1 = np.arange(-6, 11, 0.5)\n    W1,W0 = np.meshgrid(w1,w0)\n    LOSS=W0*0\n    for i in range(len(w0)):\n        for j in range(len(w1)):\n            LOSS[i,j]=torch.sum((y-w0[i]-w1[j]*x)**2)\n    ax2.plot_surface(W0, W1, LOSS, rstride=1, cstride=1, color='b',alpha=0.1)\n    ax2.azim = 30  ## 3d plot의 view 조절 \n    ax2.dist = 8   ## 3d plot의 view 조절 \n    ax2.elev = 5   ## 3d plot의 view 조절 \n    ax2.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax2.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax2.set_xticks([-5,0,5,10])  # x축 틱 간격 설정\n    ax2.set_yticks([-5,0,5,10])  # y축 틱 간격 설정\n    ax2.scatter(2.5, 4, l(2.5,4), s=200, marker='*', color='red', label=r\"${\\bf W}=[2.5, 4]'$\")\n    ax2.scatter(-5, 10, l(-5,10), s=200, marker='*', color='blue')\n    ax2.legend()\n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        ax2.scatter(np.array(What_history)[epoc,0],np.array(What_history)[epoc,1],loss_history[epoc],color='grey')\n        fig.suptitle(f\"alpha = {alpha} / epoch = {epoc}\")\n        return line\n\n    ani = animation.FuncAnimation(fig, animate, frames=30)\n    plt.close()\n    return ani\n\n\nani = show_animation(alpha=0.001)\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/02wk-2.html#e.-학습률에-따른-시각화",
    "href": "posts/02wk-2.html#e.-학습률에-따른-시각화",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "E. 학습률에 따른 시각화",
    "text": "E. 학습률에 따른 시각화\n- \\(\\alpha\\)가 너무 작다면 비효율적임\n\nshow_animation(alpha=0.0001)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- \\(\\alpha\\)가 크다고 무조건 좋은건 또 아님\n\nshow_animation(alpha=0.0083)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 수틀리면 수렴안할수도??\n\nshow_animation(alpha=0.0085)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 그냥 망할수도??\n\nshow_animation(alpha=0.01)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nplt.rcdefaults()\nplt.rcParams['figure.figsize'] = 4.5,3.0"
  },
  {
    "objectID": "posts/02wk-2.html#a.-기본패턴",
    "href": "posts/02wk-2.html#a.-기본패턴",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "A. 기본패턴",
    "text": "A. 기본패턴\n\n## -- 외우세요!!! -- ##\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    loss = torch.sum((y-yhat)**2)/100\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.1 * What.grad\n    What.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')\nplt.title(f'What={What.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/02wk-2.html#b.-step2의-수정-loss_fn-이용",
    "href": "posts/02wk-2.html#b.-step2의-수정-loss_fn-이용",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "B. Step2의 수정 – loss_fn 이용",
    "text": "B. Step2의 수정 – loss_fn 이용\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nloss_fn = torch.nn.MSELoss()\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    #loss = torch.sum((y-yhat)**2)/100\n    loss = loss_fn(yhat,y) # 여기서는 큰 상관없지만 습관적으로 yhat을 먼저넣는 연습을 하자!!\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.1 * What.grad\n    What.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')\nplt.title(f'What={What.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/02wk-2.html#c.-step1의-수정-net-이용",
    "href": "posts/02wk-2.html#c.-step1의-수정-net-이용",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "C. Step1의 수정 – net 이용",
    "text": "C. Step1의 수정 – net 이용\n# net – net 오브젝트란?\n원래 yhat을 이런식으로 구했는데 ~\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nyhat= X@What\nyhat[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n아래와 같은 방식으로 코드를 짜고 싶음..\nyhat = net(X) # \n위와 같은 코드를 가능하게 하는 net은 torch에서 지원하고 아래와 같이 사용할 수 있음.\n\n# yhat = net(X) \nnet = torch.nn.Linear(\n    in_features=2, # X:(n,2) --&gt; 2 \n    out_features=1, # yhat:(n,1) --&gt; 1 \n    bias=False \n)\n\n\nnet.weight.data = torch.tensor([[-5.0], [10.0]]).T # .T 를 해야함. 외우세요 \nnet.weight\n\nParameter containing:\ntensor([[-5., 10.]], requires_grad=True)\n\n\n\nnet(X)[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n(X@What)[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n(X@net.weight.T)[:5]\n\ntensor([[-29.8211],\n        [-28.6215],\n        [-24.9730],\n        [-21.2394],\n        [-19.7919]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n#\n- 수정된코드\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\nfor epoc in range(30):\n    # step1: yhat\n    # yhat = X@What \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    net.weight.data = net.weight.data - 0.1 * net.weight.grad\n    net.weight.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/02wk-2.html#d.-step4의-수정-optimizer의-이용",
    "href": "posts/02wk-2.html#d.-step4의-수정-optimizer의-이용",
    "title": "02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)",
    "section": "D. Step4의 수정 – optimizer의 이용",
    "text": "D. Step4의 수정 – optimizer의 이용\n- 소망: 아래의 과정을 좀 더 편하게 했으면..\nnet.weight.data = net.weight.data - 0.1 * net.weight.grad\nnet.weight.data = None \n# optimizer – 이걸 이용하면 update 과정을 손쉽게 할 수 있음\n기존코드\n\n## -- 준비과정 -- ## \n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n\n\n## -- 1에폭진행 -- ## \n# step1: \nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\nnet.weight.data = net.weight.data - 0.1 * net.weight.grad\nprint(net.weight.data)\nnet.weight.grad = None\n\ntensor([[-5., 10.]])\ntensor([[-3.6577,  8.8111]])\n\n\n\n## -- 2에폭진행 -- ## \n# step1: 2에폭진행\nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\nnet.weight.data = net.weight.data - 0.1 * net.weight.grad\nprint(net.weight.data)\nnet.weight.grad = None\n\ntensor([[-3.6577,  8.8111]])\ntensor([[-2.5548,  7.8612]])\n\n\n새로운코드 – optimizer 이용\n\n## -- 준비과정 -- ## \n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비\noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\n\n\n## -- 1에폭진행 -- ## \nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\n#net.weight.data = net.weight.data - 0.1 * net.weight.grad\noptimizr.step()\nprint(net.weight.data)\n#net.weight.grad = None\noptimizr.zero_grad()\n\ntensor([[-5., 10.]])\ntensor([[-3.6577,  8.8111]])\n\n\n\n## -- 2에폭진행 -- ## \nyhat = net(X)\n# step2: loss\nloss = loss_fn(yhat,y)\n# step3: 미분\nloss.backward()\n# step4: update\nprint(net.weight.data)\n#net.weight.data = net.weight.data - 0.1 * net.weight.grad\noptimizr.step()\nprint(net.weight.data)\n#net.weight.grad = None\noptimizr.zero_grad()\n\ntensor([[-3.6577,  8.8111]])\ntensor([[-2.5548,  7.8612]])\n\n\n#\n- 수정된코드\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비 \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/12wk-1.html#a.-파이토치의-유연성",
    "href": "posts/12wk-1.html#a.-파이토치의-유연성",
    "title": "12wk-1: (순환신경망) – 겹장(덧장), rNNCell",
    "section": "A. 파이토치의 유연성",
    "text": "A. 파이토치의 유연성\n- 아래는 엄밀한 의미에서는 계산불가능하지만 파이토치는 그냥 해준다.\n\nx = torch.randn(5)\nW = torch.randn(5,1)\nx@W \n\ntensor([5.5723])\n\n\n- 이와 유사하게 아래도 엄밀한 의미에서는 계산불가능하지만 파이토치는 그냥 해준다.\n\nlinr = torch.nn.Linear(5,1,bias=False)\nlinr.weight.data = W.T \nlinr(x)\n\ntensor([5.5723], grad_fn=&lt;SqueezeBackward4&gt;)"
  },
  {
    "objectID": "posts/12wk-1.html#b.-loss를-계산하는-다른방식",
    "href": "posts/12wk-1.html#b.-loss를-계산하는-다른방식",
    "title": "12wk-1: (순환신경망) – 겹장(덧장), rNNCell",
    "section": "B. loss를 계산하는 다른방식",
    "text": "B. loss를 계산하는 다른방식\n- 아래를 가정하자.\n\nX = torch.randn(100,5)\ny = torch.randn(100,1)\nnet = torch.nn.Linear(5,1)\nloss_fn = torch.nn.MSELoss()\n\n- loss를 계산하는 방법1\n\nyhat = net(X)\nloss = loss_fn(yhat,y)\nloss\n\ntensor(1.6908, grad_fn=&lt;MseLossBackward0&gt;)\n\n\n- loss를 계산하는 방법2\n\nloss = 0 \nfor i in range(100):\n    Xi, yi = X[i], y[i]\n    yi_hat = net(Xi)\n    loss = loss + loss_fn(yi_hat,yi)\nloss/100\n\ntensor(1.6908, grad_fn=&lt;DivBackward0&gt;)"
  },
  {
    "objectID": "posts/12wk-1.html#a.-차원의-정리",
    "href": "posts/12wk-1.html#a.-차원의-정리",
    "title": "12wk-1: (순환신경망) – 겹장(덧장), rNNCell",
    "section": "A. 차원의 정리",
    "text": "A. 차원의 정리\n- 기본버전\n\nX.shape = \\((L, H_{in})\\)\nh.shape = \\((L, H_{out})\\)\ny.shape = \\((L, Q)\\)\nXt.shape = \\((H_{in}, )\\)\nht.shape = \\((H_{out},)\\)\nyt.shape = \\((Q,)\\)\n\n- AbAcAd를 2차원공간에 임베딩하려고 할 경우.\n\nX.shape = \\((L, H_{in})\\) = \\((L,4)\\)\nh.shape = \\((L, H_{out})\\) = \\((L,2)\\)\ny.shape = \\((L, Q)\\) = \\((L,4)\\)\nXt.shape = \\((H_{in}, )\\) = \\((4,)\\)\nht.shape = \\((H_{out},)\\) = \\((2,)\\)\nyt.shape = \\((Q,)\\) = \\((4,)\\)"
  },
  {
    "objectID": "posts/12wk-1.html#b.-순환신경망-알고리즘",
    "href": "posts/12wk-1.html#b.-순환신경망-알고리즘",
    "title": "12wk-1: (순환신경망) – 겹장(덧장), rNNCell",
    "section": "B. 순환신경망 알고리즘",
    "text": "B. 순환신경망 알고리즘\n# 버전1\nstep 1: 일단 \\(\\text{간장}_0(={\\boldsymbol h}_0)\\)을 맹물로 초기화 한다. 즉 아래를 수행한다.\n\\[{\\boldsymbol h}_0 = [0,0]\\]\nstep 2: \\(\\text{콩물}_1(={\\boldsymbol x}_1)\\), \\(\\text{간장}_0(={\\boldsymbol h}_0)\\) 을 이용하여 \\(\\text{간장}_1(={\\boldsymbol h}_1)\\)을 숙성한다. 즉 아래를 수행한다. (즉 콩물과 오래된 간장을 합친뒤 숙성)\n\\[{\\boldsymbol h}_1= \\tanh({\\boldsymbol x}_1{\\bf W}_{ih}+{\\boldsymbol h}_0{\\bf W}_{hh}+{\\boldsymbol b}_{ih}+{\\boldsymbol b}_{hh})\\]\n\n\n\n\n\n\nNote\n\n\n\n아래의 식이 성립함을 관찰하자.\n\\[\\begin{bmatrix} {\\boldsymbol x}_1 & {\\boldsymbol h}_{0} \\end{bmatrix}\\begin{bmatrix} {\\bf W}_{ih} \\\\ {\\bf W}_{hh}\\end{bmatrix}={\\boldsymbol x}_1{\\bf W}_{ih}+{\\boldsymbol h}_0{\\bf W}_{hh}\\]\n\n\nstep 3: \\(\\text{간장}_1\\)을 이용하여 \\(\\text{간장계란밥}_1\\)을 만든다. 그리고 \\(\\hat{\\boldsymbol y}_1\\)을 만든다.\n\\[{\\boldsymbol o}_1= {\\bf W}_{ho}{\\boldsymbol h}_1+{\\boldsymbol b}_{ho}\\]\n\\[\\hat{\\boldsymbol y}_1 = \\text{soft}({\\boldsymbol o}_1)\\]\nstep 4: \\(t=2,3,4,5,\\dots,L\\) 에 대하여 step2-3을 반복한다.\n#\n# 버전2\ninit \\(\\boldsymbol{h}_0\\)\nfor \\(t\\) in \\(1:L\\)\n\n\\({\\boldsymbol h}_t= \\tanh({\\boldsymbol x}_t{\\bf W}_{ih}+{\\boldsymbol h}_{t-1}{\\bf W}_{hh}+{\\boldsymbol b}_{ih}+{\\boldsymbol b}_{hh})\\)\n\\({\\boldsymbol o}_t= {\\bf W}_{ho}{\\boldsymbol h}_t+{\\boldsymbol b}_{ho}\\)\n\\(\\hat{\\boldsymbol y}_t = \\text{soft}({\\boldsymbol o}_t)\\)\n\n#\n# 버전3\nht = [0,0]\nfor t in 1:T \n    ht = tanh(linr(xt)+linr(ht))\n    ot = linr(ht)\n    yt_hat = soft(ot)\n\n코드상으로는 \\(h_t\\)와 \\(h_{t-1}\\)의 구분이 교모하게 사라진다. (그래서 오히려 좋아)\n\n#\n- 따라서 실질적인 전체코드는 아래와 같은 방식으로 구현할 수 있다.\nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linr1 = torch.nn.Linear(4,2)\n        self.linr2 = torch.nn.Linear(2,2)\n        self.tanh = torch.nn.Tanh()\n    def forward(self,Xt,ht):\n        ht = self.tanh(self.linr1(Xt)+self.linr2(ht))\n        return ht\n        \nht = [0,0]        \nrnncell = rNNCell()\n\nfor t in 1:L\n    ht = rnncell(Xt,ht) #tanh(linr(Xt)+linr(ht))\n    ot = cook(ht)\n    yt_hat = soft(ot)"
  },
  {
    "objectID": "posts/12wk-1.html#c.-rnncell",
    "href": "posts/12wk-1.html#c.-rnncell",
    "title": "12wk-1: (순환신경망) – 겹장(덧장), rNNCell",
    "section": "C. rNNCell",
    "text": "C. rNNCell\n- 데이터정리\n\ntxt = list('AbAcAd'*50)\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ndf_train = pd.DataFrame({'x':txt[:-1], 'y':txt[1:]})\ndf_train[:5]\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\nA\nb\n\n\n1\nb\nA\n\n\n2\nA\nc\n\n\n3\nc\nA\n\n\n4\nA\nd\n\n\n\n\n\n\n\n\nx = torch.tensor(df_train.x.map({'A':0,'b':1,'c':2,'d':3}))\ny = torch.tensor(df_train.y.map({'A':0,'b':1,'c':2,'d':3}))\nX = torch.nn.functional.one_hot(x).float()\ny = torch.nn.functional.one_hot(y).float()\n\n\nX.shape, y.shape\n\n(torch.Size([299, 4]), torch.Size([299, 4]))\n\n\n- 순환신경망으로 적합\n\nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(4,2)\n        self.h2h = torch.nn.Linear(2,2)\n        self.tanh = torch.nn.Tanh()\n    def forward(self,Xt,ht):\n        return self.tanh(self.i2h(Xt)+self.h2h(ht))\ntorch.manual_seed(43052)\nrnncell = rNNCell()\ncook = torch.nn.Linear(2,4)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()),lr=0.1)\n#---#\nL = len(X)\nfor epoc in range(200):\n    #1~2 \n    loss = 0 \n    ht = torch.zeros(2) # 맹물\n    for t in range(L):\n        Xt, yt = X[t],y[t]\n        ht = rnncell(Xt,ht) #tanh(linr(xt)+linr(ht))\n        ot = cook(ht)\n        #yt_hat = soft(ot)\n        loss = loss + loss_fn(ot, yt) \n    loss = loss/L \n    #3\n    loss.backward()\n    #4\n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과 확인 및 시각화\n\nh = torch.zeros(L,2)\nwater = torch.zeros(2)\nh[0] = rnncell(X[0],water)\nfor t in range(1,L):\n    h[t] = rnncell(X[t],h[t-1])\nh.shape\n\ntorch.Size([299, 2])\n\n\n\nyhat = torch.nn.functional.softmax(cook(h),dim=1)\nyhat\n\ntensor([[4.1978e-03, 9.4555e-01, 1.9557e-06, 5.0253e-02],\n        [9.9994e-01, 5.5569e-05, 8.4751e-10, 1.3143e-06],\n        [2.1349e-07, 1.1345e-06, 9.7019e-01, 2.9806e-02],\n        ...,\n        [2.1339e-07, 1.1339e-06, 9.7020e-01, 2.9798e-02],\n        [9.9901e-01, 9.6573e-04, 6.9303e-09, 2.1945e-05],\n        [7.2919e-04, 2.5484e-02, 3.3011e-02, 9.4078e-01]],\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nmat = torch.concat([X,h,yhat],axis=1).data\nplt.matshow(mat[:12],cmap=\"bwr\",vmin=-1, vmax=1)\nplt.colorbar()\nplt.xticks(\n    range(10),\n    [r\"$X_A$\", r\"$X_b$\",r\"$X_c$\",r\"$X_d$\", \n     r'$h_1$',r'$h_2$',\n     r'$\\hat{y}_A$',r'$\\hat{y}_b$',r'$\\hat{y}_c$',r'$\\hat{y}_d$']\n);\nplt.axvline(x=3.5,color='lime')\nplt.axvline(x=5.5,color='lime')\n\n\n\n\n\n\n\n\n- yhat 값 분석\n\nyhat[:12].data.numpy().round(3)\n\narray([[0.004, 0.946, 0.   , 0.05 ],\n       [1.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.   , 0.97 , 0.03 ],\n       [0.999, 0.001, 0.   , 0.   ],\n       [0.001, 0.025, 0.033, 0.941],\n       [0.983, 0.016, 0.   , 0.   ],\n       [0.004, 0.965, 0.   , 0.031],\n       [1.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.   , 0.97 , 0.03 ],\n       [0.999, 0.001, 0.   , 0.   ],\n       [0.001, 0.025, 0.033, 0.941],\n       [0.983, 0.016, 0.   , 0.   ]], dtype=float32)\n\n\n\n미세하지만 뒤로갈수록 좀 더 성능이 좋다.\n\n- h1,h2 분석 (= 임베딩스페이스 분석)\n\nh1,h2 = h.T.data\n\n\nplt.plot(h1[::6], h2[::6],'o', label=\"first A\",alpha=0.1)\nplt.plot(h1[1::6], h2[1::6],'x', label=\"b\")\nplt.plot(h1[2::6], h2[2::6],'o', label=\"second A\")\nplt.plot(h1[3::6], h2[3::6],'x', label=\"c\")\nplt.plot(h1[4::6], h2[4::6],'o', label=\"third A\")\nplt.plot(h1[5::6], h2[5::6],'x', label=\"d\")\nplt.legend()"
  },
  {
    "objectID": "posts/mid.html",
    "href": "posts/mid.html",
    "title": "10wk-1: 중간고사",
    "section": "",
    "text": "import torch\nimport torchvision\nimport pandas \nimport matplotlib.pyplot as plt \n\n\n1. 기본문법 – 10점\n(1) 아래는 각각 horizontal edge, vertical edge를 의미하는 2개의 컨볼루션 필터를 설계한 것이다.\n\nh_conv = torch.nn.Conv2d(\n    in_channels=1,\n    out_channels=1,\n    kernel_size=4,\n    bias=False\n)\nh_conv.weight.data = torch.tensor([[[\n    [ 0, 0, 0, 0],\n    [ 0, -1.0, -1.0, 0],\n    [0, 1.0, 1.0, 0],\n    [ 0, 0, 0, 0]\n]]])\nv_conv = torch.nn.Conv2d(\n    in_channels=1,\n    out_channels=1,\n    kernel_size=4,\n    bias=False\n)\nv_conv.weight.data = torch.tensor([[[\n    [ 0, 0, 0, 0],\n    [ 0, 1.0, -1.0, 0],\n    [0, 1.0, -1.0, 0],\n    [ 0, 0, 0, 0]\n]]])\n\n위의 계수값을 활용하여 in_channels=1, out_channels=2, kernel_size=4 인 새로은 convolution filter를 설계하고 첫번째 아웃풋채널은 horizontal edge 을 두번째 아웃풋 채널은 vertical edge을 의미하도록 하라.\nhint:\n\ntorch.concat을 활용해야합니다.\n07wk-2강의노트를 참고하세요\n\n(2) 아래는 10장의 (28,28) 칼라이미지를 나타내는 자료이다.\n\nX = torch.rand(10,3,28,28)\n\n따라서 이미지의 각 pixel에는 3개의 숫자가 존재한다. 아래의 선형변한을 수행하여 이미지의 각 pixel에 적용하여 3개의 숫자를 하나로 줄이는 코드를 작성하라.\n\nlinr = torch.nn.Linear(3,1,bias=False)\n\nhint:\n\n변환후의 차원은 (10,1,28,28) 이어야 합니다.\ntorch.einsum을 활용해야합니다.\n08wk-2강의노트를 참고하세요\n\n\n\n2. 파라메터 count – 10점\nnote:\n\n학습가능한 파라메터가 동일할 경우 동일하다고 답할것.\n해설쓸 필요 없이 답만 쓸 것\n\n(1) net1과 net2중 학습가능한 파라메터가 더 많은 쪽은 어디인가?\n\nnet1 = torch.nn.Sequential(\n    torch.nn.Linear(10,1, bias=False),\n    torch.nn.Sigmoid()\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(10,1, bias=True)\n)\n\n(2) net1과 net2중 학습가능한 파라메터가 더 많은 쪽은 어디인가?\n\nnet1 = torch.nn.Sequential(\n    torch.nn.Linear(10,5),\n    torch.nn.Dropout(0.5),\n    torch.nn.ReLU(),\n    torch.nn.Linear(5,1)\n    \n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(10,5),\n    torch.nn.ReLU(),\n    torch.nn.Linear(5,1)\n)\n\n(3) conv1과 conv2중 학습가능한 파라메터가 더 많은 쪽은 어디인가?\n\nconv1 = torch.nn.Conv2d(\n    in_channels=1, \n    out_channels=1, \n    kernel_size=3\n)\nconv2 = torch.nn.Conv2d(\n    in_channels=1, \n    out_channels=1, \n    kernel_size=5\n)\n\n(4) conv1과 conv2중 학습가능한 파라메터가 더 많은 쪽은 어디인가?\n\nconv1 = torch.nn.Conv2d(\n    in_channels=1, \n    out_channels=2, \n    kernel_size=3\n)\nconv2 = torch.nn.Conv2d(\n    in_channels=1, \n    out_channels=1, \n    kernel_size=3\n)\n\n(5) conv1과 conv2중 학습가능한 파라메터가 더 많은 쪽은 어디인가?\n\nconv1 = torch.nn.Conv2d(\n    in_channels=1, \n    out_channels=2, \n    kernel_size=3,\n    stride=1\n)\nconv2 = torch.nn.Conv2d(\n    in_channels=1, \n    out_channels=2, \n    kernel_size=3,\n    stride=2\n)\n\n\n\n3. 최적화 – 20점\n\ntorch.manual_seed(43052)\ndist = torch.distributions.Exponential(1/2)\nx = dist.sample((10000,1))\n\n주어진 자료 \\(x_i\\)에 대하여 함수 \\(l(\\lambda)\\)를 최대화하는 \\(\\lambda\\)를 경사하강법 기반의 알고리즘을 이용하여 추정하라. 단 이때 \\(\\lambda\\)의 초기 추정값은 1로 설정하라.\n\\[\nl(\\lambda) =\\frac{1}{n} \\sum_{i=1}^{n}\\log f(x_i), \\quad f(x_i) = \\frac{1}{\\lambda} e^{-\\frac{x_i}{\\lambda}}, \\quad x_i \\geq 0\n\\]\nhint\n\n\\(l(\\lambda)\\)를 최대화하는 \\(\\lambda\\)는 \\(-l(\\lambda)\\)를 최소화합니다.\n이론적으로는 \\(l(\\lambda)\\)를 최대화하는 \\(\\lambda\\)는 x.mean()입니다. 즉 제대로 \\(\\lambda\\)를 추정한다면 x.mean()이 나오도록 되어있습니다.\n저는 경사하강법을 이용했고 학습률은 0.05로 설정했습니다. 1000회 update하니까 잘 수렴했습니다.\n\n\n\n4. 회귀 – 20점\n자유 낙하 운동이란 어떤 물체가 일정한 높이에서 떨어져 지면에 도달하기 까지 걸리는 시간을 다루는 물리학 개념이다. 다음은 물리학의 자유 낙하 운동에서 착안하여 생성한 데이터이다.\n\nh = torch.rand(100)*100\nh,_ = h.sort()\nh = h.reshape(100,1)\nt = torch.sqrt(2*h/9.8) + torch.randn([100,1])*0.1\n\n여기에서 \\(h\\)는 낙하전의 높이(단위: m), \\(t\\)는 해당높이에서 물치가 지면에 도달하기 까지 걸리는 시간(단위:초)을 의미한다. 예를 들어 아래의 자료는 \\(h=97.7798, t=4.4356\\)를 의미하는데\n\nh[-1], t[-1]\n\n(tensor([97.7798]), tensor([4.4356]))\n\n\n이것은 높이 \\(97.7798\\)m에서 낙하한 물체가 약 \\(4.4356\\)초만에 지면에 도달했음을 의미한다. 아래의 그림은 \\(x\\)축에 \\(h\\), \\(y\\)축에 \\(t\\)를 두고 해당 데이터를 산점도로 시각화 한 것이다.\n\nplt.plot(h,t,'o',alpha=0.5)\nplt.xlabel('Height (m)')\nplt.ylabel('Time to fall (sec)')\nplt.title('Free Fall Time vs Height')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n그래프를 보면 높이가 높을 수록 낙하시간도 길어지는 경향이 관찰된다. 다만 동일한 높이라 하더라도 낙하시간이 조금씩 차이나는 경우가 있는데, 이는 사람이 시간측정을 수동으로 하며 발생하는 실험오차 때문이다. 이러한 오차에도 불구하고 \\(h\\)와 \\(t\\)사이에는 일정한 규칙이 존재하는듯 하다. 물리학과 교수님께 자문을 요청한 결과 자유낙하에 걸리는 시간은 \\(\\sqrt{h}\\)에 비례함을 알 수 있었고 이를 근거로 아래와 같은 모형을 설계하였다.\n\\[t_i = \\beta_0 + \\beta_1 \\sqrt{h_i}+\\epsilon_i, \\quad \\epsilon_i \\sim {\\cal N}(0,\\sigma^2)\\]\n위의 모형을 활용하여 높이 \\(h\\)로부터 낙하시간 \\(t\\)를 예측하는 신경망 모델을 설계하고 학습하라. 학습한 신경망 모델을 활용하여 높이 40m,60m,80m 에서 물체를 자유낙하 시켰을때 지면에 도달하기까지 걸리는 시간을 각각 예측하라.\nhint\n\n\\(y_i = t_i\\) 로 생각하시고 \\(x_i= \\sqrt{h}_i\\)로 생각하시면 그냥 회귀모형이죠?\n답은 \\(2.8571\\)초, \\(3.4493\\)초, \\(4.0406\\)초 근처로 나오면 됩니다.\n제시된 모형(\\(t_i = \\beta_0 + \\beta_1 \\sqrt{h_i}+\\epsilon_i\\))을 무시하고 04wk-2와 같은 방식으로 신경망을 설계하고 푸셔도 만점으로 인정합니다.\n\n\n\n5. 분류 – 10점\n\n모든 문항을 맞출경우만 10점으로 인정\n\n아래의 자료를 고려하자.\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/iris.csv\")\ndf\n\n\n\n\n\n\n\n\nSepalLength\nSepalWidth\nPetalLength\nPetalWidth\nSpecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\n0.0\n\n\n1\n4.9\n3.0\n1.4\n0.2\n0.0\n\n\n2\n4.7\n3.2\n1.3\n0.2\n0.0\n\n\n3\n4.6\n3.1\n1.5\n0.2\n0.0\n\n\n4\n5.0\n3.6\n1.4\n0.2\n0.0\n\n\n...\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\n2.0\n\n\n146\n6.3\n2.5\n5.0\n1.9\n2.0\n\n\n147\n6.5\n3.0\n5.2\n2.0\n2.0\n\n\n148\n6.2\n3.4\n5.4\n2.3\n2.0\n\n\n149\n5.9\n3.0\n5.1\n1.8\n2.0\n\n\n\n\n150 rows × 5 columns\n\n\n\n위의 자료는 아이리스 데이터셋으로 머신러닝에서 자주 사용되는 분류(classification) 예제 데이터이다. 데이터는 다음과 같은 특징을 가지고 있다:\n샘플 수: 150개\n특징 수: 4개\n\n꽃받침 길이 (sepal length)\n꽃받침 너비 (sepal width)\n꽃잎 길이 (petal length)\n꽃잎 너비 (petal width)\n\n클래스 수: 3개 (각 50개 샘플)\n\n0: setosa\n1: versicolor\n2: virginica\n\n(1) 주어진 데이터를 8:2 비율로 학습용(df_train)과 테스트용(df_test)으로 나누고, SepalLength, SepalWidth, PetalLength, PetalWidth를 입력으로 하여 Species를 예측할 수 있도록 데이터를 텐서 형태로 변환하라.\nhint: 아래의 코드를 활용할 것\ndf_train = df.sample(frac=0.8, random_state=42)\ndf_test = df.drop(df_train.index)\n#---#\nX = torch.tensor(df_train.iloc[:,:4].values).float()\ny = ???\nXX = ???\nyy = ???\n(2) 아래의 제약사항에 맞추어 Species를 예측할 수 있는 적당한 네트워크를 학습하라.\n제약사항\n\n학습 후 test accuracy 가 70% 이상일것\n매 epoch마다 loss와 train accuracy를 출력할 것\n\n\n시험시간에 학습할 필요 없이, 기존에 공부했던 코드를 그대로 결과로 제시해도 무방함.\n\n\n\n6. CNN – 20점\n아래는 FashionMNIST 데이터셋을 불러와 torch tensor로 변환하는 코드이다.\n\ndf_train=pd.read_csv('https://media.githubusercontent.com/media/guebin/PP2023/main/posts/fashion-mnist_train.csv')\ndf_test=pd.read_csv('https://media.githubusercontent.com/media/guebin/PP2023/main/posts/fashion-mnist_test.csv')\nX = torch.tensor(df_train.iloc[:, 1:].to_numpy().reshape(-1, 1, 28, 28),dtype=torch.float32)\nXX = torch.tensor(df_test.iloc[:, 1:].to_numpy().reshape(-1, 1, 28, 28),dtype=torch.float32)\ny = torch.tensor(df_train['label'].to_numpy(), dtype=torch.long)\nyy = torch.tensor(df_test['label'].to_numpy(), dtype=torch.long)\n\n여기에서 X, y는 학습 데이터와 라벨, XX, yy는 테스트 데이터와 라벨을 의미한다. 아래의 제약사항에 맞추어 이 데이터를 학습할 수 있는 적당한 네트워크를 학습하라.\n제약사항\n\n학습 후 test accuracy 가 70% 이상일것\n매 epoch마다 loss와 train accuracy를 출력할 것\n네트워크에 torch.nn.Conv2d를 반드시 포함시킬 것\n\n\n\n7. XAI – 10점\n\n(1)-(3) 모두 맞출경우만 10점으로 인정\n\n아래의 코드를 이용하여 OxfordIIITPet 자료를 다운로드하고 물음에 답하라.\n\ntrain_dataset = torchvision.datasets.OxfordIIITPet(\n    root='./data', \n    split='trainval',\n    download=True,\n    target_types='binary-category'\n)\ntest_dataset = torchvision.datasets.OxfordIIITPet(\n    root='./data', \n    split='test',\n    download=True,\n    target_types='binary-category'\n)\n\n(1) 이 데이터를 사용하여 ResNet18을 기반으로 한 이진 분류 모델을 학습 및 평가하는 전체 파이프라인 코드를 작성하시오. 다음 제약사항을 만족해야 한다:\n제약사항\n\n각 이미지를 (512,512)로 리사이즈하고, torch.Tensor로 변환할 것 // 메모리 이슈 발생시 (256,256)으로 리사이즈 할 것.\n이용해 TensorDataset 및 DataLoader(batch_size=32)를 생성할 것 (학습 데이터는 shuffle=True)\nresnet18(pretrained=True)을 불러오고, 마지막 fully-connected layer를 torch.nn.Linear(512,1)로 교체할 것 // 메모리 이슈 발생시 torch.nn.Linear(256,1)로 교체할 것\n손실함수는 torch.nn.BCEWithLogitsLoss(), 옵티마이저는 torch.optim.Adam(resnet18.parameters(), lr=1e-5)로 설정할 것\n3번의 epoch 동안 학습하고 매 epoch 마다 학습 데이터의 정확도를 출력할 것\n학습이 끝난 이후 테스트 데이터에 대해 정확도를 계산하여 출력할 것\n\n(2) 아래의 이미지에 대한 로짓값과 그에 대응하는 확률값을 계산하고 인공지능이 이 이미지를 개라고 생각하는지 고양이라고 생각하는지 답하라.\n\nurl = 'https://github.com/guebin/DL2025/blob/main/imgs/hani2.jpeg?raw=true'\nhani_pil = PIL.Image.open(\n    io.BytesIO(requests.get(url).content)\n)\nhani_pil\n\n\n\n\n\n\n\n\n(3) (2)의 이미지에 대한 인공지능의 판단근거를 Class Activation Map (CAM) (Zhou et al. 2016)을 이용하여 시각화하라.\n\nZhou, Bolei, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. 2016. “Learning Deep Features for Discriminative Localization.” In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2921–29.\n\n\n8. GAN – 10점\n아래의 코드를 이용하여 MNIST 자료를 다운로드하라.\n\ndataset = torchvision.datasets.MNIST(\n    root = './data',\n    download=True\n)\nto_tensor = torchvision.transforms.ToTensor()\nX_real = torch.stack([to_tensor(Xi) for Xi, yi in dataset if yi==8])\n\n이안굿펠로우의 generative adversarial networks (GAN) (Goodfellow et al. 2014) 을 활용하여 (n,6) shape의 노이즈를 입력으로 하고 (n,1,28,28) shape 의 가짜이미지를 생성하는 네트워크를 훈련하고 결과를 시각화하라. 시각화 예시는 아래와 같다.\n\nGoodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. “Generative Adversarial Nets.” Advances in Neural Information Processing Systems 27."
  },
  {
    "objectID": "posts/11wk-2.html#a.-tanh",
    "href": "posts/11wk-2.html#a.-tanh",
    "title": "11wk-2: (순환신경망) – abc, abcd, 임베딩 공간의 이해, AbAcAd, 겹장(덧장)",
    "section": "A. tanh",
    "text": "A. tanh\n\nx = torch.linspace(-5,5,1001)\ntanh = torch.nn.Tanh()\nplt.plot(x,tanh(x).data)"
  },
  {
    "objectID": "posts/11wk-2.html#b.-softmax",
    "href": "posts/11wk-2.html#b.-softmax",
    "title": "11wk-2: (순환신경망) – abc, abcd, 임베딩 공간의 이해, AbAcAd, 겹장(덧장)",
    "section": "B. softmax",
    "text": "B. softmax\n\nlogits = torch.randn((10,5))\nlogits\n\ntensor([[ 0.6408, -0.2422,  1.3521,  1.1399, -0.3036],\n        [-0.5242, -0.3710, -0.3861, -0.5475,  3.1393],\n        [ 0.5174, -1.3213,  3.1802, -0.6713,  0.5917],\n        [ 0.0931,  1.0697,  0.6469, -1.1904, -0.1057],\n        [-1.3722,  0.4665, -0.7705, -0.6630, -1.1054],\n        [ 1.2289,  1.4994, -0.9319,  0.8154, -0.2033],\n        [-0.3431,  0.3966, -0.9672, -1.6696,  0.7154],\n        [ 0.4969, -0.6918,  1.1579, -2.4760,  0.1766],\n        [ 0.8880, -0.0768,  1.5095, -0.2842,  0.4944],\n        [ 0.2732, -2.0850, -0.5531,  0.1073, -0.1218]])\n\n\n\nprobs = torch.nn.functional.softmax(logits,dim=1)\nprobs\n\ntensor([[0.1823, 0.0754, 0.3712, 0.3002, 0.0709],\n        [0.0231, 0.0269, 0.0265, 0.0226, 0.9009],\n        [0.0593, 0.0094, 0.8494, 0.0181, 0.0638],\n        [0.1540, 0.4090, 0.2680, 0.0427, 0.1263],\n        [0.0803, 0.5050, 0.1466, 0.1632, 0.1049],\n        [0.3007, 0.3941, 0.0346, 0.1988, 0.0718],\n        [0.1475, 0.3091, 0.0790, 0.0392, 0.4252],\n        [0.2489, 0.0758, 0.4820, 0.0127, 0.1807],\n        [0.2366, 0.0901, 0.4404, 0.0733, 0.1596],\n        [0.3275, 0.0310, 0.1434, 0.2775, 0.2206]])"
  },
  {
    "objectID": "posts/11wk-2.html#a.-data",
    "href": "posts/11wk-2.html#a.-data",
    "title": "11wk-2: (순환신경망) – abc, abcd, 임베딩 공간의 이해, AbAcAd, 겹장(덧장)",
    "section": "A. Data",
    "text": "A. Data\n\ntxt = list('abc'*100)\ntxt[:10]\n\n['a', 'b', 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'a']\n\n\n\ndf_train = pd.DataFrame({'x': txt[:-1], 'y': txt[1:]})\ndf_train[:5]\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\na\nb\n\n\n1\nb\nc\n\n\n2\nc\na\n\n\n3\na\nb\n\n\n4\nb\nc\n\n\n\n\n\n\n\n\nx = torch.tensor(df_train.x.map({'a':0,'b':1,'c':2}))\ny = torch.tensor(df_train.y.map({'a':0,'b':1,'c':2}))\n\n\n# x,y \n# --- 원래는 이 형식이 틀림\n# 그런데 y는 onehot 안해도 알아서 토치에서 해주므로 length-n 벡터형태로 정리해도 무방\n# 그리고 x는 onehot+linr를 쓰지않고 임베딩을 쓰려고 마음먹었으면 length-n 벡터형태로 정리해도 무방"
  },
  {
    "objectID": "posts/11wk-2.html#b.-mlp-하나의-은닉노드",
    "href": "posts/11wk-2.html#b.-mlp-하나의-은닉노드",
    "title": "11wk-2: (순환신경망) – abc, abcd, 임베딩 공간의 이해, AbAcAd, 겹장(덧장)",
    "section": "B. MLP – 하나의 은닉노드",
    "text": "B. MLP – 하나의 은닉노드\n- 적합\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=3, embedding_dim=1),\n    torch.nn.Tanh(), \n    torch.nn.Linear(1,3)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1)\n#---#\nfor epoc in range(50):\n    #1 \n    netout = net(x)\n    #2 \n    loss = loss_fn(netout,y)\n    #3\n    loss.backward()\n    #4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nnetout.argmax(axis=1)[:5], y[:5]\n\n(tensor([1, 2, 0, 1, 2]), tensor([1, 2, 0, 1, 2]))\n\n\n- 결과시각화\n\nebdd,tanh,linr = net\n\n\nX = torch.nn.functional.one_hot(x)\nh = tanh(ebdd(x))\nnetout = logits = linr(h)\nyhat = torch.nn.functional.softmax(netout,dim=1)\nmat = torch.concat([X,h,netout/netout.max(),yhat],axis=1).data\nplt.matshow(mat[:6], vmin=-1, vmax=1, cmap=\"bwr\")\nplt.colorbar()\nplt.axvline(2.5,color=\"lime\")\nplt.axvline(3.5,color=\"lime\")\nplt.axvline(6.5,color=\"lime\")\nplt.xticks(ticks=[0,1,2,3,4,5,6,7,8,9],labels=[r\"$x_a$\",r\"$x_b$\",r\"$x_c$\",r\"$h$\",r\"$out_a$\",r\"$out_b$\",r\"$out_c$\",r\"$\\hat{y}_a$\",r\"$\\hat{y}_b$\",r\"$\\hat{y}_c$\"]);\nplt.tight_layout()\n\n/tmp/ipykernel_906200/1114894007.py:12: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\n- 시각화결과해석: 학습이 잘 된것 같지만 깔끔하지 않음.\n\nnetout 을 보는 요령: 가장 빨간부분이 예측값이 된다.\n문제1: \\(out_b\\)의 경우 애매한 색깔만 있음. 네트워크가 정답을 잘 모른다는 의미.\n문제1의 원인: \\(out_b\\)의 경우에 대응하는 \\({\\boldsymbol h}\\)를 살펴보니 흰색임. 이것은 값이 0이라는 의미인데 이때는 \\({\\boldsymbol h}\\) 에 걸리는 선형변환 \\(linr\\) 의 weight 가 의미없고 bias만 의미있기 때문에 특징을 잡기에 불리하다.\n문제2: \\({\\boldsymbol h}\\)가 흰색이면(=0이 나오면) 불리하며, 확실한 색을 가지고 있는것이 유리함. 그렇지만 확실한 색인 빨강 파랑은 이미 차지된 상태라서 어쩔수 없이 흰색으로 선택된 것.\n문제2를 해결하는 방법: \\(a,b,c\\)라는 세문자를 표현하기에 \\((-1,1)\\)사이의 숫자는 너무 불리함.."
  },
  {
    "objectID": "posts/11wk-2.html#c.-mlp-두개의-은닉노드",
    "href": "posts/11wk-2.html#c.-mlp-두개의-은닉노드",
    "title": "11wk-2: (순환신경망) – abc, abcd, 임베딩 공간의 이해, AbAcAd, 겹장(덧장)",
    "section": "C. MLP – 두개의 은닉노드",
    "text": "C. MLP – 두개의 은닉노드\n- 적합\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=3, embedding_dim=2),\n    torch.nn.Tanh(), \n    torch.nn.Linear(2,3)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1)\n#---#\nfor epoc in range(50):\n    #1 \n    netout = net(x)\n    #2 \n    loss = loss_fn(netout,y)\n    #3\n    loss.backward()\n    #4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nnetout.argmax(axis=1)[:5], y[:5]\n\n(tensor([1, 2, 0, 1, 2]), tensor([1, 2, 0, 1, 2]))\n\n\n- 결과시각화\n\nebdd, tanh, linr = net \nX = torch.nn.functional.one_hot(x)\nh = tanh(ebdd(x))\nnetout = logits = linr(h)\nyhat = torch.nn.functional.softmax(netout,dim=1)\nmat = torch.concat([X,h,netout/netout.max(),yhat],axis=1).data\nplt.matshow(mat[:6], vmin=-1, vmax=1, cmap=\"bwr\")\nplt.colorbar()\nplt.axvline(2.5,color=\"lime\")\nplt.axvline(4.5,color=\"lime\")\nplt.axvline(7.5,color=\"lime\")\nplt.xticks(ticks=[0,1,2,3,4,5,6,7,8,9,10],labels=[r\"$x_a$\", r\"$x_b$\", r\"$x_c$\",r\"$h_1$\",r\"$h_2$\",r\"$out_a$\",r\"$out_b$\",r\"$out_c$\",r\"$\\hat{y_a}$\",r\"$\\hat{y_b}$\",r\"$\\hat{y_c}$\"]);\n\n\n\n\n\n\n\n\n- 시각화결과해석: 깔끔함. netout의 가장 빨간부분도 너무 명확함. \\({\\boldsymbol h}\\)가 0이 아닌 값으로 학습되어있음\n\nx=a \\(\\Rightarrow\\) h=(파,빨) \\(\\Rightarrow\\) y=b\nx=b \\(\\Rightarrow\\) h=(빨,파) \\(\\Rightarrow\\) y=c\nx=c \\(\\Rightarrow\\) h=(빨,빨) \\(\\Rightarrow\\) y=a\nh = (파,파) 는 사용하지 않음. –&gt; 문자열 d를 하나 더 쓸수 있는 공간이 \\(h\\)에 있다고 해석할 수 있음.."
  },
  {
    "objectID": "posts/11wk-2.html#a.-data-1",
    "href": "posts/11wk-2.html#a.-data-1",
    "title": "11wk-2: (순환신경망) – abc, abcd, 임베딩 공간의 이해, AbAcAd, 겹장(덧장)",
    "section": "A. Data",
    "text": "A. Data\n\ntxt = list('abcd'*100)\ntxt[:10]\n\n['a', 'b', 'c', 'd', 'a', 'b', 'c', 'd', 'a', 'b']\n\n\n\ndf_train = pd.DataFrame({'x':txt[:-1], 'y':txt[1:]})\ndf_train[:5]\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\na\nb\n\n\n1\nb\nc\n\n\n2\nc\nd\n\n\n3\nd\na\n\n\n4\na\nb\n\n\n\n\n\n\n\n\nx = torch.tensor(df_train.x.map({'a':0, 'b':1, 'c':2, 'd':3}))\ny = torch.tensor(df_train.y.map({'a':0, 'b':1, 'c':2, 'd':3}))"
  },
  {
    "objectID": "posts/11wk-2.html#b.-mlp-하나의-은닉노드-1",
    "href": "posts/11wk-2.html#b.-mlp-하나의-은닉노드-1",
    "title": "11wk-2: (순환신경망) – abc, abcd, 임베딩 공간의 이해, AbAcAd, 겹장(덧장)",
    "section": "B. MLP – 하나의 은닉노드",
    "text": "B. MLP – 하나의 은닉노드\n- 적합\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4, embedding_dim=1),\n    torch.nn.Tanh(), \n    torch.nn.Linear(1,4)\n)\nebdd,tanh,linr = net \nebdd.weight.data = torch.tensor([[-0.3333],[-2.5000],[5.0000],[0.3333]])\nlinr.weight.data = torch.tensor([[1.5000],[-6.0000],[-2.0000],[6.0000]])\nlinr.bias.data = torch.tensor([0.1500, -2.0000,  0.1500, -2.000])\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1)\n#---#\nfor epoc in range(50):\n    #1 \n    netout = net(x)\n    #2 \n    loss = loss_fn(netout,y)\n    #3\n    loss.backward()\n    #4\n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화\n\nebdd,tanh,linr = net\nX = torch.nn.functional.one_hot(x)\nh = tanh(ebdd(x)).data\nnetout = linr(tanh(ebdd(x))).data\nyhat = torch.nn.functional.softmax(net(x),dim=1).data\nmat = torch.concat([X,h,netout/netout.max(),yhat],axis=1)\n#---#\nplt.matshow(mat[:10, :],cmap=\"bwr\",vmin=-1,vmax=1)\nplt.colorbar()\nplt.axvline(3.5,color=\"lime\")\nplt.axvline(4.5,color=\"lime\")\nplt.axvline(8.5,color=\"lime\")\nplt.xticks(\n    ticks=[0,1,2,3,4,5,6,7,8,9,10,11,12],\n    labels=[\n        r\"$x_a$\",r\"$x_b$\",r\"$x_c$\",r\"$x_d$\",\n        r\"$h$\",\n        r\"$out_a$\",r\"$out_b$\",r\"$out_c$\",r\"$out_d$\",\n        r\"$\\hat{y}_a$\",r\"$\\hat{y}_b$\",r\"$\\hat{y}_c$\",r\"$\\hat{y}_d$\"]\n);"
  },
  {
    "objectID": "posts/11wk-2.html#c.-mlp-두개의-은닉노드-1",
    "href": "posts/11wk-2.html#c.-mlp-두개의-은닉노드-1",
    "title": "11wk-2: (순환신경망) – abc, abcd, 임베딩 공간의 이해, AbAcAd, 겹장(덧장)",
    "section": "C. MLP – 두개의 은닉노드",
    "text": "C. MLP – 두개의 은닉노드\n- 적합\n\n#torch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4, embedding_dim=2),\n    torch.nn.Tanh(), \n    torch.nn.Linear(2,4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1)\n#---#\nfor epoc in range(50):\n    #1 \n    netout = net(x)\n    #2 \n    loss = loss_fn(netout,y)\n    #3\n    loss.backward()\n    #4\n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화\n\nebdd,tanh,linr = net\nX = torch.nn.functional.one_hot(x)\nh = tanh(ebdd(x)).data\nnetout = linr(tanh(ebdd(x))).data\nyhat = torch.nn.functional.softmax(net(x),dim=1).data\nmat = torch.concat([X,h,netout/netout.max(),yhat],axis=1)\n#---#\nplt.matshow(mat[:10, :],cmap=\"bwr\",vmin=-1,vmax=1)\nplt.colorbar()\nplt.axvline(3.5,color=\"lime\")\nplt.axvline(5.5,color=\"lime\")\nplt.axvline(9.5,color=\"lime\")\nplt.xticks(\n    ticks=[0,1,2,3,4,5,6,7,8,9,10,11,12,13],\n    labels=[\n        r\"$x_a$\",r\"$x_b$\",r\"$x_c$\",r\"$x_d$\",\n        r\"$h_1$\",r\"$h_2$\",\n        r\"$out_a$\",r\"$out_b$\",r\"$out_c$\",r\"$out_d$\",\n        r\"$\\hat{y}_a$\",r\"$\\hat{y}_b$\",r\"$\\hat{y}_c$\",r\"$\\hat{y}_d$\"]\n);"
  },
  {
    "objectID": "posts/11wk-2.html#d.-비교실험",
    "href": "posts/11wk-2.html#d.-비교실험",
    "title": "11wk-2: (순환신경망) – abc, abcd, 임베딩 공간의 이해, AbAcAd, 겹장(덧장)",
    "section": "D. 비교실험",
    "text": "D. 비교실험\n\nclass Net1(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 yhat을 구할때 사용할 레이어를 정의 \n        self.ebdd = torch.nn.Embedding(4,1)\n        self.tanh = torch.nn.Tanh()\n        self.linr = torch.nn.Linear(1,4)\n        ## 정의 끝\n    def forward(self,X):\n        ## yhat을 어떻게 구할것인지 정의 \n        ebdd_x = self.ebdd(x)\n        h = self.tanh(ebdd_x)\n        netout = self.linr(h)\n        ## 정의 끝\n        return netout\n\n\nclass Net2(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 yhat을 구할때 사용할 레이어를 정의 \n        self.ebdd = torch.nn.Embedding(4,2)\n        self.tanh = torch.nn.Tanh()\n        self.linr = torch.nn.Linear(2,4)\n        ## 정의 끝\n    def forward(self,X):\n        ## yhat을 어떻게 구할것인지 정의 \n        ebdd_x = self.ebdd(x)\n        h = self.tanh(ebdd_x)\n        netout = self.linr(h)\n        ## 정의 끝\n        return netout\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Net1()\n        optimizr = torch.optim.Adam(net.parameters(),lr=0.1)\n        loss_fn = torch.nn.CrossEntropyLoss()\n        for epoc in range(50):\n            ## 1 \n            netout = net(x)\n            ## 2 \n            loss = loss_fn(netout,y)\n            ## 3 \n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        h = net.tanh(net.ebdd(x)).data\n        yhat = torch.nn.functional.softmax(net(x),dim=1).data\n        mat = torch.concat([h,yhat],axis=1)\n        ax[i][j].matshow(mat[:6, :],cmap='bwr',vmin=-1,vmax=1)\n        ax[i][j].axvline(0.5,color='lime')\n        ax[i][j].set_xticks(ticks=[0,1,2,3,4],labels=[r\"$h$\",r\"$\\hat{y}_a$\",r\"$\\hat{y}_b$\",r\"$\\hat{y}_c$\",r\"$\\hat{y}_d$\"])\nfig.suptitle(\"# of hidden nodes = 1\", size=20)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Net2()\n        optimizr = torch.optim.Adam(net.parameters(),lr=0.1)\n        loss_fn = torch.nn.CrossEntropyLoss()\n        for epoc in range(50):\n            ## 1 \n            netout = net(x)\n            ## 2 \n            loss = loss_fn(netout,y)\n            ## 3 \n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        h = net.tanh(net.ebdd(x)).data\n        yhat = torch.nn.functional.softmax(net(x),dim=1).data\n        mat = torch.concat([h,yhat],axis=1)\n        ax[i][j].matshow(mat[:6, :],cmap='bwr',vmin=-1,vmax=1)\n        ax[i][j].axvline(1.5,color='lime')\n        ax[i][j].set_xticks(ticks=[0,1,2,3,4,5],labels=[r\"$h_1$\",r\"$h_2$\",r\"$\\hat{y}_a$\",r\"$\\hat{y}_b$\",r\"$\\hat{y}_c$\",r\"$\\hat{y}_d$\"])\nfig.suptitle(\"# of hidden nodes = 2\", size=20)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/11wk-2.html#a.-data-2",
    "href": "posts/11wk-2.html#a.-data-2",
    "title": "11wk-2: (순환신경망) – abc, abcd, 임베딩 공간의 이해, AbAcAd, 겹장(덧장)",
    "section": "A. Data",
    "text": "A. Data\n\ntxt = list('AbAcAd'*50)\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ndf_train = pd.DataFrame({'x':txt[:-1], 'y':txt[1:]})\ndf_train[:5]\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\nA\nb\n\n\n1\nb\nA\n\n\n2\nA\nc\n\n\n3\nc\nA\n\n\n4\nA\nd\n\n\n\n\n\n\n\n\nx = torch.tensor(df_train.x.map({'A':0,'b':1,'c':2,'d':3}))\ny = torch.tensor(df_train.y.map({'A':0,'b':1,'c':2,'d':3}))\n\n\nx[:8],y[:8]\n\n(tensor([0, 1, 0, 2, 0, 3, 0, 1]), tensor([1, 0, 2, 0, 3, 0, 1, 0]))"
  },
  {
    "objectID": "posts/11wk-2.html#b.-mlp-두개의-은닉노드-실패",
    "href": "posts/11wk-2.html#b.-mlp-두개의-은닉노드-실패",
    "title": "11wk-2: (순환신경망) – abc, abcd, 임베딩 공간의 이해, AbAcAd, 겹장(덧장)",
    "section": "B. MLP – 두개의 은닉노드 (실패)",
    "text": "B. MLP – 두개의 은닉노드 (실패)\n- 적합\n\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(4,2),\n    torch.nn.Tanh(),\n    torch.nn.Linear(2,4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1)\n#---#\nfor epoc in range(100):\n    #1\n    netout = net(x)\n    #2\n    loss = loss_fn(netout,y)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화\n\nebdd,tanh,linr = net\nX = torch.nn.functional.one_hot(x)\nh = tanh(ebdd(x)).data\nnetout = linr(tanh(ebdd(x))).data\nyhat = torch.nn.functional.softmax(net(x),dim=1).data\nmat = torch.concat([X,h,netout/netout.max(),yhat],axis=1)\n#---#\nplt.matshow(mat[:10, :],cmap=\"bwr\",vmin=-1,vmax=1)\nplt.colorbar()\nplt.axvline(3.5,color=\"lime\")\nplt.axvline(5.5,color=\"lime\")\nplt.axvline(9.5,color=\"lime\")\nplt.xticks(\n    ticks=[0,1,2,3,4,5,6,7,8,9,10,11,12,13],\n    labels=[\n        r\"$x_A$\",r\"$x_b$\",r\"$x_c$\",r\"$x_d$\",\n        r\"$h_1$\",r\"$h_2$\",\n        r\"$out_A$\",r\"$out_b$\",r\"$out_c$\",r\"$out_d$\",\n        r\"$\\hat{y}_A$\",r\"$\\hat{y}_b$\",r\"$\\hat{y}_c$\",r\"$\\hat{y}_d$\"]\n);\n\n\n\n\n\n\n\n\n\n100번 시도해봤자 100번 망함"
  },
  {
    "objectID": "posts/11wk-2.html#c.-discussions",
    "href": "posts/11wk-2.html#c.-discussions",
    "title": "11wk-2: (순환신경망) – abc, abcd, 임베딩 공간의 이해, AbAcAd, 겹장(덧장)",
    "section": "C. Discussions",
    "text": "C. Discussions\n- 왜 망했을까?\n- hello1 문자열을 맞출 수 있을까?\n1 2015년 Andrej Karpathy(안드레이 카파시)의 “전설적인” 블로그 https://karpathy.github.io/2015/05/21/rnn-effectiveness/ 에 담긴 예제\n이전시점을 많이 고려하면 맞출수는 있음.\n그러나 이러한 방법들(AR, N-grams)은 한계가 뚜렷 \\(\\to\\) 순환신경망의 등장"
  },
  {
    "objectID": "posts/10wk-2.html#a.-optimizer-사용-고급",
    "href": "posts/10wk-2.html#a.-optimizer-사용-고급",
    "title": "10wk-2: (추천시스템) – optimizer 사용 고급, 모델링 전략, MF-based 추천시스템",
    "section": "A. optimizer 사용 고급",
    "text": "A. optimizer 사용 고급\n# 회귀분석 – 안알려줬던 기술..\n주어진 자료가 아래와 같다고 하자.\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\nx = x.reshape(-1,1)\nones= torch.ones(100).reshape(-1,1)\nX = torch.concat([ones,x],axis=-1)\nϵ = torch.randn(100).reshape(-1,1)*0.5\ny = 2.5+ 4*x + ϵ\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n\nw = torch.tensor(10.0,requires_grad=True)\nb = torch.tensor(-5.0,requires_grad=True)\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(x*w + b).data,'--')\n\n\n\n\n\n\n\n\ntorch.optim.SGD를 이용하여 What을 update하라. 학습률은 0.1로 설정하고 30회 update하라.\n(풀이)\n\nw = torch.tensor(10.0,requires_grad=True)\nb = torch.tensor(-5.0,requires_grad=True)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD([w,b],lr=0.1)\nfor epoc in range(30):\n    yhat = x*w +b \n    loss = loss_fn(yhat,y) \n    loss.backward()\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nw,b\n\n(tensor(4.0144, requires_grad=True), tensor(2.4290, requires_grad=True))\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(x*w + b).data,'--')\n\n\n\n\n\n\n\n\n#\n# 2025-중간고사 3번\n\ntorch.manual_seed(43052)\ndist = torch.distributions.Exponential(1/2)\nx = dist.sample((10000,1))\n\n주어진 자료 \\(x_i\\)에 대하여 함수 \\(l(\\lambda)\\)를 최대화하는 \\(\\lambda\\)를 경사하강법 기반의 알고리즘을 이용하여 추정하라. 단 이때 \\(\\lambda\\)의 초기 추정값은 1로 설정하라.\n\\[\nl(\\lambda) =\\frac{1}{n} \\sum_{i=1}^{n}\\log f(x_i), \\quad f(x_i) = \\frac{1}{\\lambda} e^{-\\frac{x_i}{\\lambda}}, \\quad x_i \\geq 0\n\\]\nhint\n\n\\(l(\\lambda)\\)를 최대화하는 \\(\\lambda\\)는 \\(-l(\\lambda)\\)를 최소화합니다.\n이론적으로는 \\(l(\\lambda)\\)를 최대화하는 \\(\\lambda\\)는 x.mean()입니다. 즉 제대로 \\(\\lambda\\)를 추정한다면 x.mean()이 나오도록 되어있습니다.\n저는 경사하강법을 이용했고 학습률은 0.05로 설정했습니다. 1000회 update하니까 잘 수렴했습니다.\n\n(풀이)\n\nlamb = torch.tensor(1.0,requires_grad=True)\noptimizr = torch.optim.SGD([lamb],  lr =0.05)\n\n\nfor i in range(1000):\n    fx = torch.exp(-x/lamb)/lamb\n    l = torch.log(fx).mean()\n    (-l).backward()\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nlamb\n\ntensor(1.9874, requires_grad=True)\n\n\n#"
  },
  {
    "objectID": "posts/10wk-2.html#b.-모델링-전략",
    "href": "posts/10wk-2.html#b.-모델링-전략",
    "title": "10wk-2: (추천시스템) – optimizer 사용 고급, 모델링 전략, MF-based 추천시스템",
    "section": "B. 모델링 전략",
    "text": "B. 모델링 전략\n# 2025-중간고사 4번 – 자유 낙하 운동이란 어떤 물체가 일정한 높이에서 떨어져 지면에 도달하기 까지 걸리는 시간을 다루는 물리학 개념이다. 다음은 물리학의 자유 낙하 운동에서 착안하여 생성한 데이터이다.\n\ntorch.manual_seed(43052)\nh = torch.rand(100)*100\nh,_ = h.sort()\nh = h.reshape(100,1)\nt = torch.sqrt(2*h/9.8) + torch.randn([100,1])*0.1\n\n여기에서 \\(h\\)는 낙하전의 높이(단위: m), \\(t\\)는 해당높이에서 물치가 지면에 도달하기 까지 걸리는 시간(단위:초)을 의미한다. 예를 들어 아래의 자료는 \\(h=99.3920, t=4.4583\\)를 의미하는데\n\nh[-1], t[-1]\n\n(tensor([99.3920]), tensor([4.4583]))\n\n\n이것은 높이 \\(99.3920\\)m에서 낙하한 물체가 약 \\(4.4583\\)초만에 지면에 도달했음을 의미한다. 아래의 그림은 \\(x\\)축에 \\(h\\), \\(y\\)축에 \\(t\\)를 두고 해당 데이터를 산점도로 시각화 한 것이다.\n\nplt.plot(h,t,'o',alpha=0.5)\nplt.xlabel('Height (m)')\nplt.ylabel('Time to fall (sec)')\nplt.title('Free Fall Time vs Height')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n그래프를 보면 높이가 높을 수록 낙하시간도 길어지는 경향이 관찰된다. 다만 동일한 높이라 하더라도 낙하시간이 조금씩 차이나는 경우가 있는데, 이는 사람이 시간측정을 수동으로 하며 발생하는 실험오차 때문이다. 이러한 오차에도 불구하고 \\(h\\)와 \\(t\\)사이에는 일정한 규칙이 존재하는듯 하다. 물리학과 교수님께 자문을 요청한 결과 자유낙하에 걸리는 시간은 \\(\\sqrt{h}\\)에 비례함을 알 수 있었고 이를 근거로 아래와 같은 모형을 설계하였다.\n\\[t_i = \\beta_0 + \\beta_1 \\sqrt{h_i}+\\epsilon_i, \\quad \\epsilon_i \\sim {\\cal N}(0,\\sigma^2)\\]\n위의 모형을 활용하여 높이 \\(h\\)로부터 낙하시간 \\(t\\)를 예측하는 신경망 모델을 설계하고 학습하라. 학습한 신경망 모델을 활용하여 높이 40m,60m,80m 에서 물체를 자유낙하 시켰을때 지면에 도달하기까지 걸리는 시간을 각각 예측하라.\nhint\n\n\\(y_i = t_i\\) 로 생각하시고 \\(x_i= \\sqrt{h}_i\\)로 생각하시면 그냥 회귀모형이죠?\n답은 \\(2.8571\\)초, \\(3.4493\\)초, \\(4.0406\\)초 근처로 나오면 됩니다.\n제시된 모형(\\(t_i = \\beta_0 + \\beta_1 \\sqrt{h_i}+\\epsilon_i\\))을 무시하고 04wk-2와 같은 방식으로 신경망을 설계하고 푸셔도 만점으로 인정합니다.\n\n(풀이)\n\nlinr1 = torch.nn.Linear(1,32)\nrelu = torch.nn.ReLU()\nlinr2 = torch.nn.Linear(32,1)\noptimizr = torch.optim.Adam(list(linr1.parameters()) + list(linr2.parameters()))\nloss_fn = torch.nn.MSELoss()\n#---#\nfor epoc in range(2000):\n    #1\n    that = linr2(relu(linr1(h)))\n    #2\n    loss = loss_fn(that,t)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(h,t,'o',alpha=0.5)\nplt.plot(h,that.data,'--')\n\n\n\n\n\n\n\n\n\nhh = torch.tensor([40,60,80]).float().reshape(3,1)\nnet(hh)\n\ntensor([[2.8631],\n        [3.5162],\n        [4.0079]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(풀이2)\n\nx = torch.sqrt(h)\ny = t \nnet = torch.nn.Linear(1,1)\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(6000):\n    #1\n    yhat = net(x) \n    #2\n    loss = loss_fn(yhat,y)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(h,t,'o',alpha=0.5)\nplt.plot(h,yhat.data,'--')\n\n\n\n\n\n\n\n\n\nhh = torch.tensor([40,60,80]).float().reshape(3,1)\nxx = torch.sqrt(hh)\nnet(xx)\n\ntensor([[2.8613],\n        [3.4889],\n        [4.0180]], grad_fn=&lt;AddmmBackward0&gt;)"
  },
  {
    "objectID": "posts/10wk-2.html#a.-data-나는-solo",
    "href": "posts/10wk-2.html#a.-data-나는-solo",
    "title": "10wk-2: (추천시스템) – optimizer 사용 고급, 모델링 전략, MF-based 추천시스템",
    "section": "A. Data: 나는 SOLO",
    "text": "A. Data: 나는 SOLO\n- Data\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2025/main/posts/iamsolo.csv',index_col=0)\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n- 데이터를 이해할 때 필요한 가정들 – 제가 마음대로 설정했어요..\n\n궁합이 잘맞으면 5점, 잘 안맞으면 0점 이다.\nMBTI 성향에 따라서 궁함의 정도가 다르다. 특히 I/E의 성향일치가 중요하다.\n하니는 모든 사람들과 대체로 궁합이 잘 맞는다."
  },
  {
    "objectID": "posts/10wk-2.html#b.-아이디어",
    "href": "posts/10wk-2.html#b.-아이디어",
    "title": "10wk-2: (추천시스템) – optimizer 사용 고급, 모델링 전략, MF-based 추천시스템",
    "section": "B. 아이디어",
    "text": "B. 아이디어\n- 목표: NaN을 추정\n- 수동추론: 그럴듯한 숫자를 추정해보자.\n\n옥순(IN),영식(IN)의 궁합은? \\(\\to\\) 잘 맞을듯\n서연(ES),규빈(ES)의 궁합은? \\(\\to\\) 잘 맞을듯\n영자(IN),다호(ES)의 궁합은? \\(\\to\\) 잘 안맞을듯\n하니(I),영호(IS)의 궁합은? \\(\\to\\)엄청 잘 맞을듯\n\n- 좀 더 체계적인 추론 전략\n\nsig = torch.nn.Sigmoid()\n\n(1) 옥순(IN)과 영식(IN)의 궁합 \\(\\approx\\) 옥순의I/E성향\\(\\times\\)영식의I/E성향 \\(+\\) 옥순의N/S성향\\(\\times\\)영식의N/S성향\n\n옥순성향 =  torch.tensor([1.9, 1.9])\n영식성향 =  torch.tensor([1.9, 1.9])\nsig((옥순성향 *  영식성향).sum())*5\n\ntensor(4.9963)\n\n\n(2) 서연(ES)과 규빈(ES)의 궁합 \\(\\approx\\) 서연의I/E성향\\(\\times\\)규빈의I/E성향 \\(+\\) 서연의N/S성향\\(\\times\\)규빈의N/S성향\n\n서연성향 =  torch.tensor([-1.9, -1.9])\n규빈성향 =  torch.tensor([-1.9, -1.9])\nsig((서연성향 *  규빈성향).sum())*5\n\ntensor(4.9963)\n\n\n(3) 영자(IN)와 다호(ES)의 궁합 \\(\\approx\\) 영자I/E성향\\(\\times\\)다호I/E성향 \\(+\\) 영자N/S성향\\(\\times\\)다호의N/S성향\n\n영자성향 =  torch.tensor([1.9, 1.9])\n다호성향 =  torch.tensor([-1.9, -1.9])\nsig((영자성향 *  다호성향).sum())*5\n\ntensor(0.0037)\n\n\n(4) 하니(I)와 영호(IS)의 궁합 \\(\\approx\\) 하니I/E성향\\(\\times\\)영호I/E성향 \\(+\\) 하니N/S성향\\(\\times\\)영호의N/S성향 \\(+\\) 하니의매력\n\n하니성향 =  torch.tensor([1.9, 0])\n하니매력 =  torch.tensor(5)\n영호성향 =  torch.tensor([1.9, -1.9])\nsig((하니성향 *  영호성향).sum() + 하니매력)*5\n\ntensor(4.9991)\n\n\n- 전체 사용자의 설정값\n\nI, N = 1.8, 0.9\n\n\n옥순성향  = torch.tensor([I,N])\n영자성향 = torch.tensor([I,N])\n정숙성향 = torch.tensor([I,-N])\n영숙성향 = torch.tensor([I,-N])\n순자성향 = torch.tensor([-I,N])\n현숙성향 = torch.tensor([-I,N])\n서연성향 = torch.tensor([-I,-N])\n보람성향 = torch.tensor([-I,-N])\n하니성향 = torch.tensor([I,0])\nW = torch.stack([옥순성향,영자성향,정숙성향,영숙성향,순자성향,현숙성향,서연성향,보람성향,하니성향])\nb1 = torch.tensor([0,0,0,0,0,0,0,0,5]).reshape(-1,1).float()\nW,b1\n\n(tensor([[ 1.8000,  0.9000],\n         [ 1.8000,  0.9000],\n         [ 1.8000, -0.9000],\n         [ 1.8000, -0.9000],\n         [-1.8000,  0.9000],\n         [-1.8000,  0.9000],\n         [-1.8000, -0.9000],\n         [-1.8000, -0.9000],\n         [ 1.8000,  0.0000]]),\n tensor([[0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [5.]]))\n\n\n\n영식성향  = torch.tensor([I,N])\n영철성향 = torch.tensor([I,N])\n영호성향 = torch.tensor([I,-N])\n광수성향 = torch.tensor([I,-N])\n상철성향 = torch.tensor([-I,N])\n영수성향 = torch.tensor([-I,N])\n규빈성향 = torch.tensor([-I,-N])\n다호성향 = torch.tensor([-I,-N])\nM = torch.stack([영식성향,영철성향,영호성향,광수성향,상철성향,영수성향,규빈성향,다호성향])\nb2 = torch.tensor([0,0,0,0,0,0,0,0]).reshape(-1,1).float()\n\n\nW.shape, M.shape, b1.shape, b2.shape\n\n(torch.Size([9, 2]),\n torch.Size([8, 2]),\n torch.Size([9, 1]),\n torch.Size([8, 1]))\n\n\n- 아래의 행렬곱 관찰\n\nsig(W @ M.T + b1 + b2.T)*5\n\ntensor([[4.9144, 4.9144, 4.5954, 4.5954, 0.4046, 0.4046, 0.0856, 0.0856],\n        [4.9144, 4.9144, 4.5954, 4.5954, 0.4046, 0.4046, 0.0856, 0.0856],\n        [4.5954, 4.5954, 4.9144, 4.9144, 0.0856, 0.0856, 0.4046, 0.4046],\n        [4.5954, 4.5954, 4.9144, 4.9144, 0.0856, 0.0856, 0.4046, 0.4046],\n        [0.4046, 0.4046, 0.0856, 0.0856, 4.9144, 4.9144, 4.5954, 4.5954],\n        [0.4046, 0.4046, 0.0856, 0.0856, 4.9144, 4.9144, 4.5954, 4.5954],\n        [0.0856, 0.0856, 0.4046, 0.4046, 4.5954, 4.5954, 4.9144, 4.9144],\n        [0.0856, 0.0856, 0.4046, 0.4046, 4.5954, 4.5954, 4.9144, 4.9144],\n        [4.9987, 4.9987, 4.9987, 4.9987, 4.2660, 4.2660, 4.2660, 4.2660]])\n\n\n\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n- 모델링\n\\[{\\tt df\\_view} \\approx sig\\left({\\bf W}@{\\bf M}^\\top + bias \\right) \\times 5\\]\n- 자료를 아래와 같이 정리한다면?\n\ndf_train = df_view.stack().reset_index().set_axis(['여성출연자','남성출연자','궁합점수'],axis=1)\ndf_train\n\n\n\n\n\n\n\n\n여성출연자\n남성출연자\n궁합점수\n\n\n\n\n0\n옥순(IN)\n영철(IN)\n4.02\n\n\n1\n옥순(IN)\n영호(IS)\n3.45\n\n\n2\n옥순(IN)\n광수(IS)\n3.42\n\n\n3\n옥순(IN)\n상철(EN)\n0.84\n\n\n4\n옥순(IN)\n영수(EN)\n1.12\n\n\n...\n...\n...\n...\n\n\n58\n하니(I)\n광수(IS)\n4.98\n\n\n59\n하니(I)\n상철(EN)\n4.53\n\n\n60\n하니(I)\n영수(EN)\n4.39\n\n\n61\n하니(I)\n규빈(ES)\n4.45\n\n\n62\n하니(I)\n다호(ES)\n4.52\n\n\n\n\n63 rows × 3 columns\n\n\n\n\n{name: i for i,name in enumerate(set(df_train.여성출연자))}\n\n{'영숙(IS)': 0,\n '영자(IN)': 1,\n '정숙(IS)': 2,\n '현숙(EN)': 3,\n '하니(I)': 4,\n '순자(EN)': 5,\n '보람(ES)': 6,\n '옥순(IN)': 7,\n '서연(ES)': 8}\n\n\n\nX1 = torch.nn.functional.one_hot(torch.tensor(df_train.여성출연자.map({name: i for i,name in enumerate(set(df_train.여성출연자))}))).float()\nX2 = torch.nn.functional.one_hot(torch.tensor(df_train.남성출연자.map({name: i for i,name in enumerate(set(df_train.남성출연자))}))).float()\n\n\nl1 = torch.nn.Linear(9,2,bias=False)\nb1 = torch.nn.Linear(9,1,bias=False)\nl2 = torch.nn.Linear(8,2,bias=False)\nb2 = torch.nn.Linear(8,1,bias=False)\n\n\nyhat = sig((l1(X1) * l2(X2)).sum(axis=1).reshape(-1,1) + b1(X1) + b2(X2))*5"
  },
  {
    "objectID": "posts/10wk-2.html#c.-학습",
    "href": "posts/10wk-2.html#c.-학습",
    "title": "10wk-2: (추천시스템) – optimizer 사용 고급, 모델링 전략, MF-based 추천시스템",
    "section": "C. 학습",
    "text": "C. 학습\n\n#df_view\ndf_train = df_view.stack().reset_index().set_axis(['여성출연자','남성출연자','궁합점수'],axis=1)\n여성인덱스 = {'옥순(IN)':0, '영자(IN)':1, '정숙(IS)':2, '영숙(IS)':3, '순자(EN)':4, '현숙(EN)':5, '서연(ES)':6, '보람(ES)':7, '하니(I)':8}\n남성인덱스 = {'영식(IN)':0, '영철(IN)':1, '영호(IS)':2, '광수(IS)':3, '상철(EN)':4, '영수(EN)':5, '규빈(ES)':6, '다호(ES)':7}\nX1 = torch.nn.functional.one_hot(torch.tensor(df_train.여성출연자.map(여성인덱스))).float()\nX2 = torch.nn.functional.one_hot(torch.tensor(df_train.남성출연자.map(남성인덱스))).float()\ny = torch.tensor(df_train.궁합점수).reshape(-1,1).float()\n#----#\nloss_fn = torch.nn.MSELoss() \nl1 = torch.nn.Linear(9,2,bias=False)\nl2 = torch.nn.Linear(8,2,bias=False)\nb1 = torch.nn.Linear(9,1,bias=False)\nb2 = torch.nn.Linear(8,1,bias=False)\nparams = list(l1.parameters()) + list(l2.parameters())  + list(b1.parameters()) + list(b2.parameters())\noptimizr = torch.optim.Adam(params)\nsig = torch.nn.Sigmoid()\n#----#\nfor epoc in range(5000):\n    #step1\n    W_features = l1(X1) \n    M_features = l2(X2) \n    W_bias = b1(X1)\n    M_bais = b2(X2)\n    yhat = sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bais)*5\n    #step2\n    loss = loss_fn(yhat,y)\n    #step3\n    loss.backward()\n    #step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\ny[:5], yhat[:5]\n\n(tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200]]),\n tensor([[4.0370],\n         [3.4701],\n         [3.4334],\n         [0.8374],\n         [0.9061]], grad_fn=&lt;SliceBackward0&gt;))"
  },
  {
    "objectID": "posts/10wk-2.html#d.-예측",
    "href": "posts/10wk-2.html#d.-예측",
    "title": "10wk-2: (추천시스템) – optimizer 사용 고급, 모델링 전략, MF-based 추천시스템",
    "section": "D. 예측",
    "text": "D. 예측\n\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n\ndf_train[:2]\n\n\n\n\n\n\n\n\n여성출연자\n남성출연자\n궁합점수\n\n\n\n\n0\n옥순(IN)\n영철(IN)\n4.02\n\n\n1\n옥순(IN)\n영호(IS)\n3.45\n\n\n\n\n\n\n\n적합된 네트워크를 바탕으로 아래의 값에 대한 예측을 수행하라.\n\ndf_test = pd.DataFrame({'여성출연자':['옥순(IN)','하니(I)'],'남성출연자':['영식(IN)','영호(IS)']})\ndf_test\n\n\n\n\n\n\n\n\n여성출연자\n남성출연자\n\n\n\n\n0\n옥순(IN)\n영식(IN)\n\n\n1\n하니(I)\n영호(IS)\n\n\n\n\n\n\n\n\nXX1 = torch.nn.functional.one_hot(torch.tensor(df_test.여성출연자.map(여성인덱스)),num_classes=9).float()\nXX2 = torch.nn.functional.one_hot(torch.tensor(df_test.남성출연자.map(남성인덱스)),num_classes=8).float()\n\n\nsig((l1(XX1) * l2(XX2)).sum(axis=1).reshape(2,1) + b1(XX1) + b2(XX2))*5\n\ntensor([[3.9640],\n        [4.6568]], grad_fn=&lt;MulBackward0&gt;)"
  },
  {
    "objectID": "posts/exercise.html#벡터와-행렬",
    "href": "posts/exercise.html#벡터와-행렬",
    "title": "A1: Exercise – ver. 0505-1",
    "section": "$. 벡터와 행렬",
    "text": "$. 벡터와 행렬\n(1) 아래와 같이 length 5 인 vector를 torch.tensor로 선언하는 코드를 작성하라.\n\\[{\\bf x} = [1,2,3,4,5]\\]\n(풀이)\n\nx = torch.tensor([1,2,3,4,5])\nx\n\ntensor([1, 2, 3, 4, 5])\n\n\n(2) 아래와 같은 2x2 matrix 를 torch.tensor로 선언하는 코드를 작성하라.\n\\[{\\bf A} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}\\]\n(3) 아래와 같은 matrix 를 torch.tensor로 선언하는 코드를 작성하라.\n\\[{\\bf W} = \\begin{bmatrix} 2.5  \\\\  4 \\end{bmatrix}\\]\n(4) 아래와 같은 matrix 를 torch.tensor로 선언하는 코드를 작성하라.\n\\[{\\bf x} = \\begin{bmatrix} 2.5  & 4 \\end{bmatrix}\\]"
  },
  {
    "objectID": "posts/exercise.html#concat-stack",
    "href": "posts/exercise.html#concat-stack",
    "title": "A1: Exercise – ver. 0505-1",
    "section": "$. concat, stack",
    "text": "$. concat, stack\na,b가 아래와 같이 주어졌다고 하자.\n\na = torch.tensor([1]*10)\nb = torch.tensor([2]*10)\n\n아래를 잘 읽고 물음에 답하라.\n(1) 주어진 a,b와 torch.concat를 이용하여 아래와 같은 배열을 만들어라.\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n\ntorch.concat([a.reshape(-1,1), b.reshape(-1,1)])\n\ntensor([[1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2]])\n\n\n(2) 주어진 a,b 와 torch.concat,.reshape를 이용하여 아래와 같은 배열을 만들어라.\ntensor([[1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [1],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2],\n        [2]])\n(3) 주어진 a,b 와 torch.concat,.reshape를 이용하여 아래와 같은 배열을 만들어라.\ntensor([[1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2]])\n(4) 주어진 a,b와 torch.stack 을 이용하여 아래와 같은 배열을 만들어라.\ntensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]\n(5) 주어진 a,b와 torch.stack을 이용하여 아래와 같은 배열을 만들어라.\ntensor([[1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2],\n        [1, 2]])"
  },
  {
    "objectID": "posts/exercise.html#행렬곱",
    "href": "posts/exercise.html#행렬곱",
    "title": "A1: Exercise – ver. 0505-1",
    "section": "$. 행렬곱",
    "text": "$. 행렬곱\n(1) 아래와 같은 텐서를 고려하자.\n\na = torch.tensor([1,2,3,4,5]).reshape(-1,1)\nb = torch.tensor([3,2,1,1,2]).reshape(-1,1)\n\n@ 연산자를 이용하여 \\(\\sum_{i=1}^{5}a_ib_i\\)를 계산하라.\n(풀이)\n\na.T @ b\n\ntensor([[24]])\n\n\n(2) 아래와 같은 텐서를 고려하자.\n\ntorch.manual_seed(0)\nx = torch.randn(100).reshape(-1,1)\n\n@연산자를 이용하여 \\(\\sum_{i=1}^{100}x_i^2\\)을 계산하라."
  },
  {
    "objectID": "posts/exercise.html#인덱싱",
    "href": "posts/exercise.html#인덱싱",
    "title": "A1: Exercise – ver. 0505-1",
    "section": "$. 인덱싱",
    "text": "$. 인덱싱\n아래와 같은 배열을 선언하라.\n\ntorch.manual_seed(1)\nx = torch.randn(12).reshape(3,4)\nx\n\ntensor([[ 0.6614,  0.2669,  0.0617,  0.6213],\n        [-0.4519, -0.1661, -1.5228,  0.3817],\n        [-1.0276, -0.5631, -0.8923, -0.0583]])\n\n\n(1) 1열을 추출하는 코드를 작성하라. 즉 결과가 아래와 같이 나오도록 하라.\ntensor([[ 0.6614],\n        [-0.4519],\n        [-1.0276]])\n(2) 2-3열을 추출하는 코드를 작성하라. 즉 결과가 아래와 같이 나오도록 하라.\ntensor([[ 0.2669,  0.0617],\n        [-0.1661, -1.5228],\n        [-0.5631, -0.8923]])\n(3) 2-3행을 추출하는 코드를 작성하라. 즉 결과가 아래와 같이 나오도록 하라.\ntensor([[-0.4519, -0.1661, -1.5228,  0.3817],\n        [-1.0276, -0.5631, -0.8923, -0.0583]])"
  },
  {
    "objectID": "posts/exercise.html#torch.einsum",
    "href": "posts/exercise.html#torch.einsum",
    "title": "A1: Exercise – ver. 0505-1",
    "section": "$. torch.einsum",
    "text": "$. torch.einsum\n(1) 아래에 코드중 X.t()에 대응하는 코드를 torch.einsum으로 구현하라.\n\nX = torch.randn(5,2)\nX.t()\n\ntensor([[ 0.2055,  0.0693,  0.2733, -0.0948, -0.9798],\n        [ 0.6524, -0.0180,  0.1093, -2.3999,  0.5101]])\n\n\n(2) 아래에 코드중 X@b에 대응하는 코드를 torch.einsum으로 구현하라.\n\nX = torch.randn(5,2)\nb = torch.randn(2,1)\nX@b\n\ntensor([[-0.2886],\n        [-0.1229],\n        [ 0.9096],\n        [ 0.2358],\n        [-0.2577]])\n\n\n(3) 아래에 코드중 linr(X)에 대응하는 코드를 torch.einsum으로 구현하라.\n\nX =  torch.randn(5,2)\nlinr = torch.nn.Linear(2,1,bias=False)\nlinr(X)\n\ntensor([[ 0.1934],\n        [-0.2889],\n        [ 0.5970],\n        [ 0.1249],\n        [ 1.1178]], grad_fn=&lt;MmBackward0&gt;)"
  },
  {
    "objectID": "posts/exercise.html#경사하강법",
    "href": "posts/exercise.html#경사하강법",
    "title": "A1: Exercise – ver. 0505-1",
    "section": "$. 경사하강법",
    "text": "$. 경사하강법\n(1) 아래의 함수를 최소화하는 \\(x\\)를 경사하강법기반의 알고리즘을 활용하여 추정하라. (꼭 SGD를 쓸 필요는 없음)\n\\[f(x)=(x-1)^2\\]\n초기값은 \\(x=3\\) 으로 설정하라.\n(2) 아래의 함수를 최대화하는 \\(x\\)를 경사하강법기반의 알고리즘을 활용하여 추정하라. (꼭 SGD를 쓸 필요는 없음)\n\\[f(x)=-x^2 +6x-9 \\]\n초기값은 \\(x=0\\) 으로 설정하라.\nhint: \\(f(x)\\)을 최대화하는 \\(x\\)는 \\(-f(x)\\)를 최소화한다."
  },
  {
    "objectID": "posts/exercise.html#정규분포-mle",
    "href": "posts/exercise.html#정규분포-mle",
    "title": "A1: Exercise – ver. 0505-1",
    "section": "$. 정규분포 MLE",
    "text": "$. 정규분포 MLE\n아래는 \\(X_i \\sim N(3, 2^2)\\) 를 생성하는 코드이다.\n\ntorch.manual_seed(43052)\nx = torch.randn((10000,1)) * 2 + 3\n\n함수 \\(l(\\mu, \\sigma)\\)를 최대화하는 \\((\\mu, \\sigma)\\)를 경사하강법기반의 알고리즘을 활용하여 추정하라. (꼭 SGD를 쓸 필요는 없음)\n\\[l(\\mu, \\sigma) = \\sum_{i=1}^{n} \\log f(x_i), \\quad\nf(x_i) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(x_i - \\mu)^2}{2\\sigma^2}\\right)\\]"
  },
  {
    "objectID": "posts/exercise.html#베르누이-mle",
    "href": "posts/exercise.html#베르누이-mle",
    "title": "A1: Exercise – ver. 0505-1",
    "section": "$. 베르누이 MLE",
    "text": "$. 베르누이 MLE\n아래는 \\(X_i \\overset{iid}{\\sim} Ber(0.8)\\)을 생성하는 코드이다.\n\ntorch.manual_seed(43052)\nx = torch.bernoulli(torch.tensor([0.8]*10000)).reshape(-1,1)\n\n함수 \\(l(p)\\)를 최대화하는 \\(p\\)를 경사하강법기반을 알고리즘을 활용하여 추정하라. (꼭 SGD를 쓸 필요는 없음)\n\\[l(p) = \\sum_{i=1}^{n} \\log f(x_i), \\quad f(x_i) = p^{x_i} (1-p)^{1-x_i}\\]"
  },
  {
    "objectID": "posts/exercise.html#회귀모형의-mle",
    "href": "posts/exercise.html#회귀모형의-mle",
    "title": "A1: Exercise – ver. 0505-1",
    "section": "$. 회귀모형의 MLE",
    "text": "$. 회귀모형의 MLE\n아래의 모형을 생각하자.\n\n\\(Y_i \\overset{iid}{\\sim} \\mathcal{N}(\\mu_i, 1)\\)\n\\(\\mu_i = \\beta_0 + \\beta_1 x_i = 0.5 + 2x_i\\)\n\n아래는 위의 모형에서 얻은 샘플이다.\n\nx = torch.linspace(0,1,10000).reshape(10000,1)\ny = 0.5+2*x + torch.randn(10000,1)\n\n함수 \\(l(\\beta_0, \\beta_1)\\)를 최대화하는 \\((\\beta_0, \\beta_1)\\)를 경사하강법기반의 알고리즘을 활용하여 추정하라. (꼭 SGD를 쓸 필요는 없음)\n\\[\nl(\\beta_0, \\beta_1) = \\sum_{i=1}^{n} \\log f(y_i), \\quad f(y_i) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}(y_i - \\mu_i)^2}, \\quad \\mu_i = \\beta_0 + \\beta_1 x_i\n\\]"
  },
  {
    "objectID": "posts/exercise.html#로지스틱모형의-mle",
    "href": "posts/exercise.html#로지스틱모형의-mle",
    "title": "A1: Exercise – ver. 0505-1",
    "section": "$. 로지스틱모형의 MLE",
    "text": "$. 로지스틱모형의 MLE\n아래의 모형을 생각하자.\n\n\\(Y_i \\overset{iid}{\\sim} Ber(\\pi_i)\\)\n\\(\\pi_i = \\dfrac{\\exp(w_0 + w_1 x_i)}{1 + \\exp(w_0 + w_1 x_i)} = \\dfrac{\\exp(-1 + 0.5x_i)}{1 + \\exp(-1 + 0.5x_i)}\\)\n\n아래는 위의 모형에서 얻은 샘플이다.\n\nx = torch.linspace(-1,1,10000).reshape(10000,1)\npi = torch.exp(-1 + 0.5* x) / (1 + torch.exp(-1 + 0.5 * x))\ny = torch.bernoulli(pi)\n\n함수 \\(l(w_0, w_1)\\)을 최대화하는 파라미터 \\((w_0, w_1)\\)를 경사하강법기반을 알고리즘을 활용하여 추정하라. (꼭 SGD를 쓸 필요는 없음)\n\\[\nl(w_0, w_1) = \\sum_{i=1}^{n} \\log f(y_i), \\quad\nf(x_i) = \\pi_i^{y_i}(1 - \\pi_i)^{1 - y_i}, \\quad\n\\pi_i = \\dfrac{\\exp(w_0 + w_1 x_i)}{1 + \\exp(w_0 + w_1 x_i)}\n\\]\n(풀이1)\n\nX = torch.concat([torch.ones((10000,1)),x],axis=1)\nWhat = torch.tensor([[-0.1], [-0.1]],requires_grad=True)\n\n\nfor i in range(1,501):\n    pi_hat = torch.exp(X@What)/(torch.exp(X@What)+1)\n    pdf = pi_hat**y * (1-pi_hat)**(1-y)\n    l  = - torch.sum(torch.log(pdf)) \n    l.backward()\n    What.data = What.data - 0.00001 * What.grad \n    What.grad = None\n    if i %50 ==0:\n        print(f\"# of iterations = {i}\\tlog_L = {l.item():.4f} \\t  What= {What.data.reshape(-1).numpy()}\")\n\n# of iterations = 50    log_L = 5980.3896     What= [-0.673138    0.06826053]\n# of iterations = 100   log_L = 5877.2261     What= [-0.855518    0.18514545]\n# of iterations = 150   log_L = 5853.4365     What= [-0.91999674  0.26959354]\n# of iterations = 200   log_L = 5844.4150     What= [-0.94476056  0.33098808]\n# of iterations = 250   log_L = 5840.1309     What= [-0.95529944  0.375552  ]\n# of iterations = 300   log_L = 5837.9512     What= [-0.9604368   0.40783867]\n# of iterations = 350   log_L = 5836.8213     What= [-0.9633348   0.43120864]\n# of iterations = 400   log_L = 5836.2314     What= [-0.96517617  0.44812122]\n# of iterations = 450   log_L = 5835.9229     What= [-0.9664379  0.4603632]\n# of iterations = 500   log_L = 5835.7617     What= [-0.96733695  0.46922773]\n\n\n(풀이2) – 약간의 통계지식을 요하는 풀이\n로그가능도함수 \\(l(w_0, w_1)\\)을 최대화하는 \\(w_0, w_1\\)은 아래를 최소화하는 \\(w_0, w_1\\)과 같다.\n\\[\n-l(w_0, w_1) = - \\sum_{i=1}^{n} \\big( y_i \\log(\\pi_i) + (1 - y_i) \\log(1 - \\pi_i) \\big)\n\\]\n\\(w_0, w_1\\)의 추정값을 \\(\\hat{w}_0, \\hat{w}_1\\) 이라고 하고 점차 업데이트 한다고 하자. 그러면 \\(l(w_0, w_1)\\)을 점차 크게 만드는 일은 아래를 점차 작게 만드는 일과 같다.\n\\[- l(\\hat{w}_0,\\hat{w}_1) = - \\sum_{i=1}^{n} \\big( y_i \\log(\\hat{\\pi}_i) + (1 - y_i) \\log(1 - \\hat{\\pi}_i) \\big)\\]\n여기에서 \\(\\hat{\\pi}_i = \\frac{\\exp(\\hat{w}_0 + \\hat{w}_1 x_i)}{1 + \\exp(\\hat{w}_0 + \\hat{w}_1 x_i)} = \\hat{y}_i\\) 이다. 따라서 위의 식은 우리에게 친숙한 \\(n \\times \\text{BCELoss}\\)의 형태임을 쉽게 알 수 있다. 결국 \\(l(w_0, w_1)\\)을 최대화 하는 일은 BCELoss를 최소화하는 일과 같게 된다. 따라서 아래와 같이 풀면된다.\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nnet[0].bias.data = torch.tensor([-0.1])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\n#---#\nfor epoc in range(1,501):\n    #1\n    yhat = net(x) \n    #2\n    loss = loss_fn(yhat,y)\n    #3\n    loss.backward()\n    #4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nlist(net.parameters())\n\n[Parameter containing:\n tensor([[0.4851]], requires_grad=True),\n Parameter containing:\n tensor([-0.9689], requires_grad=True)]"
  },
  {
    "objectID": "posts/exercise.html#dl2024-mid-3",
    "href": "posts/exercise.html#dl2024-mid-3",
    "title": "A1: Exercise – ver. 0505-1",
    "section": "$. DL2024-MID-3",
    "text": "$. DL2024-MID-3\n\n이 문제의 경우 풀이가 https://guebin.github.io/DL2024/posts/09wk-2.html#%EB%8B%A8%EC%88%9C%ED%9A%8C%EA%B7%80%EB%AC%B8%EC%A0%9C-10%EC%A0%90 에 있습니다.\n\n주어진 자료가 아래와 같다고 하자.\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\nx = x.reshape(-1,1)\nϵ = torch.randn(100).reshape(-1,1)*0.5\ny = 2.5+ 4*x + ϵ\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n(1) torch.nn.Linear를 이용하여 아래와 같은 최초의 직선을 생성하는 네트워크를 설계하라.\n\\[\\hat{y}_i = -5.0 + 10.0 x_i \\]\n(2) 아래의 수식에 대응하는 loss를 계산하라. 여기에서 \\(\\hat{y}_i\\)은 (1)의 결과로 얻은 값을 사용하라.\n\\[loss = \\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2\\]\n(3) 적당한 matrix \\({\\bf X}_{n\\times 2}\\) 와 \\(\\hat{\\bf W}_{2\\times 1}\\)을 정의하여 아래와 같이 \\(\\hat{y}_i\\)을 구하라.\n\\[\\hat{y}_i = -5.0 + 5.0 x_i \\]\n(4) 아래의 수식에 대응하는 loss를 계산하라. 여기에서 \\(\\hat{y}_i\\)은 (3)의 결과로 얻은 값을 사용하라.\n\\[loss = \\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2\\]\n(5) (2)에서 얻은 \\(\\hat{y}_i\\) (4)에서 얻은 \\(\\hat{y}_i\\) 중 무엇이 더 적절하다고 생각하는가? 이유는 무엇인가? 손실(=loss)에 근거하여 설명하라.\n(6) .backward() 를 이용하여 (2)와 (4)에 해당하는 미분값을 계산하라. 학습률이 0.01인 경사하강법을 이용하여 (1),(3) 에 대응하는 가중치를 update 하라."
  },
  {
    "objectID": "posts/exercise.html#obs",
    "href": "posts/exercise.html#obs",
    "title": "A1: Exercise – ver. 0505-1",
    "section": "$. 5obs",
    "text": "$. 5obs\n아래와 같은 5개의 자료를 관측하였다고 가정하자.\n\n\n\n\nx\ny\n\n\n\n\n0\n11\n17.7\n\n\n1\n12\n18.5\n\n\n2\n13\n21.2\n\n\n3\n14\n23.6\n\n\n4\n15\n24.2\n\n\n\n\\(x\\)에서 \\(y\\)로 향하는 규칙을 찾기 위해 아래와 같은 모형을 고려하였다. (\\(\\beta_0, \\beta_1\\) 대신에 \\(w_0, w_1\\) 이라 생각해도 무방)\n\\[y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i, \\quad i =1,2,\\dots, n\\]\n(1) \\(\\hat{\\beta}_0=3, \\hat{\\beta}_1=3\\) 일 경우의 loss를 계산하라. 단, 손실함수는 MSELoss로 설정한다.\n(2) \\(\\hat{\\beta}_0=3, \\hat{\\beta}_1=3\\) 에서 손실함수의 미분계수를 계산하라.\n(3) 아래의 제약사항을 준수하여 추정값 \\(\\hat{\\beta}_0=3, \\hat{\\beta}_1=3\\) 의 값을 1회 update하라.\n제약사항\n\nyhat = X@Bhat 을 만족하는 적당한 X, Bhat을 선언하여 문제를 풀 것. (즉 torch.nn.Linear() 를 사용하지 말 것)\n손실함수는 torch.nn.MSELoss()를 사용하지 말고 직접 손실을 구할 것\n(확률적)경사하강법을 이용하여 update 하되 직접 수식을 입력할 것. 즉 torch.optim.SGD()를 사용하지 말 것.\n학습률은 0.001로 설정할 것\n\n(4) 아래의 제약사항을 준수하여 추정값 \\(\\hat{\\beta}_0=3, \\hat{\\beta}_1=3\\) 의 값을 다시 1회 update하라. 결과를 (3)과 비교하라 (동일결과가 나와야함)\n제약사항\n\nyhat = net(X) 을 만족하는 적당한 X, net을 선언하여 문제를 풀 것. 이때 net는 torch.nn.Linear(??,??,bias=False) 를 사용하여 선언할 것.\n손실함수는 torch.nn.MSELoss()를 사용하지 말고 직접 손실을 구할 것\n(확률적)경사하강법을 이용하여 update 하되 직접 수식을 입력할 것. 즉 torch.optim.SGD()를 사용하지 말 것.\n학습률은 0.001로 설정할 것\n\n(5) 아래의 제약사항을 준수하여 추정값 \\(\\hat{\\beta}_0=3, \\hat{\\beta}_1=3\\) 의 값을 다시 1회 update하라. 결과를 (3)-(4)와 비교하라 (모두 동일결과가 나와야함)\n제약사항\n\nyhat = net(X) 을 만족하는 적당한 X, net을 선언하여 문제를 풀 것. 이때 net는 torch.nn.Linear(??,??,bias=False) 를 사용하여 선언할 것.\n손실함수는 torch.nn.MSELoss()를 사용하지 말고 직접 손실을 구할 것\ntorch.optim.SGD()를 이용하여 update할 것\n학습률은 0.001로 설정할 것\n\n(6) 아래의 제약사항을 준수하여 추정값 \\(\\hat{\\beta}_0=3, \\hat{\\beta}_1=3\\) 의 값을 다시 1회 update하라. 결과를 (3)-(5)와 비교하라 (모두 동일결과가 나와야함)\n제약사항\n\nyhat = net(x) 을 만족하는 적당한 x, net을 선언하여 문제를 풀 것. 이때 net는 torch.nn.Linear(??,??,bias=True) 를 사용하여 선언할 것.\n손실함수는 torch.nn.MSELoss()를 사용하지 말고 직접 손실을 구할 것\n(확률적)경사하강법을 이용하여 update 하되 직접 수식을 입력할 것. 즉 torch.optim.SGD()를 사용하지 말 것.\n학습률은 0.001로 설정할 것"
  },
  {
    "objectID": "posts/exercise.html#d",
    "href": "posts/exercise.html#d",
    "title": "A1: Exercise – ver. 0505-1",
    "section": "$. 2d",
    "text": "$. 2d\n아래의 데이터를 고려하자.\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/regression_2d.csv\")\nx1 = torch.tensor(df.x1).float().reshape(-1,1)\nx2 = torch.tensor(df.x2).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\n\n\\(x_1, x_2\\) 에서 \\(y\\)로 향하는 규칙을 찾기 위해 아래와 같은 모형을 고려하였다. (\\(\\beta_0,\\beta_1,\\beta_2\\) 대신에 \\(w_0, w_1, w_2\\) 라고 생각해도 무방)\n\\[y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\epsilon_i \\quad i = 1, 2, \\ldots, n\\]\n(1) 아래의 제약사항에 맞추어서 \\(\\beta_0,\\beta_1,\\beta_2\\)의 값을 추정하라.\n제약사항\n\nyhat = X@Bhat 을 만족하는 적당한 X, Bhat을 선언하여 문제를 풀 것. (즉 torch.nn.Linear() 를 사용하지 말 것)\n손실함수는 MSE로 설정하되 torch.nn.MSELoss()를 사용하지 말고 직접 손실을 구할 것\n(확률적)경사하강법을 이용하여 update 하되 직접 수식을 입력할 것. 즉 torch.optim.SGD()를 사용하지 말 것.\n\nhint: 참값은 \\(\\beta_0=2.5, \\beta_1=4 , \\beta_2= -2\\) 임\n(2) (1)에서 구한 X에 대하여 아래의 수식을 이용하여 추정값을 구하여라.\n\\[\\hat{\\boldsymbol \\beta}^{LSE} = \\begin{bmatrix} \\hat{\\beta}_0^{LSE} \\\\  \\hat{\\beta}_1^{LSE} \\\\  \\hat{\\beta}_2^{LSE}\\end{bmatrix} = ({\\bf X}^\\top {\\bf X})^{-1}{\\bf X}^\\top {\\bf y}\\]\n(1)에서 추정한 값과 비교하라. 비슷한가?\nhint: (1)과 (2)의 추정값은 거의 같아야합니다..\n(3) 이 문제에서 모수의 참값은 \\(\\beta_0=2.5, \\beta_1=4 , \\beta_2= -2\\) 이다. epoch을 증가할수록 (1)에서 추정된 값은 참값에 근접해갈까? (epoch을 무한대로 하면 결국 참값에 수렴할까?)\n(4) 아래의 제약사항에 맞추어서 \\(\\beta_0,\\beta_1,\\beta_2\\)의 값을 다시 추정하라.\n제약사항\n\nyhat = net(X) 을 만족하는 적당한 X, net을 선언하여 문제를 풀 것. 이때 net는 torch.nn.Linear(??,??,bias=False) 를 사용하여 선언할 것.\ntorch.nn.MSELoss()를 이용하여 손실을 구할 것\ntorch.optim.SGD()를 이용하여 update할 것\n\n(5) 아래의 제약사항에 맞추어서 \\(\\beta_0,\\beta_1,\\beta_2\\)의 값을 다시 추정하라.\n제약사항\n\nyhat = net(X) 을 만족하는 적당한 X, net을 선언하여 문제를 풀 것. 이때 net는 torch.nn.Linear(??,??,bias=True) 를 사용하여 선언할 것.\ntorch.nn.MSELoss()를 이용하여 손실을 구할 것\ntorch.optim.SGD()를 이용하여 update할 것"
  },
  {
    "objectID": "posts/exercise.html#dl2022-mid-2",
    "href": "posts/exercise.html#dl2022-mid-2",
    "title": "A1: Exercise – ver. 0505-1",
    "section": "$. DL2022-MID-2",
    "text": "$. DL2022-MID-2\n\n이 문제의 경우 풀이가 https://guebin.github.io/DL2022/posts/2022-10-28-9wk-1-midsol.html 에 있습니다.\n\n주어진 자료가 아래와 같다고 하자.\n\ntorch.manual_seed(7676)\nx = torch.randn(100).sort().values\nϵ = torch.randn(100)*0.5\ny = 2.5+ 4*x + ϵ\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n아래와 같은 모형을 가정하고 물음에 답하라.\n\\[y_i = w_0+w_1 x_i +\\epsilon_i, \\quad \\epsilon_i \\overset{iid}{\\sim} N(0,\\sigma^2)\\]\n(1) ??를 적당하게 채워 아래와 같은 네트워크를 설정하고 최초의 예측값이 \\(\\hat{y}_i=-5+10x_i\\)가 출력되도록 net의 가중치를 조정하라.\nnet = torch.nn.Linear(in_features=2,out_features=??,bias=??)\n(2) 학습률은 0.1로 설정하고 torch.optim.Adam을 이용하여 optimizer를 선언하라. \\((\\hat{w}_0,\\hat{w}_1)=(-5,10)\\)에서 MSELoss의 미분계수 \\(\\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1) ~\\Big|_{~\\hat{w}_0,\\hat{w}_1}\\)를 구하고 이를 바탕으로 \\((\\hat{w}_0,\\hat{w}_1)\\)의 값을 1회 갱신하라. 계산된 미분계수값과 갱신된 \\((\\hat{w}_0,\\hat{w}_1)\\)의 값을 출력하라.\n(3) (2)에서 설정한 optimizer를 이용하여 \\((\\hat{w}_0, \\hat{w}_1)\\)의 값을 5회 갱신한 값을 구하여라. - 문제(2)에 갱신한 1회를 포함하여 5회임.\n(4) 학습률을 0.2로 설정하고 torch.optim.SGD를 이용하여 새로운 optimizr를 선언하라. (3)의 결과로 총 5회 갱신된 값에 이어서 10회 추가로 학습하라. 학습된 값은 얼마인가?\n(5) (4)의 수렴값이 학습이 잘 되었다고 생각하는가? 잘 되었다고 생각하면 그 근거는 무엇인가? (단, \\((w_0,w_1)\\)의 참값은 모른다고 가정한다)\n\nhint: 미분값을 근거로 대답할 것"
  },
  {
    "objectID": "posts/exercise.html#과잉매개변수-dl2022-ass-2",
    "href": "posts/exercise.html#과잉매개변수-dl2022-ass-2",
    "title": "A1: Exercise – ver. 0505-1",
    "section": "$. 과잉매개변수 (DL2022-ASS-2)",
    "text": "$. 과잉매개변수 (DL2022-ASS-2)\n\n이 내용은 overparameterized model에 대한 내용을 다루고 있습니다. 이 문제의 경우는 풀이가 https://guebin.github.io/DL2022/posts/II.%20DNN/2022-10-26-Assignment2.html 에 제공되어있습니다.\n\n\nOverparameterized model은 03wk-1, 3-B 의 내용과도 관련 있습니다.\n\n아래와 같은 자료가 있다고 가정하자.\n\nx = torch.rand([1000,1])*2-1\ny = 3.14 + 6.28*x + torch.randn([1000,1]) \n\n\nplt.plot(x,y,'o',alpha=0.1)\n\n\n\n\n\n\n\n\n(1) 아래의 모형을 가정하고 \\(\\beta_0,\\beta_1\\)을 파이토치를 이용하여 추정하라.\n\n\\(y_i = \\beta_0  + \\beta_1 x_i + \\epsilon_i,\\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n(2) 아래의 모형을 가정하고 \\(\\beta_0\\)를 파이토치를 이용하여 추정하라.\n\n\\(y_i = \\beta_0  + \\epsilon_i,\\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n(3) 아래의 모형을 가정하고 \\(\\beta_1\\)을 파이토치를 이용하여 추정하라.\n\n\\(y_i = \\beta_1x_i  + \\epsilon_i \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n(4) 아래의 모형을 가정하고 \\(\\alpha_0,\\beta_0,\\beta_1\\)을 파이토치를 이용하여 추정하라.\n\n\\(y_i = \\alpha_0+\\beta_0+ \\beta_1x_i  + \\epsilon_i \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n\\(\\hat{\\alpha}_0+\\hat{\\beta}_0\\)은 얼마인가? 이 값과 문제 (1)에서 추정된 \\(\\hat{\\beta_0}\\)의 값과 비교하여 보라.\n(5) 아래의 모형을 가정하고 \\(\\alpha_0,\\alpha_1,\\beta_0,\\beta_1\\)을 파이토치를 이용하여 추정하라.\n\n\\(y_i = \\alpha_0+\\beta_0+ \\beta_1x_i + \\alpha_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n\\(\\hat{\\alpha}_0+\\hat{\\beta}_0\\), \\(\\hat{\\alpha}_1 + \\hat{\\beta}_1\\)의 값은 각각 얼마인가? 이 값들을 (1) 에서 추정된 \\(\\hat{\\beta}_0\\), \\(\\hat{\\beta}_1\\) 값들과 비교하라.\n(6) 다음은 위의 모형에 대하여 학생들이 discussion한 결과이다. 올바르게 해석한 학생을 모두 골라라.\n민정: \\((x_i,y_i)\\)의 산점도는 직선모양이고 직선의 절펴과 기울기 모두 유의미해 보이므로 \\(y_i = \\beta_0 + \\beta_1 x_i\\) 꼴을 적합하는게 좋겠다.\n슬기: 나도 그렇게 생각해. 그래서 (2)-(3)과 같이 기울기를 제외하고 적합하거나 절편을 제외하고 적합하면 underfitting의 상황에 빠질 수 있어.\n성재: (2)의 경우 사실상 \\(\\bar{y}=\\frac{1}{n}\\sum_{i=1}^{n}y_i\\)를 추정하는 것과 같아지게 되지.\n세민: (4)의 경우 \\({\\bf X}=\\begin{bmatrix} 1  & x_1 \\\\ 1 & x_2 \\\\ \\dots & \\dots \\\\ 1 & x_n \\end{bmatrix}\\) 와 같이 설정하고 네트워크를 아래와 같이 설정할 경우 얻어지는 모형이야.\nnet = torch.nn.Linear(in_features=2,out_features=1,bias=True)\n구환: 모델 (4)-(5)는 표현력은 (1)과 동일하지만 추정할 파라메터는 (1)보다 많으므로 효율적인 모델이라고 볼 수 없어."
  },
  {
    "objectID": "posts/exercise.html#iris",
    "href": "posts/exercise.html#iris",
    "title": "A1: Exercise – ver. 0505-1",
    "section": "$. iris",
    "text": "$. iris\n아래의 자료를 고려하자.\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/iris.csv\")\ndf\n\n\n\n\n\n\n\n\nSepalLength\nSepalWidth\nPetalLength\nPetalWidth\nSpecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\n0.0\n\n\n1\n4.9\n3.0\n1.4\n0.2\n0.0\n\n\n2\n4.7\n3.2\n1.3\n0.2\n0.0\n\n\n3\n4.6\n3.1\n1.5\n0.2\n0.0\n\n\n4\n5.0\n3.6\n1.4\n0.2\n0.0\n\n\n...\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\n2.0\n\n\n146\n6.3\n2.5\n5.0\n1.9\n2.0\n\n\n147\n6.5\n3.0\n5.2\n2.0\n2.0\n\n\n148\n6.2\n3.4\n5.4\n2.3\n2.0\n\n\n149\n5.9\n3.0\n5.1\n1.8\n2.0\n\n\n\n\n150 rows × 5 columns\n\n\n\n위의 자료는 아이리스 데이터셋으로 머신러닝에서 자주 사용되는 분류(classification) 예제 데이터이다. 데이터는 다음과 같은 특징을 가지고 있다:\n샘플 수: 150개\n특징 수: 4개\n\n꽃받침 길이 (sepal length)\n꽃받침 너비 (sepal width)\n꽃잎 길이 (petal length)\n꽃잎 너비 (petal width)\n\n클래스 수: 3개 (각 50개 샘플)\n\n0: setosa\n1: versicolor\n2: virginica\n\n(1) 주어진 데이터를 8:2 비율로 학습용(df_train)과 테스트용(df_test)으로 나누고, SepalLength, SepalWidth, PetalLength, PetalWidth를 입력으로 하여 Species를 예측할 수 있도록 데이터를 텐서 형태로 변환하라.\nhint: 아래의 코드를 활용할 것\ndf_train = df.sample(frac=0.8, random_state=42)\ndf_test = df.drop(df_train.index)\n#---#\nX = torch.tensor(df_train.iloc[:,:4].values).float()\ny = ???\nXX = ???\nyy = ???\n(2) 아래의 제약사항에 맞추어 Species를 예측할 수 있는 적당한 네트워크를 학습하라.\n제약사항\n\n학습가능한 파라메터는 1층만 설계할 것\n학습 후 test accuracy 가 70% 이상일것\n\n(3) 아래의 제약사항에 맞추어 Species를 예측할 수 있는 적당한 네트워크를 학습하라.\n제약사항\n\n학습가능한 파라메터는 1층만 설계할 것\n학습 후 test accuracy 가 70% 이상일것\ntrain/test에서 모두 batch_size = 10 으로 설정할 것\nGPU를 사용할 것\n\n(4) 아래의 제약사항에 맞추어 Species를 예측할 수 있는 적당한 네트워크를 학습하라.\n제약사항\n\n학습가능한 파라메터는 1층만 설계할 것\n학습 후 test accuracy 가 70% 이상일 것\ntrain에서 batch_size = 50 으로, test에서는 batch_size=30을 설정할것\nGPU를 사용할 것\n매 epoch마다 loss와 train accuracy를 출력할 것\n\n(5) 아래의 제약사항에 맞추어 Species를 예측할 수 있는 적당한 네트워크를 학습하라.\n제약사항\n\n학습가능한 파라메터는 2층이상 설계할 것\n드랍아웃을 포함시킬 것\n학습 후 test accuracy 가 70% 이상일 것\ntrain에서 batch_size=50 으로, test에서는 batch_size=30을 설정할것\nGPU를 사용할 것\n매 epoch마다 loss와 train accuracy를 출력할 것"
  },
  {
    "objectID": "posts/01wk-1.html#a.-torch",
    "href": "posts/01wk-1.html#a.-torch",
    "title": "01wk-1: (토치) – 강의소개, 파이토치 기본",
    "section": "A. torch",
    "text": "A. torch\n- 벡터\n\ntorch.tensor([1,2,3])\n\ntensor([1, 2, 3])\n\n\n- 벡터의 덧셈\n\ntorch.tensor([1,2,3]) + torch.tensor([2,2,2])\n\ntensor([3, 4, 5])\n\n\n- 브로드캐스팅\n\ntorch.tensor([1,2,3]) + 2\n\ntensor([3, 4, 5])"
  },
  {
    "objectID": "posts/01wk-1.html#b.-벡터와-매트릭스",
    "href": "posts/01wk-1.html#b.-벡터와-매트릭스",
    "title": "01wk-1: (토치) – 강의소개, 파이토치 기본",
    "section": "B. 벡터와 매트릭스",
    "text": "B. 벡터와 매트릭스\n- \\(3 \\times 2\\) matrix\n\ntorch.tensor([[1,2],[3,4],[5,6]]) \n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n- \\(3 \\times 1\\) matrix = \\(3 \\times 1\\) column vector\n\ntorch.tensor([[1],[3],[5]]) \n\ntensor([[1],\n        [3],\n        [5]])\n\n\n- \\(1 \\times 2\\) matrix = \\(1 \\times 2\\) row vector\n\ntorch.tensor([[1,2]]) \n\ntensor([[1, 2]])\n\n\n- 더하기\n브로드캐스팅(편한거)\n\ntorch.tensor([[1,2],[3,4],[5,6]]) - 1\n\ntensor([[0, 1],\n        [2, 3],\n        [4, 5]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-3],[-5]])\n\ntensor([[0, 1],\n        [0, 1],\n        [0, 1]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-2]])\n\ntensor([[0, 0],\n        [2, 2],\n        [4, 4]])\n\n\n잘못된 브로드캐스팅\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-3,-5]])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[13], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1,-3,-5]])\n\nRuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\n\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-2]])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[14], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([[-1],[-2]])\n\nRuntimeError: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0\n\n\n\n이상한 것\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-2])\n\ntensor([[0, 0],\n        [2, 2],\n        [4, 4]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-3,-5])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[16], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) + torch.tensor([-1,-3,-5])\n\nRuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1\n\n\n\n- 행렬곱\n정상적인 행렬곱\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1],[2]])\n\ntensor([[ 5],\n        [11],\n        [17]])\n\n\n\ntorch.tensor([[1,2,3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\ntensor([[22, 28]])\n\n\n잘못된 행렬곱\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1,2]])\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[19], line 1\n----&gt; 1 torch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([[1,2]])\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 1x2)\n\n\n\n\ntorch.tensor([[1],[2],[3]]) @ torch.tensor([[1,2],[3,4],[5,6]]) \n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[20], line 1\n----&gt; 1 torch.tensor([[1],[2],[3]]) @ torch.tensor([[1,2],[3,4],[5,6]])\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (3x1 and 3x2)\n\n\n\n이상한 것\n\ntorch.tensor([[1,2],[3,4],[5,6]]) @ torch.tensor([1,2]) # 이게 왜 가능..\n\ntensor([ 5, 11, 17])\n\n\n\ntorch.tensor([1,2,3]) @ torch.tensor([[1,2],[3,4],[5,6]]) # 이건 왜 가능?\n\ntensor([22, 28])"
  },
  {
    "objectID": "posts/01wk-1.html#c.-transpose-reshape",
    "href": "posts/01wk-1.html#c.-transpose-reshape",
    "title": "01wk-1: (토치) – 강의소개, 파이토치 기본",
    "section": "C. transpose, reshape",
    "text": "C. transpose, reshape\n- transpose\n\ntorch.tensor([[1,2],[3,4]]).T \n\ntensor([[1, 3],\n        [2, 4]])\n\n\n\ntorch.tensor([[1],[3]]).T \n\ntensor([[1, 3]])\n\n\n\ntorch.tensor([[1,2]]).T \n\ntensor([[1],\n        [2]])\n\n\n- reshape\n일반적인 사용\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(2,3)\n\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]])\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(1,6)\n\ntensor([[1, 2, 3, 4, 5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(6)\n\ntensor([1, 2, 3, 4, 5, 6])\n\n\n편한 것\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(2,-1)\n\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(6,-1)\n\ntensor([[1],\n        [2],\n        [3],\n        [4],\n        [5],\n        [6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(-1,6)\n\ntensor([[1, 2, 3, 4, 5, 6]])\n\n\n\ntorch.tensor([[1,2],[3,4],[5,6]]).reshape(-1)\n\ntensor([1, 2, 3, 4, 5, 6])"
  },
  {
    "objectID": "posts/01wk-1.html#d.-concat-stack-starstarstar",
    "href": "posts/01wk-1.html#d.-concat-stack-starstarstar",
    "title": "01wk-1: (토치) – 강의소개, 파이토치 기본",
    "section": "D. concat, stack \\((\\star\\star\\star)\\)",
    "text": "D. concat, stack \\((\\star\\star\\star)\\)\n- concat\n\na = torch.tensor([[1],[3],[5]])\nb = torch.tensor([[2],[4],[6]])\ntorch.concat([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n\ntorch.concat([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n- stack\n\na = torch.tensor([1,3,5])\nb = torch.tensor([2,4,6])\ntorch.stack([a,b],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n\ntorch.concat([a.reshape(3,1),b.reshape(3,1)],axis=1)\n\ntensor([[1, 2],\n        [3, 4],\n        [5, 6]])\n\n\n\n\n\n\n\n\nWarning\n\n\n\nconcat과 stack을 지금 처음본다면 아래를 복습하시는게 좋습니다.\nhttps://guebin.github.io/PP2024/posts/06wk-2.html#numpy와-축axis"
  },
  {
    "objectID": "posts/01wk-2.html#a.-아이스-아메리카노-가짜자료",
    "href": "posts/01wk-2.html#a.-아이스-아메리카노-가짜자료",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "A. 아이스 아메리카노 (가짜자료)",
    "text": "A. 아이스 아메리카노 (가짜자료)\n- 카페주인인 박혜원씨는 온도와 아이스아메리카노 판매량이 관계가 있다는 것을 알았다. 구체적으로는\n\n“온도가 높아질 수록 (=날씨가 더울수록) 아이스아메리카노의 판매량이 증가”\n\n한다는 사실을 알게 되었다. 이를 확인하기 위해서 아래와 같이 100개의 데이터를 모았다.\n\ntemp = [-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632]\n\n\nsales= [-8.5420, -6.5767, -5.9496, -4.4794, -4.2516, -3.1326, -4.0239, -4.1862,\n        -3.3403, -2.2027, -2.0262, -2.5619, -1.3353, -2.0466, -0.4664, -1.3513,\n        -1.6472, -0.1089, -0.3071, -0.6299, -0.0438,  0.4163,  0.4166, -0.0943,\n         0.2662,  0.4591,  0.8905,  0.8998,  0.6314,  1.3845,  0.8085,  1.2594,\n         1.1211,  1.9232,  1.0619,  1.3552,  2.1161,  1.1437,  1.6245,  1.7639,\n         1.6022,  1.7465,  0.9830,  1.7824,  2.1116,  2.8621,  2.1165,  1.5226,\n         2.5572,  2.8361,  3.3956,  2.0679,  2.8140,  3.4852,  3.6059,  2.5966,\n         2.8854,  3.9173,  3.6527,  4.1029,  4.3125,  3.4026,  3.2180,  4.5686,\n         4.3772,  4.3075,  4.4895,  4.4827,  5.3170,  5.4987,  5.4632,  6.0328,\n         5.2842,  5.0539,  5.4538,  6.0337,  5.7250,  5.7587,  6.2020,  6.5992,\n         6.4621,  6.5140,  6.6846,  7.3497,  8.0909,  7.0794,  6.8667,  7.4229,\n         7.2544,  7.1967,  9.5006,  9.0339,  7.4887,  9.0759, 11.0946, 10.3260,\n        12.2665, 13.0983, 12.5468, 13.8340]\n\n여기에서 temp는 평균기온이고, sales는 아이스아메리카노 판매량이다. 평균기온과 판매량의 그래프를 그려보면 아래와 같다.\n\nplt.plot(temp,sales,'o')\n\n\n\n\n\n\n\n\n오늘 바깥의 온도는 0.5도 이다. 아이스 아메라카노를 몇잔정도 만들어 두면 좋을까?"
  },
  {
    "objectID": "posts/01wk-2.html#b.-가짜자료를-만든-방법",
    "href": "posts/01wk-2.html#b.-가짜자료를-만든-방법",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "B. 가짜자료를 만든 방법",
    "text": "B. 가짜자료를 만든 방법\n- 방법1: \\(y_i= w_0+w_1 x_i +\\epsilon_i = 2.5 + 4x_i +\\epsilon_i, \\quad i=1,2,\\dots,n\\)\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\ny = x * 4 + 2.5 + eps\n\n\nx[:5], y[:5]\n\n(tensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792]),\n tensor([-8.5420, -6.5767, -5.9496, -4.4794, -4.2516]))\n\n\n- 방법2: \\({\\bf y}={\\bf X}{\\bf W} +\\boldsymbol{\\epsilon}\\)\n\n\\({\\bf y}=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\dots \\\\ y_n\\end{bmatrix}, \\quad {\\bf X}=\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots \\\\ 1 & x_n\\end{bmatrix}, \\quad {\\bf W}=\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}, \\quad \\boldsymbol{\\epsilon}= \\begin{bmatrix} \\epsilon_1 \\\\ \\dots \\\\ \\epsilon_n\\end{bmatrix}\\)\n\n\nX = torch.stack([torch.ones(100),x],axis=1)\nW = torch.tensor([[2.5],[4.0]])\ny = X@W + eps.reshape(100,1)\nx = X[:,[1]]\n\n\nX[:5,:], y[:5,:]\n\n(tensor([[ 1.0000, -2.4821],\n         [ 1.0000, -2.3621],\n         [ 1.0000, -1.9973],\n         [ 1.0000, -1.6239],\n         [ 1.0000, -1.4792]]),\n tensor([[-8.5420],\n         [-6.5767],\n         [-5.9496],\n         [-4.4794],\n         [-4.2516]]))\n\n\n- ture와 observed data를 동시에 시각화\n\nplt.plot(x,y,'o',label=r\"observed data: $(x_i,y_i)$\")\n#plt.plot(x,2.5+4*x,'--',label=r\"true: $(x_i, 4x_i+2.5)$ // $y=4x+2.5$ \")\nplt.legend()"
  },
  {
    "objectID": "posts/01wk-2.html#c.-회귀분석이란",
    "href": "posts/01wk-2.html#c.-회귀분석이란",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "C. 회귀분석이란?",
    "text": "C. 회귀분석이란?\n- 클리셰: 관측한 자료 \\((x_i,y_i)\\) 가 있음 \\(\\to\\) 우리는 \\((x_i,y_i)\\)의 관계를 파악하여 새로운 \\(x\\)가 왔을때 그것에 대한 예측값(predicted value) \\(\\hat{y}\\)을 알아내는 법칙을 알고 싶음 \\(\\to\\) 관계를 파악하기 위해서 \\((x_i, y_i)\\)의 산점도를 그려보니 \\(x_i\\)와 \\(y_i\\)는 선형성을 가지고 있다는 것이 파악됨 \\(\\to\\) 오차항이 등분산성을 가지고 어쩌고 저쩌고… \\(\\to\\) 하여튼 \\((x_i,y_i)\\) 를 “적당히 잘 관통하는” 어떠한 하나의 추세선을 잘 추정하면 된다.\n- 회귀분석이란 산점도를 보고 적당한 추세선을 찾는 것이다. 좀 더 정확하게 말하면 \\((x_1,y_1) \\dots (x_n,y_n)\\) 으로 \\(\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\) 를 최대한 \\(\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}\\)와 비슷하게 찾는 것.\n\ngiven data : \\(\\big\\{(x_i,y_i) \\big\\}_{i=1}^{n}\\)\nparameter: \\({\\bf W}=\\begin{bmatrix} w_0 \\\\ w_1 \\end{bmatrix}\\)\nestimated parameter: \\({\\bf \\hat{W}}=\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\)\n\n- 더 쉽게 말하면 아래의 그림을 보고 “적당한” 추세선을 찾는 것이다.\n\nplt.plot(x,y,'o',label=r\"observed data: $(x_i,y_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 추세선을 그리는 행위 = \\((w_0,w_1)\\)을 선택하는일"
  },
  {
    "objectID": "posts/01wk-2.html#a.-1단계-최초의-점선",
    "href": "posts/01wk-2.html#a.-1단계-최초의-점선",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "A. 1단계 – 최초의 점선",
    "text": "A. 1단계 – 최초의 점선\n\nWhat = torch.tensor([[-5.0],[10.0]])\nWhat\n\ntensor([[-5.],\n        [10.]])\n\n\n\nyhat = X@What \n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')"
  },
  {
    "objectID": "posts/01wk-2.html#b.-2단계-update",
    "href": "posts/01wk-2.html#b.-2단계-update",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "B. 2단계 – update",
    "text": "B. 2단계 – update\n- ’적당한 정도’를 판단하기 위한 장치: loss function 도입!\n\\[\\begin{align*}\nloss=& \\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2\\\\\n=&({\\bf y}-{\\bf\\hat{y}})^\\top({\\bf y}-{\\bf\\hat{y}})=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\n\\end{align*}\\]\n- loss 함수의 특징: 위 그림의 주황색 점선이 ‘적당할 수록’ loss값이 작다.\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat)\n\n\n\n\n\n\n\n\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875)\n\n\n- 우리의 목표: 이 loss(=8587.6275)을 더 줄이자.\n\n궁극적으로는 아예 모든 조합 \\((\\hat{w}_0,\\hat{w}_1)\\)에 대하여 가장 작은 loss를 찾으면 좋겠다.\n\n- 문제의 치환: 생각해보니까 우리의 문제는 아래와 같이 수학적으로 단순화 되었다.\n\n가장 적당한 주황색 선을 찾자 \\(\\to\\) \\(loss(\\hat{w}_0,\\hat{w}_1)\\)를 최소로하는 \\((\\hat{w}_0,\\hat{w}_1)\\)의 값을 찾자.\n\n- 수정된 목표: \\(loss(\\hat{w}_0,\\hat{w}_1)\\)를 최소로 하는 \\((\\hat{w}_0,\\hat{w}_1)\\)을 구하라.\n\n단순한 수학문제가 되었다. 이것은 마치 \\(f(x,y)\\)를 최소화하는 \\((x,y)\\)를 찾으라는 것임.\n함수의 최대값 혹은 최소값을 컴퓨터를 이용하여 찾는것을 “최적화”라고 하며 이는 산공교수님들이 가장 잘하는 분야임. (산공교수님들에게 부탁하면 잘해줌, 산공교수님들은 보통 최적화해서 어디에 쓸지보다 최적화 자체에 더 관심을 가지고 연구하심)\n최적화를 하는 방법? 경사하강법\n\n# 경사하강법 아이디어 (1차원)\n\n임의의 점을 찍는다.\n그 점에서 순간기울기를 구한다. (접선) &lt;– 미분\n순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 움직인다.\n\n\n팁: 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 조절한다. \\(\\to\\) \\(\\alpha\\)를 도입\n\n\n최종수식: \\(\\hat{w} \\leftarrow \\hat{w} - \\alpha \\times \\frac{\\partial}{\\partial w}loss(w)\\)\n\n#\n# 경사하강법 아이디어 (2차원)\n\n\n임의의 점을 찍는다.\n그 점에서 순간기울기를 구한다. (접평면) &lt;– 편미분\n순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 각각 움직인다.\n\n\n팁: 여기서도 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 각각 조절한다. \\(\\to\\) \\(\\alpha\\)를 도입.\n\n#\n- 경사하강법 = loss를 줄이도록 \\({\\bf \\hat{W}}\\)를 개선하는 방법\n\n업데이트 공식: 수정값 = 원래값 - \\(\\alpha\\) \\(\\times\\) 기울어진크기(=미분계수)\n여기에서 \\(\\alpha\\)는 전체적인 보폭의 크기를 결정한다. 즉 \\(\\alpha\\)값이 클수록 한번의 update에 움직이는 양이 크다.\n\n- loss는 \\(\\hat{\\bf W} =\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\) 에 따라서 값이 바뀌는 함수로 해석가능하고 구체적인 형태는 아래와 같음.\n\n\\(loss(\\hat{w}_0,\\hat{w}_1) =\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2\\)\n\\(loss(\\hat{\\bf W})=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\)\n\n따라서 구하고 싶은것은 아래와 같음\n\\[\\hat{\\bf W}^{LSE} = \\underset{\\bf \\hat{W}}{\\operatorname{argmin}} ~ loss(\\hat{\\bf W})\\]\n\n\n\n\n\n\nWarning\n\n\n\n아래의 수식\n\\[\\hat{\\bf W}^{LSE} = \\underset{\\bf \\hat{W}}{\\operatorname{argmin}} ~ loss(\\hat{\\bf W})\\]\n은 아래와 같이 표현해도 무방합니다.\n\\[\\hat{\\bf W} = \\underset{\\bf W}{\\operatorname{argmin}} ~ loss({\\bf W})\\]\n마치 함수 \\(f(\\hat{x})=({\\hat x}-1)^2\\) 을 \\(f(x)=(x-1)^2\\) 이라고 표현할 수 있는 것 처럼요..\n\n\n여기까지 01wk-2에서 수업했습니다~\n\n여기부터는 02wk-1에서..\n# 지난시간 복습\n\n# x,X,W,y // X = [1 x], W = [w0, w1]' # 회귀분석에서는 W=β\n# 회귀모형: y=X@W+ϵ = X@β+ϵ\n# true: E(y)=X@W\n# observed: (x,y)\n# estimated W = What = [w0hat, w1hat]' &lt;-- 아무값이나넣었음.. \n# estimated y = yhat = X@What = X@β̂ \n# loss = yhat이랑 y랑 얼마나 비슷한지 = sum((y-yhat)^2)\n# (x,y) 보고 최적의 선분을 그리는것 = loss를 가장 작게 만드는 What = [w0hat, w1hat] 를 찾는것\n# 전략: (1) 아무 What나 찍는다 (2) 그거보다 더 나은 What을 찾는다. (3) 1-2를 반복한다. \n# 전략2가 어려운데, 이를 수행하는 방법이 경사하강법 \n# 경사하강법 알고리즘: 더나은What = 원래What - 0.1*미분값\n\n\nWhat = torch.tensor([[-5.0],[10.0]])\nWhat\n\ntensor([[-5.],\n        [10.]])\n\n\n\nyhat = X@What \nplt.plot(x,y,'o')\nplt.plot(x,yhat,'--')\n\n\n\n\n\n\n\n\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875)\n\n\n복습끝~\n#\n- 더 나은 선으로 업데이트하기 위해서는 공식 “더나은What = 원래What - 0.1*미분값” 를 적용해야하고 이를 위해서는 미분값을 계산할 수 있어야 함.\n\n\n\n\n\n\nImportant\n\n\n\n경사하강법을 좀 더 엄밀하게 써보자. 경사하강법은 \\(loss(\\hat{\\bf W})\\)를 최소로 만드는 \\(\\hat{\\bf W}\\)를 컴퓨터로 구하는 방법인데, 구체적으로는 아래와 같다.\n1. 임의의 점 \\(\\hat{\\bf W}\\)를 찍는다.\n2. 그 점에서 순간기울기를 구한다. 즉 \\(\\left.\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\right|_{{\\bf W}=\\hat{\\bf W}}\\) 를 계산한다.\n3. \\(\\hat{\\bf W}\\)에서의 순간기울기의 부호를 살펴보고 부호와 반대방향으로 움직인다. 이때 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 각각 조절한다. 즉 아래의 수식에 따라 업데이트 한다.\n\n\\(\\hat{\\bf W} \\leftarrow \\hat{\\bf W} - \\alpha \\times \\left.\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\right|_{{\\bf W}=\\hat{\\bf W}}\\)\n\n여기에서 맨 마지막 수식을 간단하게 쓴 것이 더나은What = 원래What - 0.1*미분값 이다.\n\n\n- 미분값을 계산하는 방법1\n\n# 손실 8587.6875 를 계산하는 또 다른 방식\ndef l(w0,w1):\n    yhat = w0 + w1*x\n    return torch.sum((y-yhat)**2)\n\n\nl(-5,10)\n\ntensor(8587.6875)\n\n\n\nh=0.001\nprint((l(-5+h,10) - l(-5,10))/h)\nprint((l(-5,10+h) - l(-5,10))/h)\n\ntensor(-1341.7968)\ntensor(1190.4297)\n\n\n일단 이거로 업데이트해볼까?\n\n# 더나은What = 원래What - 0.1*미분값\n# [-5,10] - 0.001 * [-1341.7968,1190.4297]\n\n\nsssss = What - 0.001 * torch.tensor([[-1341.7968],[1190.4297]])\nsssss\n\ntensor([[-3.6582],\n        [ 8.8096]])\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What,'-') # 원래What: 주황색\nplt.plot(x,X@sssss,'-') # 더나은What: 초록색\n\n\n\n\n\n\n\n\n\n잘 된 것 같긴한데..\n미분구하는게 너무 어려워..\n다른 방법 없을까?\n\n\n\n\n\n\n\nImportant\n\n\n\n사실 이 방법은\n\n\\(\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\approx \\frac{loss(w_0+h,w_1)-loss(w_0,w_1)}{h}\\)\n\\(\\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\approx \\frac{loss(w_0,w_1+h)-loss(w_0,w_1)}{h}\\)\n\n이 계산을 이용하여\n\n\\(\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W}):= \\begin{bmatrix} \\frac{\\partial}{\\partial w_0} \\\\ \\frac{\\partial}{\\partial w_1}\\end{bmatrix}loss({\\bf W}) =  \\begin{bmatrix} \\frac{\\partial}{\\partial w_0}loss({\\bf W}) \\\\ \\frac{\\partial}{\\partial w_1}loss({\\bf W})\\end{bmatrix}  =  \\begin{bmatrix} \\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\\\ \\frac{\\partial}{\\partial w_1}loss(w_0,w_1)\\end{bmatrix}\\)\n\n를 계산한 것이라 볼 수 있죠\n\n\n- 미분값을 계산하는 방법2\n\n## 약간의 지식이 필요함. \n# loss = (y-XWhat)'(y-XWhat)\n# = (y'-What'X')(y-XWhat)\n# = y'y-y'XWhat -What'X'y + What'X'XWhat \n# loss를 What으로 미분\n# loss' = -X'y - X'y + 2X'XWhat\n\n\n-2*X.T@y + 2*X.T@X@What\n\ntensor([[-1342.2524],\n        [ 1188.9302]])\n\n\n\n\n\n\n\n\nImportant\n\n\n\n이 방법은 \\(loss({\\bf W})\\)의 미분을 구할수 있어야 사용가능합니다. 즉\n\\[\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})= -2{\\bf X}^\\top {\\bf y} + 2{\\bf X}^\\top {\\bf X}{\\bf W}\\]\n를 계산할 수 있어야 합니다.\n\n\n- 미분값을 계산하는 방법3 – 이 패턴을 외우세여\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875, grad_fn=&lt;SumBackward0&gt;)\n\n\n\nloss.backward() # loss를 미분하라.. 꼬리표가 있게 한 What으로.. \n\n\nWhat.grad\n\ntensor([[-1342.2524],\n        [ 1188.9305]])\n\n\n- 위의 코드를 다시 복습해보자.\n– loss.backward()실행전 –\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nyhat = X@What\nloss = torch.sum((y-yhat)**2)\n\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n None)\n\n\n– loss.backward()실행후 –\n\nloss.backward()\n\n\nWhat.data, What.grad\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-1342.2524],\n         [ 1188.9305]]))\n\n\n# 1회 업데이트 과정을 차근차근 시각화하며 정리해보자.\n\nalpha = 0.001 \nprint(f\"{What.data} -- 수정전\")\nprint(f\"{-alpha*What.grad} -- 수정하는폭\")\nprint(f\"{What.data-alpha*What.grad} -- 수정후\")\nprint(f\"{torch.tensor([[2.5],[4]])} -- 참값(이건 비밀~~)\")\n\ntensor([[-5.],\n        [10.]]) -- 수정전\ntensor([[ 1.3423],\n        [-1.1889]]) -- 수정하는폭\ntensor([[-3.6577],\n        [ 8.8111]]) -- 수정후\ntensor([[2.5000],\n        [4.0000]]) -- 참값(이건 비밀~~)\n\n\n\nWbefore = What.data\nWafter = What.data - alpha * What.grad \nWbefore, Wafter\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-3.6577],\n         [ 8.8111]]))\n\n\n\nplt.plot(x,y,'o',label=r'observed data')\nplt.plot(x,X@Wbefore,'--', label=r\"$\\hat{\\bf y}_{before}={\\bf X}@\\hat{\\bf W}_{before}$\")\nplt.plot(x,X@Wafter,'--', label=r\"$\\hat{\\bf y}_{after}={\\bf X}@\\hat{\\bf W}_{after}$\")\nplt.legend()\n\n\n\n\n\n\n\n\n#"
  },
  {
    "objectID": "posts/01wk-2.html#c.-3단계-iteration-learn-estimate-bfhat-w",
    "href": "posts/01wk-2.html#c.-3단계-iteration-learn-estimate-bfhat-w",
    "title": "01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정",
    "section": "C. 3단계 – iteration (=learn = estimate \\(\\bf{\\hat W}\\))",
    "text": "C. 3단계 – iteration (=learn = estimate \\(\\bf{\\hat W}\\))\n- 이제 1단계와 2단계를 반복만하면된다. 그래서 아래와 같은 코드를 작성하면 될 것 같은데…\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True) # 최초의 직선을 만드는 값\nfor epoc in range(30):\n    yhat = X@What \n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n돌려보면 잘 안된다.\n- 아래와 같이 해야한다.\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True) # 최초의 직선을 만드는 값\nfor epoc in range(30):\n    yhat = X@What \n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    What.grad = None \n\n\nplt.plot(x,y,'o',label=r\"observed: $(x_i,y_i)$\")\nplt.plot(x,X@What.data,'--o', label=r\"estimated: $(x_i,\\hat{y}_i)$ -- after 30 iterations (=epochs)\", alpha=0.4 )\nplt.legend()\n\n\n\n\n\n\n\n\n- 왜? loss.backward() 는 아래의 역할을 하는것 처럼 이해되었지만\n\nWhat.grad \\(\\leftarrow\\) What에서미분값\n\n실제로는 아래의 역할을 수행하기 때문이다. (컴퓨터공학적인 이유로..)\n\nWhat.grad \\(\\leftarrow\\) What.grad + What에서미분값\n\n\n\n\n\n\n\nNote\n\n\n\nWhat.grad \\(\\leftarrow\\) What.grad + What에서미분값 임을 확인하기 위해서.. 약간의 테스트를 했습니다.\n먼저\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True) # 최초의 직선을 만드는 값\nprint(What.data)\nprint(What.grad)\n를 확인한뒤 아래를 반복실행해봤을때\nyhat = X@What \nloss = torch.sum((y-yhat)**2)\nloss.backward() # \nprint(What.data)\nprint(What.grad)\nWhat.data와 What.grad 값이 계속 일정하게 나온다면\n\nWhat.grad \\(\\leftarrow\\) What에서미분값\n\n이와 같은 계산이 진행되는 것이겠고, What.grad의 값이 자꾸 커진다면\n\nWhat.grad \\(\\leftarrow\\) What.grad + What에서미분값\n\n이와 같은 계산이 진행되는 것이겠죠?"
  },
  {
    "objectID": "posts/11wk-1.html#a.-임베딩레이어",
    "href": "posts/11wk-1.html#a.-임베딩레이어",
    "title": "11wk-1: (추천시스템) – Embedding 레이어, 사용자정의 네트워크, MF-based 추천시스템을 넘어서",
    "section": "A. 임베딩레이어",
    "text": "A. 임베딩레이어\n- 모티브: torch.nn.functional.one_hot + torch.nn.Linear 를 매번 쓰는건 너무 귀찮지 않어?\n\ntorch.manual_seed(43052)\n#x  = ['옥순', '영숙', '하니', '옥순', '영숙'] \nx = torch.tensor([0,1,2,0,1])\nX = torch.nn.functional.one_hot(x).float()\nlinr = torch.nn.Linear(3,1,bias=False)\nlinr(X)\n\ntensor([[-0.2002],\n        [-0.4890],\n        [ 0.2081],\n        [-0.2002],\n        [-0.4890]], grad_fn=&lt;MmBackward0&gt;)\n\n\n- 계산방식\n\n\\({\\boldsymbol x}= \\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 0 \\\\ 1 \\end{bmatrix} \\Longrightarrow {\\bf X}= \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\\)\n\\(\\text{linr}({\\bf X})= \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\\begin{bmatrix} -0.2002 \\\\ -0.4890 \\\\ 0.2081 \\end{bmatrix} = \\begin{bmatrix} -0.2002 \\\\ -0.4890 \\\\ 0.2081 \\\\ -0.2002 \\\\ -0.4890 \\end{bmatrix}\\)\n\n- torch.nn.functional.one_hot + torch.nn.Linear 를 함께처리해주는 레이어 torch.nn.Embedding 존재\n\n#x  = ['옥순', '영숙', '하니', '옥순', '영숙'] \nx = torch.tensor([0,1,2,0,1])\nebdd = torch.nn.Embedding(3,1)\nebdd.weight.data = torch.tensor([[-0.2002],[-0.4890],[0.2081]])\nebdd(x)\n\ntensor([[-0.2002],\n        [-0.4890],\n        [ 0.2081],\n        [-0.2002],\n        [-0.4890]], grad_fn=&lt;EmbeddingBackward0&gt;)\n\n\n\n\\(\\text{ebdd}({\\boldsymbol x})= \\text{linr}\\big(\\text{onehot}({\\boldsymbol x})\\big) = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\\begin{bmatrix} -0.2002 \\\\ -0.4890 \\\\ 0.2081 \\end{bmatrix} = \\begin{bmatrix} -0.2002 \\\\ -0.4890 \\\\ 0.2081 \\\\ -0.2002 \\\\ -0.4890 \\end{bmatrix}\\)\n우리가 이전에 구현했던 코드 “onehot + linr” 와 “ebdd”는 정확하게 동일한 동작을 수행함.\n\n- 결론: 아래의 두개의 코드는 같다.\nx= torch.tensor([0,1,2,0,1])\n\n## 코드1 \nlinr = torch.nn.Linear(3,1) \nlinr(torch.nn.functional.one_hot(x))\n\n## 코드2 \nebdd = torch.nn.Embedding(3,1)\nebdd(x)"
  },
  {
    "objectID": "posts/11wk-1.html#b.-mf-based-추천시스템-재설계",
    "href": "posts/11wk-1.html#b.-mf-based-추천시스템-재설계",
    "title": "11wk-1: (추천시스템) – Embedding 레이어, 사용자정의 네트워크, MF-based 추천시스템을 넘어서",
    "section": "B. MF-based 추천시스템 재설계",
    "text": "B. MF-based 추천시스템 재설계\n아래의 자료를 활용하여 추천시스템을 설계하고자한다.\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2025/main/posts/iamsolo.csv',index_col=0)\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n\ndf_train = df_view.stack().reset_index().set_axis(['W','M','y'],axis=1)\n여성인덱스 = {'옥순(IN)':0, '영자(IN)':1, '정숙(IS)':2, '영숙(IS)':3, '순자(EN)':4, '현숙(EN)':5, '서연(ES)':6, '보람(ES)':7, '하니(I)':8}\n남성인덱스 = {'영식(IN)':0, '영철(IN)':1, '영호(IS)':2, '광수(IS)':3, '상철(EN)':4, '영수(EN)':5, '규빈(ES)':6, '다호(ES)':7}\nx1 = torch.tensor(df_train['W'].map(여성인덱스)) # length-n int vector \nx2 = torch.tensor(df_train['M'].map(남성인덱스)) # length-n int vector \ny = torch.tensor(df_train['y']).float().reshape(-1,1) # (n,1) float vector\n\n임베딩레이어를 활용하여 MF-based 추천시스템을 설계하라.\n(풀이)\n\n#df_view\nloss_fn = torch.nn.MSELoss() \nebdd1 = torch.nn.Embedding(9,2)\nebdd2 = torch.nn.Embedding(8,2)\nb1 = torch.nn.Embedding(9,1)\nb2 = torch.nn.Embedding(8,1)\nparams = list(ebdd1.parameters()) + list(ebdd2.parameters())  + list(b1.parameters()) + list(b2.parameters())\noptimizr = torch.optim.Adam(params)\nsig = torch.nn.Sigmoid()\n#----#\nfor epoc in range(5000):\n    #step1\n    W_features = ebdd1(x1) \n    M_features = ebdd2(x2) \n    W_bias = b1(x1)\n    M_bais = b2(x2)\n    yhat = sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bais)*5\n    #step2\n    loss = loss_fn(yhat,y)\n    #step3\n    loss.backward()\n    #step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\ny[:5], yhat[:5]\n\n(tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200]]),\n tensor([[3.9809],\n         [3.4865],\n         [3.4730],\n         [0.8163],\n         [0.9715]], grad_fn=&lt;SliceBackward0&gt;))"
  },
  {
    "objectID": "posts/11wk-1.html#a.-사용자정의-네트워크-사용법",
    "href": "posts/11wk-1.html#a.-사용자정의-네트워크-사용법",
    "title": "11wk-1: (추천시스템) – Embedding 레이어, 사용자정의 네트워크, MF-based 추천시스템을 넘어서",
    "section": "A. 사용자정의 네트워크 사용법",
    "text": "A. 사용자정의 네트워크 사용법\n# 예비학습1: net(X)와 사실 net.forward(X)는 같다.\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nX = torch.randn(5,1)\n\n\nnet(X)\n#net.forward(X)\n\ntensor([[0.3340],\n        [0.4480],\n        [0.3143],\n        [0.2375],\n        [0.2066]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n그래서 net.forward를 재정의하면 net(X)의 기능을 재정의 할 수 있다.\n\ndef func(x):\n    return \"메롱\"\n\n\nnet.forward = func \n\n\nnet.forward(X) \n\n'메롱'\n\n\n\nnet(X)\n\n'메롱'\n\n\n#\n# 예비학습2: torch.nn.Module을 상속받아서 네트워크를 만들면 (= “class XXX(torch.nn.Module):” 와 같은 방식으로 클래스를 선언하면) 약속된 아키텍처를 가진 네트워크를 찍어내는 함수를 만들 수 있다.\n\n\n\n\n\n\nNote\n\n\n\n클래스의 기초가 부족한 분들은 아래의 링크에서\n\nhttps://guebin.github.io/PP2024/\n\n11wk-2, 12wk-2, 13wk-2, 14wk-2 에 대한내용을 학습하시길 바랍니다.\n\n\n(예제1) – torch.nn.Module의 상속을 이용하여 아래와 동일한 아키텍처를 가지는 네트워크를 설계하라.\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True), # linr1\n    torch.nn.Sigmoid(),#sig\n    torch.nn.Linear(in_features=1,out_features=1,bias=False) # linr2 \n)\n\n\nx = torch.tensor([[1.0]])\n\n\nnet(x)\n\ntensor([[-0.5737]], grad_fn=&lt;MmBackward0&gt;)\n\n\n(풀이)\n\nclass MyNet1(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linr1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.sig = torch.nn.Sigmoid()\n        self.linr2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n    def forward(self,x):\n        out = self.linr2(self.sig(self.linr1(x)))\n        return out \n\n(예시2) – torch.nn.Module의 상속을 이용하여 아래와 동일한 동작을 하는 네트워크를 설계하라.\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\n\n(풀이)\n\nclass MyNet2(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linr1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.relu = torch.nn.ReLU()\n        self.linr2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n    def forward(self,X):\n        netout = self.linr2(self.relu(self.linr1(x)))\n        return netout\n\n사용자 정의 네트워크를 만드는 방법\nstep1: 아래와 코드를 복사하여 틀을 만든다. (이건 무조건 고정임, XXXX 자리는 원하는 이름을 넣는다)\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 netout을 구할때 사용할 레이어를 정의 \n        \n        ## 정의 끝\n    def forward(self,X):\n        ## netout을 어떻게 구할것인지 정의 \n        \n        ## 정의 끝\n        return netout\n\nforward의 입력: X는 net(X)에 사용하는 X임\nforward의 출력: netout은 net.forward(X) 함수의 리턴값임\n당연히 X/netout은 다른 변수로 써도 무방 (예를들면 input/output 이라든지)\n\nstep2: def __init__(self):에 yhat을 구하기 위해 필요한 재료를 레이어를 정의하고 이름을 붙인다. 이름은 항상 self.xxx 와 같은 식으로 정의한다.\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 netout을 구할때 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Sigmoid()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 정의 끝\n    def forward(self,X):\n        ## netout을 어떻게 구할것인지 정의 \n        \n        ## 정의 끝\n        return netout\nstep3: def forward:에 “X –&gt; netout” 으로 가는 과정을 묘사한 코드를 작성하고 netout을 리턴하도록 한다.\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 netout 구할때 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Sigmoid()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 정의 끝\n    def forward(self,X):\n        ## netout을 어떻게 구할것인지 정의 \n        u = self.xxx1(X) \n        v = self.xxx2(u)\n        netout = self.xxx3(v) \n        ## 정의 끝\n        return netout\n#\n# 실습(2025-중간고사 4번): 자유 낙하 운동이란 어떤 물체가 일정한 높이에서 떨어져 지면에 도달하기 까지 걸리는 시간을 다루는 물리학 개념이다. 다음은 물리학의 자유 낙하 운동에서 착안하여 생성한 데이터이다.\n\ntorch.manual_seed(43052)\nh = torch.rand(100)*100\nh,_ = h.sort()\nh = h.reshape(100,1)\nt = torch.sqrt(2*h/9.8) + torch.randn([100,1])*0.1\n\n여기에서 \\(h\\)는 낙하전의 높이(단위: m), \\(t\\)는 해당높이에서 물치가 지면에 도달하기 까지 걸리는 시간(단위:초)을 의미한다. 예를 들어 아래의 자료는 \\(h=99.3920, t=4.4583\\)를 의미하는데\n\nh[-1], t[-1]\n\n(tensor([99.3920]), tensor([4.4583]))\n\n\n이것은 높이 \\(99.3920\\)m에서 낙하한 물체가 약 \\(4.4583\\)초만에 지면에 도달했음을 의미한다. 아래의 그림은 \\(x\\)축에 \\(h\\), \\(y\\)축에 \\(t\\)를 두고 해당 데이터를 산점도로 시각화 한 것이다.\n\nplt.plot(h,t,'o',alpha=0.5)\nplt.xlabel('Height (m)')\nplt.ylabel('Time to fall (sec)')\nplt.title('Free Fall Time vs Height')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n그래프를 보면 높이가 높을 수록 낙하시간도 길어지는 경향이 관찰된다. 다만 동일한 높이라 하더라도 낙하시간이 조금씩 차이나는 경우가 있는데, 이는 사람이 시간측정을 수동으로 하며 발생하는 실험오차 때문이다. 이러한 오차에도 불구하고 \\(h\\)와 \\(t\\)사이에는 일정한 규칙이 존재하는듯 하다. 물리학과 교수님께 자문을 요청한 결과 자유낙하에 걸리는 시간은 \\(\\sqrt{h}\\)에 비례함을 알 수 있었고 이를 근거로 아래와 같은 모형을 설계하였다.\n\\[t_i = \\beta_0 + \\beta_1 \\sqrt{h_i}+\\epsilon_i, \\quad \\epsilon_i \\sim {\\cal N}(0,\\sigma^2)\\]\n위의 모형을 활용하여 높이 \\(h\\)로부터 낙하시간 \\(t\\)를 예측하는 신경망 모델을 설계하고 학습하라. 학습한 신경망 모델을 활용하여 높이 40m,60m,80m 에서 물체를 자유낙하 시켰을때 지면에 도달하기까지 걸리는 시간을 각각 예측하라.\n(풀이)\n\nclass FreeFallNet(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linr = torch.nn.Linear(1,1)\n    def forward(self,h):\n        netout = self.linr(torch.sqrt(h))\n        return netout    \n\n\nnet = FreeFallNet()\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(10000):\n    #1\n    netout = net(h)\n    #2\n    loss = loss_fn(netout,t)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(h,t,'o',alpha=0.5)\nplt.xlabel('Height (m)')\nplt.ylabel('Time to fall (sec)')\nplt.title('Free Fall Time vs Height')\nplt.plot(h,net(h).data,'--')\n\n\n\n\n\n\n\n\n\nhh = torch.tensor([20,30,40,50,60,70]).reshape(6,1)\nnet(hh)\n\ntensor([[2.0253],\n        [2.4746],\n        [2.8534],\n        [3.1872],\n        [3.4889],\n        [3.7664]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n#"
  },
  {
    "objectID": "posts/11wk-1.html#b.-mf-based-추천시스템-재설계-1",
    "href": "posts/11wk-1.html#b.-mf-based-추천시스템-재설계-1",
    "title": "11wk-1: (추천시스템) – Embedding 레이어, 사용자정의 네트워크, MF-based 추천시스템을 넘어서",
    "section": "B. MF-based 추천시스템 재설계",
    "text": "B. MF-based 추천시스템 재설계\n아래의 자료를 활용하여 추천시스템을 설계하고자한다.\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2024/main/posts/solo.csv',index_col=0)\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n사용자정의 네트워크를 이용하여 MF-based 추천시스템을 설계하라.\n(풀이1) – net(x1,x2)\n\n#df_view\nclass MFbased1(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.ebdd1 = torch.nn.Embedding(9,2)\n        self.ebdd2 = torch.nn.Embedding(8,2)\n        self.b1 = torch.nn.Embedding(9,1)\n        self.b2 = torch.nn.Embedding(8,1)        \n        self.sig = torch.nn.Sigmoid()\n    def forward(self,x1,x2):\n        W_features = self.ebdd1(x1) \n        M_features = self.ebdd2(x2) \n        W_bias = self.b1(x1)\n        M_bais = self.b2(x2)\n        yhat = self.sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bais)*5        \n        return yhat\nnet = MFbased1()\nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.Adam(net.parameters())\n#----#\nfor epoc in range(10000):\n    #step1\n    yhat = net(x1,x2)\n    #step2\n    loss = loss_fn(yhat,y)\n    #step3\n    loss.backward()\n    #step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\ny[:5], yhat[:5]\n\n(tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200]]),\n tensor([[4.0800],\n         [3.4664],\n         [3.3650],\n         [0.9111],\n         [0.9538]], grad_fn=&lt;SliceBackward0&gt;))\n\n\n(풀이2) – net(X)\n\nX = torch.stack([x1,x2],axis=1) \n\n\nclass MFbased2(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.ebdd1 = torch.nn.Embedding(9,2)\n        self.ebdd2 = torch.nn.Embedding(8,2)\n        self.b1 = torch.nn.Embedding(9,1)\n        self.b2 = torch.nn.Embedding(8,1)        \n        self.sig = torch.nn.Sigmoid()\n    def forward(self,X):\n        x1 = X[:,0]\n        x2 = X[:,1]\n        W_features = self.ebdd1(x1) \n        M_features = self.ebdd2(x2) \n        W_bias = self.b1(x1)\n        M_bais = self.b2(x2)\n        yhat = self.sig((W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bais)*5        \n        return yhat\nnet = MFbased2()\nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.Adam(net.parameters())\n#----#\nfor epoc in range(10000):\n    #step1\n    yhat = net(X)\n    #step2\n    loss = loss_fn(yhat,y)\n    #step3\n    loss.backward()\n    #step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\ny[:5], yhat[:5]\n\n(tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200]]),\n tensor([[4.0800],\n         [3.4664],\n         [3.3651],\n         [0.9111],\n         [0.9538]], grad_fn=&lt;SliceBackward0&gt;))"
  },
  {
    "objectID": "posts/11wk-1.html#a.-nn-based-방식",
    "href": "posts/11wk-1.html#a.-nn-based-방식",
    "title": "11wk-1: (추천시스템) – Embedding 레이어, 사용자정의 네트워크, MF-based 추천시스템을 넘어서",
    "section": "A. NN-based 방식",
    "text": "A. NN-based 방식\n아래의 자료를 활용하여 추천시스템을 설계하고자한다.\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2025/main/posts/iamsolo.csv',index_col=0)\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n\n#df_view\ndf_train = df_view.stack().reset_index().set_axis(['여성출연자','남성출연자','궁합점수'],axis=1)\n여성인덱스 = {'옥순(IN)':0, '영자(IN)':1, '정숙(IS)':2, '영숙(IS)':3, '순자(EN)':4, '현숙(EN)':5, '서연(ES)':6, '보람(ES)':7, '하니(I)':8}\n남성인덱스 = {'영식(IN)':0, '영철(IN)':1, '영호(IS)':2, '광수(IS)':3, '상철(EN)':4, '영수(EN)':5, '규빈(ES)':6, '다호(ES)':7}\nx1 = torch.tensor(df_train.여성출연자.map(여성인덱스))\nx2 = torch.tensor(df_train.남성출연자.map(남성인덱스))\ny = torch.tensor(df_train.궁합점수).reshape(-1,1).float()\n\nNN-based 추천시스템을 설계하라.\n(풀이1) – 실패\n\nclass NNbased1(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        #--#\n        self.ebdd1 = torch.nn.Embedding(9,2)\n        self.ebdd2 = torch.nn.Embedding(8,2)\n        self.b1 = torch.nn.Embedding(9,1)\n        self.b2 = torch.nn.Embedding(8,1)\n        self.sig = torch.nn.Sigmoid()\n        self.mlp = torch.nn.Sequential(\n            torch.nn.Linear(6,1),\n            torch.nn.Sigmoid()\n        )\n    def forward(self,x1,x2):\n        W_feature = self.ebdd1(x1)\n        W_bias = self.b1(x1)\n        M_feature = self.ebdd2(x2)\n        M_bias = self.b2(x2)\n        #yhat = sig((W_feature * M_feature).sum(axis=1).reshape(-1,1) + W_bias + M_bias ) * 5 \n        Z = torch.concat([W_feature, M_feature, W_bias, M_bias],axis=1)\n        yhat = self.mlp(Z) * 5 \n        return yhat\n\n\nnet = NNbased1()\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1) # 이게 편해요!!\n#--# \nfor epoc in range(5000):\n    # 1\n    yhat = net(x1,x2) \n    # 2\n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat[:5], y[:5]\n\n(tensor([[2.1563],\n         [1.6488],\n         [2.0608],\n         [1.9119],\n         [2.3126]], grad_fn=&lt;SliceBackward0&gt;),\n tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200]]))\n\n\n(풀이2) – 에라 모르겠다 깊은신경망..\n\nclass NNbased2(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        #--#\n        self.ebdd1 = torch.nn.Embedding(9,2)\n        self.ebdd2 = torch.nn.Embedding(8,2)\n        self.b1 = torch.nn.Embedding(9,1)\n        self.b2 = torch.nn.Embedding(8,1)\n        self.sig = torch.nn.Sigmoid()\n        self.mlp = torch.nn.Sequential(\n            torch.nn.Linear(6,15),\n            torch.nn.ReLU(),\n            torch.nn.Linear(15,1),\n            torch.nn.Sigmoid()\n        )\n    def forward(self,x1,x2):\n        W_feature = self.ebdd1(x1)\n        W_bias = self.b1(x1)\n        M_feature = self.ebdd2(x2)\n        M_bias = self.b2(x2)\n        #yhat = sig((W_feature * M_feature).sum(axis=1).reshape(-1,1) + W_bias + M_bias ) * 5 \n        Z = torch.concat([W_feature, M_feature, W_bias, M_bias],axis=1)\n        yhat = self.mlp(Z) * 5 \n        return yhat\n\n\nnet = NNbased2()\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1)\n#--# \nfor epoc in range(3000):\n    # 1\n    yhat = net(x1,x2) \n    # 2\n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat[:10], y[:10]\n\n(tensor([[4.0395],\n         [3.4880],\n         [3.4527],\n         [0.8548],\n         [1.1290],\n         [0.4416],\n         [0.5041],\n         [3.9470],\n         [4.0075],\n         [3.6544]], grad_fn=&lt;SliceBackward0&gt;),\n tensor([[4.0200],\n         [3.4500],\n         [3.4200],\n         [0.8400],\n         [1.1200],\n         [0.4300],\n         [0.4900],\n         [3.9300],\n         [3.9900],\n         [3.6300]]))\n\n\n(옥순-영식), (영자-다호), (하니-영호) 를 예측해보자.\n\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n\nxx1 = torch.tensor([0,1,8])\nxx2 = torch.tensor([0,7,2])\n\n\nnet(xx1,xx2)\n\ntensor([[3.9317],\n        [0.6682],\n        [4.9322]], grad_fn=&lt;MulBackward0&gt;)"
  },
  {
    "objectID": "posts/11wk-1.html#b.-ncf-he2017neural",
    "href": "posts/11wk-1.html#b.-ncf-he2017neural",
    "title": "11wk-1: (추천시스템) – Embedding 레이어, 사용자정의 네트워크, MF-based 추천시스템을 넘어서",
    "section": "B. NCF (He et al. 2017)",
    "text": "B. NCF (He et al. 2017)\n\nHe, Xiangnan, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. “Neural Collaborative Filtering.” In Proceedings of the 26th International Conference on World Wide Web, 173–82.\n- MF-based와 NN-base를 합친것"
  },
  {
    "objectID": "posts/06wk-1.html#a.-일반적인-traintest-셋팅",
    "href": "posts/06wk-1.html#a.-일반적인-traintest-셋팅",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴",
    "section": "A. 일반적인 train/test 셋팅",
    "text": "A. 일반적인 train/test 셋팅\n- Step1: 데이터정리\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\ntest_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX0 = torch.stack([to_tensor(img) for img, lbl in train_dataset if lbl==0])\nX1 = torch.stack([to_tensor(img) for img, lbl in train_dataset if lbl==1])\nX = torch.concat([X0,X1],axis=0).reshape(-1,784)\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\nXX0 = torch.stack([to_tensor(img) for img, lbl in test_dataset if lbl==0])\nXX1 = torch.stack([to_tensor(img) for img, lbl in test_dataset if lbl==1])\nXX = torch.concat([XX0,XX1],axis=0).reshape(-1,784)\nyy = torch.tensor([0.0]*len(XX0) + [1.0]*len(XX1)).reshape(-1,1)\n\n- Step2: 학습가능한 오브젝트들의 설정 (모델링과정 포함)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n- Step3: 학습 (=적합)\n\nfor epoc in range(1,501):\n    #---에폭시작---# \n    # 1 \n    yhat = net(X) \n    # 2 \n    loss = loss_fn(yhat,y) \n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n    #---에폭끝---# \n    #에폭마다 내가 보고싶은것들을 보여주는 코드\n    if (epoc % 50) ==0:\n        acc = ((net(X).data &gt; 0.5) == y).float().mean().item()\n        print(f\"# of epochs={epoc}   \\t train_acc = {acc:.4f}\")\n\n# of epochs=50       train_acc = 0.4677\n# of epochs=100      train_acc = 0.4677\n# of epochs=150      train_acc = 0.4757\n# of epochs=200      train_acc = 0.5295\n# of epochs=250      train_acc = 0.6632\n# of epochs=300      train_acc = 0.7929\n# of epochs=350      train_acc = 0.8731\n# of epochs=400      train_acc = 0.9206\n# of epochs=450      train_acc = 0.9465\n# of epochs=500      train_acc = 0.9634\n\n\n- Step4: 예측 & 결과분석\ntrain acc\n\n((net(X).data &gt; 0.5) == y).float().mean()\n\ntensor(0.9634)\n\n\ntest acc\n\n((net(XX).data&gt;0.5) == yy).float().mean()\n\ntensor(0.9749)"
  },
  {
    "objectID": "posts/06wk-1.html#b.-dropout-사용",
    "href": "posts/06wk-1.html#b.-dropout-사용",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴",
    "section": "B. Dropout 사용",
    "text": "B. Dropout 사용\n- Step1: 데이터정리\n\npass\n\n- Step2: 학습가능한 오브젝트들의 설정 (모델링과정 포함)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.Dropout(0.9),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n- Step3: 학습 (=적합)\n\nfor epoc in range(1,501):\n    net.train()\n    #---에폭시작---# \n    # 1 \n    yhat = net(X) \n    # 2 \n    loss = loss_fn(yhat,y) \n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n    #---에폭끝---# \n    net.eval()\n    #에폭마다 내가 보고싶은것들을 보여주는 코드\n    if (epoc % 50) ==0:\n        acc = ((net(X).data &gt; 0.5) == y).float().mean().item()\n        print(f\"# of epochs={epoc}   \\t train_acc = {acc:.4f}\")\n\n# of epochs=50       train_acc = 0.4677\n# of epochs=100      train_acc = 0.4677\n# of epochs=150      train_acc = 0.4744\n# of epochs=200      train_acc = 0.5215\n# of epochs=250      train_acc = 0.6435\n# of epochs=300      train_acc = 0.7675\n# of epochs=350      train_acc = 0.8468\n# of epochs=400      train_acc = 0.8978\n# of epochs=450      train_acc = 0.9301\n# of epochs=500      train_acc = 0.9492\n\n\n- Step4: 예측 & 결과분석\ntrain acc\n\n((net(X).data &gt; 0.5) == y).float().mean()\n\ntensor(0.9492)\n\n\ntest acc\n\n((net(XX).data&gt;0.5) == yy).float().mean()\n\ntensor(0.9626)"
  },
  {
    "objectID": "posts/06wk-1.html#c.-gpu도-사용",
    "href": "posts/06wk-1.html#c.-gpu도-사용",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴",
    "section": "C. GPU도 사용",
    "text": "C. GPU도 사용\n- Step1: 데이터정리\n\npass\n\n- Step2: 학습가능한 오브젝트들의 설정 (모델링과정 포함)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.Dropout(0.9),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n- Step3: 학습 (=적합)\n\nfor epoc in range(1,501):\n    net.train()\n    #---에폭시작---# \n    X = X.to(\"cuda:0\")\n    y = y.to(\"cuda:0\")\n    # 1 \n    yhat = net(X) \n    # 2 \n    loss = loss_fn(yhat,y) \n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n    #---에폭끝---# \n    net.eval()\n    #에폭마다 내가 보고싶은것들을 보여주는 코드\n    if (epoc % 50) ==0:\n        acc = ((net(X).data &gt; 0.5) == y).float().mean().item()\n        print(f\"# of epochs={epoc}   \\t train_acc = {acc:.4f}\")\n\n# of epochs=50       train_acc = 0.4677\n# of epochs=100      train_acc = 0.4677\n# of epochs=150      train_acc = 0.4745\n# of epochs=200      train_acc = 0.5223\n# of epochs=250      train_acc = 0.6441\n# of epochs=300      train_acc = 0.7686\n# of epochs=350      train_acc = 0.8469\n# of epochs=400      train_acc = 0.8979\n# of epochs=450      train_acc = 0.9302\n# of epochs=500      train_acc = 0.9492\n\n\n- Step4: 예측 & 결과분석\ntrain acc\n\n((net(X).data &gt; 0.5) == y).float().mean()\n\ntensor(0.9492, device='cuda:0')\n\n\ntest acc\n\nXX = XX.to(\"cuda:0\")\nyy = yy.to(\"cuda:0\") \n\n\n((net(XX).data&gt;0.5) == yy).float().mean()\n\ntensor(0.9626, device='cuda:0')"
  },
  {
    "objectID": "posts/06wk-1.html#d.-미니배치도-사용",
    "href": "posts/06wk-1.html#d.-미니배치도-사용",
    "title": "06wk-1: (신경망) – 데이터분석 코딩패턴",
    "section": "D. 미니배치도 사용",
    "text": "D. 미니배치도 사용\n- Step1: 데이터정리\n\nX = X.to(\"cpu\")\ny = y.to(\"cpu\")\nXX = XX.to(\"cpu\")\nyy = yy.to(\"cpu\")\n\n\nds  = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size = 16, shuffle=True) \n\n- Step2: 학습가능한 오브젝트들의 설정 (모델링과정 포함)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.Dropout(0.9),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n- Step3: 학습 (=적합)\n\nfor epoc in range(1,3):\n    net.train()\n    #---에폭시작---# \n    for Xm,ym in dl:         \n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # 1 \n        ym_hat = net(Xm) \n        # 2 \n        loss = loss_fn(ym_hat,ym) \n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #---에폭끝---# \n    net.eval()\n    #에폭마다 내가 보고싶은것들을 보여주는 코드\n    s = 0 \n    for Xm, ym in dl:\n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        s = s + ((net(Xm) &gt; 0.5) == ym).float().sum()\n    acc = s/12665        \n    print(f\"# of epochs={epoc}   \\t train_acc = {acc:.4f}\")\n\n# of epochs=1        train_acc = 0.9860\n# of epochs=2        train_acc = 0.9931\n\n\n- Step4: 예측 & 결과분석\n\nnet.to(\"cpu\")\n\nSequential(\n  (0): Linear(in_features=784, out_features=32, bias=True)\n  (1): Dropout(p=0.9, inplace=False)\n  (2): ReLU()\n  (3): Linear(in_features=32, out_features=1, bias=True)\n  (4): Sigmoid()\n)\n\n\ntrain acc\n\n((net(X) &gt; 0.5) == y).float().mean()\n\ntensor(0.9931)\n\n\ntest acc\n\n((net(XX) &gt; 0.5) == yy).float().mean()\n\ntensor(0.9967)\n\n\n\n점점 비본질적인 코드가 늘어남 (=코드가 드럽다는 소리에요) –&gt; Trainer의 개념 등장"
  },
  {
    "objectID": "posts/13wk-1.html#a.-대충-개념만-실습",
    "href": "posts/13wk-1.html#a.-대충-개념만-실습",
    "title": "13wk-1: (강화학습) – 강화학습 Intro, Bandit 게임 설명, Bandit 환경 설계 및 풀이",
    "section": "A. 대충 개념만 실습",
    "text": "A. 대충 개념만 실습\n\naction_space = [0,1] \nactions_deque = collections.deque(maxlen=500)\nrewards_deque =  collections.deque(maxlen=500)\n#---#\n\n\nfor _ in range(10):\n    action = np.random.choice(action_space)\n    if action == 1:\n        reward = 10 \n    else:\n        reward = 1\n    actions_deque.append(action)\n    rewards_deque.append(reward)\n\n\nactions_deque\n\ndeque([0, 1, 0, 0, 0, 1, 0, 1, 1, 0], maxlen=500)\n\n\n\nrewards_deque\n\ndeque([1, 10, 1, 1, 1, 10, 1, 10, 10, 1], maxlen=500)\n\n\n\nactions_numpy = np.array(actions_deque)\nrewards_numpy = np.array(rewards_deque)\n\n\nq0 = rewards_numpy[actions_numpy == 0].mean()\nq1 = rewards_numpy[actions_numpy == 1].mean()\nq_table = np.array([q0,q1])\nq_table\n\narray([ 1., 10.])\n\n\n\naction = q_table.argmax()\n\n\nfor _ in range(5):\n    action = q_table.argmax()\n    if action == 1:\n        reward = 10 \n    else:\n        reward = 1\n    actions_deque.append(action)\n    rewards_deque.append(reward)\n    actions_numpy = np.array(actions_deque)\n    rewards_numpy = np.array(rewards_deque)    \n    q0 = rewards_numpy[actions_numpy == 0].mean()\n    q1 = rewards_numpy[actions_numpy == 1].mean()\n    q_table = np.array([q0,q1])\n\n\nactions_numpy\n\narray([0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1])\n\n\n\nrewards_numpy\n\narray([ 1, 10,  1,  1,  1, 10,  1, 10, 10,  1, 10, 10, 10, 10, 10])"
  },
  {
    "objectID": "posts/13wk-1.html#b.-클래스를-이용한-구현",
    "href": "posts/13wk-1.html#b.-클래스를-이용한-구현",
    "title": "13wk-1: (강화학습) – 강화학습 Intro, Bandit 게임 설명, Bandit 환경 설계 및 풀이",
    "section": "B. 클래스를 이용한 구현",
    "text": "B. 클래스를 이용한 구현\n\nclass Bandit:\n    def __init__(self):\n        self.reward = None \n    def step(self,action):\n        if action == 0:\n            self.reward = 1\n        else: \n            self.reward = 10 \n        return self.reward \n\n\nenv = Bandit()\n\n\nclass Agent:\n    def __init__(self):\n        pass \n    def act(self):\n        # 만약에 경험이 20보다 작음 --&gt; 랜덤액션 \n        # 경험이 20보다 크면 --&gt; action = q_tabel.argmax()\n        pass \n    def save_experience(self):\n        # 데이터 저장 \n        pass \n    def learn(self):\n        # q_table 을 업데이트하는 과정 \n        pass\n\n\n\n\n\n\n\nImportant\n\n\n\n앞으로의 수업에서는 아래에 해당하는 클래스의 기본 개념을 숙지하셔야 합니다. (13wk-2 주차 강의듣기전까지 꼭!)\n\n클래스와 인스턴스의 개념, __init__, self, 메소드\n클래스의 상속\n\n관련하여 제가 작년에 수업한 자료는 아래와 같습니다\n\nhttps://guebin.github.io/PP2024/posts/11wk-2.html 에서 1-7까지..\nhttps://guebin.github.io/PP2024/posts/14wk-2.html 에서 8-A\n\n물론, 꼭 제 강의노트로만 공부하셔야하는것은 아닙니다. 제 수업 외에도 클래스를 잘 설명하는 다양한 자료들이 많이 있으니 자유롭게 참고하여 학습하시기 바랍니다."
  },
  {
    "objectID": "posts/test.html",
    "href": "posts/test.html",
    "title": "DL2025",
    "section": "",
    "text": "#!apt-get install swig\n#!pip install gymnasium[box2d]\nimport gymnasium as gym\n#--#\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation\nimport IPython\n#--#\nimport collections\nimport random\n#--#\nimport torch\n\n\ndef show(ims,jump=10):\n    ims = ims[::jump]\n    fig = plt.Figure()\n    ax = fig.subplots()\n    def update(i):\n        ax.imshow(ims[i])\n    ani = FuncAnimation(fig,update,frames=len(ims))\n    display(IPython.display.HTML(ani.to_jshtml()))\n\n\nclass AgentRandom: \n    def __init__(self):\n        #--# define spaces \n        self.action_space = gym.spaces.Discrete(4)\n        #\n        self.state =  None    ## 길이가 8인 np.array        \n        self.action = None            ## int, 0,1,2,3 중 하나\n        self.reward = None            ## float  \n        self.next_state =  None       ## np.array\n        self.terminated = None        ## bool \n        #\n        self.buffer_size = 5000\n        self.states = collections.deque(maxlen=self.buffer_size) # 원소는 텐서         \n        self.actions = collections.deque(maxlen=self.buffer_size) # 원소는 텐서 \n        self.rewards = collections.deque(maxlen=self.buffer_size) # 원소는 텐서\n        self.next_states = collections.deque(maxlen=self.buffer_size) # 원소는 텐서 \n        self.terminations = collections.deque(maxlen=self.buffer_size) # 원소는 텐서 \n        #\n        self.n_experiences = 0 \n    def act(self):\n        self.action = self.action_space.sample()\n    def learn(self):\n        pass \n    def save_experience(self):\n        self.states.append(torch.tensor(self.state))\n        self.actions.append(torch.tensor(self.action))\n        self.rewards.append(torch.tensor(self.reward))\n        self.next_states.append(torch.tensor(self.next_state))\n        self.terminations.append(torch.tensor(self.terminated))           \n        #--#\n        self.n_experiences = self.n_experiences + 1 \n\n\nclass Agent(AgentRandom):\n    def __init__(self):\n        super().__init__()\n        self.eps = 0 \n        self.q_net = torch.nn.Sequential(\n            torch.nn.Linear(8,256),\n            torch.nn.ReLU(),\n            torch.nn.Linear(256,128),\n            torch.nn.ReLU(),\n            torch.nn.Linear(128,64),\n            torch.nn.ReLU(),    \n            torch.nn.Linear(64,4)\n        )\n        self.optimizr = torch.optim.Adam(self.q_net.parameters(),lr=0.0001)\n        self.batch_size = 64\n    def act(self):\n        if random.random() &lt; self.eps: \n            self.action = self.action_space.sample()\n        else: \n            s = torch.tensor(self.state)\n            self.action = self.q_net(s).argmax().item() \n    def learn(self):\n        if self.n_experiences &lt; self.batch_size:\n            pass \n        else: \n            for epoc in range(1):\n                memory = list(zip(\n                    self.states,\n                    self.actions,\n                    self.rewards,\n                    self.next_states,\n                    self.terminations\n                ))\n                minibatch = random.sample(memory,self.batch_size)\n                ## step 1~2 \n                loss = 0 \n                for s,a,r,ss,tmd in minibatch:\n                    # step1: q_hat \n                    q_hat = self.q_net(s)[a]        \n                    # step2: loss를 계산한다. \n                    if self.terminated:\n                        q = r\n                    else:\n                        future = self.q_net(ss).max().data\n                        q = r + 0.99 * future\n                    loss = loss + (q_hat-q)**2 \n                loss = loss / self.batch_size \n                # step3 \n                loss.backward()\n                # step4 \n                self.optimizr.step()\n                self.optimizr.zero_grad() \n\n\nenv = gym.make(\"LunarLander-v3\",render_mode = 'rgb_array')\nplayer_dummy = Agent() \n#player_dummy.q_net = player.q_net # 비법전수 \nplayer_dummy.q_net.load_state_dict(torch.load(\"2025q_net_600.pth\"))\nplayer_dummy.state, _ = env.reset()\nscore = 0 \nims = [] \nims.append(env.render())\nfor t in range(1001):\n    player_dummy.act() \n    player_dummy.next_state, player_dummy.reward, player_dummy.terminated, player_dummy.truncated, _  = env.step(player_dummy.action)\n    score = score + player_dummy.reward\n    ims.append(env.render())\n    player_dummy.state = player_dummy.next_state\n    if player_dummy.terminated or player_dummy.truncated: \n        break \n\n\nshow(ims)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\nscore\n\n20.596325587960106"
  },
  {
    "objectID": "posts/12wk-2.html#a.-bf-x-bf-y",
    "href": "posts/12wk-2.html#a.-bf-x-bf-y",
    "title": "12wk-2: (순환신경망) – RNNCell, RNN, LSTM, Appedix A",
    "section": "A. \\({\\bf X}\\), \\({\\bf y}\\)",
    "text": "A. \\({\\bf X}\\), \\({\\bf y}\\)\n- X, y를 지칭하는 이름\n\n\n\n\n\n\n\n\n기호\n용어\n설명\n\n\n\n\n\\({\\bf X}\\)\n설명변수  (Explanatory Variable)\n종속변수(반응변수)를 설명하거나 예측하는 데 사용되는 변수로, 전통 통계 및 머신러닝에서의 입력 역할\n\n\n\n독립변수  (Independent Variable)\n전통적인 통계학 및 회귀 분석 문맥에서 사용됨\n\n\n\n입력변수  (Input Variable)\n머신러닝 모델에서 입력 데이터로 사용되며, 특히 신경망 구조 등에서 많이 쓰임\n\n\n\n특징 / 특성  (Feature)\n머신러닝, 데이터마이닝, 딥러닝 등에서 데이터를 구성하는 속성 또는 설명 변수로 사용됨\n\n\n\n예측 변수  (Predictor)\n예측 모델 설계 시 독립변수를 지칭하는 용어로, 모델링/통계 분석 문맥에서 흔히 사용됨\n\n\n\n공변량  (Covariate)\n실험 디자인, 특히 임상연구나 사회과학 연구에서 제어 변수로 사용됨\n\n\n\n\n\n\n\n\\({\\bf y}\\)\n반응변수  (Response Variable)\n독립변수의 영향을 받는 결과 변수로, 모델링이나 인과 추론에서 핵심적인 대상\n\n\n\n종속변수  (Dependent Variable)\n전통 통계학과 회귀분석에서 사용되며, 독립변수의 영향을 받는 변수로 정의됨\n\n\n\n출력변수  (Output Variable)\n머신러닝 및 딥러닝에서 모델의 예측 결과로 출력되는 값으로 사용됨\n\n\n\n타겟 / 정답  (Target / Label)\n지도학습에서 모델이 학습해야 하는 실제 정답값을 의미하며, 분류/회귀 문제에 공통적으로 사용됨\n\n\n\n- 더 다양함: https://ko.wikipedia.org/wiki/독립변수와_종속변수"
  },
  {
    "objectID": "posts/12wk-2.html#b.-지도학습",
    "href": "posts/12wk-2.html#b.-지도학습",
    "title": "12wk-2: (순환신경망) – RNNCell, RNN, LSTM, Appedix A",
    "section": "B. 지도학습",
    "text": "B. 지도학습\n- 우리가 수업에서 다루는 데이터는 주로 아래와 같은 느낌이다.\n\n데이터는 \\((X,y)\\) 의 형태로 정리되어 있다.\n\\(y\\)는 우리가 관심이 있는 변수이다. 즉 우리는 \\(y\\)를 적절하게 추정하는 것에 관심이 있다.\n\\(X\\)는 \\(y\\)를 추정하기 위해 필요한 정보이다.\n\n\n\n\n\n\n\n\n\n\n\n\\(X\\)\n\\(y\\)\n비고\n순서\n예시\n\n\n\n\n기온(온도)\n아이스 아메리카노 판매량\n회귀\n상관없음\n날씨가 판매량에 미치는 영향 분석\n\n\n스펙\n합격 여부\n로지스틱\n상관없음\n입사 지원자의 합격 예측\n\n\n이미지\n카테고리\n합성곱신경망 (CNN)\n상관없음\n개/고양이 이미지 구분\n\n\n유저, 아이템 정보\n평점\n추천시스템\n상관없음\n넷플릭스 영화 추천\n\n\n처음 \\(m\\)개의 단어(문장)\n이후 1개의 단어(문장)\n순환신경망 (RNN)\n순서 상관 있음\n챗봇, 문장 생성, 언어 모델링\n\n\n처음 \\(m\\)개의 단어(문장)\n카테고리\n순환신경망 (RNN)\n순서 상관 있음\n영화리뷰 감정 분류\n\n\n\n- 이러한 문제상황, 즉 \\((X,y)\\)가 주어졌을때 \\(X \\to y\\)를 추정하는 문제를 supervised learning 이라한다."
  },
  {
    "objectID": "posts/12wk-2.html#c.-모델이란",
    "href": "posts/12wk-2.html#c.-모델이란",
    "title": "12wk-2: (순환신경망) – RNNCell, RNN, LSTM, Appedix A",
    "section": "C. 모델이란?",
    "text": "C. 모델이란?\n- 통계학에서 모델은 y와 x의 관계를 의미하며 오차항의 설계를 포함하는 개념이다. 이는 통계학이 “데이터 = 정보 + 오차”의 관점을 유지하기 때문이다. 따라서 통계학에서 모델링이란\n\\[y_i = net(x_i) + \\epsilon_i\\]\n에서 (1) 적절한 함수 \\(net\\)를 선택하는 일 (2) 적절한 오차항 \\(\\epsilon_i\\) 을 설계하는일 모두를 포함한다.\n- 딥러닝 혹은 머신러닝에서 모델은 단순히\n\\[y_i \\approx net(x_i)\\]\n를 의미하는 경우가 많다. 즉 “model=net”라고 생각해도 무방하다. 이 경우 “모델링”이란 단순히 적절한 \\(net\\)을 설계하는 것만을 의미할 경우가 많다.\n- 그래서 생긴일\n\n통계학교재 특징: 분류문제와 회귀문제를 엄밀하게 구분하지 않는다. 사실 오차항만 다를뿐이지 크게보면 같은 회귀모형이라는 관점이다. 그래서 일반화선형모형(GLM)이라는 용어를 쓴다.\n머신러닝/딥러닝교재 특징: 회귀문제와 분류문제를 구분해서 설명한다. (표도 만듦) 이는 오차항에 대한 기술을 모호하게 하여 생기는 현상이다."
  },
  {
    "objectID": "posts/12wk-2.html#d.-학습이란",
    "href": "posts/12wk-2.html#d.-학습이란",
    "title": "12wk-2: (순환신경망) – RNNCell, RNN, LSTM, Appedix A",
    "section": "D. 학습이란?",
    "text": "D. 학습이란?\n- 학습이란 주어진 자료 \\((X,y)\\)를 잘 분석하여 \\(X\\)에서 \\(y\\)로 가는 어떠한 “규칙” 혹은 “원리”를 찾는 것이다.\n\n학습이란 주어진 자료 \\((X,y)\\)를 잘 분석하여 \\(X\\)에서 \\(y\\)로 가는 어떠한 “맵핑”을 찾는 것이다.\n학습이란 주어진 자료 \\((X,y)\\)를 잘 분석하여 \\(X\\)에서 \\(y\\)로 가는 어떠한 “함수”을 찾는 것이다. 즉 \\(y\\approx f(X)\\)가 되도록 만드는 \\(f\\)를 잘 찾는 것이다. (이 경우 “함수를 추정한다”라고 표현)\n학습이란 주어진 자료 \\((X,y)\\)를 잘 분석하여 \\(X\\)에서 \\(y\\)로 가는 어떠한 “모델” 혹은 “모형”을 찾는 것이다. 즉 \\(y\\approx model(X)\\)가 되도록 만드는 \\(model\\)을 잘 찾는 것이다. (이 경우 “모형을 학습시킨다”라고 표현)\n학습이란 주어진 자료 \\((X,y)\\)를 잘 분석하여 \\(X\\)에서 \\(y\\)로 가는 어떠한 “네트워크”을 찾는 것이다. 즉 \\(y\\approx net(X)\\)가 되도록 만드는 \\(net\\)을 잘 찾는 것이다. (이 경우 “네트워크를 학습시킨다”라고 표현)\n\n- prediction이란 학습과정에서 찾은 “규칙” 혹은 “원리”를 \\(X\\)에 적용하여 \\(\\hat{y}\\)을 구하는 과정이다. 학습과정에서 찾은 규칙 혹은 원리는 \\(f\\),\\(model\\),\\(net\\) 으로 생각가능한데 이에 따르면 아래가 성립한다.\n\n\\(\\hat{y} = f(X)\\)\n\\(\\hat{y} = model(X)\\)\n\\(\\hat{y} = net(X)\\)"
  },
  {
    "objectID": "posts/12wk-2.html#e.-haty를-부르는-다양한-이름",
    "href": "posts/12wk-2.html#e.-haty를-부르는-다양한-이름",
    "title": "12wk-2: (순환신경망) – RNNCell, RNN, LSTM, Appedix A",
    "section": "E. \\(\\hat{y}\\)를 부르는 다양한 이름",
    "text": "E. \\(\\hat{y}\\)를 부르는 다양한 이름\n- \\(\\hat{y}\\)는 \\(X\\)가 주어진 자료에 있는 값인지 아니면 새로운 값 인지에 따라 지칭하는 이름이 미묘하게 다르다.\n\n\\(X \\in data\\): \\(\\hat{y}=net(X)\\) 는 predicted value, fitted value 라고 부른다.\n\\(X \\notin data\\): \\(\\hat{y}=net(X)\\) 는 predicted value, predicted value with new data 라고 부른다."
  },
  {
    "objectID": "posts/12wk-2.html#f.-다양한-코드들",
    "href": "posts/12wk-2.html#f.-다양한-코드들",
    "title": "12wk-2: (순환신경망) – RNNCell, RNN, LSTM, Appedix A",
    "section": "F. 다양한 코드들",
    "text": "F. 다양한 코드들\n- 파이썬 코드..\n#Python\npredictor.fit(X,y) # autogluon 에서 \"학습\"을 의미하는 과정\nmodel.fit(X,y) # sklearn 에서 \"학습\"을 의미하는 과정\ntrainer.train() # huggingface 에서 \"학습\"을 의미하는 과정\ntrainer.predict(dataset) # huggingface 에서 \"예측\"을 의미하는 과정\nmodel.fit(x, y, batch_size=32, epochs=10) # keras에서 \"학습\"을 의미하는 과정\nmodel.predict(test_img) # keras에서 \"예측\"을 의미하는 과정 \n- R 코드..\n# R\nols &lt;- lm(y~x) # 선형회귀분석에서 학습을 의미하는 함수\nols$fitted.values # 선형회귀분석에서 yhat을 출력 \npredict(ols, newdata=test) # 선형회귀분석에서 test에 대한 예측값을 출력하는 함수\nols$coef # 선형회귀분석에서 weight를 확인하는 방법"
  },
  {
    "objectID": "posts/03wk-1.html#a.-bias의-사용",
    "href": "posts/03wk-1.html#a.-bias의-사용",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "A. bias의 사용",
    "text": "A. bias의 사용\nnet에서 bias를 사용\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=1,\n    out_features=1,\n    bias=True\n) # net(x) = x@net.weight.T + net.bias \nnet.bias.data = torch.tensor([-5.0])\nnet.weight.data = torch.tensor([[10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비 \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(x)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nnet.bias.data, net.weight.data\n\n(tensor([2.4290]), tensor([[4.0144]]))\n\n\n#"
  },
  {
    "objectID": "posts/03wk-1.html#b.-잘못된-코드",
    "href": "posts/03wk-1.html#b.-잘못된-코드",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "B. 잘못된(?) 코드",
    "text": "B. 잘못된(?) 코드\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비 \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');\n\n\n\n\n\n\n\n\n- 나쁘지 않은 이유?\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n)\nyhat = net(X) = X@net.weight.T + net.bias\n\n\nnet.weight\n\nParameter containing:\ntensor([[-1.0241,  4.0080]], requires_grad=True)\n\n\n\nnet.bias\n\nParameter containing:\ntensor([3.4689], requires_grad=True)"
  },
  {
    "objectID": "posts/03wk-1.html#a.-hatbf-y",
    "href": "posts/03wk-1.html#a.-hatbf-y",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "A. \\(\\hat{\\bf y} = ??\\)",
    "text": "A. \\(\\hat{\\bf y} = ??\\)\n- \\({\\bf X}\\)를 가지고 \\({\\bf y}\\)를 맞추는 아래와 같은 문제\n\nx = torch.tensor([-6,-5,-4,-3,-2,-1, 0, 1, 2, 3, 4, 5, 6.0]).reshape(-1,1)\ny = torch.tensor([ 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1]).reshape(-1,1)\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n- 아래와 같이 모형화 하면?\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(x)/(1+torch.exp(x)),'o--', label = \"underlying (without error)\")\nplt.legend()"
  },
  {
    "objectID": "posts/03wk-1.html#b.-hatbf-y-fracexptextlinrbf-x1exptextlinrbf-x",
    "href": "posts/03wk-1.html#b.-hatbf-y-fracexptextlinrbf-x1exptextlinrbf-x",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "B. \\(\\hat{\\bf y} = \\frac{\\exp(\\text{linr}({\\bf X}))}{1+\\exp(\\text{linr}({\\bf X}))}\\)",
    "text": "B. \\(\\hat{\\bf y} = \\frac{\\exp(\\text{linr}({\\bf X}))}{1+\\exp(\\text{linr}({\\bf X}))}\\)\n- 걱정: 산점도가 꼭 아래와 같은 방식이 아니라면 어쩌지?\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n\n\\(x\\)가 증가할수록 \\(y\\)가 0이 된다면?\n0근처에서 변화가 일어나지 않고 2근처에서 변화가 일어난다면?\n변화가 좀 더 급하게 (혹은 완만하게 일어난다면?)\n\n\nplt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(5*x+3)/(1+torch.exp(5*x+3)),'o--', label = \"underlying (without error)\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 걱정해결\n\n#plt.plot(x,y,'o', label=r\"observed data (with error) = $(x_i,y_i)$\")\nplt.plot(x,torch.exp(x)/(1+torch.exp(x)),'o--', label = \"underlying type1 (without error)\", color=\"C1\")\nplt.plot(x,torch.exp(5*x)/(1+torch.exp(5*x)),'o--', label = \"underlying type2 (without error)\", color=\"C2\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n회귀 vs 로지스틱\n\n\\({\\bf X} \\to {\\bf y}\\) 에 대한 패턴이 \\(\\text{linr}({\\bf X}) \\approx {\\bf y}\\) 이라면 회귀!\n\\({\\bf X} \\to {\\bf y}\\) 에 대한 패턴이 \\(\\frac{\\exp(\\text{linr}({\\bf X}))}{1+\\exp(\\text{linr}({\\bf X}))} \\approx {\\bf y}\\) 이라면 로지스틱!"
  },
  {
    "objectID": "posts/03wk-1.html#c.-로지스틱-모형",
    "href": "posts/03wk-1.html#c.-로지스틱-모형",
    "title": "03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형",
    "section": "C. 로지스틱 모형",
    "text": "C. 로지스틱 모형\n- \\(x\\)가 커질수록 (혹은 작아질수록) \\(y=1\\)이 잘나오는 모형은 아래와 같이 설계할 수 있음 &lt;— 외우세요!!!\n\n\\(y_i \\sim {\\cal B}(\\pi_i),\\quad\\) where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)} = \\frac{1}{1+\\exp(-w_0-w_1x_i)}\\)\n\\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\n- 회귀모형과 로지스틱 모형의 비교\n\n회귀모형: \\(y_i \\sim {\\cal N}(w_0+w_1x_i, \\sigma^2)\\)1\n로지스틱: \\(y_i \\sim {\\cal B}\\big(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\big)\\)\n\n1 원래는 이렇게 썼었지.. \\(y_i = w_0 + w_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim {\\cal N}(0,\\sigma^2)\\)- 우리가 예측하고 싶은것\n\n회귀모형: 정규분포의 평균을 예측하고 싶음. 즉 \\(w_0+w_1x_i\\)를 예측하고 싶음. 예측값으로는 \\(\\hat{w}_0 + \\hat{w}_1x_i\\)를 사용!\n로지스틱: 베르누이의 평균을 예측하고 싶음. 즉 \\(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)를 예측하고 싶음. 예측값으로는 \\(\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}\\)를 사용!"
  },
  {
    "objectID": "posts/04wk-2.html#a.-step은-표현-불가능하지-않나",
    "href": "posts/04wk-2.html#a.-step은-표현-불가능하지-않나",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "A. Step은 표현 불가능하지 않나?",
    "text": "A. Step은 표현 불가능하지 않나?\n# 예제1 – 일부러 이상하게 만든 취업합격률 곡선\n\ntorch.manual_seed(43052)\nx = torch.linspace(-1,1,2000).reshape(-1,1)\nu = 0*x-3\nu[x&lt;-0.2] = (15*x+6)[x&lt;-0.2]\nu[(-0.2&lt;x)&(x&lt;0.4)] = (0*x-1)[(-0.2&lt;x)&(x&lt;0.4)]\nsig = torch.nn.Sigmoid()\nv = π = sig(u)\ny = torch.bernoulli(v)\n\n\nplt.plot(x,y,'.',alpha=0.03, label=\"observed\")\nplt.plot(x,v,'--', label=\"unobserved\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.03, label=\"observed\")\nplt.plot(x,v, label=\"true\")\nplt.plot(x,net(x).data,'--', label=\"estimated\")\nplt.legend()\n\n\n\n\n\n\n\n\n#"
  },
  {
    "objectID": "posts/04wk-2.html#b.-곡선은-표현-불가능하지-않나",
    "href": "posts/04wk-2.html#b.-곡선은-표현-불가능하지-않나",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "B. 곡선은 표현 불가능하지 않나?",
    "text": "B. 곡선은 표현 불가능하지 않나?\n# 예제2 – 2024년 수능 미적30번 문제에 나온 곡선\n\\[y_i = e^{-x_i} \\times  |\\cos(5x_i)| \\times \\sin(5x) + \\epsilon_i, \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\]\n\ntorch.manual_seed(43052)\nx = torch.linspace(0,2,2000).reshape(-1,1)\neps = torch.randn(2000).reshape(-1,1)*0.05\nfx = torch.exp(-1*x)* torch.abs(torch.cos(3*x))*(torch.sin(3*x))\ny = fx + eps\n\n\nplt.plot(x,y,label=\"observed\",alpha=0.5)\nplt.plot(x,fx,label=\"true\")\n\n\n\n\n\n\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048), # 꺽이지않은 1024개의 직선\n    torch.nn.ReLU(), # 꺽인(렐루된) 1024개의 직선 \n    torch.nn.Linear(2048,1), # 합쳐진 하나의 꺽인 직선 \n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n## \nfor epoc in range(1000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,label=\"observed\",alpha=0.5)\nplt.plot(x,fx,label=\"true\")\nplt.plot(x,net(x).data,'--',label=\"estimated\")\nplt.legend()\n\n\n\n\n\n\n\n\n#"
  },
  {
    "objectID": "posts/04wk-2.html#a.-시벤코정리-소개",
    "href": "posts/04wk-2.html#a.-시벤코정리-소개",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "A. 시벤코정리 소개",
    "text": "A. 시벤코정리 소개\n\n\n\n\n\n\nUniversal Approximation Thm (Cybenko 1989)\n\n\n\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크 \\(net: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\)는\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n모든 보렐 가측함수 (Borel measurable function)\n\\[f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\]\n를 원하는 정확도로 “근사”시킬 수 있다. 쉽게 말하면 \\({\\bf X} \\to {\\bf y}\\) 인 어떠한 복잡한 규칙라도 하나의 은닉층을 가진 신경망이 원하는 정확도로 근사시킨다는 의미이다. 예를들면 아래와 같은 문제를 해결할 수 있다.\n\n\\({\\bf X}_{n\\times 2}\\)는 토익점수, GPA 이고 \\({\\bf y}_{n\\times 1}\\)는 취업여부일 경우 \\({\\bf X} \\to {\\bf y}\\)인 규칙을 신경망은 항상 찾을 수 있다.\n\\({\\bf X}_{n \\times p}\\)는 주택이미지, 지역정보, 주택면적, 주택에 대한 설명 이고 \\({\\bf y}_{n\\times 1}\\)는 주택가격일 경우 \\({\\bf X} \\to {\\bf y}\\)인 규칙을 신경망은 항상 찾을 수 있다.\n\n즉 하나의 은닉층을 가진 신경망의 표현력은 거의 무한대라 볼 수 있다.\n\n\n\nCybenko, George. 1989. “Approximation by Superpositions of a Sigmoidal Function.” Mathematics of Control, Signals and Systems 2 (4): 303–14.\n\n보렐가측함수에 대한 정의는 측도론에 대한 이해가 있어야 가능함. 측도론에 대한 내용이 궁금하다면 https://guebin.github.io/SS2024/ 을 공부해보세요"
  },
  {
    "objectID": "posts/04wk-2.html#b.-왜-가능한가",
    "href": "posts/04wk-2.html#b.-왜-가능한가",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "B. 왜 가능한가??",
    "text": "B. 왜 가능한가??\n- 준비\n\nx = torch.linspace(-10,10,200).reshape(-1,1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(in_features=2,out_features=1)\n)\nl1,a1,l2 = net\n\n\nnet\n\nSequential(\n  (0): Linear(in_features=1, out_features=2, bias=True)\n  (1): Sigmoid()\n  (2): Linear(in_features=2, out_features=1, bias=True)\n)\n\n\n# 생각1 – 2개의 시그모이드를 우연히 잘 조합하면 하나의 계단함수를 만들 수 있다.\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+10.00,+10.00])\n\n\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\n\n\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x)[:,[0]].data,label=r\"$-5x+10$\")\nax[0].plot(x,l1(x)[:,[1]].data,label=r\"$5x+10$\")\nax[0].set_title('$l_1(x)$')\nax[0].legend()\nax[1].plot(x,a1(l1(x))[:,[0]].data,label=r\"$v_1=sig(-5x+10)$\")\nax[1].plot(x,a1(l1(x))[:,[1]].data,label=r\"$v_2=sig(5x+10)$\")\nax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[1].legend()\nax[2].plot(x,l2(a1(l1(x))).data,color='C2',label=r\"$v_1+v_2-1$\")\nax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$')\nax[2].legend()\n\n\n\n\n\n\n\n\n#\n# 생각2 – 계단함수의 모양이 꼭 생각1과 같을 필요는 없다. 중심은 이동가능하고, 높이도 조절가능하다.\n가능한 예시1\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+0.00,+20.00])\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data.numpy(),'--',color='C0'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C0'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C0'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nax[2].set_ylim(-0.1,2.6)\n\n\n\n\n\n\n\n\n가능한 예시2\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+20.00,+00.00])\nl2.weight.data = torch.tensor([[2.50,2.50]])\nl2.bias.data = torch.tensor([-2.50])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data.numpy(),'--',color='C1'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C1'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C1'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nax[2].set_ylim(-0.1,2.6)\n\n\n\n\n\n\n\n\n#\n# 생각3: 첫번째 선형변환(=\\(l_1\\))에서 out_features=4로 하고 적당한 가중치를 조정하면 \\((l_2\\circ a_1 \\circ l_1)(x)\\)의 결과로 생각2의 예시1,2를 조합한 형태도 가능할 것 같다. 즉 4개의 시그모이드를 잘 조합하면 2단계 계단함수를 만들 수 있다.\n\nl1 = torch.nn.Linear(in_features=1,out_features=4)\na1 = torch.nn.Sigmoid()\nl2 = torch.nn.Linear(in_features=4,out_features=1)\n\n\nl1.weight.data = torch.tensor([[-5.00],[5.00],[-5.00],[5.00]])\nl1.bias.data = torch.tensor([0.00, 20.00, 20.00, 0])\nl2.weight.data = torch.tensor([[1.00,  1.00, 2.50,  2.50]])\nl2.bias.data = torch.tensor([-1.0-2.5])\n\n\nplt.plot(l2(a1(l1(x))).data,'--')\nplt.title(r\"$(l_2 \\circ a_1 \\circ l_1)(x)$\")\n\nText(0.5, 1.0, '$(l_2 \\\\circ a_1 \\\\circ l_1)(x)$')\n\n\n\n\n\n\n\n\n\n\n이러한 함수는 계단모양이며, 0을 제외한 서로다른 계단의 높이는 2개가 된다. 이를 간단히 “2단계-계단함수”라고 칭하자.\n\n#\n# 생각4 – \\(2m\\)개의 시그모이드를 우연히 잘 조합하면 \\(m\\)단계 계단함수를 만들 수 있다.\n- 정리1: 2개의 시그모이드를 우연히 잘 결합하면 아래와 같은 “1단계-계단함수” 함수 \\(h\\)를 만들 수 있다.\n\ndef h(x):\n    sig = torch.nn.Sigmoid()\n    v1 = -sig(200*(x-0.5))\n    v2 = sig(200*(x+0.5))\n    return v1+v2 \n\n\nplt.plot(x,h(x))\nplt.title(\"$h(x)$\")\n\nText(0.5, 1.0, '$h(x)$')\n\n\n\n\n\n\n\n\n\n- 정리2: 위와 같은 함수 \\(h\\)를 이용한 아래의 네트워크를 고려하자. 이는 “m단계-계단함수”를 만든다.\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n그리고 위의 네트워크와 동일한 효과를 주는 아래의 네트워크가 항상 존재함.\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,2m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n#\n# 생각5 – 그런데 어지간한 함수형태는 구불구불한 “m단계-계단함수”로 다 근사할 수 있지 않나?\n그렇다면 아래의 네트워크에서 (1) ?? 를 충분히 키우고 (2) 적절하게 학습만 잘 된다면\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n위의 네트워크는 거의 무한한 표현력을 가진다. –&gt; 이런식으로 증명하면 됩니당\n#"
  },
  {
    "objectID": "posts/04wk-2.html#c.-h의-위력",
    "href": "posts/04wk-2.html#c.-h의-위력",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "C. \\(h\\)의 위력",
    "text": "C. \\(h\\)의 위력\n- 소망: 아래와 같이 net을 설계해서, 그 위력을 체감해보고 싶은데..\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,??),\n    torch.nn.H(),\n    torch.nn.Linear(??,1)\n)\n- \\(h(x)\\)를 생성하는 클래스를 만들어보자.\n\nclass H(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,x):\n        def h(x):\n            sig = torch.nn.Sigmoid()\n            v1 = -sig(200*(x-0.5))\n            v2 = sig(200*(x+0.5))\n            return v1+v2 \n        out = h(x)\n        return out \n\n\nh = H()\n\n- \\(h\\)의 위력을 체감해보자.\n# 예제1 – 스펙의 역설\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/ironyofspec.csv\")\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    H(),\n    torch.nn.Linear(2048,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(200):\n    ## 1 \n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,prob)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n#\n# 예제2 – 수능곡선\n\ntorch.manual_seed(43052)\nx = torch.linspace(0,2,2000).reshape(-1,1)\neps = torch.randn(2000).reshape(-1,1)*0.05\nfx = torch.exp(-1*x)* torch.abs(torch.cos(3*x))*(torch.sin(3*x))\ny = fx + eps\n\n\nplt.plot(x,y,alpha=0.5)\nplt.plot(x,fx)\n\n\n\n\n\n\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    H(),\n    torch.nn.Linear(2048,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(200):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,alpha=0.5)\nplt.plot(x,fx)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n#"
  },
  {
    "objectID": "posts/04wk-2.html#d.-의문점",
    "href": "posts/04wk-2.html#d.-의문점",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "D. 의문점",
    "text": "D. 의문점\n- 이 수업을 잘 이해한 사람: 그냥 활성화함수를 \\(h\\)로 쓰면 끝 아니야? 뭐하러 relu 를 쓰는거지?\n- 딥러닝을 좀 공부해본사람1: 왜 딥러닝이 2010년이 지나서야 떳지? 1989년에 세상의 모든 문제가 풀려야 하는것 아닌가?\n- 딥러닝을 좀 공부해본사람2: 하나의 은닉층을 가진 네크워크는 잘 안쓰지 않나? 은닉층이 깊을수록 좋다고 들었는데?\n- 약간의 의구심이 있지만 아무튼 우리는 아래의 무기를 가진 꼴이 되었다.\n\n\n\n\n\n\n우리의 무기\n\n\n\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크로,\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n\\(f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\) 인 모든 보렐 가측 함수 \\(f\\) 을 원하는 정확도로 “근사”시킬 수 있다."
  },
  {
    "objectID": "posts/04wk-2.html#a.-예비학습-plt.imshow",
    "href": "posts/04wk-2.html#a.-예비학습-plt.imshow",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "A. 예비학습 – plt.imshow()",
    "text": "A. 예비학습 – plt.imshow()\n- plt.imshow(..., cmap=\"gray\") 에서 ...이 shape이 (??,??)이면 흑백이미지를 출력\n\nimg = torch.tensor([[255,100],\n                    [255,0]])\nplt.imshow(img,cmap=\"gray\")\n\n\n\n\n\n\n\n\n- plt.imshow(...) 에서 ...의 shape이 (??,??,3)이면 칼라이미지를 출력\n\nr = torch.tensor([[255,0],\n                  [255,0]])\ng = torch.tensor([[0,255],\n                  [0,0]])\nb = torch.tensor([[0,0],\n                  [0,255]])\nimg = torch.stack([r,g,b],axis=-1)\nplt.imshow(img)\n\n\n\n\n\n\n\n\n- plt.imshow(...) 에서 ...의 자료형이 int인지 float인지에 따라서 인식이 다름\n\nr = torch.tensor([[1,0],\n                  [1,0]])\ng = torch.tensor([[0,1],\n                  [0,0]])\nb = torch.tensor([[0,0],\n                  [0,1]])\nimg = torch.stack([r,g,b],axis=-1)\nplt.imshow(img)\n\n\n\n\n\n\n\n\n\nr = torch.tensor([[255,0],\n                  [255,0]])/255\ng = torch.tensor([[0,255],\n                  [0,0]])/255\nb = torch.tensor([[0,0],\n                  [0,255]])/255\nimg = torch.stack([r,g,b],axis=-1)\nplt.imshow(img)"
  },
  {
    "objectID": "posts/04wk-2.html#b.-데이터",
    "href": "posts/04wk-2.html#b.-데이터",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "B. 데이터",
    "text": "B. 데이터\n- 데이터 정리코드\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX3 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==3])\nX7 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==7])\nX = torch.concat([X3,X7],axis=0)\ny = torch.tensor([0.0]*len(X3) + [1.0]*len(X7))\n\n\nplt.plot(y,'.')\n\n\n\n\n\n\n\n\n- 우리는 \\({\\bf X}: (n,1,28,28)\\) 에서 \\({\\bf y}: (n,1)\\)으로 가는 맵핑을 배우고 싶음. \\(\\to\\) 이런건 배운적이 없는데?.. \\(\\to\\) 그렇다면 \\({\\bf X}:(n,784) \\to {\\bf y}:(n,1)\\) 으로 가는 맵핑을 학습하자.\n\nX = torch.stack([img.reshape(-1) for img in X])\ny = y.reshape(-1,1)\n\n\nX.shape,y.shape\n\n(torch.Size([12396, 784]), torch.Size([12396, 1]))"
  },
  {
    "objectID": "posts/04wk-2.html#c.-학습",
    "href": "posts/04wk-2.html#c.-학습",
    "title": "04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "C. 학습",
    "text": "C. 학습\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(200):\n    ## 1 \n    yhat = net(X) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y,'.')\nplt.plot(net(X).data,'.',alpha=0.2)\n\n\n\n\n\n\n\n\n\n((y == (net(X).data &gt; 0.5))*1.0).mean()\n\ntensor(0.9901)\n\n\n\n\n\n\n\n\nNote\n\n\n\n이미지자료의 차원\n\n칼라이미지데이터 \\({\\bf X}\\)는 (n,3,h,w) 의 차원을 가지거나 (n,h,w,3)의 차원을 가진다.\n흑백이미지데이터 \\({\\bf X}\\)는 (n,h,w) 의 차원을 가지거나 (n,1,h,w)의 차원을 가지거나 (n,h,w,1)의 차원을 가진다."
  },
  {
    "objectID": "posts/05wk-2.html#a.-로지스틱",
    "href": "posts/05wk-2.html#a.-로지스틱",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "A. 로지스틱",
    "text": "A. 로지스틱\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(1)}} =\\underset{(n,1)}{\\hat{\\bf y}}\\]\n- 모든 observation과 가중치를 명시한 버전\n(표현1)\n\n\n단점: 똑같은 그림의 반복이 너무 많음\n\n- observation 반복을 생략한 버전들\n(표현2) 모든 \\(i\\)에 대하여 아래의 그림을 반복한다고 하면 (표현1)과 같다.\n\n(표현3) 그런데 (표현2)에서 아래와 같이 \\(x_i\\), \\(y_i\\) 대신에 간단히 \\(x\\), \\(y\\)로 쓰는 경우도 많음\n\n- 1을 생략한 버전들\n(표현4) bais=False 대신에 bias=True를 주면 1을 생략할 수 있음\n\n(표현4의 수정) \\(\\hat{w}_1\\)대신에 \\(\\hat{w}\\)를 쓰는 것이 더 자연스러움\n\n(표현5) 선형변환의 결과는 아래와 같이 \\(u\\)로 표현하기도 한다.\n\n\n다이어그램은 그리는 사람의 취향에 따라 그리는 방법이 조금씩 다릅니다. 즉 교재마다 달라요."
  },
  {
    "objectID": "posts/05wk-2.html#b.-스펙의역설",
    "href": "posts/05wk-2.html#b.-스펙의역설",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "B. 스펙의역설",
    "text": "B. 스펙의역설\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\bf y}}\\]\n참고: 코드로 표현\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=2,out_features=1),\n    torch.nn.Sigmoid()\n)\n- 이해를 위해서 예젠에 다루었던 아래의 상황을 고려하자.\n\n(강의노트의 표현)\n\n(좀 더 일반화된 표현) 상황을 일반화하면 아래와 같다.\n\n* Layer의 개념: \\({\\bf X}\\)에서 \\(\\hat{\\boldsymbol y}\\)로 가는 과정은 “선형변환+비선형변환”이 반복되는 구조이다. “선형변환+비선형변환”을 하나의 세트로 보면 아래와 같이 표현할 수 있다.\n\n\\(\\underset{(n,1)}{\\bf X}  \\overset{l_1}{\\to} \\left( \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\right) \\overset{l_2}{\\to} \\left(\\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}\\right), \\quad  \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{net({\\bf X})}=\\underset{(n,1)}{\\hat{\\bf y}}\\)\n\n이것을 다이어그램으로 표현한다면 아래와 같다.\n(선형+비선형을 하나의 Layer로 묶은 표현)\n\nLayer를 세는 방법\n\n제 방식: 학습가능한 파라메터가 몇층으로 있는지… &lt;– 이것만 기억하세여\n일부 교재 설명: 입력층은 계산하지 않음, activation layer는 계산하지 않음. &lt;– 무시하세요.. 이러면 헷갈립니다..\n위의 예제의 경우 number of layer = 2 이다.\n\nHidden Layer의 수를 세는 방법\n\n제 방식: Hidden Layer의 수 = Layer의 수 -1 &lt;– 이걸 기억하세여..\n\n일부 교재 설명: Layer의 수 = Hidden Layer의 수 + 출력층의 수 = Hidden Layer의 수 + 1 &lt;– 기억하지 마세여\n위의 예제의 경우 number of hidden layer = 1 이다.\n\n\n\n\n\n\n\nImportant\n\n\n\n무조건 학습가능한 파라메터가 몇겹으로 있는지만 판단하세요. 딴거 아무것도 생각하지마세여\n## 예시1 -- 2층 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n)\n## 예시2 -- 2층 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid(),\n)\n## 예시3 -- 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n) \n## 예시4 -- 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n) \n## 예시5 -- 3층 (히든레이어는 2층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층    \n) \n## 예시6 -- 3층 (히든레이어는 2층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU()\n    torch.nn.Dropout(??)\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU()\n    torch.nn.Dropout(??)\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층  \n    torch.nn.Sigmoid()\n) \n\n\n\n\n\n\n\n\nImportant\n\n\n\n문헌에 따라서 레이어를 세는 개념이 제가 설명한 방식과 다른경우가 있습니다. 제가 설명한 방식보다 1씩 더해서 셉니다. 즉 아래의 경우 레이어를 3개로 카운트합니다.\n## 예시1 -- 문헌에 따라 3층으로 세는 경우가 있음 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n)\n예를 들어 여기에서는 위의 경우 레이어는 3개라고 설명하고 있습니다. 이러한 카운팅은 “무시”하세요. 제가 설명한 방식이 맞아요. 이 링크 잘못(?) 나와있는 이유는 아래와 같습니다.\n- 진짜 예전에 MLP를 소개할 초창기에서는 위의 경우 Layer를 3개로 셌음. (Rosenblatt et al. 1962)\n- 그런데 요즘은 그렇게 안셈.. (그리고 애초에 MLP라는 용어도 잘 안쓰죠..)\n참고로 히든레이어의 수는 예전방식이나 지금방식이나 동일하게 카운트하므로 히든레이어만 세면 혼돈이 없습니다.\n\n\n\nRosenblatt, Frank et al. 1962. Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanisms. Vol. 55. Spartan books Washington, DC.\n* node의 개념: \\(u\\to v\\)로 가는 쌍을 간단히 노드라는 개념을 이용하여 나타낼 수 있음.\n(노드의 개념이 포함된 그림)\n\n여기에서 node의 숫자 = feature의 숫자와 같이 이해할 수 있다. 즉 아래와 같이 이해할 수 있다.\n(“number of nodes = number of features”로 이해한 그림)\n\n\n다이어그램의 표현방식은 교재마다 달라서 모든 예시를 달달 외울 필요는 없습니다. 다만 임의의 다이어그램을 보고 대응하는 네트워크를 pytorch로 구현하는 능력은 매우 중요합니다."
  },
  {
    "objectID": "posts/05wk-2.html#c.-mnist",
    "href": "posts/05wk-2.html#c.-mnist",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "C. MNIST",
    "text": "C. MNIST\n\\[\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n(다이어그램표현)\n\n\nLayer0,1,2 대신에 Input Layer, Hidden Layer, Output Layer로 표현함\n\n- 위의 다이어그램에 대응하는 코드\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=28*28*1,out_features=32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=32,out_features=1),\n    torch.nn.Sigmoid() \n)"
  },
  {
    "objectID": "posts/05wk-2.html#a.-gpu-사용방법",
    "href": "posts/05wk-2.html#a.-gpu-사용방법",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "A. GPU 사용방법",
    "text": "A. GPU 사용방법\n- cpu 연산이 가능한 메모리에 데이터 저장\n\ntorch.manual_seed(43052)\nx_cpu = torch.tensor([0.0,0.1,0.2]).reshape(-1,1) \ny_cpu = torch.tensor([0.0,0.2,0.4]).reshape(-1,1) \nnet_cpu = torch.nn.Linear(1,1) \n\n\nnet_cpu(x_cpu)\n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nx_cpu\n\ntensor([[0.0000],\n        [0.1000],\n        [0.2000]])\n\n\n- gpu 연산이 가능한 메모리에 데이터 저장\n\n!nvidia-smi # before\n\nMon Apr  7 09:48:42 2025       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA GeForce RTX 3090        Off | 00000000:09:00.0 Off |                  N/A |\n|  0%   29C    P8              27W / 420W |     26MiB / 24576MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|    0   N/A  N/A      1152      G   /usr/lib/xorg/Xorg                            9MiB |\n|    0   N/A  N/A      1471      G   /usr/bin/gnome-shell                          8MiB |\n+---------------------------------------------------------------------------------------+\n\n\n\ntorch.manual_seed(43052)\nx_gpu = x_cpu.to(\"cuda:0\")\ny_gpu = y_cpu.to(\"cuda:0\")\nnet_gpu = torch.nn.Linear(1,1).to(\"cuda:0\") \n\n\n!nvidia-smi\n\nMon Apr  7 09:48:43 2025       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA GeForce RTX 3090        Off | 00000000:09:00.0 Off |                  N/A |\n|  0%   34C    P2              65W / 420W |    287MiB / 24576MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|    0   N/A  N/A      1152      G   /usr/lib/xorg/Xorg                            9MiB |\n|    0   N/A  N/A      1471      G   /usr/bin/gnome-shell                          8MiB |\n|    0   N/A  N/A    140211      C   ...b3/anaconda3/envs/dl2025/bin/python      256MiB |\n+---------------------------------------------------------------------------------------+\n\n\n\nGPU에 메모리를 올리면 GPU메모리가 점유된다! (26MiB -&gt; 287MiB)\n\n- cpu 혹은 gpu 연산이 가능한 메모리에 저장된 값들을 확인\n\nx_cpu, y_cpu, net_cpu.weight, net_cpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]]),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]]),\n Parameter containing:\n tensor([[0.3604]], requires_grad=True),\n Parameter containing:\n tensor([0.9336], requires_grad=True))\n\n\n\nx_gpu, y_gpu, net_gpu.weight, net_gpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]], device='cuda:0'),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]], device='cuda:0'),\n Parameter containing:\n tensor([[-0.3467]], device='cuda:0', requires_grad=True),\n Parameter containing:\n tensor([-0.8470], device='cuda:0', requires_grad=True))\n\n\n- gpu는 gpu끼리 연산가능하고 cpu는 cpu끼리 연산가능함\n(예시1)\n\nnet_cpu(x_cpu) \n\ntensor([[0.9336],\n        [0.9696],\n        [1.0057]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시2)\n\nnet_gpu(x_gpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시3)\n\nnet_cpu(x_gpu) \n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[41], line 1\n----&gt; 1 net_cpu(x_gpu) \n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/module.py:1739, in Module._wrapped_call_impl(self, *args, **kwargs)\n   1737     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n   1738 else:\n-&gt; 1739     return self._call_impl(*args, **kwargs)\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/module.py:1750, in Module._call_impl(self, *args, **kwargs)\n   1745 # If we don't have any hooks, we want to skip the rest of the logic in\n   1746 # this function, and just call forward.\n   1747 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1748         or _global_backward_pre_hooks or _global_backward_hooks\n   1749         or _global_forward_hooks or _global_forward_pre_hooks):\n-&gt; 1750     return forward_call(*args, **kwargs)\n   1752 result = None\n   1753 called_always_called_hooks = set()\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/linear.py:125, in Linear.forward(self, input)\n    124 def forward(self, input: Tensor) -&gt; Tensor:\n--&gt; 125     return F.linear(input, self.weight, self.bias)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)\n\n\n\n(예시4)\n\nnet_gpu(x_cpu)\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[42], line 1\n----&gt; 1 net_gpu(x_cpu)\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/module.py:1739, in Module._wrapped_call_impl(self, *args, **kwargs)\n   1737     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n   1738 else:\n-&gt; 1739     return self._call_impl(*args, **kwargs)\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/module.py:1750, in Module._call_impl(self, *args, **kwargs)\n   1745 # If we don't have any hooks, we want to skip the rest of the logic in\n   1746 # this function, and just call forward.\n   1747 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1748         or _global_backward_pre_hooks or _global_backward_hooks\n   1749         or _global_forward_hooks or _global_forward_pre_hooks):\n-&gt; 1750     return forward_call(*args, **kwargs)\n   1752 result = None\n   1753 called_always_called_hooks = set()\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/linear.py:125, in Linear.forward(self, input)\n    124 def forward(self, input: Tensor) -&gt; Tensor:\n--&gt; 125     return F.linear(input, self.weight, self.bias)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)\n\n\n\n(예시5)\n\ntorch.mean((y_cpu-net_cpu(x_cpu))**2)\n\ntensor(0.6102, grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시6)\n\ntorch.mean((y_gpu-net_gpu(x_gpu))**2)\n\ntensor(1.2068, device='cuda:0', grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시7)\n\ntorch.mean((y_gpu-net_cpu(x_cpu))**2)\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[18], line 1\n----&gt; 1 torch.mean((y_gpu-net_cpu(x_cpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n\n\n\n(예시8)\n\ntorch.mean((y_cpu-net_gpu(x_gpu))**2)\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[53], line 1\n----&gt; 1 torch.mean((y_cpu-net_gpu(x_gpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
  },
  {
    "objectID": "posts/05wk-2.html#b.-시간측정-예비학습",
    "href": "posts/05wk-2.html#b.-시간측정-예비학습",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "B. 시간측정 (예비학습)",
    "text": "B. 시간측정 (예비학습)\n\nimport time \n\n\nt1 = time.time()\n\n\nt2 = time.time()\n\n\nt2-t1\n\n5.440181732177734"
  },
  {
    "objectID": "posts/05wk-2.html#c.-cpu-vs-gpu-500-nodes",
    "href": "posts/05wk-2.html#c.-cpu-vs-gpu-500-nodes",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "C. CPU vs GPU (500 nodes)",
    "text": "C. CPU vs GPU (500 nodes)\n- CPU (500 nodes)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,500),\n    torch.nn.ReLU(),\n    torch.nn.Linear(500,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.36923766136169434\n\n\n- GPU (500 nodes)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,500),\n    torch.nn.ReLU(),\n    torch.nn.Linear(500,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.5803208351135254\n\n\n\nCPU가 더 빠르다??"
  },
  {
    "objectID": "posts/05wk-2.html#d.-cpu-vs-gpu-200000-nodes",
    "href": "posts/05wk-2.html#d.-cpu-vs-gpu-200000-nodes",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "D. CPU vs GPU (200,000 nodes)",
    "text": "D. CPU vs GPU (200,000 nodes)\n- CPU (200,000)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,200000),\n    torch.nn.ReLU(),\n    torch.nn.Linear(200000,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n84.05620455741882\n\n\n- GPU (204,800)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,200000),\n    torch.nn.ReLU(),\n    torch.nn.Linear(200000,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n1.373826026916504\n\n\n\n왜 이런 차이가 나는가?\n연산을 하는 주체는 코어인데 CPU는 수는 적지만 일을 잘하는 코어들을 가지고 있고 GPU는 일은 못하지만 다수의 코어를 가지고 있기 때문"
  },
  {
    "objectID": "posts/05wk-2.html#e.-주의점",
    "href": "posts/05wk-2.html#e.-주의점",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "E. 주의점",
    "text": "E. 주의점\n- tensor 일 경우\n\nx = torch.tensor([1,2,3])\nx.to(\"cuda:0\"), x\n\n(tensor([1, 2, 3], device='cuda:0'), tensor([1, 2, 3]))\n\n\n- net일 경우\n\nnet = torch.nn.Linear(1,1).to(\"cuda:0\")\nnet.weight, net.bias\n\n(Parameter containing:\n tensor([[-0.5348]], device='cuda:0', requires_grad=True),\n Parameter containing:\n tensor([-0.3825], device='cuda:0', requires_grad=True))"
  },
  {
    "objectID": "posts/05wk-2.html#a.-의문-좀-이상하지-않아요",
    "href": "posts/05wk-2.html#a.-의문-좀-이상하지-않아요",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "A. 의문: 좀 이상하지 않아요?",
    "text": "A. 의문: 좀 이상하지 않아요?\n- 국민상식: GPU 비싸요.. https://bbs.ruliweb.com/community/board/300143/read/61066881\n\nGPU 메모리 많아봐야 24GB, 그래도 비싸요.. http://shop.danawa.com/virtualestimate/?controller=estimateMain&methods=index&marketPlaceSeq=16\nGPU 메모리가 80GB일 경우 가격: https://prod.danawa.com/info/?pcode=21458333\n\n- 우리가 분석하는 데이터\n\nx = torch.linspace(-10,10,100000).reshape(-1,1)\neps = torch.randn(100000).reshape(-1,1)\ny = x*2 + eps \n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,2*x,'--')\n\n\n\n\n\n\n\n\n- 데이터의 크기가 커지는 순간 x.to(\"cuda:0\"), y.to(\"cuda:0\") 쓰면 난리나겠는걸? \\(\\to\\) 이런식이면 GPU를 이용하여 아무런 분석도 못할것 같은데?? 뭔가 좀 이상한데??\n- 아이디어: 데이터를 100개중에 1개 꼴로만 쓰면 어떨까?\n\nplt.plot(x[::100],y[::100],'o',alpha=0.05)\nplt.plot(x,2*x,'--')\n\n\n\n\n\n\n\n\n\n대충 이거만 가지고 적합해도 충분히 정확할것 같은데?"
  },
  {
    "objectID": "posts/05wk-2.html#b.-xy-데이터를-굳이-모두-gpu에-넘겨야-하는가",
    "href": "posts/05wk-2.html#b.-xy-데이터를-굳이-모두-gpu에-넘겨야-하는가",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "B. X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?",
    "text": "B. X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?\n- 데이터셋을 짝홀로 나누어서 번갈아가면서 GPU에 올렸다 내렸다하면 안되나?\n- 아래의 알고리즘을 생각해보자.\n\n데이터를 반으로 나눈다.\n짝수obs의 x,y 그리고 net의 모든 파라메터를 GPU에 올린다.\nyhat, loss, grad, update 수행\n짝수obs의 x,y를 GPU메모리에서 내린다. 그리고 홀수obs의 x,y를 GPU메모리에 올린다.\nyhat, loss, grad, update 수행\n홀수obs의 x,y를 GPU메모리에서 내린다. 그리고 짝수obs의 x,y를 GPU메모리에 올린다.\n반복\n\n\n이러면 되는거아니야???? —&gt; 맞아요"
  },
  {
    "objectID": "posts/05wk-2.html#c.-경사하강법-확률적경사하강법-미니배치-경사하강법",
    "href": "posts/05wk-2.html#c.-경사하강법-확률적경사하강법-미니배치-경사하강법",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "C. 경사하강법, 확률적경사하강법, 미니배치 경사하강법",
    "text": "C. 경사하강법, 확률적경사하강법, 미니배치 경사하강법\n10개의 샘플이 있다고 가정. \\(\\{(x_i,y_i)\\}_{i=1}^{10}\\)\n# ver1 – 모든 샘플을 이용하여 slope 계산\n(epoch 1) \\(loss=\\sum_{i=1}^{10}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2 \\to slope  \\to update\\)\n(epoch 2) \\(loss=\\sum_{i=1}^{10}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2 \\to slope  \\to update\\)\n…\n\n우리가 항상 이렇게 했죠!\n\n# ver2 – 하나의 샘플만을 이용하여 slope 계산\n(epoch 1)\n\n\\(loss=(y_1-\\hat{w}_0-\\hat{w}_1x_1)^2 \\to slope \\to update\\)\n\\(loss=(y_2-\\hat{w}_0-\\hat{w}_1x_2)^2 \\to slope \\to update\\)\n…\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n(epoch 2)\n\n\\(loss=(y_1-\\hat{w}_0-\\hat{w}_1x_1)^2  \\to slope  \\to  update\\)\n\\(loss=(y_2-\\hat{w}_0-\\hat{w}_1x_2)^2  \\to slope  \\to  update\\)\n…\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n…\n# ver3 – \\(m (\\leq n)\\) 개의 샘플을 이용하여 slope 계산\n\\(m=3\\)이라고 하자.\n(epoch 1)\n\n\\(loss=\\sum_{i=1}^{3}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=4}^{6}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=7}^{9}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n(epoch 2)\n\n\\(loss=\\sum_{i=1}^{3}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=4}^{6}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=\\sum_{i=7}^{9}(y_i-\\hat{w}_0-\\hat{w}_1x_i)^2  \\to  slope  \\to  update\\)\n\\(loss=(y_{10}-\\hat{w}_0-\\hat{w}_1x_{10})^2  \\to  slope  \\to  update\\)\n\n…"
  },
  {
    "objectID": "posts/05wk-2.html#d.-용어의-정리",
    "href": "posts/05wk-2.html#d.-용어의-정리",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "D. 용어의 정리",
    "text": "D. 용어의 정리\n옛날\n- ver1(모든): gradient descent, batch gradient descent\n- ver2(하나만): stochastic gradient descent\n- ver3(몇개만): mini-batch gradient descent, mini-batch stochastic gradient descent\n요즘\n- ver1(모든): gradient descent\n- ver2(하나만): stochastic gradient descent with batch size = 1\n- ver3(몇개만): stochastic gradient descent - https://www.deeplearningbook.org/contents/optimization.html, 알고리즘 8-1 참고."
  },
  {
    "objectID": "posts/05wk-2.html#e.-datasetds-dataloaderdl",
    "href": "posts/05wk-2.html#e.-datasetds-dataloaderdl",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "E. Dataset(ds), DataLoader(dl)",
    "text": "E. Dataset(ds), DataLoader(dl)\n\n취지는 알겠으나, C의 과정을 실제 구현하려면 진짜 어려움.. (입코딩과 손코딩의 차이) –&gt; 이걸 해결하기 위해서 파이토치에서는 DataLoader라는 오브젝트를 준비했음!\n\n- 데이터\n\nx=torch.tensor(range(10)).float().reshape(-1,1)\ny=torch.tensor([1.0]*5+[0.0]*5).reshape(-1,1)\ntorch.concat([x,y],axis=1)\n\ntensor([[0., 1.],\n        [1., 1.],\n        [2., 1.],\n        [3., 1.],\n        [4., 1.],\n        [5., 0.],\n        [6., 0.],\n        [7., 0.],\n        [8., 0.],\n        [9., 0.]])\n\n\n- ds오브젝트\n\nds = torch.utils.data.TensorDataset(x,y)\nds\n\n&lt;torch.utils.data.dataset.TensorDataset at 0x750d76514d30&gt;\n\n\n\nds.tensors \n# 생긴건 ds.tensors = (x,y) 임\n\n(tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]),\n tensor([[1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.]]))\n\n\n\nds[0],(x,y)[0] # (x,y) 튜플자체는 아님.. 인덱싱이 다르게 동작\n\n((tensor([0.]), tensor([1.])),\n tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]))\n\n\n- dl 오브젝트\n\ndl = torch.utils.data.DataLoader(ds, batch_size=3)\n\n\nfor x_mbatch,y_mbatch in dl:\n    print(f\"x_mini_batch:{x_mbatch.tolist()} \\t y_mini_batch:{y_mbatch.tolist()}\")\n\nx_mini_batch:[[0.0], [1.0], [2.0]]   y_mini_batch:[[1.0], [1.0], [1.0]]\nx_mini_batch:[[3.0], [4.0], [5.0]]   y_mini_batch:[[1.0], [1.0], [0.0]]\nx_mini_batch:[[6.0], [7.0], [8.0]]   y_mini_batch:[[0.0], [0.0], [0.0]]\nx_mini_batch:[[9.0]]     y_mini_batch:[[0.0]]\n\n\n- 마지막관측치는 뭔데 단독으로 업데이트하냐?? –&gt; shuffle True 같이 자잘한 옵션도 있음..\n\ndl = torch.utils.data.DataLoader(ds,batch_size=3,shuffle=True)\nfor x_mbatch,y_mbatch in dl:\n    print(f\"x_mini_batch:{x_mbatch.tolist()} \\t y_mini_batch:{y_mbatch.tolist()}\")\n\nx_mini_batch:[[5.0], [2.0], [9.0]]   y_mini_batch:[[0.0], [1.0], [0.0]]\nx_mini_batch:[[0.0], [7.0], [8.0]]   y_mini_batch:[[1.0], [0.0], [0.0]]\nx_mini_batch:[[1.0], [6.0], [4.0]]   y_mini_batch:[[1.0], [0.0], [1.0]]\nx_mini_batch:[[3.0]]     y_mini_batch:[[1.0]]"
  },
  {
    "objectID": "posts/05wk-2.html#f.-성능체크",
    "href": "posts/05wk-2.html#f.-성능체크",
    "title": "05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법",
    "section": "F. 성능체크",
    "text": "F. 성능체크\n- 목표: 확률적경사하강법과 그냥 경사하강법의 성능을 “동일 반복횟수”로 비교해보자.\n- MNIST자료를 그냥 경사하강법으로 적합해보자.\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX0 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\nX1 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\nX = torch.concat([X0,X1],axis=0).reshape(-1,784)\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n\nfor epoc in range(700):\n    # step1 \n    yhat = net(X)\n    # step2 \n    loss = loss_fn(yhat,y)\n    # step3     \n    loss.backward()\n    # step4 \n    optimizr.step()\n    optimizr.zero_grad()    \n\n\n((yhat &gt; 0.5) ==  y).float().mean()\n\ntensor(0.9953)\n\n\n- MNIST자료를 확률적 경사하강법으로 적합해보자. – 미니배치 쓰는 학습\n\n# train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n# to_tensor = torchvision.transforms.ToTensor()\n# X0 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\n# X1 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\n# X = torch.concat([X0,X1],axis=0).reshape(-1,784)\n# y = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=2048)\n\n\nlen(X)/2048\n\n6.18408203125\n\n\n\n따라서 (mini) batchsize 가 2048 이라면 한 epoch당 7회 update\n\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n\n\nfor epoc in range(100): \n    for xm,ym in dl:        \n        # step1 \n        ym_hat = net(xm)\n        # step2 \n        loss = loss_fn(ym_hat,ym)\n        # step3     \n        loss.backward()\n        # step4 \n        optimizr.step()\n        optimizr.zero_grad()\n\n\n((net(X) &gt; 0.5) ==  y).float().mean()\n\ntensor(0.9931)"
  },
  {
    "objectID": "posts/08wk-1.html#a.-직접설계",
    "href": "posts/08wk-1.html#a.-직접설계",
    "title": "08wk-1: (합성곱신경망) – MNIST, CIFAR10, XAI란?",
    "section": "A. 직접설계",
    "text": "A. 직접설계\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(3,32,kernel_size=5),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=2),\n    torch.nn.Conv2d(32,32,kernel_size=3),\n    torch.nn.ReLU(),\n    torch.nn.Flatten(),\n    #---#\n    torch.nn.Linear(4608,10)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nnet.to(\"cuda:0\")\nX = X.to(\"cuda:0\")\ny = y.to(\"cuda:0\")\nXX = XX.to(\"cuda:0\")\nyy = yy.to(\"cuda:0\")\n#---#\nfor epoc in range(500):\n    #1\n    netout = net(X)\n    #2\n    loss = loss_fn(netout,y)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\n(net(X).argmax(axis=1) == y).float().mean()\n\ntensor(0.7344, device='cuda:0')\n\n\n\n(net(XX).argmax(axis=1) == yy).float().mean()\n\ntensor(0.6080, device='cuda:0')\n\n\n\n표현력자체에 문제가 있어보임\n\n\ntorch.cuda.empty_cache()"
  },
  {
    "objectID": "posts/08wk-1.html#b.-알렉스넷",
    "href": "posts/08wk-1.html#b.-알렉스넷",
    "title": "08wk-1: (합성곱신경망) – MNIST, CIFAR10, XAI란?",
    "section": "B. 알렉스넷?",
    "text": "B. 알렉스넷?\n\n\nimg = torch.zeros(1,3*224*224).reshape(1,3,224,224)\nimg.shape\n\ntorch.Size([1, 3, 224, 224])\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(3,96,kernel_size=(11,11),stride=4),\n    torch.nn.ReLU(),    \n    torch.nn.MaxPool2d((3,3),stride=2), # default stride는 3\n    torch.nn.Conv2d(96,256,kernel_size=(5,5),padding=2),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((3,3),stride=2), # default stride는 3\n    torch.nn.Conv2d(256,384,kernel_size=(3,3),padding=1),\n    torch.nn.ReLU(),\n    torch.nn.Conv2d(384,384,kernel_size=(3,3),padding=1),\n    torch.nn.ReLU(),    \n    torch.nn.Conv2d(384,256,kernel_size=(3,3),padding=1),\n    torch.nn.ReLU(),    \n    torch.nn.MaxPool2d((3,3),stride=2),\n    torch.nn.Flatten(),\n    torch.nn.Linear(6400,4096),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.5),\n    torch.nn.Linear(4096,4096),        \n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.5),    \n    torch.nn.Linear(4096,1000),\n)"
  },
  {
    "objectID": "posts/08wk-1.html#c.-알렉스넷으로-imagenet-적합",
    "href": "posts/08wk-1.html#c.-알렉스넷으로-imagenet-적합",
    "title": "08wk-1: (합성곱신경망) – MNIST, CIFAR10, XAI란?",
    "section": "C. 알렉스넷으로 ImageNet 적합",
    "text": "C. 알렉스넷으로 ImageNet 적합\n\nnet[-1] = torch.nn.Linear(4096,10)\n\n\nimg = torch.randn(1,3,32,32)\n\n\nnet(img)\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[18], line 1\n----&gt; 1 net(img)\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/module.py:1739, in Module._wrapped_call_impl(self, *args, **kwargs)\n   1737     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n   1738 else:\n-&gt; 1739     return self._call_impl(*args, **kwargs)\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/module.py:1750, in Module._call_impl(self, *args, **kwargs)\n   1745 # If we don't have any hooks, we want to skip the rest of the logic in\n   1746 # this function, and just call forward.\n   1747 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1748         or _global_backward_pre_hooks or _global_backward_hooks\n   1749         or _global_forward_hooks or _global_forward_pre_hooks):\n-&gt; 1750     return forward_call(*args, **kwargs)\n   1752 result = None\n   1753 called_always_called_hooks = set()\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/container.py:250, in Sequential.forward(self, input)\n    248 def forward(self, input):\n    249     for module in self:\n--&gt; 250         input = module(input)\n    251     return input\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/module.py:1739, in Module._wrapped_call_impl(self, *args, **kwargs)\n   1737     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n   1738 else:\n-&gt; 1739     return self._call_impl(*args, **kwargs)\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/module.py:1750, in Module._call_impl(self, *args, **kwargs)\n   1745 # If we don't have any hooks, we want to skip the rest of the logic in\n   1746 # this function, and just call forward.\n   1747 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1748         or _global_backward_pre_hooks or _global_backward_hooks\n   1749         or _global_forward_hooks or _global_forward_pre_hooks):\n-&gt; 1750     return forward_call(*args, **kwargs)\n   1752 result = None\n   1753 called_always_called_hooks = set()\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/modules/pooling.py:213, in MaxPool2d.forward(self, input)\n    212 def forward(self, input: Tensor):\n--&gt; 213     return F.max_pool2d(\n    214         input,\n    215         self.kernel_size,\n    216         self.stride,\n    217         self.padding,\n    218         self.dilation,\n    219         ceil_mode=self.ceil_mode,\n    220         return_indices=self.return_indices,\n    221     )\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/_jit_internal.py:624, in boolean_dispatch.&lt;locals&gt;.fn(*args, **kwargs)\n    622     return if_true(*args, **kwargs)\n    623 else:\n--&gt; 624     return if_false(*args, **kwargs)\n\nFile ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/torch/nn/functional.py:830, in _max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\n    828 if stride is None:\n    829     stride = torch.jit.annotate(List[int], [])\n--&gt; 830 return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n\nRuntimeError: Given input size: (256x2x2). Calculated output size: (256x0x0). Output size is too small\n\n\n\n\nnet[:5](img).shape\n\ntorch.Size([1, 256, 2, 2])\n\n\n\nnet[5]\n\nMaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n\n\n실패 ㅠㅠ"
  },
  {
    "objectID": "posts/08wk-1.html#d.-renset18",
    "href": "posts/08wk-1.html#d.-renset18",
    "title": "08wk-1: (합성곱신경망) – MNIST, CIFAR10, XAI란?",
    "section": "D. renset18",
    "text": "D. renset18\n- res: https://arxiv.org/pdf/1512.03385\n\nnet = torchvision.models.resnet18()\n# net \n\n\nnet.fc = torch.nn.Linear(512,10)\n\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nnet.to(\"cuda:0\")\nX = X.to(\"cuda:0\")\ny = y.to(\"cuda:0\")\nXX = XX.to(\"cuda:0\")\nyy = yy.to(\"cuda:0\")\n#---#\nfor epoc in range(500):\n    #1\n    netout = net(X)\n    #2\n    loss = loss_fn(netout,y)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nnet.eval()\nprint((net(X).argmax(axis=1) == y).float().mean())\nprint((net(XX).argmax(axis=1) == yy).float().mean())\n\ntensor(1., device='cuda:0')\ntensor(0.5930, device='cuda:0')\n\n\n\n오버피팅이 있어보긴하지만 표현력자체는 올라감\n\n\ntorch.cuda.empty_cache()"
  },
  {
    "objectID": "posts/08wk-1.html#e.-resnet18-pretrainedtrue",
    "href": "posts/08wk-1.html#e.-resnet18-pretrainedtrue",
    "title": "08wk-1: (합성곱신경망) – MNIST, CIFAR10, XAI란?",
    "section": "E. resnet18, pretrained=True",
    "text": "E. resnet18, pretrained=True\n- 아이디어: 하나를 잘하는 모델은 다른것도 잘하지 않을까? &lt;– transfer learning\n\nnet = torchvision.models.resnet18(pretrained=True) # 아키텍처 + 학습된 가중치까지 \nnet.fc = torch.nn.Linear(512,10)\n\n/home/cgb3/anaconda3/envs/dl2025/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/home/cgb3/anaconda3/envs/dl2025/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nnet.to(\"cuda:0\")\nX = X.to(\"cuda:0\")\ny = y.to(\"cuda:0\")\nXX = XX.to(\"cuda:0\")\nyy = yy.to(\"cuda:0\")\n#---#\nfor epoc in range(500):\n    #1\n    netout = net(X)\n    #2\n    loss = loss_fn(netout,y)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nnet.eval()\nprint((net(X).argmax(axis=1) == y).float().mean())\nprint((net(XX).argmax(axis=1) == yy).float().mean())\n\ntensor(1., device='cuda:0')\ntensor(0.8050, device='cuda:0')\n\n\n\n잘함 (오버피팅은 여전히 있음)\n\n\ntorch.cuda.empty_cache()"
  },
  {
    "objectID": "posts/13wk-2.html#a.-대충-개념만-실습",
    "href": "posts/13wk-2.html#a.-대충-개념만-실습",
    "title": "13wk-2: (강화학습) – Bandit 환경 설계 및 풀이, 4x4 Grid World 게임설명, 환경구현, 에이전트(랜덤)구현",
    "section": "A. 대충 개념만 실습",
    "text": "A. 대충 개념만 실습\n\naction_space = [0,1] \nactions_deque = collections.deque(maxlen=500)\nrewards_deque =  collections.deque(maxlen=500)\n#---#\n\n\nfor _ in range(10):\n    action = np.random.choice(action_space)\n    if action == 1:\n        reward = 10 \n    else:\n        reward = 1\n    actions_deque.append(action)\n    rewards_deque.append(reward)\n\n\nactions_deque\n\ndeque([0, 1, 0, 1, 1, 1, 0, 1, 0, 1], maxlen=500)\n\n\n\nrewards_deque\n\ndeque([1, 10, 1, 10, 10, 10, 1, 10, 1, 10], maxlen=500)\n\n\n\nactions_numpy = np.array(actions_deque)\nrewards_numpy = np.array(rewards_deque)\n\n\nq0 = rewards_numpy[actions_numpy == 0].mean()\nq1 = rewards_numpy[actions_numpy == 1].mean()\nq_table = np.array([q0,q1])\nq_table\n\narray([ 1., 10.])\n\n\n\naction = q_table.argmax()\n\n\nfor _ in range(5):\n    action = q_table.argmax()\n    if action == 1:\n        reward = 10 \n    else:\n        reward = 1\n    actions_deque.append(action)\n    rewards_deque.append(reward)\n    actions_numpy = np.array(actions_deque)\n    rewards_numpy = np.array(rewards_deque)    \n    q0 = rewards_numpy[actions_numpy == 0].mean()\n    q1 = rewards_numpy[actions_numpy == 1].mean()\n    q_table = np.array([q0,q1])\n\n\nactions_numpy\n\narray([0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1])\n\n\n\nrewards_numpy\n\narray([ 1, 10,  1, 10, 10, 10,  1, 10,  1, 10, 10, 10, 10, 10, 10])"
  },
  {
    "objectID": "posts/13wk-2.html#b.-클래스를-이용한-구현",
    "href": "posts/13wk-2.html#b.-클래스를-이용한-구현",
    "title": "13wk-2: (강화학습) – Bandit 환경 설계 및 풀이, 4x4 Grid World 게임설명, 환경구현, 에이전트(랜덤)구현",
    "section": "B. 클래스를 이용한 구현",
    "text": "B. 클래스를 이용한 구현\n\nclass Bandit:\n    def __init__(self):\n        self.reward = None \n    def step(self,action):\n        if action == 0:\n            self.reward = 1\n        else: \n            self.reward = 10 \n        return self.reward \n\n\nclass Agent:\n    def __init__(self):\n        pass \n    def act(self):\n        # 만약에 경험이 20보다 작음 --&gt; 랜덤액션 \n        # 경험이 20보다 크면 --&gt; action = q_tabel.argmax()\n        pass \n    def save_experience(self):\n        # 데이터 저장 \n        pass \n    def learn(self):\n        # q_table 을 업데이트하는 과정 \n        pass\n\n\n\nclass Agent:\n    def __init__(self):\n        self.action = None \n        self.reward = None \n        self.actions = collections.deque(maxlen=500)\n        self.rewards = collections.deque(maxlen=500)\n        self.action_space = [0,1] \n        self.q_table = None \n        self.n_experience = 0\n    def act(self):\n        if self.n_experience &lt; 20:\n            self.action = np.random.choice(self.action_space)\n        else: \n            self.action = self.q_table.argmax()\n        print(f\"버튼{self.action}누름!\")\n    def save_experience(self):\n        self.actions.append(self.action)\n        self.rewards.append(self.reward)\n        self.n_experience = self.n_experience + 1\n    def learn(self):\n        if self.n_experience &lt; 20:\n            pass\n        else:\n            # q_table 을 업데이트하는 과정 \n            actions = np.array(self.actions)\n            rewards = np.array(self.rewards)\n            q0 = rewards[actions == 0].mean() # 행동0을했을때 얻는 보상의 평균값\n            q1 = rewards[actions == 1].mean()# 행동1을했을때 얻는 보상의 평균값\n            self.q_table = np.array([q0,q1])\n\n\nenv = Bandit()\nplayer = Agent()\nfor _ in range(100):\n    # step1: agent action \n    player.act()\n    # step2: action --&gt; state, reward\n    player.reward = env.step(player.action)\n    # step3: agent가 데이터를 축적하고 학습\n    player.save_experience() # 데이터를 저장\n    player.learn() #저장된 데이터를 학습 \n    #---강화학습의 종료를 결정--#\n    if player.n_experience &lt; 20:\n        pass \n    else: \n        if np.array(player.rewards)[-20:].mean() &gt; 9.5:\n            print(\"---게임클리어---\")\n            break\n\n버튼1누름!\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼0누름!\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼1누름!\n버튼0누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼0누름!\n버튼0누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n버튼1누름!\n---게임클리어---"
  },
  {
    "objectID": "posts/13wk-2.html#a.-게임설명",
    "href": "posts/13wk-2.html#a.-게임설명",
    "title": "13wk-2: (강화학습) – Bandit 환경 설계 및 풀이, 4x4 Grid World 게임설명, 환경구현, 에이전트(랜덤)구현",
    "section": "A. 게임설명",
    "text": "A. 게임설명\n- 문제설명: 4x4 그리드월드에서 상하좌우로 움직이는 에이전트가 목표점에 도달하도록 하는 게임\n\n백문이 불여일견: https://claude.ai/public/artifacts/76e13820-2b51-4e7e-a514-00190de17c45 (출처: 클로드)\n\n- GridWorld에서 사용되는 주요변수\n\nState: 각 격자 셀이 하나의 상태이며, 에이전트는 이러한 상태 중 하나에 있을 수 있음.\nAction: 에이전트는 현재상태에서 다음상태로 이동하기 위해 상,하,좌,우 중 하나의 행동을 취할 수 있음.\nReward: 에이전트가 현재상태에서 특정 action을 하면 얻어지는 보상.\nTerminated: 하나의 에피소드가 종료되었음을 나타내는 상태."
  },
  {
    "objectID": "posts/13wk-2.html#b.-시각화",
    "href": "posts/13wk-2.html#b.-시각화",
    "title": "13wk-2: (강화학습) – Bandit 환경 설계 및 풀이, 4x4 Grid World 게임설명, 환경구현, 에이전트(랜덤)구현",
    "section": "B. 시각화",
    "text": "B. 시각화\n\ndef show(states):\n    fig = plt.Figure()\n    ax = fig.subplots()\n    ax.matshow(np.zeros([4,4]), cmap='bwr',alpha=0.0)\n    sc = ax.scatter(0, 0, color='red', s=500)  \n    ax.text(0, 0, 'start', ha='center', va='center')\n    ax.text(3, 3, 'end', ha='center', va='center')\n    # Adding grid lines to the plot\n    ax.set_xticks(np.arange(-.5, 4, 1), minor=True)\n    ax.set_yticks(np.arange(-.5, 4, 1), minor=True)\n    ax.grid(which='minor', color='black', linestyle='-', linewidth=2)\n    state_space = gym.spaces.MultiDiscrete([4,4])\n    def update(t):\n        if states[t] in state_space:\n            s1,s2 = states[t]\n            states[t] = [s2,s1]\n            sc.set_offsets(states[t])\n        else:\n            s1,s2 = states[t]\n            s1 = s1 + 0.5 if s1 &lt; 0 else (s1 - 0.5 if s1 &gt; 3 else s1)\n            s2 = s2 + 0.5 if s2 &lt; 0 else (s2 - 0.5 if s2 &gt; 3 else s2)\n            states[t] = [s2,s1]       \n            sc.set_offsets(states[t])\n    ani = FuncAnimation(fig,update,frames=len(states))\n    display(IPython.display.HTML(ani.to_jshtml()))\n\n\nshow([[0,0],[1,0],[2,0],[3,0],[4,0]]) # show 사용방법\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/08wk-2.html#a.-transpose",
    "href": "posts/08wk-2.html#a.-transpose",
    "title": "08wk-2, 09wk-1: (XAI, 설명가능한 인공지능) – Class Activation Map",
    "section": "A. transpose",
    "text": "A. transpose\n- test tensor\n\ntsr = torch.arange(12).reshape(4,3)\ntsr\n\ntensor([[ 0,  1,  2],\n        [ 3,  4,  5],\n        [ 6,  7,  8],\n        [ 9, 10, 11]])\n\n\n- 행렬을 transpose하는 방법1\n\ntsr.t()\n\ntensor([[ 0,  3,  6,  9],\n        [ 1,  4,  7, 10],\n        [ 2,  5,  8, 11]])\n\n\n- 행렬을 transpose하는 방법2\n\ntorch.einsum('ij -&gt; ji', tsr)\n\ntensor([[ 0,  3,  6,  9],\n        [ 1,  4,  7, 10],\n        [ 2,  5,  8, 11]])"
  },
  {
    "objectID": "posts/08wk-2.html#b.-행렬곱",
    "href": "posts/08wk-2.html#b.-행렬곱",
    "title": "08wk-2, 09wk-1: (XAI, 설명가능한 인공지능) – Class Activation Map",
    "section": "B. 행렬곱",
    "text": "B. 행렬곱\n- test tensors\n\ntsr1 = torch.arange(12).reshape(4,3).float()\ntsr2 = torch.arange(15).reshape(3,5).float()\ntsr1,tsr2\n\n(tensor([[ 0.,  1.,  2.],\n         [ 3.,  4.,  5.],\n         [ 6.,  7.,  8.],\n         [ 9., 10., 11.]]),\n tensor([[ 0.,  1.,  2.,  3.,  4.],\n         [ 5.,  6.,  7.,  8.,  9.],\n         [10., 11., 12., 13., 14.]]))\n\n\n- 행렬곱을 수행하는 방법1\n\ntsr1 @ tsr2\n\ntensor([[ 25.,  28.,  31.,  34.,  37.],\n        [ 70.,  82.,  94., 106., 118.],\n        [115., 136., 157., 178., 199.],\n        [160., 190., 220., 250., 280.]])\n\n\n- 행렬곱을 수행하는 방법2\n\ntorch.einsum('ij, jk -&gt; ik', tsr1,tsr2)\n\ntensor([[ 25.,  28.,  31.,  34.,  37.],\n        [ 70.,  82.,  94., 106., 118.],\n        [115., 136., 157., 178., 199.],\n        [160., 190., 220., 250., 280.]])"
  },
  {
    "objectID": "posts/08wk-2.html#c.-img_plt-vs-img_pytorch",
    "href": "posts/08wk-2.html#c.-img_plt-vs-img_pytorch",
    "title": "08wk-2, 09wk-1: (XAI, 설명가능한 인공지능) – Class Activation Map",
    "section": "C. img_plt vs img_pytorch",
    "text": "C. img_plt vs img_pytorch\n- r,g,b 를 의미하는 tensor\n\nr = torch.zeros(16).reshape(4,4) + 1.0\ng = torch.zeros(16).reshape(4,4)\nb = torch.zeros(16).reshape(4,4)\n\n- torch를 쓰기 위해서는 이미지가 이렇게 저장되어 있어야함\n\nimg_pytorch = torch.stack([r,g,b],axis=0).reshape(1,3,4,4)\nprint(img_pytorch)\nprint(img_pytorch.shape)\n\ntensor([[[[1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.],\n          [1., 1., 1., 1.]],\n\n         [[0., 0., 0., 0.],\n          [0., 0., 0., 0.],\n          [0., 0., 0., 0.],\n          [0., 0., 0., 0.]],\n\n         [[0., 0., 0., 0.],\n          [0., 0., 0., 0.],\n          [0., 0., 0., 0.],\n          [0., 0., 0., 0.]]]])\ntorch.Size([1, 3, 4, 4])\n\n\n- matplotlib로 시각화를 하기 위해서는 이미지가 이렇게 저장되어 있어야함\n\nimg_matplotlib = torch.stack([r,g,b],axis=-1)\nprint(img_matplotlib)\nprint(img_matplotlib.shape)\nplt.imshow(img_matplotlib)\n\ntensor([[[1., 0., 0.],\n         [1., 0., 0.],\n         [1., 0., 0.],\n         [1., 0., 0.]],\n\n        [[1., 0., 0.],\n         [1., 0., 0.],\n         [1., 0., 0.],\n         [1., 0., 0.]],\n\n        [[1., 0., 0.],\n         [1., 0., 0.],\n         [1., 0., 0.],\n         [1., 0., 0.]],\n\n        [[1., 0., 0.],\n         [1., 0., 0.],\n         [1., 0., 0.],\n         [1., 0., 0.]]])\ntorch.Size([4, 4, 3])\n\n\n\n\n\n\n\n\n\n- img_pytorch 를 plt.imshow로 시각화\n\n# 잘못된코드\nplt.imshow(img_pytorch.squeeze().reshape(4,4,3))\n\n\n\n\n\n\n\n\n\n# 올바른코드1\nplt.imshow(torch.einsum('cij -&gt; ijc', img_pytorch.squeeze()))\n\n\n\n\n\n\n\n\n\n# 올바른코드2\nplt.imshow(img_pytorch.squeeze().permute(1,2,0))"
  },
  {
    "objectID": "posts/08wk-2.html#a.-데이터",
    "href": "posts/08wk-2.html#a.-데이터",
    "title": "08wk-2, 09wk-1: (XAI, 설명가능한 인공지능) – Class Activation Map",
    "section": "A. 데이터",
    "text": "A. 데이터\n- 데이터 다운로드\n\ntrain_dataset = torchvision.datasets.OxfordIIITPet(\n    root='./data', \n    split='trainval',\n    download=True,\n    target_types='binary-category'\n)\ntest_dataset = torchvision.datasets.OxfordIIITPet(\n    root='./data', \n    split='test',\n    download=True,\n    target_types='binary-category'\n)\n\n\ntrain_dataset[0][0]\n\n\n\n\n\n\n\n\n\ntrain_dataset[0][1]\n\n0"
  },
  {
    "objectID": "posts/08wk-2.html#b.-이미지-변환",
    "href": "posts/08wk-2.html#b.-이미지-변환",
    "title": "08wk-2, 09wk-1: (XAI, 설명가능한 인공지능) – Class Activation Map",
    "section": "B. 이미지 변환",
    "text": "B. 이미지 변환\n- x_pil 을 tensor로 바꾸어 보자.\n\nx_pil = train_dataset[0][0]\nx_pil\n\n\n\n\n\n\n\n\n\nto_tensor = torchvision.transforms.ToTensor() # PIL를 텐서로 만드는 함수를 리턴\nto_tensor(x_pil) \n\ntensor([[[0.1451, 0.1373, 0.1412,  ..., 0.9686, 0.9765, 0.9765],\n         [0.1373, 0.1373, 0.1451,  ..., 0.9647, 0.9725, 0.9765],\n         [0.1373, 0.1412, 0.1529,  ..., 0.9686, 0.9804, 0.9804],\n         ...,\n         [0.0196, 0.0157, 0.0157,  ..., 0.2863, 0.2471, 0.2706],\n         [0.0157, 0.0118, 0.0118,  ..., 0.2392, 0.2157, 0.2510],\n         [0.1098, 0.1098, 0.1059,  ..., 0.2314, 0.2549, 0.2980]],\n\n        [[0.0784, 0.0706, 0.0745,  ..., 0.9725, 0.9725, 0.9725],\n         [0.0706, 0.0706, 0.0784,  ..., 0.9686, 0.9686, 0.9725],\n         [0.0706, 0.0745, 0.0863,  ..., 0.9647, 0.9765, 0.9765],\n         ...,\n         [0.0235, 0.0196, 0.0196,  ..., 0.4627, 0.4039, 0.4314],\n         [0.0118, 0.0078, 0.0078,  ..., 0.3882, 0.3843, 0.4235],\n         [0.1059, 0.1059, 0.1059,  ..., 0.3686, 0.4157, 0.4588]],\n\n        [[0.0471, 0.0392, 0.0431,  ..., 0.9922, 0.9922, 0.9922],\n         [0.0392, 0.0392, 0.0471,  ..., 0.9843, 0.9882, 0.9922],\n         [0.0392, 0.0431, 0.0549,  ..., 0.9843, 0.9961, 0.9961],\n         ...,\n         [0.0941, 0.0902, 0.0902,  ..., 0.9608, 0.9216, 0.8784],\n         [0.0745, 0.0706, 0.0706,  ..., 0.9255, 0.9373, 0.8980],\n         [0.1373, 0.1373, 0.1373,  ..., 0.8392, 0.9098, 0.8745]]])\n\n\n\nplt.imshow(to_tensor(x_pil) .permute(1,2,0))\n\n\n\n\n\n\n\n\n- 궁극적으로는 train_dataset의 모든 이미지를 (3680,3,???,???)로 정리하여 X라고 하고 싶음. \\(\\to\\) 이걸 하기 위해서는 이미지 크기를 통일시켜야함. \\(\\to\\) 이미지크기를 통일시키는 방법을 알아보자.\n\nresize = torchvision.transforms.Resize((512,512)) # 512,512로 이미지를 조정해주는 함수가 리턴\n\n\nto_tensor(resize(train_dataset[0][0])).shape\n\ntorch.Size([3, 512, 512])\n\n\n- 크기가 8인 이미지들의 배치를 만들기\n\nXm = torch.stack([to_tensor(resize(train_dataset[n][0])) for n in range(8)],axis=0)\nXm.shape\n\ntorch.Size([8, 3, 512, 512])"
  },
  {
    "objectID": "posts/08wk-2.html#a.-ap-layer",
    "href": "posts/08wk-2.html#a.-ap-layer",
    "title": "08wk-2, 09wk-1: (XAI, 설명가능한 인공지능) – Class Activation Map",
    "section": "A. AP layer",
    "text": "A. AP layer\n\nap = torch.nn.AdaptiveAvgPool2d(output_size=1)\n\n\nX = torch.arange(1*3*4*4).reshape(1,3,4,4).float()\nX\n\ntensor([[[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]],\n\n         [[16., 17., 18., 19.],\n          [20., 21., 22., 23.],\n          [24., 25., 26., 27.],\n          [28., 29., 30., 31.]],\n\n         [[32., 33., 34., 35.],\n          [36., 37., 38., 39.],\n          [40., 41., 42., 43.],\n          [44., 45., 46., 47.]]]])\n\n\n\nap(X) # 채널별평균\n\ntensor([[[[ 7.5000]],\n\n         [[23.5000]],\n\n         [[39.5000]]]])"
  },
  {
    "objectID": "posts/08wk-2.html#b.-ap-linear의-교환",
    "href": "posts/08wk-2.html#b.-ap-linear의-교환",
    "title": "08wk-2, 09wk-1: (XAI, 설명가능한 인공지능) – Class Activation Map",
    "section": "B. AP, Linear의 교환",
    "text": "B. AP, Linear의 교환\n- 신기한것 보여줄게요..\n\nr = X[:,0,:,:]\ng = X[:,1,:,:]\nb = X[:,2,:,:]\n\n\nap(r)*0.1 + ap(g)*0.2 + ap(b)*0.3\n\ntensor([[[17.3000]]])\n\n\n\nap(r*0.1 + g*0.2 + b*0.3)\n\ntensor([[[17.3000]]])\n\n\n\n신기한게 아니고 당연하죠..\n\n- 위의 두 계산결과를 torch.nn.AdaptiveAvgPool2d, torch.nn.Linear, 그리고 torch.nn.Flatten()을 조합하여 구현해보자.\n\nresnet18\n\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1, bias=True)\n)\n\n\n\n# ap(r)*0.1 + ap(g)*0.2 + ap(b)*0.3\nap = torch.nn.AdaptiveAvgPool2d(output_size=1)\nflattn = torch.nn.Flatten()\nlinr = torch.nn.Linear(3,1,bias=False)\nlinr.weight.data = torch.tensor([[ 0.1,  0.2, 0.3]])\n#---#\nprint(X.shape)\nprint(ap(X).shape) # ap(r), ap(g), ap(b) 의 값이 들어있음.\nprint(flattn(ap(X)).shape) # [ap(r), ap(g), ap(b)] 형태로\nprint(linr(flattn(ap(X))).shape) # ap(r)*0.1 + ap(g)*0.2 + ap(b)*0.3\n\ntorch.Size([1, 3, 4, 4])\ntorch.Size([1, 3, 1, 1])\ntorch.Size([1, 3])\ntorch.Size([1, 1])\n\n\n\n#ap(r*0.1 + g*0.2 + b*0.3)\nap = torch.nn.AdaptiveAvgPool2d(output_size=1)\nflattn = torch.nn.Flatten()\nlinr = torch.nn.Linear(3,1,bias=False)\nlinr.weight.data = torch.tensor([[ 0.1,  0.2, 0.3]])\n#---#\ndef _linr(X):\n    return torch.einsum('ocij, kc -&gt; okij', X, linr.weight.data)\n#---#\nprint(X.shape) # \nprint(_linr(X).shape) # r*0.1 + g*0.2 + b*0.3 \nprint(ap(_linr(X)).shape) # ap(r*0.1 + g*0.2 + b*0.3 )\nprint(flattn(ap(_linr(X))).shape)\n\ntorch.Size([1, 3, 4, 4])\ntorch.Size([1, 1, 4, 4])\ntorch.Size([1, 1, 1, 1])\ntorch.Size([1, 1])"
  },
  {
    "objectID": "posts/08wk-2.html#a.-0단계-xy-xxyy",
    "href": "posts/08wk-2.html#a.-0단계-xy-xxyy",
    "title": "08wk-2, 09wk-1: (XAI, 설명가능한 인공지능) – Class Activation Map",
    "section": "A. 0단계 – (X,y), (XX,yy)",
    "text": "A. 0단계 – (X,y), (XX,yy)\n\ntrain_dataset = torchvision.datasets.OxfordIIITPet(\n    root='./data', \n    split='trainval',\n    download=True,\n    target_types='binary-category',\n)\ntest_dataset = torchvision.datasets.OxfordIIITPet(\n    root='./data', \n    split='test',\n    download=True,\n    target_types='binary-category',\n)\n\n\ncompose = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((512,512)),\n    torchvision.transforms.ToTensor()\n])\n\n\nX = torch.stack([compose(train_dataset[i][0]) for i in range(3680)],axis=0)\nXX = torch.stack([compose(test_dataset[i][0]) for i in range(3669)],axis=0)\ny = torch.tensor([train_dataset[i][1] for i in range(3680)]).reshape(-1,1).float()\nyy = torch.tensor([test_dataset[i][1] for i in range(3669)]).reshape(-1,1).float()"
  },
  {
    "objectID": "posts/08wk-2.html#b.-1단계-이미지분류-잘하는-네트워크-선택-후-학습",
    "href": "posts/08wk-2.html#b.-1단계-이미지분류-잘하는-네트워크-선택-후-학습",
    "title": "08wk-2, 09wk-1: (XAI, 설명가능한 인공지능) – Class Activation Map",
    "section": "B. 1단계 – 이미지분류 잘하는 네트워크 선택 후 학습",
    "text": "B. 1단계 – 이미지분류 잘하는 네트워크 선택 후 학습\n\ntorch.manual_seed(43052)\n#--Step1\nds_train = torch.utils.data.TensorDataset(X,y)\ndl_train = torch.utils.data.DataLoader(ds_train, batch_size=32, shuffle=True)\nds_test = torch.utils.data.TensorDataset(XX,yy)\ndl_test = torch.utils.data.DataLoader(ds_test, batch_size=32)\n#--Step2\nresnet18 = torchvision.models.resnet18(pretrained=True)\nresnet18.fc = torch.nn.Linear(512,1)\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(resnet18.parameters(), lr=1e-5)\n#--Step3 \nresnet18.to(\"cuda:0\")\nfor epoc in range(3):\n    resnet18.train()\n    for Xm,ym in dl_train:\n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        #1\n        netout = resnet18(Xm)\n        #2\n        loss = loss_fn(netout,ym)\n        #3\n        loss.backward()\n        #4\n        optimizr.step()\n        optimizr.zero_grad()\n    #---# \n    resnet18.eval()\n    s = 0 \n    for Xm,ym in dl_train:\n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        s = s + ((resnet18(Xm).data &gt; 0) == ym).sum().item()\n    acc = s/3680\n    print(f\"train_acc = {acc:.4f}\")\n#--Step4 \nresnet18.eval()\ns = 0 \nfor Xm,ym in dl_test:\n    Xm = Xm.to(\"cuda:0\")\n    ym = ym.to(\"cuda:0\")\n    s = s + ((resnet18(Xm).data &gt; 0) == ym).sum().item()\nacc = s/3669\nprint(f\"test_acc = {acc:.4f}\")\n\n/home/cgb3/anaconda3/envs/dl2025/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/home/cgb3/anaconda3/envs/dl2025/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\ntrain_acc = 0.9815\ntrain_acc = 0.9973\ntrain_acc = 0.9995\ntest_acc = 0.9951"
  },
  {
    "objectID": "posts/08wk-2.html#c.-2단계-linear와-ap의-순서를-바꿈",
    "href": "posts/08wk-2.html#c.-2단계-linear와-ap의-순서를-바꿈",
    "title": "08wk-2, 09wk-1: (XAI, 설명가능한 인공지능) – Class Activation Map",
    "section": "C. 2단계– Linear와 AP의 순서를 바꿈",
    "text": "C. 2단계– Linear와 AP의 순서를 바꿈\n- resnet18 을 재구성하여 net 를 만들자.\n\nstem = torch.nn.Sequential(\n    torch.nn.Sequential(\n        resnet18.conv1,\n        resnet18.bn1,\n        resnet18.relu,\n        resnet18.maxpool\n    ),\n    resnet18.layer1,\n    resnet18.layer2,\n    resnet18.layer3,\n    resnet18.layer4\n)\nhead = torch.nn.Sequential(\n    resnet18.avgpool,\n    torch.nn.Flatten(),\n    resnet18.fc\n)\nnet = torch.nn.Sequential(\n    stem,\n    head\n)\n\n- 1개의 observation을 고정\n\nx = X[[0]].to(\"cuda:0\")\n\n\nnet(x), resnet18(x)\n\n(tensor([[-5.5613]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-5.5613]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;))\n\n\n- 위와 같은 값 -5.5636이 나오는 과정을 추적하여 보자.\n\n# 계산방식1: 원래계산방식\nap = head[0]\nflattn = head[1]\nlinr = head[2]\n#---#\nprint(f\"{x.shape} -- x\")\nprint(f\"{stem(x).shape} -- stem(x)\")\nprint(f\"{ap(stem(x)).shape} -- ap(stem(x))\")\nprint(f\"{flattn(ap(stem(x))).shape} -- flattn(ap(stem(x)))\")\nprint(f\"{linr(flattn(ap(stem(x)))).shape} -- linr(flattn(ap(stem(x))))\")\n\ntorch.Size([1, 3, 512, 512]) -- x\ntorch.Size([1, 512, 16, 16]) -- stem(x)\ntorch.Size([1, 512, 1, 1]) -- ap(stem(x))\ntorch.Size([1, 512]) -- flattn(ap(stem(x)))\ntorch.Size([1, 1]) -- linr(flattn(ap(stem(x))))\n\n\n현재 네트워크 \\[\\underset{(1,3,512,512)}{\\boldsymbol x} \\overset{stem}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{ap}{\\to} \\underset{(1,512,1,1)}{{\\boldsymbol \\sharp}}\\overset{flattn}{\\to} \\underset{(1,512)}{{\\boldsymbol \\sharp}}\\overset{linr}{\\to} \\underset{(1,1)}{logit}\\right) = [[-5.5613]]\\]\n바꾸고 싶은 네트워크 \\[\\underset{(1,3,224,224)}{\\boldsymbol x} \\overset{stem}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{\\_linr}{\\to} \\underset{(1,1,16,16)}{{\\boldsymbol \\sharp}}\\overset{ap}{\\to} \\underset{(1,1,1,1)}{{\\boldsymbol \\sharp}}\\overset{flattn}{\\to} \\underset{(1,1)}{logit}\\right) = [[-5.5613]]\\]\n\n# 계산방식2\nap = head[0]\nflattn = head[1]\nlinr = head[2]\ndef _linr(xtilde):\n    return torch.einsum('ocij, kc -&gt; okij', xtilde, linr.weight.data) + linr.bias.data\n#---#\nprint(f\"{x.shape} -- x\")\nprint(f\"{stem(x).shape} -- stem(x)\")\nprint(f\"{_linr(stem(x)).shape} -- _linr(stem(x))\")\nprint(f\"{ap(_linr(stem(x))).shape} -- ap(_linr(stem(x)))\")\nprint(f\"{flattn(ap(_linr(stem(x)))).shape} -- flattn(ap(_linr(stem(x))))\")\n\ntorch.Size([1, 3, 512, 512]) -- x\ntorch.Size([1, 512, 16, 16]) -- stem(x)\ntorch.Size([1, 1, 16, 16]) -- _linr(stem(x))\ntorch.Size([1, 1, 1, 1]) -- ap(_linr(stem(x)))\ntorch.Size([1, 1]) -- flattn(ap(_linr(stem(x))))\n\n\n\nlinr(flattn(ap(stem(x)))), flattn(ap(_linr(stem(x))))\n\n(tensor([[-5.5613]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-5.5613]], device='cuda:0', grad_fn=&lt;ViewBackward0&gt;))\n\n\n\n\\(\\star\\) 잠깐 멈추고 생각 좀 해보자..\n- 원래 계산방식을 적용\n\nlinr(flattn(ap(stem(x))))\n\ntensor([[-5.5613]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;)\n\n\n- 바뀐 계산방식을 적용\n\nflattn(ap(_linr(stem(x))))\n\ntensor([[-5.5613]], device='cuda:0', grad_fn=&lt;ViewBackward0&gt;)\n\n\n- 바뀐 계산방식을 좀더 파고 들어서 분석해보자.\n\n_linr(stem(x)).long()\n\ntensor([[[[  0,   0,   0,   0,   0,   0,   0,   0,  -1,  -2,  -2,  -2,   0,   0,\n             0,   0],\n          [  0,   0,   0,   0,   0,   0,   0,  -1,   0,  -2,  -3,  -4,  -1,   0,\n             0,   0],\n          [  0,   0,   0,   1,   0,   0,   0,   0,   1,   0,  -3,  -5,  -4,  -2,\n             0,   0],\n          [  0,   0,   0,   0,   0,   0,   0,   0,  -1,  -4,  -9, -12, -12,  -8,\n            -2,   0],\n          [  0,   0,   0,   0,   0,   0,  -1,  -5, -11, -16, -20, -24, -22, -14,\n            -4,   0],\n          [ -1,  -1,   0,   0,   0,   0,  -5, -16, -28, -35, -40, -43, -38, -23,\n            -7,   0],\n          [ -1,  -1,   0,   0,   0,   0, -10, -28, -47, -56, -56, -53, -43, -25,\n            -7,   0],\n          [  0,  -1,   0,   0,   0,   0, -11, -29, -49, -57, -54, -47, -34, -19,\n            -4,   1],\n          [  0,   0,   0,   0,   0,   0,  -7, -21, -36, -43, -38, -29, -18,  -8,\n            -1,   0],\n          [  0,   0,  -1,  -1,   0,   0,  -3,  -9, -16, -19, -16, -11,  -4,   0,\n             0,   0],\n          [  0,   0,  -2,  -2,   0,   0,  -1,  -3,  -6,  -7,  -5,  -2,   0,   0,\n             1,   1],\n          [  0,   0,  -2,  -1,   0,   0,  -1,  -3,  -4,  -3,  -1,   0,   0,   0,\n             1,   1],\n          [  0,   0,  -1,   0,   0,   0,   0,  -2,  -2,  -1,   0,   0,   0,   0,\n             1,   1],\n          [  0,   0,   0,   0,   0,   0,   0,  -1,  -1,   0,   0,   0,   0,   1,\n             2,   1],\n          [ -1,  -1,  -1,  -1,   0,   0,   0,  -1,   0,   0,   0,   1,   1,   2,\n             2,   2],\n          [  0,  -1,  -1,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,\n             1,   1]]]], device='cuda:0')\n\n\n\n여러가지 값들이 있지만 (16*16=256개의 값들) 아무튼 이 값들의 평균은 -5.5613 임. (이 값이 작을수록 이 그림은 고양이라는 의미임)\n그런데 살펴보니까 대부분의 위치에서 -에 가까운 값을가지고, 특정위치에서만 엄청 작은 값이 존재하여 -5.5613 이라는 평균값이 나오는 것임.\n결국 이 특정위치에 존재하는 엄청 작은 값들이 x가 고양이라고 판단하는 근거가 된다.\n\n\nwhy = _linr(stem(x)) \n\n바꾸고 싶은 네트워크 – why라는 이름을 적용하여 \\[\\underset{(1,3,224,224)}{\\boldsymbol x} \\overset{stem}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{\\_linr}{\\to} \\underset{(1,1,16,16)}{\\bf why}\\overset{ap}{\\to} \\underset{(1,1,1,1)}{{\\boldsymbol \\sharp}}\\overset{flattn}{\\to} \\underset{(1,1)}{logit}\\right) = [[-5.5613]]\\]"
  },
  {
    "objectID": "posts/08wk-2.html#d.-3단계-why-시각화",
    "href": "posts/08wk-2.html#d.-3단계-why-시각화",
    "title": "08wk-2, 09wk-1: (XAI, 설명가능한 인공지능) – Class Activation Map",
    "section": "D. 3단계 – WHY 시각화",
    "text": "D. 3단계 – WHY 시각화\n# 시각화1 – why와 img를 겹쳐서 그려보자.\n\nplt.imshow(why.squeeze().cpu().detach(),cmap=\"bwr\")\nplt.colorbar()\n\n\n\n\n\n\n\n\n\nplt.imshow(x.cpu().detach().squeeze().permute(1,2,0))\nwhy_resized = torch.nn.functional.interpolate(\n    why,\n    size=(512,512),\n    mode=\"bilinear\",\n)\nplt.imshow(why_resized.squeeze().cpu().detach(),cmap=\"bwr\",alpha=0.5)\nplt.colorbar()\n\n\n\n\n\n\n\n\n#\n# 시각화2 – colormap을 magma로 적용\n\nx = X[[0]].to(\"cuda:0\")\nif net(x) &gt; 0: \n    pred = \"dog\"\n    why = _linr(stem(x)) \nelse: \n    pred = \"cat\" \n    why = - _linr(stem(x)) \nplt.imshow(x.cpu().detach().squeeze().permute(1,2,0))\nwhy_resized = torch.nn.functional.interpolate(\n    why,\n    size=(512,512),\n    mode=\"bilinear\",\n)\nplt.imshow(why_resized.squeeze().cpu().detach(),cmap=\"magma\",alpha=0.5)\nplt.title(f\"prediction = {pred}\");\n\n\n\n\n\n\n\n\n#\n# 시각화3 – 하니를 시각화해보자.\n\nurl = 'https://github.com/guebin/DL2025/blob/main/imgs/hani1.jpeg?raw=true'\nhani_pil = PIL.Image.open(\n    io.BytesIO(requests.get(url).content)\n)\n\n\nx = compose(hani_pil).reshape(1,3,512,512).to(\"cuda:0\")\nif net(x) &gt; 0: \n    pred = \"dog\"\n    why = _linr(stem(x)) \nelse: \n    pred = \"cat\" \n    why = - _linr(stem(x)) \nplt.imshow(x.cpu().detach().squeeze().permute(1,2,0))\nwhy_resized = torch.nn.functional.interpolate(\n    why,\n    size=(512,512),\n    mode=\"bilinear\",\n)\nplt.imshow(why_resized.squeeze().cpu().detach(),cmap=\"magma\",alpha=0.5)\nplt.title(f\"prediction = {pred}\");\n\n\n\n\n\n\n\n\n#\n# 시각화4 – XX의 이미지를 시각화해보자.\n\nfig, ax = plt.subplots(5,5)\n#---#\nk = 0 \nfor i in range(5):\n    for j in range(5):\n        x = XX[[k]].to(\"cuda:0\")\n        if net(x) &gt; 0: \n            pred = \"dog\"\n            why = _linr(stem(x)) \n        else: \n            pred = \"cat\" \n            why = - _linr(stem(x)) \n        plt.imshow(x.cpu().detach().squeeze().permute(1,2,0))\n        why_resized = torch.nn.functional.interpolate(\n            why,\n            size=(512,512),\n            mode=\"bilinear\",\n        )\n        ax[i][j].imshow(x.squeeze().permute(1,2,0).cpu())\n        ax[i][j].imshow(why_resized.squeeze().cpu().detach(),cmap=\"magma\",alpha=0.5)\n        ax[i][j].set_title(f\"prediction = {pred}\");\n        ax[i][j].set_xticks([])\n        ax[i][j].set_yticks([])\n        k = k+50\nfig.set_figheight(16)\nfig.set_figwidth(16)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(5,5)\n#---#\nk = 1 \nfor i in range(5):\n    for j in range(5):\n        x = XX[[k]].to(\"cuda:0\")\n        if net(x) &gt; 0: \n            pred = \"dog\"\n            why = _linr(stem(x)) \n        else: \n            pred = \"cat\" \n            why = - _linr(stem(x)) \n        plt.imshow(x.cpu().detach().squeeze().permute(1,2,0))\n        why_resized = torch.nn.functional.interpolate(\n            why,\n            size=(512,512),\n            mode=\"bilinear\",\n        )\n        ax[i][j].imshow(x.squeeze().permute(1,2,0).cpu())\n        ax[i][j].imshow(why_resized.squeeze().cpu().detach(),cmap=\"magma\",alpha=0.5)\n        ax[i][j].set_title(f\"prediction = {pred}\");\n        ax[i][j].set_xticks([])\n        ax[i][j].set_yticks([])\n        k = k+50\nfig.set_figheight(16)\nfig.set_figwidth(16)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(5,5)\n#---#\nk = 2\nfor i in range(5):\n    for j in range(5):\n        x = XX[[k]].to(\"cuda:0\")\n        if net(x) &gt; 0: \n            pred = \"dog\"\n            why = _linr(stem(x)) \n        else: \n            pred = \"cat\" \n            why = - _linr(stem(x)) \n        plt.imshow(x.cpu().detach().squeeze().permute(1,2,0))\n        why_resized = torch.nn.functional.interpolate(\n            why,\n            size=(512,512),\n            mode=\"bilinear\",\n        )\n        ax[i][j].imshow(x.squeeze().permute(1,2,0).cpu())\n        ax[i][j].imshow(why_resized.squeeze().cpu().detach(),cmap=\"magma\",alpha=0.5)\n        ax[i][j].set_title(f\"prediction = {pred}\");\n        ax[i][j].set_xticks([])\n        ax[i][j].set_yticks([])\n        k = k+50\nfig.set_figheight(16)\nfig.set_figwidth(16)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(5,5)\n#---#\nk = 3\nfor i in range(5):\n    for j in range(5):\n        x = XX[[k]].to(\"cuda:0\")\n        if net(x) &gt; 0: \n            pred = \"dog\"\n            why = _linr(stem(x)) \n        else: \n            pred = \"cat\" \n            why = - _linr(stem(x)) \n        plt.imshow(x.cpu().detach().squeeze().permute(1,2,0))\n        why_resized = torch.nn.functional.interpolate(\n            why,\n            size=(512,512),\n            mode=\"bilinear\",\n        )\n        ax[i][j].imshow(x.squeeze().permute(1,2,0).cpu())\n        ax[i][j].imshow(why_resized.squeeze().cpu().detach(),cmap=\"magma\",alpha=0.5)\n        ax[i][j].set_title(f\"prediction = {pred}\");\n        ax[i][j].set_xticks([])\n        ax[i][j].set_yticks([])\n        k = k+50\nfig.set_figheight(16)\nfig.set_figwidth(16)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n#"
  },
  {
    "objectID": "posts/07wk-1.html#a.-성능좋음",
    "href": "posts/07wk-1.html#a.-성능좋음",
    "title": "07wk-1: (합성곱신경망) – CNN 자랑, CNN 핵심레이어",
    "section": "A. 성능좋음",
    "text": "A. 성능좋음\nFashion MNIST\n\ntrain_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True)\ntest_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True)\ntrain_dataset = torch.utils.data.Subset(train_dataset, range(5000))\ntest_dataset = torch.utils.data.Subset(test_dataset, range(1000))\nto_tensor = torchvision.transforms.ToTensor()\nX = torch.stack([to_tensor(img) for img, lbl in train_dataset]).to(\"cuda:0\")\ny = torch.tensor([lbl for img, lbl in train_dataset])\ny = torch.nn.functional.one_hot(y).float().to(\"cuda:0\")\nXX = torch.stack([to_tensor(img) for img, lbl in test_dataset]).to(\"cuda:0\")\nyy = torch.tensor([lbl for img, lbl in test_dataset])\nyy = torch.nn.functional.one_hot(yy).float().to(\"cuda:0\")\n\n발악수준으로 설계한 신경망\n\ntorch.manual_seed(0)\nnet = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,2048),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2048,10)\n).to(\"cuda\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(1,500):\n    #1\n    logits = net(X)\n    #2\n    loss = loss_fn(logits, y) \n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\n(net(X).argmax(axis=1) == y.argmax(axis=1)).float().mean()\n\ntensor(1., device='cuda:0')\n\n\n\n(net(XX).argmax(axis=1) == yy.argmax(axis=1)).float().mean()\n\ntensor(0.8530, device='cuda:0')\n\n\n대충대충 설계한 합성곱신경망\n\ntorch.manual_seed(0)\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,2),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(2),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2704,10),\n).to(\"cuda\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(1,500):\n    #1\n    logits = net(X)\n    #2\n    loss = loss_fn(logits, y) \n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\n(net(X).argmax(axis=1) == y.argmax(axis=1)).float().mean()\n\ntensor(0.9670, device='cuda:0')\n\n\n\n(net(XX).argmax(axis=1) == yy.argmax(axis=1)).float().mean()\n\ntensor(0.8730, device='cuda:0')"
  },
  {
    "objectID": "posts/07wk-1.html#b.-파라메터적음",
    "href": "posts/07wk-1.html#b.-파라메터적음",
    "title": "07wk-1: (합성곱신경망) – CNN 자랑, CNN 핵심레이어",
    "section": "B. 파라메터적음",
    "text": "B. 파라메터적음\n\nnet1 = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,2048),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2048,10)\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,2),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(2),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2704,10),\n)\n\n\nnet1_params = list(net1.parameters())\nprint(net1_params[0].shape)\nprint(net1_params[1].shape)\nprint(net1_params[2].shape)\nprint(net1_params[3].shape)\n\ntorch.Size([2048, 784])\ntorch.Size([2048])\ntorch.Size([10, 2048])\ntorch.Size([10])\n\n\n\n2048*784 + 2048 + 10*2048 + 10 \n\n1628170\n\n\n\nnet2_params = list(net2.parameters())\nprint(net2_params[0].shape)\nprint(net2_params[1].shape)\nprint(net2_params[2].shape)\nprint(net2_params[3].shape)\n\ntorch.Size([16, 1, 2, 2])\ntorch.Size([16])\ntorch.Size([10, 2704])\ntorch.Size([10])\n\n\n\n16*1*2*2 + 16 + 10*2704 + 10 \n\n27130\n\n\n\n27130/1628170\n\n0.01666287918337766"
  },
  {
    "objectID": "posts/07wk-1.html#c.-유명함",
    "href": "posts/07wk-1.html#c.-유명함",
    "title": "07wk-1: (합성곱신경망) – CNN 자랑, CNN 핵심레이어",
    "section": "C. 유명함",
    "text": "C. 유명함\n- https://brunch.co.kr/@hvnpoet/109"
  },
  {
    "objectID": "posts/07wk-1.html#a.-torch.nn.relu",
    "href": "posts/07wk-1.html#a.-torch.nn.relu",
    "title": "07wk-1: (합성곱신경망) – CNN 자랑, CNN 핵심레이어",
    "section": "A. torch.nn.ReLU",
    "text": "A. torch.nn.ReLU\n(예시1) 연산방법\n\nimg = torch.randn(1,1,4,4) # (4,4) 흑백이미지 한장\nrelu = torch.nn.ReLU()\n\n\nimg\n\ntensor([[[[ 0.0052,  1.1922,  0.7636,  0.0099],\n          [-0.9365,  0.0695, -0.1974, -0.1691],\n          [-1.9972,  0.9638, -0.8581, -1.1956],\n          [ 1.2276,  0.9221,  1.3697, -0.2663]]]])\n\n\n\nrelu(img)\n\ntensor([[[[0.0052, 1.1922, 0.7636, 0.0099],\n          [0.0000, 0.0695, 0.0000, 0.0000],\n          [0.0000, 0.9638, 0.0000, 0.0000],\n          [1.2276, 0.9221, 1.3697, 0.0000]]]])"
  },
  {
    "objectID": "posts/07wk-1.html#b.-torch.nn.maxpool2d",
    "href": "posts/07wk-1.html#b.-torch.nn.maxpool2d",
    "title": "07wk-1: (합성곱신경망) – CNN 자랑, CNN 핵심레이어",
    "section": "B. torch.nn.MaxPool2d",
    "text": "B. torch.nn.MaxPool2d\n(예시1) 연산방법, kernel_size 의 의미\n\nimg = torch.rand(1,1,4,4)\nmp = torch.nn.MaxPool2d(kernel_size=2)\n\n\nimg\n\ntensor([[[[0.4601, 0.1505, 0.8785, 0.2573],\n          [0.4426, 0.5923, 0.4630, 0.9225],\n          [0.9051, 0.5439, 0.8494, 0.6388],\n          [0.9822, 0.1382, 0.6126, 0.9961]]]])\n\n\n\nmp(img)\n\ntensor([[[[0.5923, 0.9225],\n          [0.9822, 0.9961]]]])\n\n\n(예시2) 이미지크기와 딱 맞지않는 커널일경우?\n\nimg = torch.rand(1,1,5,5)\nmp = torch.nn.MaxPool2d(kernel_size=3)\n\n\nimg\n\ntensor([[[[0.4661, 0.5162, 0.0087, 0.7542, 0.1391],\n          [0.0969, 0.5140, 0.3865, 0.1853, 0.5127],\n          [0.7183, 0.3710, 0.5541, 0.1578, 0.4765],\n          [0.6287, 0.1574, 0.6492, 0.9207, 0.5921],\n          [0.7354, 0.9558, 0.8880, 0.9573, 0.7333]]]])\n\n\n\nmp(img)\n\ntensor([[[[0.7183]]]])\n\n\n(예시3) 정사각형이 아닌 커널\n\nimg = torch.rand(1,1,4,4)\nmp = torch.nn.MaxPool2d(kernel_size=(4,2))\n\n\nimg\n\ntensor([[[[0.9469, 0.4182, 0.0710, 0.1394],\n          [0.2413, 0.7493, 0.0440, 0.7918],\n          [0.9179, 0.8230, 0.0547, 0.4162],\n          [0.9223, 0.5011, 0.8517, 0.9853]]]])\n\n\n\nmp(img)\n\ntensor([[[[0.9469, 0.9853]]]])"
  },
  {
    "objectID": "posts/07wk-1.html#c.-torch.nn.conv2d",
    "href": "posts/07wk-1.html#c.-torch.nn.conv2d",
    "title": "07wk-1: (합성곱신경망) – CNN 자랑, CNN 핵심레이어",
    "section": "C. torch.nn.Conv2d",
    "text": "C. torch.nn.Conv2d\n(예시1) 연산방법, stride=2\n\nimg = torch.rand(1,1,4,4)\nconv = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=2,stride=2)\n\n\nimg\n\ntensor([[[[0.0197, 0.3086, 0.0321, 0.0743],\n          [0.5398, 0.4104, 0.7244, 0.0238],\n          [0.9728, 0.4270, 0.2396, 0.1358],\n          [0.1888, 0.2525, 0.1224, 0.5778]]]])\n\n\n\nconv(img)\n\ntensor([[[[-0.3077, -0.4760],\n          [ 0.0550, -0.0650]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n??\n\nconv.weight.data, conv.bias.data\n\n(tensor([[[[ 0.3095,  0.0207],\n           [-0.3130,  0.2836]]]]),\n tensor([-0.2675]))\n\n\n\n(img[:,  :,  :2,  :2] * conv.weight.data).sum()+conv.bias.data, conv(img)\n\n(tensor([-0.3077]),\n tensor([[[[-0.3077, -0.4760],\n           [ 0.0550, -0.0650]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n\n(img[:,  :,  :2,  2:] * conv.weight.data).sum()+conv.bias.data, conv(img)\n\n(tensor([-0.4760]),\n tensor([[[[-0.3077, -0.4760],\n           [ 0.0550, -0.0650]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n\n(img[:,  :,  2:,  :2] * conv.weight.data).sum()+conv.bias.data, conv(img)\n\n(tensor([0.0550]),\n tensor([[[[-0.3077, -0.4760],\n           [ 0.0550, -0.0650]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n\n(img[:,  :,  2:,  2:] * conv.weight.data).sum()+conv.bias.data, conv(img)\n\n(tensor([-0.0650]),\n tensor([[[[-0.3077, -0.4760],\n           [ 0.0550, -0.0650]]]], grad_fn=&lt;ConvolutionBackward0&gt;))"
  },
  {
    "objectID": "posts/06wk-2.html#a.-이항분류와-bcewithlogitsloss",
    "href": "posts/06wk-2.html#a.-이항분류와-bcewithlogitsloss",
    "title": "06wk-2: (신경망) – 다항분류, FashionMNIST",
    "section": "A. 이항분류와 BCEWithLogitsLoss",
    "text": "A. 이항분류와 BCEWithLogitsLoss\n- 데이터\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX0_train = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\nX1_train = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\nX = torch.concat([X0_train,X1_train],axis=0).reshape(-1,784)\ny = torch.tensor([0.0]*len(X0_train) + [1.0]*len(X1_train)).reshape(-1,1)\n\n- 예전에 적합했던 코드에서 sig를 분리한것\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n)\nsig = torch.nn.Sigmoid()\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1,31):\n    #1\n    netout = net(X)\n    yhat = sig(netout)\n    #2\n    loss = loss_fn(yhat,y)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n# netout(=logits) 의 특징\n\n\\(netout &gt;0 \\Leftrightarrow sig(netout) &gt; 0.5\\)\n\\(netout &lt;0 \\Leftrightarrow sig(netout) &lt; 0.5\\)\n\n\n((net(X)&gt;0) ==y).float().mean()\n\ntensor(0.9956)\n\n\n- 아래의 코드는 위의 코드와 같은 코드임\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n)\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1,31):\n    #1\n    netout = net(X) \n    #2\n    loss = loss_fn(netout,y)\n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()"
  },
  {
    "objectID": "posts/06wk-2.html#b.-범주형자료의-변환",
    "href": "posts/06wk-2.html#b.-범주형자료의-변환",
    "title": "06wk-2: (신경망) – 다항분류, FashionMNIST",
    "section": "B. 범주형자료의 변환",
    "text": "B. 범주형자료의 변환\n- 범주형자료를 숫자로 어떻게 바꿀까?\n\n실패 / 성공 \\(\\to\\) 0 / 1\n숫자0그림 / 숫자1그림 \\(\\to\\) 0 / 1\n강아지그림 / 고양이그림 \\(\\to\\) 0 / 1\n강아지그림 / 고양이그림 / 토끼그림 \\(\\to\\) 0 / 1 / 2 ?????\n\n- 주입식교육: 강아지그림/고양이그림/토끼그림일 경우 숫자화시키는 방법\n\n잘못된방식: 강아지그림 = 0, 고양이그림 = 1, 토끼그림 = 2\n올바른방식: 강아지그림 = [1,0,0], 고양이그림 = [0,1,0], 토끼그림 = [0,0,1] ### &lt;– 이런방식을 원핫인코딩이라함\n\n- 왜?\n\n설명1: 강아지그림, 고양이그림, 토끼그림은 서열측도가 아니라 명목척도임. 그래서 범주를 0,1,2 로 숫자화하면 평균등의 의미가 없음 (사회조사분석사 2급 스타일)\n설명2: 범주형은 원핫인코딩으로 해야함 (“30일만에 끝내는 실전머신러닝” 이런 책에 나오는 스타일)\n설명3: 동전을 한번 던져서 나오는 결과는 \\(n=1\\)인 이항분포를 따름. 주사위 한번 던져서 나오는 눈금의 숫자는 \\(n=1\\)인 다항분포를 따름. \\(n=1\\)인 이항분포의 실현값은 0,1 이고, \\(n=1\\)인 다항분포의 실현값은 [1,0,0], [0,1,0], [0,0,1] 이므로 당연히 \\(y_i\\) 는 [1,0,0], [0,1,0], [0,0,1] 중 하나의 형태를 가진다고 가정하는게 바람직함 (이 설명이 이 중에서 가장 정확한 설명임)"
  },
  {
    "objectID": "posts/06wk-2.html#c.-실습-3개의-클래스를-구분",
    "href": "posts/06wk-2.html#c.-실습-3개의-클래스를-구분",
    "title": "06wk-2: (신경망) – 다항분류, FashionMNIST",
    "section": "C. 실습: 3개의 클래스를 구분",
    "text": "C. 실습: 3개의 클래스를 구분\n- 데이터준비\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX0 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==0])\nX1 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==1])\nX2 = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==2])\nX = torch.concat([X0,X1,X2]).reshape(-1,1*28*28)\ny = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2)).reshape(-1,1).float()\n\n\ny = torch.nn.functional.one_hot(y.reshape(-1).long()).float()\ny\n\ntensor([[1., 0., 0.],\n        [1., 0., 0.],\n        [1., 0., 0.],\n        ...,\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [0., 0., 1.]])\n\n\n- 적합\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,3),\n)\nloss_fn = torch.nn.CrossEntropyLoss() # 의미상 CEWithLogitsLoss\noptimizr = torch.optim.Adam(net.parameters())\nfor epoc in range(1,31):\n    #1\n    netout = net(X) # netout: (n,3) \n    #2\n    loss = loss_fn(netout,y) \n    #3\n    loss.backward()\n    #4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\n(netout.argmax(axis=1) == y.argmax(axis=1)).float().mean()\n\ntensor(0.9669)"
  },
  {
    "objectID": "posts/06wk-2.html#d.-결론-외우세여",
    "href": "posts/06wk-2.html#d.-결론-외우세여",
    "title": "06wk-2: (신경망) – 다항분류, FashionMNIST",
    "section": "D. 결론 – 외우세여",
    "text": "D. 결론 – 외우세여\n- 파이토치버전 // 코딩용\n\n\n\n분류\nnetout의 의미\n손실함수\n\n\n\n\n이항분류\nprob\nBCELoss\n\n\n이항분류\nlogit\nBCEWithLogitsLoss\n\n\n다항분류\nprobs\nNA\n\n\n다항분류\nlogits\nCrossEntropyLoss\n\n\n\n\nCrossEntropyLoss 이거 이름이 완전 마음에 안들어요.. CEWithLogitsLoss 라고 하는게 더 좋을 것 같습니다.\n\n- 일반적개념 // 이론용\n\n\n\n\n\n\n\n\n\n분류\n오차항의가정\n마지막활성화함수\n손실함수\n\n\n\n\n이항분류\n이항분포\nsigmoid1\nBinary Cross Entropy\n\n\n다항분류\n다항분포\nsoftmax2\nCross Entropy\n\n\n\n1 prob=sig(logit)2 probs=soft(logits)- 참고 (sigmoid, softmax 계산과정비교)\n\n\\(prob = \\text{sig}(logit) =\\frac{\\exp(logit)}{1+\\exp(logit)}\\)\n\\(probs= \\text{softmax}\\left(\\begin{bmatrix} logit_1 \\\\ logit_2 \\\\ logit_3\\end{bmatrix}\\right) =\\begin{bmatrix} \\frac{\\exp(logit_1)}{\\exp(logit_1)+\\exp(logit_2)+\\exp(logit_3)} \\\\\n\\frac{\\exp(logit_2)}{\\exp(logit_1)+\\exp(logit_2)+\\exp(logit_3)} \\\\\n\\frac{\\exp(logit_3)}{\\exp(logit_1)+\\exp(logit_2)+\\exp(logit_3)} \\end{bmatrix}\\)"
  },
  {
    "objectID": "posts/06wk-2.html#a.-데이터",
    "href": "posts/06wk-2.html#a.-데이터",
    "title": "06wk-2: (신경망) – 다항분류, FashionMNIST",
    "section": "A. 데이터",
    "text": "A. 데이터\nhttps://arxiv.org/abs/1708.07747 (Xiao, Rasul, and Vollgraf 2017)\n\nXiao, Han, Kashif Rasul, and Roland Vollgraf. 2017. “Fashion-Mnist: A Novel Image Dataset for Benchmarking Machine Learning Algorithms.” arXiv Preprint arXiv:1708.07747.\n\ntrain_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True)\ntest_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX = torch.stack([to_tensor(img) for img, lbl in train_dataset])\ny = torch.tensor([lbl for img, lbl in train_dataset])\ny = torch.nn.functional.one_hot(y).float()\nXX = torch.stack([to_tensor(img) for img, lbl in test_dataset])\nyy = torch.tensor([lbl for img, lbl in test_dataset])\nyy = torch.nn.functional.one_hot(yy).float()\n\n\nobs_idx = 301\nplt.imshow(X[obs_idx,0,:,:],cmap=\"gray\")\nplt.title(torchvision.datasets.FashionMNIST.classes[y[obs_idx,:].argmax().item()]);"
  },
  {
    "objectID": "posts/06wk-2.html#b.-간단한-신경망",
    "href": "posts/06wk-2.html#b.-간단한-신경망",
    "title": "06wk-2: (신경망) – 다항분류, FashionMNIST",
    "section": "B. 간단한 신경망",
    "text": "B. 간단한 신경망\n- Step1: 데이터정리\n\nds_train = torch.utils.data.TensorDataset(X,y)\ndl_train = torch.utils.data.DataLoader(ds_train,batch_size=256,shuffle=True)\nds_test = torch.utils.data.TensorDataset(XX,yy)\ndl_test = torch.utils.data.DataLoader(ds_test,batch_size=256)\n\n- Step2: 학습에 필요한 준비 (모델링)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,10)\n).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\n- Step3: 적합\n\nfor epoc in range(1,31):\n    net.train()\n    #---에폭시작---#\n    for Xm,ym in dl_train:        \n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # 1\n        netout = net(Xm)\n        # 2 \n        loss = loss_fn(netout,ym)\n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #---에폭끝---#\n    if epoc % 5 == 0:\n        net.eval()\n        s =0\n        for Xm,ym in dl_train:        \n            Xm = Xm.to(\"cuda:0\")\n            ym = ym.to(\"cuda:0\")        \n            logits = net(Xm).data \n            s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\n        acc = s / len(X)\n        print(f\"# of epochs = {epoc},train_acc = {acc:.4f}\") \n\n# of epochs = 5,train_acc = 0.8588\n# of epochs = 10,train_acc = 0.8659\n# of epochs = 15,train_acc = 0.8779\n# of epochs = 20,train_acc = 0.8830\n# of epochs = 25,train_acc = 0.8857\n# of epochs = 30,train_acc = 0.8875\n\n\n- Step4: 적합결과 시각화 및 분석\n\nnet.eval()\ns =0\nfor Xm,ym in dl_test:        \n    Xm = Xm.to(\"cuda:0\")\n    ym = ym.to(\"cuda:0\")        \n    logits = net(Xm).data \n    s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\nacc = s / len(XX)\nprint(f\"test_acc = {acc:.4f}\") \n\ntest_acc = 0.8639"
  },
  {
    "objectID": "posts/06wk-2.html#c.-약간-더-복잡한-신경망",
    "href": "posts/06wk-2.html#c.-약간-더-복잡한-신경망",
    "title": "06wk-2: (신경망) – 다항분류, FashionMNIST",
    "section": "C. 약간 더 복잡한 신경망",
    "text": "C. 약간 더 복잡한 신경망\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,256),\n    torch.nn.ReLU(),\n    torch.nn.Linear(256,10)\n).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\n\nfor epoc in range(1,31):\n    net.train()\n    #---에폭시작---#\n    for Xm,ym in dl_train:        \n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # 1\n        netout = net(Xm)\n        # 2 \n        loss = loss_fn(netout,ym)\n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #---에폭끝---#\n    if epoc % 5 == 0:\n        net.eval()\n        s =0\n        for Xm,ym in dl_train:        \n            Xm = Xm.to(\"cuda:0\")\n            ym = ym.to(\"cuda:0\")        \n            logits = net(Xm).data \n            s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\n        acc = s / len(X)\n        print(f\"# of epochs = {epoc},train_acc = {acc:.4f}\") \n\n# of epochs = 5,train_acc = 0.8831\n# of epochs = 10,train_acc = 0.9028\n# of epochs = 15,train_acc = 0.9183\n# of epochs = 20,train_acc = 0.9281\n# of epochs = 25,train_acc = 0.9331\n# of epochs = 30,train_acc = 0.9332\n\n\n\nnet.eval()\ns =0\nfor Xm,ym in dl_test:        \n    Xm = Xm.to(\"cuda:0\")\n    ym = ym.to(\"cuda:0\")        \n    logits = net(Xm).data \n    s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\nacc = s / len(XX)\nprint(f\"test_acc = {acc:.4f}\") \n\ntest_acc = 0.8833"
  },
  {
    "objectID": "posts/06wk-2.html#d.-발악",
    "href": "posts/06wk-2.html#d.-발악",
    "title": "06wk-2: (신경망) – 다항분류, FashionMNIST",
    "section": "D. 발악",
    "text": "D. 발악\n- 노드를 많이..\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,4096),\n    torch.nn.Dropout(0.5),\n    torch.nn.ReLU(),\n    torch.nn.Linear(4096,10)\n).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\n\nfor epoc in range(1,31):\n    net.train()\n    #---에폭시작---#\n    for Xm,ym in dl_train:        \n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # 1\n        netout = net(Xm)\n        # 2 \n        loss = loss_fn(netout,ym)\n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #---에폭끝---#\n    if epoc % 5 == 0:\n        net.eval()\n        s =0\n        for Xm,ym in dl_train:        \n            Xm = Xm.to(\"cuda:0\")\n            ym = ym.to(\"cuda:0\")        \n            logits = net(Xm).data \n            s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\n        acc = s / len(X)\n        print(f\"# of epochs = {epoc},train_acc = {acc:.4f}\") \n\n# of epochs = 5,train_acc = 0.8885\n# of epochs = 10,train_acc = 0.8977\n# of epochs = 15,train_acc = 0.9130\n# of epochs = 20,train_acc = 0.9232\n# of epochs = 25,train_acc = 0.9318\n# of epochs = 30,train_acc = 0.9308\n\n\n\nnet.eval()\ns =0\nfor Xm,ym in dl_test:        \n    Xm = Xm.to(\"cuda:0\")\n    ym = ym.to(\"cuda:0\")        \n    logits = net(Xm).data \n    s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\nacc = s / len(XX)\nprint(f\"test_acc = {acc:.4f}\") \n\ntest_acc = 0.8934\n\n\n- 레이어를 많이..\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,256),\n    torch.nn.ReLU(),\n    torch.nn.Linear(256,256),\n    torch.nn.ReLU(),\n    torch.nn.Linear(256,256),\n    torch.nn.ReLU(), \n    torch.nn.Linear(256,256),\n    torch.nn.ReLU(),    \n    torch.nn.Linear(256,10)\n).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\n\nfor epoc in range(1,31):\n    net.train()\n    #---에폭시작---#\n    for Xm,ym in dl_train:        \n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # 1\n        netout = net(Xm)\n        # 2 \n        loss = loss_fn(netout,ym)\n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #---에폭끝---#\n    if epoc % 5 == 0:\n        net.eval()\n        s =0\n        for Xm,ym in dl_train:        \n            Xm = Xm.to(\"cuda:0\")\n            ym = ym.to(\"cuda:0\")        \n            logits = net(Xm).data \n            s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\n        acc = s / len(X)\n        print(f\"# of epochs = {epoc},train_acc = {acc:.4f}\") \n\n# of epochs = 5,train_acc = 0.8917\n# of epochs = 10,train_acc = 0.9174\n# of epochs = 15,train_acc = 0.9256\n# of epochs = 20,train_acc = 0.9373\n# of epochs = 25,train_acc = 0.9471\n# of epochs = 30,train_acc = 0.9587\n\n\n\nnet.eval()\ns =0\nfor Xm,ym in dl_test:        \n    Xm = Xm.to(\"cuda:0\")\n    ym = ym.to(\"cuda:0\")        \n    logits = net(Xm).data \n    s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\nacc = s / len(XX)\nprint(f\"test_acc = {acc:.4f}\") \n\ntest_acc = 0.8952\n\n\n\ntest_acc 90% 넘기는게 엄청 힘들다"
  },
  {
    "objectID": "posts/06wk-2.html#f.-합성곱신경망",
    "href": "posts/06wk-2.html#f.-합성곱신경망",
    "title": "06wk-2: (신경망) – 다항분류, FashionMNIST",
    "section": "F. 합성곱신경망",
    "text": "F. 합성곱신경망\n- https://brunch.co.kr/@hvnpoet/109\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(in_channels=1 ,out_channels=64,kernel_size=5),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=2),\n    torch.nn.Conv2d(in_channels=64 ,out_channels=64,kernel_size=5),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=2),    \n    torch.nn.Flatten(),\n    torch.nn.Linear(1024,10)\n).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\n\n\nfor epoc in range(1,31):\n    net.train()\n    #---에폭시작---#\n    for Xm,ym in dl_train:        \n        Xm = Xm.to(\"cuda:0\")\n        ym = ym.to(\"cuda:0\")\n        # 1\n        netout = net(Xm)\n        # 2 \n        loss = loss_fn(netout,ym)\n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    #---에폭끝---#\n    if epoc % 5 == 0:\n        net.eval()\n        s =0\n        for Xm,ym in dl_train:        \n            Xm = Xm.to(\"cuda:0\")\n            ym = ym.to(\"cuda:0\")        \n            logits = net(Xm).data \n            s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\n        acc = s / len(X)\n        print(f\"# of epochs = {epoc},train_acc = {acc:.4f}\") \n\n# of epochs = 5,train_acc = 0.9065\n# of epochs = 10,train_acc = 0.9323\n# of epochs = 15,train_acc = 0.9434\n# of epochs = 20,train_acc = 0.9535\n# of epochs = 25,train_acc = 0.9665\n# of epochs = 30,train_acc = 0.9759\n\n\n\nnet.eval()\ns =0\nfor Xm,ym in dl_test:        \n    Xm = Xm.to(\"cuda:0\")\n    ym = ym.to(\"cuda:0\")        \n    logits = net(Xm).data \n    s = s+ (logits.argmax(axis=1) == ym.argmax(axis=1)).float().sum()\nacc = s / len(XX)\nprint(f\"test_acc = {acc:.4f}\") \n\ntest_acc = 0.9154\n\n\n\n\n\n\n\n\nNote\n\n\n\n네트워크를 아래와 같이 설정했더니\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(in_channels=1 ,out_channels=64,kernel_size=5),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=2),\n    torch.nn.Conv2d(in_channels=64 ,out_channels=64,kernel_size=5),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d(kernel_size=2),    \n    torch.nn.Flatten(),\n    torch.nn.Linear(1024,10)\n)\n결과가 좋네? 정도만 알면됩니다."
  },
  {
    "objectID": "posts/05wk-1.html#a.-데이터",
    "href": "posts/05wk-1.html#a.-데이터",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "A. 데이터",
    "text": "A. 데이터\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\neps = torch.randn(100)*0.5\ny = x * 4 + 2.5 + eps\nx,y = x.reshape(-1,1), y.reshape(-1,1)\n\n\nplt.plot(x,y,'o')"
  },
  {
    "objectID": "posts/05wk-1.html#b.-학습",
    "href": "posts/05wk-1.html#b.-학습",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "B. 학습",
    "text": "B. 학습\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1)\n## \nfor epoc in range(200):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n\nnet[0].weight, net[0].bias\n\n(Parameter containing:\n tensor([[4.0042]], requires_grad=True),\n Parameter containing:\n tensor([2.4459], requires_grad=True))"
  },
  {
    "objectID": "posts/05wk-1.html#c.-예측",
    "href": "posts/05wk-1.html#c.-예측",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "C. 예측",
    "text": "C. 예측\n온도가 0.1 도일때, 커피를 얼마나 팔까?\n\n0.1 * 4.0042 + 2.4459 \n\n2.84632\n\n\n\nxx = torch.tensor([[0.1]])\nnet(xx)\n\ntensor([[2.8463]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n온도가 0.2도일때 커피를 얼마나 팔까?\n\n0.2 * 4.0042 + 2.4459 \n\n3.24674\n\n\n\nxx = torch.tensor([[0.2]])\nnet(xx)\n\ntensor([[3.2467]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n온도가 [0.1, 0.2] 일때의 예측값을 한번에 보고 싶다면?\n\nxx = torch.tensor([[0.1],\n                   [0.2]])\nnet(xx)\n\ntensor([[2.8463],\n        [3.2467]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\n\n\n\n\n\nNote\n\n\n\n이거 질문이 와서 좀 더 자세히 설명하겠습니다. (아직 net(x)의 계산 과정을 선형 변환 관점에서 수식으로 정리하는 데 익숙하지 않으셔서 그럴 수 있습니다. 이건 단순 산수라서 하나씩 차근차근 따라가다 보면 충분히 이해하실 수 있어요. 처음부터 바로 이해되지 않더라도 전혀 걱정하실 필요 없습니다.)\n하나의 값 \\(x\\)에 대하여 \\(net(x)\\)는 아래를 의미하는 연산을 합니다.\nnet(x) = 4.0042 * x + 2.4459  = net[0].weight * x + net[0].bias\n사실 위의 과정을 수식으로 엄밀하게 쓰면 아래와 같습니다.\n\\[net(\\begin{bmatrix} x \\end{bmatrix}) = 2.4459 + \\begin{bmatrix} x \\end{bmatrix} \\begin{bmatrix} 4.0042 \\end{bmatrix}\\]\n여기에서 \\(\\begin{bmatrix} x \\end{bmatrix}\\) 와 \\(\\begin{bmatrix} 4.0042  \\end{bmatrix}\\) 는 모두 \\(1\\times 1\\) matrix를 의미합니다. 만약에 \\(2 \\times 1\\) matrix \\({\\bf x} = \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}\\)를 네트워크의 입력으로 고려한다면 아래와 같이 됩니다.\n\\[net({\\bf x})=net\\left(\\begin{bmatrix}x_1 \\\\ x_2 \\end{bmatrix}\\right) = 2.4459 + \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\begin{bmatrix} 4.0042 \\end{bmatrix} = \\begin{bmatrix} 2.4459 + 4.0042 x_1 \\\\ 2.4459 + 4.0042 x_2\\end{bmatrix} \\]\n따라서 \\({\\bf xx} = \\begin{bmatrix} 0.1 \\\\ 0.2 \\end{bmatrix}\\) 를 네트워크의 입력으로 넣으면\n\\[net({\\bf xx})= \\begin{bmatrix} 2.4459 + 4.0042 \\times 0.1 \\\\ 2.4459 + 4.0042 \\times 0.2\\end{bmatrix}= \\begin{bmatrix} 2.8463 \\\\ 3.2467 \\end{bmatrix}\\]\n와 같이 계산되겠죠."
  },
  {
    "objectID": "posts/05wk-1.html#a.-오버피팅",
    "href": "posts/05wk-1.html#a.-오버피팅",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "A. 오버피팅",
    "text": "A. 오버피팅\n- 오버피팅이란?\n\n위키: In mathematical modeling, overfitting is “the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit to additional data or predict future observations reliably”. (수학적 모델링에서 과적합이란 “어떤 모델이 주어진 데이터에 너무 꼭 맞춰져 있어서, 새로운 데이터나 미래의 결과를 잘 예측하지 못할 수 있는 상태”를 의미한다.)\n제 개념: 데이터를 “데이터 = 언더라잉 + 오차”라고 생각할때 우리가 데이터로부터 적합할 것은 언더라잉인데 오차항을 적합하고 있는 현상."
  },
  {
    "objectID": "posts/05wk-1.html#b.-오버피팅-예시",
    "href": "posts/05wk-1.html#b.-오버피팅-예시",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "B. 오버피팅 예시",
    "text": "B. 오버피팅 예시\n- \\(m\\)이 매우 클때 아래의 네트워크 거의 무엇이든 맞출 수 있다고 보면 된다.\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n- 그런데 종종 맞추지 말아야 할 것들도 맞춘다.\n\\[\\text{model:} \\quad y_i = (0\\times x_i) + \\epsilon_i,~~ \\text{where}~ \\epsilon_i \\sim N(0,0.01^2)\\]\n\ntorch.manual_seed(5) \nx = torch.linspace(0,1,100).reshape(100,1)\ny = torch.randn(100).reshape(100,1)*0.01\nplt.plot(x,y,'--o',alpha=0.5)\n\n\n\n\n\n\n\n\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'--o',alpha=0.5)\nplt.plot(x,net(x).data,'--')"
  },
  {
    "objectID": "posts/05wk-1.html#c.-오버피팅이라는-뚜렷한-증거-train-test",
    "href": "posts/05wk-1.html#c.-오버피팅이라는-뚜렷한-증거-train-test",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "C. 오버피팅이라는 뚜렷한 증거! (train / test)",
    "text": "C. 오버피팅이라는 뚜렷한 증거! (train / test)\n- 데이터의 분리하여 보자.\n\ntorch.manual_seed(5) \nx_all = torch.linspace(0,1,100).reshape(100,1)\ny_all = torch.randn(100).reshape(100,1)*0.01\nx,xx = x_all[:80], x_all[80:]\ny,yy = y_all[:80], y_all[80:]\nplt.plot(x,y,'--o',alpha=0.5,label=\"training\")\nplt.plot(xx,yy,'--o',alpha=0.5,label=\"test\")\nplt.legend()\n\n\n\n\n\n\n\n\n- train만 학습\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- training data로 학습한 net를 training data 에 적용\n\nplt.plot(x_all,y_all,'--o',alpha=0.5,color=\"gray\")\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n\ntraining에서는 그럭저럭 잘 맞춤\n\n- training data로 학습한 net를 test data 에 적용\n\nplt.plot(x_all,y_all,'--o',alpha=0.5,color=\"gray\")\nplt.plot(x,net(x).data,'--')\nplt.plot(xx,net(xx).data,'--')\n\n\n\n\n\n\n\n\n\ntrain에서는 그럭저럭 잘 맞추는데 test에서는 엉망이다 = overfit"
  },
  {
    "objectID": "posts/05wk-1.html#d.-시벤코정리의-올바른-이해",
    "href": "posts/05wk-1.html#d.-시벤코정리의-올바른-이해",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "D. 시벤코정리의 올바른 이해",
    "text": "D. 시벤코정리의 올바른 이해\n\n\n\n\n\n\nNote\n\n\n\n시벤코의 항변(?) (Cybenko 1989)\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크 \\(net: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\)는\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(), ## &lt;-- 여기에 렐루를 써도 된다. \n    torch.nn.Linear(???,q)\n)\n모든 보렐가측함수\n\\[f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\]\n를 원하는 정확도로 “근사”시킬 수 있다. 쉽게 말하면 \\({\\bf X} \\to {\\bf y}\\) 인 어떠한 복잡한 규칙라도 하나의 은닉층을 가진 신경망이 원하는 정확도로 근사시킨다는 의미이다. 그렇지만 이러한 규칙이 네크워크가 학습하지 못했던 자료 (처음 보는 자료, unseen data) \\({\\bf XX}_{m \\times p}\\), \\({\\bf yy}_{m \\times q}\\) 에 대하여서도 올바르게 적용된다라는 보장은 없다. 시벤코는 단지 net가 가지는 표현력의 한계를 수학적으로 밝혔을 뿐이다.\n\n\n\nCybenko, George. 1989. “Approximation by Superpositions of a Sigmoidal Function.” Mathematics of Control, Signals and Systems 2 (4): 303–14."
  },
  {
    "objectID": "posts/05wk-1.html#a.-오버피팅의-해결",
    "href": "posts/05wk-1.html#a.-오버피팅의-해결",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "A. 오버피팅의 해결",
    "text": "A. 오버피팅의 해결\n- 오버피팅의 해결책: 드랍아웃\n- 데이터\n\ntorch.manual_seed(5) \nx_all = torch.linspace(0,1,100).reshape(100,1)\ny_all = torch.randn(100).reshape(100,1)*0.01\n#plt.plot(x_all,y_all,'--o',alpha=0.5)\nx,y = x_all[:80], y_all[:80]\nxx,yy = x_all[80:], y_all[80:]\nplt.plot(x,y,'--o',color=\"C0\")\nplt.plot(xx,yy,'--o',color=\"C1\")\n\n\n\n\n\n\n\n\n- 학습\n\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.8),\n    torch.nn.Linear(512,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(1000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화 (잘못된 사용)\n\nplt.plot(x_all,y_all,'--o',alpha=0.5,color=\"gray\")\nplt.plot(x,net(x).data,'--')\nplt.plot(xx,net(xx).data,'--')\n\n\n\n\n\n\n\n\n- 결과시각화 (올바른 사용)\n\nnet.training \n\nTrue\n\n\n\nnet.eval()\n\nSequential(\n  (0): Linear(in_features=1, out_features=512, bias=True)\n  (1): ReLU()\n  (2): Dropout(p=0.8, inplace=False)\n  (3): Linear(in_features=512, out_features=1, bias=True)\n)\n\n\n\nnet.training\n\nFalse\n\n\n\nplt.plot(x_all,y_all,'--o',alpha=0.5,color=\"gray\")\nplt.plot(x,net(x).data,'--')\nplt.plot(xx,net(xx).data,'--')"
  },
  {
    "objectID": "posts/05wk-1.html#b.-드랍아웃-레이어",
    "href": "posts/05wk-1.html#b.-드랍아웃-레이어",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "B. 드랍아웃 레이어",
    "text": "B. 드랍아웃 레이어\n- 드랍아웃의 성질1: 드랍아웃의 계산방식을 이해해보자.\n\nu = torch.randn(10,2)\nd = torch.nn.Dropout(0.9)\nu\n\ntensor([[ 0.2325, -0.2137],\n        [-1.1099,  0.1651],\n        [-0.6292, -0.6375],\n        [-0.7331, -0.4100],\n        [ 0.3024,  0.1195],\n        [ 1.6408,  0.9799],\n        [ 0.6248, -0.6950],\n        [-0.4911, -1.5387],\n        [ 0.3758,  0.2701],\n        [ 1.5462, -0.1872]])\n\n\n\nd(u)\n\ntensor([[ 0.0000, -0.0000],\n        [-0.0000,  0.0000],\n        [-6.2916, -0.0000],\n        [-7.3306, -4.0995],\n        [ 0.0000,  0.0000],\n        [ 0.0000,  0.0000],\n        [ 0.0000, -0.0000],\n        [-0.0000, -0.0000],\n        [ 0.0000,  0.0000],\n        [ 0.0000, -0.0000]])\n\n\n\n90%의 드랍아웃: 드랍아웃층의 입력 중 임의로 90%를 골라서 결과를 0으로 만든다. + 그리고 0이 되지않고 살아남은 값들은 10배 만큼 값이 커진다.\n남은값을 10배 키우는 이유? 출력의 평균값을 보정하기 위해서\n\n- 드랍아웃의 성질2: 드랍아웃을 on/off 하는 방법을 이해해보자.\n\nu = torch.randn(10,2)\nu\n\ntensor([[ 1.5448,  0.6084],\n        [-0.2335, -0.0364],\n        [ 0.2034,  1.2170],\n        [-0.3361,  0.2241],\n        [ 1.7618,  0.2731],\n        [-0.5324, -1.4465],\n        [-1.0775,  1.2933],\n        [ 0.8029, -1.0636],\n        [-0.6346, -0.7101],\n        [ 0.9358, -0.2241]])\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Dropout(0.9)\n)\nnet\n\nSequential(\n  (0): Dropout(p=0.9, inplace=False)\n)\n\n\n\nu,net(u)\n\n(tensor([[ 1.5448,  0.6084],\n         [-0.2335, -0.0364],\n         [ 0.2034,  1.2170],\n         [-0.3361,  0.2241],\n         [ 1.7618,  0.2731],\n         [-0.5324, -1.4465],\n         [-1.0775,  1.2933],\n         [ 0.8029, -1.0636],\n         [-0.6346, -0.7101],\n         [ 0.9358, -0.2241]]),\n tensor([[0.0000, 0.0000],\n         [-0.0000, -0.0000],\n         [0.0000, 0.0000],\n         [-0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [-0.0000, -0.0000],\n         [-0.0000, 0.0000],\n         [0.0000, -0.0000],\n         [-0.0000, -0.0000],\n         [9.3584, -0.0000]]))\n\n\n\nnet.training\n\nTrue\n\n\n\nnet.eval() # 드랍아웃이 무력화\n\nSequential(\n  (0): Dropout(p=0.9, inplace=False)\n)\n\n\n\nu,net(u)\n\n(tensor([[ 1.5448,  0.6084],\n         [-0.2335, -0.0364],\n         [ 0.2034,  1.2170],\n         [-0.3361,  0.2241],\n         [ 1.7618,  0.2731],\n         [-0.5324, -1.4465],\n         [-1.0775,  1.2933],\n         [ 0.8029, -1.0636],\n         [-0.6346, -0.7101],\n         [ 0.9358, -0.2241]]),\n tensor([[ 1.5448,  0.6084],\n         [-0.2335, -0.0364],\n         [ 0.2034,  1.2170],\n         [-0.3361,  0.2241],\n         [ 1.7618,  0.2731],\n         [-0.5324, -1.4465],\n         [-1.0775,  1.2933],\n         [ 0.8029, -1.0636],\n         [-0.6346, -0.7101],\n         [ 0.9358, -0.2241]]))\n\n\n- 드랍아웃레이어 정리\n\n계산: (1) 입력의 일부를 임의로 0으로 만드는 역할 (2) 0이 안된것들은 스칼라배하여 드랍아웃을 통과한 모든 숫자들의 총합이 대체로 일정하게 되도록 조정\non/off: 학습시에는 dropout on / 학습을 하지 않을 경우는 dropout off\n느낌: 일부러 패널티를 안고 학습하는 느낌..\n효과: 오버피팅을 억제하는 효과가 있음\n\n\n참고: 오버피팅을 잡는 방법은 드랍아웃만 있는게 아니다.."
  },
  {
    "objectID": "posts/05wk-1.html#c.-드랍아웃-레이어의-위치",
    "href": "posts/05wk-1.html#c.-드랍아웃-레이어의-위치",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "C. 드랍아웃 레이어의 위치",
    "text": "C. 드랍아웃 레이어의 위치\n- ReLU,dropout의 특이한 성질: \\(\\text{dropout}(\\text{relu}({\\bf x}))=\\text{relu}(\\text{dropout}({\\bf x}))\\)\n\nu = torch.randn(10,2)\nr = torch.nn.ReLU()\nd = torch.nn.Dropout()\n\n\ntorch.manual_seed(0)\nd(r(u))\n\ntensor([[2.8004, 0.0000],\n        [0.0000, 1.4576],\n        [4.3925, 0.0000],\n        [0.0000, 1.4472],\n        [0.0000, 2.3459],\n        [0.0000, 0.0000],\n        [0.0000, 0.4245],\n        [0.0000, 1.8586],\n        [0.0000, 0.1394],\n        [0.0000, 0.0000]])\n\n\n\ntorch.manual_seed(0)\nr(d(u))\n\ntensor([[2.8004, 0.0000],\n        [-0.0000, 1.4576],\n        [4.3925, -0.0000],\n        [-0.0000, 1.4472],\n        [0.0000, 2.3459],\n        [0.0000, 0.0000],\n        [0.0000, 0.4245],\n        [0.0000, 1.8586],\n        [-0.0000, 0.1394],\n        [-0.0000, 0.0000]])\n\n\n- 다른 활성화함수는 성립안함\n\nu = torch.randn(10,2)\ns = torch.nn.Sigmoid()\nd = torch.nn.Dropout()\n\n\ntorch.manual_seed(0)\nd(s(u))\n\ntensor([[0.4801, 0.0000],\n        [0.0000, 1.4006],\n        [0.3487, 0.0000],\n        [0.0000, 1.2299],\n        [0.9213, 1.6180],\n        [1.1322, 0.0000],\n        [0.0000, 1.4407],\n        [0.6015, 1.4349],\n        [0.0000, 1.7626],\n        [0.0000, 0.0000]])\n\n\n\ntorch.manual_seed(0)\ns(d(u))\n\ntensor([[0.0907, 0.5000],\n        [0.5000, 0.8452],\n        [0.0427, 0.5000],\n        [0.5000, 0.7183],\n        [0.4218, 0.9472],\n        [0.6300, 0.5000],\n        [0.5000, 0.8691],\n        [0.1561, 0.8657],\n        [0.5000, 0.9822],\n        [0.5000, 0.5000]])\n\n\n- 결론: 드랍아웃은 활성화 함수 바로 뒤에 오는게 맞음. (그렇지 않다면 0을 만들 수 없는걸?) 그렇지만 ReLU의 경우 활성화 함수 직전에 취하기도 함."
  },
  {
    "objectID": "posts/05wk-1.html#d.-평균보정의-필요성-선택학습",
    "href": "posts/05wk-1.html#d.-평균보정의-필요성-선택학습",
    "title": "05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃",
    "section": "D. 평균보정의 필요성 (선택학습)",
    "text": "D. 평균보정의 필요성 (선택학습)\n\n\n\n\n\n\nNote\n\n\n\n90%의 드랍아웃에서 출력결과에 왜 x10하는지 좀 더 자세히 설명한 챕터입니다. 궁금하시다면 읽어보시고 아니라면 넘어가셔도 무방합니다.\n\n\n- 아래의 데이터를 관찰하자.\n\nx,_ = torch.randn(300).sort()\ny = relu(20*x) + torch.randn(300)\nx,y = x.reshape(-1,1), y.reshape(-1,1)\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n- 적합해보자.\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1000),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.1),\n    torch.nn.Linear(1000,1,bias=False),\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(5000):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nnet.eval()\n\nSequential(\n  (0): Linear(in_features=1, out_features=1000, bias=True)\n  (1): ReLU()\n  (2): Dropout(p=0.1, inplace=False)\n  (3): Linear(in_features=1000, out_features=1, bias=False)\n)\n\n\n\nnet.training\n\nFalse\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n- 주황색선이나오는 이유 설명해보자.\n\nU = net[:-1](x).data \nW = net[-1].weight.T \n\n아래3개는 동일한코드임\n\nnet(x).reshape(-1)[:10] # 코드1\n\ntensor([-0.9858, -0.5127, -0.4687,  0.0514,  0.0558,  0.2089,  0.2213,  0.2619,\n         0.2691,  0.2823], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n(U@W).reshape(-1)[:10] # 코드2\n\ntensor([-0.9858, -0.5127, -0.4687,  0.0514,  0.0558,  0.2089,  0.2213,  0.2619,\n         0.2691,  0.2823], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\n((U*W.reshape(-1)).sum(axis=1))[:10] # 코드3\n\ntensor([-0.9858, -0.5127, -0.4687,  0.0514,  0.0558,  0.2089,  0.2213,  0.2619,\n         0.2691,  0.2823], grad_fn=&lt;SliceBackward0&gt;)\n\n\n따라서 아래의 주황색선들의 .sum(axis=1) 하기만 하면 net(x)의 결과가 된다.\n\nplt.plot(x,U*W.reshape(-1).data,color=\"C1\",alpha=0.02);\n\n\n\n\n\n\n\n\n- 즉 왼쪽의 주황색선1이 모두 합쳐져서 오른쪽의 점선이된다.\n1 1000개가 있음\nfig,ax = plt.subplots(1,2,figsize=(9,3))\nax[0].plot(x,U*W.reshape(-1).data,color=\"C1\",alpha=0.02);\nax[0].set_title(\"1,000 ReLUs\")\nax[1].plot(x,net(x).data,'--',color=\"C1\")\nax[1].set_title(r\"$net({\\bf x})$=sum(1,000 ReLUs)\");\n\n\n\n\n\n\n\n\n\n만약에 왼쪽의 주황색선이 10%만 사용되어서 100개의 렐루만 사용되었다면? 대충 x10을 해줘야 net(x) 가 나오지 않겠어요?"
  },
  {
    "objectID": "posts/examguidelines.html",
    "href": "posts/examguidelines.html",
    "title": "A2: Exam Guidelines",
    "section": "",
    "text": "총 40분\n\n\n\n\n\n답안지 (.ipynb)\n시험 장면 영상 촬영본\n\n\n\n\n\n답안지와 영상촬영본 모두 LMS에 업로드\n\n\n\n\n\n\n\nZoom 로그인하여 혼자 새 회의 시작 (비디오, 마이크 셋팅 불필요)\n화면 공유 시작 \\(\\to\\) 전체화면 공유\n녹화 버튼 클릭\n시험 종료 후 화면공유 종료 \\(\\to\\) 녹화종료 \\(\\to\\) 영상을 이 컴퓨터에 저장\n\n기본 저장 위치: 내 PC &gt; 문서 &gt; Zoom 폴더\n\n\n※ Zoom 무료 계정은 40분 제한이 있으니, 필요한 경우 나누어 촬영\n\n\n\n\nCommand + Shift + 5 키 입력\n화면 하단 도구에서 전체 화면 지정 후 녹화 시작\n시험 종료 후 메뉴 막대에서 정지 버튼 클릭\n영상은 기본적으로 바탕화면에 저장됨\n\n\n기타 OBS Studio 등 녹화 프로그램을 활용해도 무방함. 녹화본은 반드시 시험 시작부터 종료까지 전 과정을 포함해야 하며 LMS 업로드 마감 시간 내 제출할 것"
  },
  {
    "objectID": "posts/examguidelines.html#시험-시간",
    "href": "posts/examguidelines.html#시험-시간",
    "title": "A2: Exam Guidelines",
    "section": "",
    "text": "총 40분"
  },
  {
    "objectID": "posts/examguidelines.html#제출물",
    "href": "posts/examguidelines.html#제출물",
    "title": "A2: Exam Guidelines",
    "section": "",
    "text": "답안지 (.ipynb)\n시험 장면 영상 촬영본"
  },
  {
    "objectID": "posts/examguidelines.html#제출-방법",
    "href": "posts/examguidelines.html#제출-방법",
    "title": "A2: Exam Guidelines",
    "section": "",
    "text": "답안지와 영상촬영본 모두 LMS에 업로드"
  },
  {
    "objectID": "posts/examguidelines.html#영상-촬영-방법",
    "href": "posts/examguidelines.html#영상-촬영-방법",
    "title": "A2: Exam Guidelines",
    "section": "",
    "text": "Zoom 로그인하여 혼자 새 회의 시작 (비디오, 마이크 셋팅 불필요)\n화면 공유 시작 \\(\\to\\) 전체화면 공유\n녹화 버튼 클릭\n시험 종료 후 화면공유 종료 \\(\\to\\) 녹화종료 \\(\\to\\) 영상을 이 컴퓨터에 저장\n\n기본 저장 위치: 내 PC &gt; 문서 &gt; Zoom 폴더\n\n\n※ Zoom 무료 계정은 40분 제한이 있으니, 필요한 경우 나누어 촬영\n\n\n\n\nCommand + Shift + 5 키 입력\n화면 하단 도구에서 전체 화면 지정 후 녹화 시작\n시험 종료 후 메뉴 막대에서 정지 버튼 클릭\n영상은 기본적으로 바탕화면에 저장됨\n\n\n기타 OBS Studio 등 녹화 프로그램을 활용해도 무방함. 녹화본은 반드시 시험 시작부터 종료까지 전 과정을 포함해야 하며 LMS 업로드 마감 시간 내 제출할 것"
  },
  {
    "objectID": "posts/14wk-1.html#a.-데이터-축적",
    "href": "posts/14wk-1.html#a.-데이터-축적",
    "title": "14wk-1: (강화학습) – 4x4 Grid World 환경의 이해",
    "section": "A. 데이터 축적",
    "text": "A. 데이터 축적\n- 랜덤에이전트를 이용해 무작위로 100,000 에피소드를 진행해보자.\n\nplayer = RandomAgent()\nenv = GridWorld()\nscores = [] \nscore = 0 \n#\nfor e in range(1,100000):\n    #---에피소드시작---#\n    while True:\n        # step1 -- 액션선택\n        player.act()\n        # step2 -- 환경반응 \n        player.next_state, player.reward, player.terminated = env.step(player.action)\n        # step3 -- 경험기록 & 학습 \n        player.save_experience()\n        player.learn()\n        # step4 --종료 조건 체크 & 후속 처리\n        if env.terminated:\n            score = score + player.reward\n            scores.append(score)\n            score = 0 \n            player.state = env.reset() \n            break\n        else: \n            score = score + player.reward            \n            player.state = player.next_state\n\n\n\n\n\n\n\nImportant\n\n\n\n강의노트 수정 2025-06-12\n노규호학생의 도움으로 예전강의의 오류를 발견하여 수정하였습니다.\n# 수정전\n...\n        if env.terminated:\n            ...\n        else: \n            score = score + player.reward\n            scores.append(score)            \n            player.state = player.next_state\n            \n# 수정후\n        if env.terminated:\n            ...\n        else: \n            score = score + player.reward\n#            scores.append(score)            ### &lt;--- 여기를 주석처리해야함!! \n            player.state = player.next_state\n:::\n\n::: {#ef29fdf9-b027-4d88-8bd7-1e5c6d3b08d9 .cell tags='[]' execution_count=82}\n``` {.python .cell-code}\nplayer.n_experience\n\n325268"
  },
  {
    "objectID": "posts/14wk-1.html#b.-첫번째-q_table",
    "href": "posts/14wk-1.html#b.-첫번째-q_table",
    "title": "14wk-1: (강화학습) – 4x4 Grid World 환경의 이해",
    "section": "B. 첫번째 q_table",
    "text": "B. 첫번째 q_table\n- 밴딧게임에서는 \\(q(a)\\) 를 정의했었음.\n\n\\(q(0) = 1\\)\n\\(q(1) = 10\\)\n\n- 여기에서는 \\(q(s_1,s_2,a)\\)를 정의해야함!\n\n\n\n\n\n\nNote\n\n\n\n직관적으로 아래의 그림이 떠오름 \n그림에 대응하는 \\(q(s_1,s_2,a)\\)의 값은 아래와 같음\n\n\\(a=0\\)\\(a=1\\)\\(a=2\\)\\(a=3\\)\n\n\n\\(a=0 \\Leftrightarrow \\text{\\tt action=right}\\)\n\\[ \\begin{bmatrix}\nq(0,0,0) & q(0,1,0) & q(0,2,0) & q(0,3,0) \\\\\nq(1,0,0) & q(1,1,0) & q(1,2,0) & q(1,3,0) \\\\\nq(2,0,0) & q(2,1,0) & q(2,2,0) & q(2,3,0) \\\\\nq(3,0,0) & q(3,1,0) &q(3,2,0) & q(3,3,0) \\\\\n\\end{bmatrix} =  \\begin{bmatrix}\n-1 & -1 & -1 & -10 \\\\\n-1 & -1 & -1 & -10 \\\\\n-1 & -1 & -1 & -10 \\\\\n-1 & -1 & 100 &  \\text{-} \\\\\n\\end{bmatrix}\n\\]\n\n\n\\(a=1 \\Leftrightarrow \\text{\\tt action=left}\\)\n\\[ \\begin{bmatrix}\nq(0,0,1) & q(0,1,1) & q(0,2,1) & q(0,3,1) \\\\\nq(1,0,1) & q(1,1,1) & q(1,2,1) & q(1,3,1) \\\\\nq(2,0,1) & q(2,1,1) & q(2,2,1) & q(2,3,1) \\\\\nq(3,0,1) & q(3,1,1) &q(3,2,1) & q(3,3,1) \\\\\n\\end{bmatrix} = \\begin{bmatrix}\n-10 & -1 & -1 & -1 \\\\\n-10& -1 & -1 & -1 \\\\\n-10 & -1 & -1 & -1 \\\\\n-10 & -1 & -1 &  \\text{-} \\\\\n\\end{bmatrix}\n\\]\n\n\n\\(a=2 \\Leftrightarrow \\text{\\tt action=down}\\)\n\\[  \\begin{bmatrix}\nq(0,0,2) & q(0,1,2) & q(0,2,2) & q(0,3,2) \\\\\nq(1,0,2) & q(1,1,2) & q(1,2,2) & q(1,3,2) \\\\\nq(2,0,2) & q(2,1,2) & q(2,2,2) & q(2,3,2) \\\\\nq(3,0,2) & q(3,1,2) &q(3,2,2) & q(3,3,2) \\\\\n\\end{bmatrix} = \\begin{bmatrix}\n-1 & -1 & -1 & -1 \\\\\n-1& -1 & -1 & -1 \\\\\n-1 & -1 & -1 & 100\\\\\n-10 & -10 & -10 &  \\text{-} \\\\\n\\end{bmatrix}\n\\]\n\n\n\\(a=3 \\Leftrightarrow \\text{\\tt action=up}\\)\n\\[  \\begin{bmatrix}\nq(0,0,3) & q(0,1,3) & q(0,2,3) & q(0,3,3) \\\\\nq(1,0,3) & q(1,1,3) & q(1,2,3) & q(1,3,3) \\\\\nq(2,0,3) & q(2,1,3) & q(2,2,3) & q(2,3,3) \\\\\nq(3,0,3) & q(3,1,3) &q(3,2,3) & q(3,3,3) \\\\\n\\end{bmatrix} =\\begin{bmatrix}\n-10 & -10 & -10 & -10\\\\\n-1& -1 & -1 & -1 \\\\\n-1 & -1 & -1 & -1 \\\\\n-1 & -1 & -1 &  \\text{-} \\\\\n\\end{bmatrix}\n\\]\n\n\n\n\n\n- 데이터를 바탕으로 \\(q(s_1,s_2,a)\\)를 구해보자.\n\nplayer.states[0], player.actions[0], player.rewards[0]\n\n(array([0, 0]), 0, -1)\n\n\n\nq_table = np.zeros((4,4,4))\ncount = np.zeros((4,4,4))\n\n\nmemory =  zip(player.states, player.actions, player.rewards)\nfor (s1,s2), a, r in memory:\n    q_table[s1,s2,a] = q_table[s1,s2,a] + r\n    count[s1,s2,a] = count[s1,s2,a] + 1 \n\n\ncount[count==0] = 0.001 \n\n\nq_table = q_table / count\n\n\nq_table[...,0], q_table[...,1], q_table[...,2], q_table[...,3]\n\n(array([[ -1.,  -1.,  -1., -10.],\n        [ -1.,  -1.,  -1., -10.],\n        [ -1.,  -1.,  -1., -10.],\n        [ -1.,  -1., 100.,   0.]]),\n array([[-10.,  -1.,  -1.,  -1.],\n        [-10.,  -1.,  -1.,  -1.],\n        [-10.,  -1.,  -1.,  -1.],\n        [-10.,  -1.,  -1.,   0.]]),\n array([[ -1.,  -1.,  -1.,  -1.],\n        [ -1.,  -1.,  -1.,  -1.],\n        [ -1.,  -1.,  -1., 100.],\n        [-10., -10., -10.,   0.]]),\n array([[-10., -10., -10., -10.],\n        [ -1.,  -1.,  -1.,  -1.],\n        [ -1.,  -1.,  -1.,  -1.],\n        [ -1.,  -1.,  -1.,   0.]]))\n\n\n- count를 사용하지 않는 방법은 없을까? – 테크닉\n\nq_table = np.zeros((4,4,4))\nmemory =  zip(player.states, player.actions, player.rewards)\nfor (s1,s2), a, r in memory:\n    qhat = q_table[s1,s2,a] # 내가 생각했던갓\n    q = r # 실제값\n    diff = q-qhat # 차이\n    q_table[s1,s2,a] = q_table[s1,s2,a]  + 0.01*diff# update\n\n\nq_table.round(2)\n\narray([[[ -1.  , -10.  ,  -1.  , -10.  ],\n        [ -1.  ,  -1.  ,  -1.  , -10.  ],\n        [ -1.  ,  -1.  ,  -1.  , -10.  ],\n        [-10.  ,  -1.  ,  -1.  , -10.  ]],\n\n       [[ -1.  , -10.  ,  -1.  ,  -1.  ],\n        [ -1.  ,  -1.  ,  -1.  ,  -1.  ],\n        [ -1.  ,  -1.  ,  -1.  ,  -1.  ],\n        [-10.  ,  -1.  ,  -1.  ,  -1.  ]],\n\n       [[ -1.  , -10.  ,  -1.  ,  -1.  ],\n        [ -1.  ,  -1.  ,  -1.  ,  -1.  ],\n        [ -1.  ,  -1.  ,  -1.  ,  -1.  ],\n        [-10.  ,  -1.  ,  99.99,  -1.  ]],\n\n       [[ -1.  , -10.  , -10.  ,  -1.  ],\n        [ -1.  ,  -1.  , -10.  ,  -1.  ],\n        [ 99.99,  -1.  , -10.  ,  -1.  ],\n        [  0.  ,   0.  ,   0.  ,   0.  ]]])"
  },
  {
    "objectID": "posts/14wk-1.html#c.-첫번째-q_table보다-나은-것",
    "href": "posts/14wk-1.html#c.-첫번째-q_table보다-나은-것",
    "title": "14wk-1: (강화학습) – 4x4 Grid World 환경의 이해",
    "section": "C. 첫번째 q_table보다 나은 것?",
    "text": "C. 첫번째 q_table보다 나은 것?\n- 첫번째 q_table을 알고있다고 가정하자.\n\n- 정책시각화 (합리적인 행동)\n\n- 이게 최선의 정책일까?"
  },
  {
    "objectID": "posts/15wk-1.html",
    "href": "posts/15wk-1.html",
    "title": "15wk-1: (강화학습) – LunarLander",
    "section": "",
    "text": "1. 강의영상\n\n# {{&lt;video https://youtu.be/playlist?list=PLQqh36zP38-zesXx2Ad1CQF3V85SBnmcl&si=1N-UhzaPrEwP2sNn &gt;}}\n\n\n\n2. Imports\n\n\n\n\n\n\nNote\n\n\n\n코랩사용자는 아래코드 실행후 실습할것 \n!pip install swig\n!pip install gymnasium[box2d]\n학과서버사용자는 가상환경에서 아래를 설치\nconda install conda-forge::gymnasium-box2d \n\n\n\nimport gymnasium as gym\n#--#\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation\nimport IPython\n#--#\nimport collections\nimport random\n#--#\nimport torch\n\n\ndef show(imgs,jump=10):\n    imgs = imgs[::jump]\n    fig = plt.Figure()\n    ax = fig.subplots()\n    def update(i):\n        ax.imshow(imgs[i])\n    ani = FuncAnimation(fig,update,frames=len(imgs))\n    display(IPython.display.HTML(ani.to_jshtml()))\n\n\n\n3. 예비학습\n- random.sample()의 용법을 살펴보자.\n# 예시1\n\nrandom.sample([1,2,3,4,5],2)\n\n[3, 4]\n\n\n# 예시2\n\ns = [[0,0], [0,2], [3,2]]\na = [0,1,2]\nmemory = list(zip(s,a))\nrandom.sample(memory,2)\n\n[([0, 0], 0), ([0, 2], 1)]\n\n\n\n\n4. env: LunarLander\n- ref: https://gymnasium.farama.org/environments/box2d/lunar_lander/\n- Lunar Lander: 요약\nObservation Space (State Space) – 8개의 변수\n\n착륙선의 x 좌표\n착륙선의 y 좌표\n착륙선의 x 속도\n착륙선의 y 속도\n착륙선의 각도\n착륙선의 각속도\n왼쪽 다리가 땅에 닿아있는지 여부 (1 또는 0)\n오른쪽 다리가 땅에 닿아있는지 여부 (1 또는 0)\n\nAction Space – 4개의 변수\n\n{0 : 아무 행동도 하지 않음}\n{1 : 왼쪽 엔진 발사 (오른쪽으로 기울임)}\n{2 : 메인 엔진 발사 (위로 밀어 올림)}\n{3 : 오른쪽 엔진 발사 (왼쪽으로 기울임)}\n\nReward\n\n거리 보상: 착륙 패드에 가까울수록 보상 증가\n속도 보상: 속도가 낮을수록 보상 증가\n각도 보상: 각도가 수직에 가까울수록 보상 증가\n착륙 다리 보상: 다리가 착륙 패드에 닿으면 보상\n연료 사용 패널티: 엔진 사용 시 패널티\n안전한 착륙 보상: 안정적으로 착륙 시 큰 보상 (+100~+140)\n충돌 패널티: 착륙 패드 이외의 장소에 충돌 시 패널티 (-100)\n\n- 환경생성\n\nenv = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\")\nenv \n\n&lt;frozen importlib._bootstrap&gt;:228: RuntimeWarning: Your system is avx2 capable but pygame was not built with support for it. The performance of some of your blits could be adversely affected. Consider enabling compile time detection with environment variables like PYGAME_DETECT_AVX2=1 if you are compiling without cross compilation.\n\n\n&lt;TimeLimit&lt;OrderEnforcing&lt;PassiveEnvChecker&lt;LunarLander&lt;LunarLander-v3&gt;&gt;&gt;&gt;&gt;\n\n\n- state_space\n\nenv.observation_space.sample()\n\narray([-0.97548735,  1.9658699 , -5.502299  , -3.0781555 , -0.1566145 ,\n        5.4568334 ,  0.5433386 ,  0.08443172], dtype=float32)\n\n\n\n8개의 숫자가 포함된 array가 나옴\n이 8개의 숫자는 각각 상태를 의미함\n\n- action_space\n\nenv.action_space.sample()\n\n3\n\n\n\n0,1,2,3 중 하나가 랜덤으로 뽑힘\n\n- env.reset()\n\nenv.reset()\n\n(array([-0.00374269,  1.4069686 , -0.37910524, -0.17564307,  0.00434359,\n         0.08587295,  0.        ,  0.        ], dtype=float32),\n {})\n\n\n- env.render()\n\nplt.imshow(env.render())\n\n\n\n\n\n\n\n\n- env.step\n\nenv.step??\n\n\nSignature: env.step(action: 'ActType') -&gt; 'tuple[ObsType, SupportsFloat, bool, bool, dict[str, Any]]'\nSource:   \n    def step(\n        self, action: ActType\n    ) -&gt; tuple[ObsType, SupportsFloat, bool, bool, dict[str, Any]]:\n        \"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\n        Args:\n            action: The environment step action\n        Returns:\n            The environment step ``(observation, reward, terminated, truncated, info)`` with `truncated=True`\n            if the number of steps elapsed &gt;= max episode steps\n        \"\"\"\n        observation, reward, terminated, truncated, info = self.env.step(action)\n        self._elapsed_steps += 1\n        if self._elapsed_steps &gt;= self._max_episode_steps:\n            truncated = True\n        return observation, reward, terminated, truncated, info\nFile:      ~/anaconda3/envs/dl2025/lib/python3.9/site-packages/gymnasium/wrappers/common.py\nType:      method\n\n\n\n\n리턴되는 값은 observation, reward, terminated, truncated, info\n우리가 쓰는 값은 observation, reward, terminated, truncated\n\n- play\n첫시작화면\n\nenv.reset()\nplt.imshow(env.render())\n\n\n\n\n\n\n\n\n플레이해보자\n\nfor _ in range(5):\n    env.step(0) \n    env.step(3) \nplt.imshow(env.render())\n\n\n\n\n\n\n\n\n\n\n5. 시각화\n\nstate, _ = env.reset()\nimgs = []\nfor t in range(500):\n    action = env.action_space.sample()\n    next_state, reward, terminated, truncated, _ = env.step(action)\n    imgs.append(env.render())\n    state = next_state \n    if terminated or truncated:\n        break\n\n\nshow(imgs)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n6. RandomAgent\n\nclass RandomAgent:\n    def __init__(self):\n        self.action_spcae = gym.spaces.Discrete(4)\n        self.n_experieces = 0 \n        #---#\n        self.state = None \n        self.action = None \n        self.reward = None \n        self.next_state = None \n        self.terminated = None \n        #---#\n        self.states = collections.deque(maxlen = 5000)\n        self.actions = collections.deque(maxlen = 5000)\n        self.rewards = collections.deque(maxlen = 5000)\n        self.next_states = collections.deque(maxlen = 5000)\n        self.terminations = collections.deque(maxlen = 5000)\n    def act(self):\n        self.action = self.action_spcae.sample()\n    def learn(self):\n        pass \n    def save_experience(self):\n        self.states.append(torch.tensor(self.state))\n        self.actions.append(self.action)\n        self.rewards.append(self.reward)\n        self.next_states.append(torch.tensor(self.next_state))\n        self.terminations.append(self.terminated)\n        self.n_experieces = self.n_experieces+1\n\n\nenv = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\")\nplayer = RandomAgent()\nplayer.state,_ = env.reset()\nfor e in range(1,101):\n    while True:\n        # step1\n        player.act()\n        # step2\n        player.next_state, player.reward, player.terminated, player.truncated, _ = env.step(player.action)\n        # step3\n        player.save_experience()\n        player.learn()\n        # step4 \n        if player.terminated or player.truncated: \n            player.state, _ = env.reset()\n            break \n        else: \n            player.state = player.next_state\n\n\n\n7. q_net\n\n# 이제 우리가 할것: q_table --&gt; action 을 결정해야함. \n\n# 4x4 그리드 -- 복습 \n# q_table[상태] = [행동0을했을때 품질, 행동1을했을때품질, 행동2를했을때품질, 행동3을했을때품질]  \n# 행동 = argmax(q_talbe[상태])\n\n# 루나랜더 -- 오늘 할것 \n# q_net[8개의숫자] = [행동0을했을때 품질, 행동1을했을때품질, 행동2를했을때품질, 행동3을했을때품질] # 결국 숫자8개를 숫자4개로 만들어주는 적당한 q_net을 구성\n# 행동 = argmax(q_net[8개의숫자])\n\n- 전략: 4x4에서 q_table에 대응하는 뭔가가 있으면 된다. 그런데 q_table와 같이 테이블 형식으로는 힘들것 같다. \\(\\to\\) q_net를 만들자.\n\n4x4 grid: 상태공간의 차원은 2차원이며 가질수 있는 값은 16개, 각 상태공간에서 할수 있는 행동이 4개 -&gt; 총 16*4의 경우의 수에 대한 reward만 조사하면 되었음\nLunarLander: 상태공간의 차원은 8차원이지만 가질수 있는 값의 범위는 무한대 -&gt; 무수히 많은 경우에 대한 reward 값을 조사하는건 현실적으로 불가능\n\n상황\n\nstate = player.states[100]\naction = player.actions[100]\nreward = player.rewards[100]\nnext_state = player.next_states[100]\nterminated = player.terminations[100]\n\n1. q_net\n\nplayer.q_net = torch.nn.Sequential(\n    torch.nn.Linear(8,256),\n    torch.nn.ReLU(),\n    torch.nn.Linear(256,128),\n    torch.nn.ReLU(),\n    torch.nn.Linear(128,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,4)\n)\n\n\nplayer.q_net(state)\n\ntensor([-0.0910,  0.0414,  0.0588,  0.0722], grad_fn=&lt;ViewBackward0&gt;)\n\n\n\n8개의 숫자가 들어가서 4개의 숫자가 나옴\n\n2. q_hat\n\nq_hat = player.q_net(state)[action]\n\n3. q (\\(q = r + 0.99 \\times {\\tt future}\\))\n\nif terminated: \n    q = reward # q는 꼬리표가 없는 숫자 \nelse: \n    future = player.q_net(next_state).max().data # future에 꼬리표가 있으면 q에도 꼬리표가 생기므로 꼬리표 제거 \n    q = reward + 0.99 * future # q는 꼬리표가 없는 숫자 \n\n4. q_hat 을 점점 q 와 비슷하게 만드는 과정 = player.q_net를 학습하는 과정\n\n# loss = (q_hat - q)**2\n# loss를 점차 줄이면됨\n\n\nplayer.optimizr = torch.optim.Adam(player.q_net.parameters())\nfor epoc in range(5):\n    memory = list(zip(player.states, player.actions, player.rewards, player.next_states, player.terminations))\n    mini_batch = random.sample(memory,64)\n    # step1-2 \n    loss = 0\n    for s,a,r,ss,tmd in mini_batch:\n        q_hat = player.q_net(s)[a]\n        if tmd: \n            q = r \n        else: \n            future = player.q_net(ss).max().data \n            q = r + 0.99 * future\n        loss = loss + (q_hat-q)**2\n    loss = loss / 64\n    # step3\n    loss.backward()\n    # step4 \n    player.optimizr.step()\n    player.optimizr.zero_grad()\n\n5. 행동..?\n\n# 이전에는 아래와 같은 방식\n## 1. 특정 시점 이전에는 계속 랜덤액션만\n## 2. 특정 시점 이후에는 계속 q_table에서 도출되는 행동만 \n# 이번에는 아래와 같이 해보자. \n## 1. 처음에는 랜덤액션\n## 2. 점차 에피소드가 지날수록, q_net에서 근거한 행동만\n\n\nplayer.eps = 0.5 \nif random.random() &lt; player.eps: \n    player.action = player.action_spcae.sample()\nelse:\n    state = torch.tensor(player.state)\n    player.action = player.q_net(state).argmax().item()\n\n\n# 다음에피소드에서는 아래와 같이 확률을 조금 낮게 \nplayer.eps = player.eps* 0.99 \n\n\n\n8. Agent\n\nclass Agent(RandomAgent):\n    def __init__(self):\n        super().__init__()\n        self.eps = 1.0 \n        self.q_net = torch.nn.Sequential(\n            torch.nn.Linear(8,256),\n            torch.nn.ReLU(),\n            torch.nn.Linear(256,128),\n            torch.nn.ReLU(),\n            torch.nn.Linear(128,64),\n            torch.nn.ReLU(),\n            torch.nn.Linear(64,4)\n        )\n        self.optimizr = torch.optim.Adam(self.q_net.parameters())\n    def act(self):\n        if random.random() &lt; self.eps: \n            self.action = self.action_spcae.sample()\n        else:\n            state = torch.tensor(self.state)\n            self.action = self.q_net(state).argmax().item()\n    def learn(self):\n        if self.n_experieces &gt; 64:\n            for epoc in range(1):\n                memory = list(zip(self.states, self.actions, self.rewards, self.next_states, self.terminations))\n                mini_batch = random.sample(memory,64)\n                # step1-2 \n                loss = 0\n                for s,a,r,ss,tmd in mini_batch:\n                    q_hat = self.q_net(s)[a]\n                    if tmd: \n                        q = r \n                    else: \n                        future = self.q_net(ss).max().data \n                        q = r + 0.99 * future\n                    loss = loss + (q_hat-q)**2\n                loss = loss / 64\n                # step3\n                loss.backward()\n                # step4 \n                self.optimizr.step()\n                self.optimizr.zero_grad()        \n\n\n\n9. Solve\n\nenv = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\")\nplayer = Agent()\nplayer.state, _ = env.reset()\nscore = 0\nplaytime = 0\nscores = [] \nplaytimes = []\n#---#\nfor e in range(1,21):\n    #---에피소드시작---#\n    while True:\n        #step1\n        player.act()\n        #step2\n        player.next_state, player.reward, player.terminated, player.truncated, _ = env.step(player.action)\n        #step3\n        player.save_experience()\n        player.learn()\n        #step4\n        if player.terminated or player.truncated:\n            score = score + player.reward\n            scores.append(score)\n            score = 0\n            playtimes.append(playtime)\n            playtime = 0\n            player.state, _ = env.reset()\n            break\n        else: \n            score = score + player.reward\n            playtime = playtime + 1 \n            player.state = player.next_state\n    #---에피소드끝---#\n    player.eps = player.eps * 0.995\n    if (e % 2) ==0:\n        print(\n            f\"에피소드: {e}\\t\",\n            f\"경험: {player.n_experieces}\\t\",\n            f\"점수(평균): {np.mean(scores[-100:]):.2f}\\t\",\n            f\"게임시간(평균): {np.mean(playtimes[-100:]):.2f}\\t\",\n            f\"돌방행동: {player.eps:.2f}\\t\",\n        )\n    if np.mean(scores[-100:]) &gt; 200:\n        print(\"--루나랜더 클리어(2025.06.14.)--\")\n        break\n\n\n아래코드 실행하면 제가 실습에 사용한 파일 받아올수있어요\n!wget https://github.com/guebin/DL2025/raw/main/posts/q_net.pth\n\n\nplayer_dummy = Agent()\nplayer_dummy.q_net.load_state_dict(\n    torch.load(\"q_net.pth\")\n)\nplayer_dummy.state, _ = env.reset()\nimgs = []\n\n\nplayer_dummy.eps = 0 \nwhile True:\n    player_dummy.act()\n    player_dummy.next_state, player_dummy.reward, player_dummy.terminated, player_dummy.truncated, _ = env.step(player_dummy.action)\n    imgs.append(env.render())\n    if player_dummy.terminated or player_dummy.truncated:\n        break\n    else:\n        player_dummy.state = player_dummy.next_state\n\n\nshow(imgs)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-2.html#a.-로지스틱-모형",
    "href": "posts/03wk-2.html#a.-로지스틱-모형",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 로지스틱 모형",
    "text": "A. 로지스틱 모형\n- \\(x\\)가 커질수록 (혹은 작아질수록) \\(y=1\\)이 잘나오는 모형은 아래와 같이 설계할 수 있음 &lt;— 외우세요!!!\n\n\\(y_i \\sim {\\cal B}(\\pi_i),\\quad\\) where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)} = \\frac{1}{1+\\exp(-w_0-w_1x_i)}\\)\n\\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\n- 회귀모형과 로지스틱 모형의 비교\n\n회귀모형: \\(y_i \\sim {\\cal N}(w_0+w_1x_i, \\sigma^2)\\)1\n로지스틱: \\(y_i \\sim {\\cal B}\\big(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\big)\\)\n\n1 원래는 이렇게 썼었지.. \\(y_i = w_0 + w_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim {\\cal N}(0,\\sigma^2)\\)- 우리가 예측하고 싶은것\n\n회귀모형: 정규분포의 평균을 예측하고 싶음. 즉 \\(w_0+w_1x_i\\)를 예측하고 싶음. 예측값으로는 \\(\\hat{w}_0 + \\hat{w}_1x_i\\)를 사용!\n로지스틱: 베르누이의 평균을 예측하고 싶음. 즉 \\(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)를 예측하고 싶음. 예측값으로는 \\(\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}\\)를 사용!"
  },
  {
    "objectID": "posts/03wk-2.html#b.-데이터-스펙과-취업",
    "href": "posts/03wk-2.html#b.-데이터-스펙과-취업",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 데이터 – 스펙과 취업",
    "text": "B. 데이터 – 스펙과 취업\n\ntorch.manual_seed(43052)\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nw0,w1 = -1, 5\nprob = torch.exp(w0+w1*x) / (1+torch.exp(w0+w1*x)) \ny = torch.bernoulli(prob)\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'.',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.legend()"
  },
  {
    "objectID": "posts/03wk-2.html#c.-step1-net-설계-모델링",
    "href": "posts/03wk-2.html#c.-step1-net-설계-모델링",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "C. Step1: net 설계 (모델링)",
    "text": "C. Step1: net 설계 (모델링)\n- 최초의 곡선을 그려보자.\n\n최초의직선: \\(\\hat{y}_i= \\hat{w}_0+\\hat{w}_1x_i\\) 에서 아무 \\(\\hat{w}_0\\), \\(\\hat{w}_1\\) 을 설정하면 된다.\n최초의곡선: \\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\) 에서 아무 \\(\\hat{w}_0\\), \\(\\hat{w}_1\\) 을 설정하면 된다.\n\n\n\n\n\n\n\nNote\n\n\n\n일단은 초기 설정값을 \\(\\hat{w}_0 = -0.8\\), \\(\\hat{w}_1 = -0.3\\) 으로 하자. (실제값은 \\(w_0=-1\\), \\(w_1=5\\) 이다)\n\n\n# 방법1 – l1, sigmoid\n\nl1 = torch.nn.Linear(1,1)\nl1(x) # w0hat + w1hat*x \n\ntensor([[ 0.6311],\n        [ 0.6304],\n        [ 0.6297],\n        ...,\n        [-0.6902],\n        [-0.6909],\n        [-0.6916]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n\n\ndef sigmoid(x):\n    return torch.exp(x)/(1+torch.exp(x))\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.plot(x,sigmoid(l1(x)).data,'--b', label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$ -- first curve\")\nplt.legend()\n\n\n\n\n\n\n\n\n#\n# 방법2 – l1, a1\n\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n\n\na1 = torch.nn.Sigmoid()\n\n\nsigmoid(l1(x)), a1(l1(x)) # 똑같아요\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;DivBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;))\n\n\n- 지금까지의 구현 확인\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.plot(x,a1(l1(x)).data,'--b', label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$ -- first curve with $(a_1 \\circ l_1)(x)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n#\n# 방법3 - l1, a1 만들고 \\(\\to\\) net\n- 관찰: 지금 아래의 구조이다.\n\\[{\\bf x} \\overset{l_1}{\\to} {\\bf u} \\overset{a_1}{\\to} {\\bf v} = \\hat{\\bf y}\\]\n- 소망: 함수 \\(l_1, a_1\\) 의 합성을 하나로 묶어서\n\\[(a_1\\circ l_1)({\\bf x}) := net({\\bf x})\\]\n이러한 기능을 하는 하나의 함수 \\(net\\)을 만들 수 없을까?\n\nl1 = torch.nn.Linear(1,1)\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\na1 = torch.nn.Sigmoid()\n\n\nnet = torch.nn.Sequential(l1,a1) #l1을 취하고 그다음에 a1을 취하라는 의미\n\n\nnet(x), a1(l1(x)), sigmoid(l1(x))\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;DivBackward0&gt;))\n\n\n* net 구조 잠깐 살펴보기\n\nnet[0], net[1]\n\n(Linear(in_features=1, out_features=1, bias=True), Sigmoid())\n\n\n\nl1 is net[0]\n\nTrue\n\n\n\na1 is net[1]\n\nTrue\n\n\n#\n# 방법4 – net을 바로 만들기\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nnet[0].weight.data = torch.tensor([[-0.3]])\nnet[0].bias.data = torch.tensor([-0.8])\nyhat = net(x)\n\n\nnet(x)\n\ntensor([[0.3775],\n        [0.3775],\n        [0.3774],\n        ...,\n        [0.2499],\n        [0.2498],\n        [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n#"
  },
  {
    "objectID": "posts/03wk-2.html#d.-step14",
    "href": "posts/03wk-2.html#d.-step14",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "D. Step1~4",
    "text": "D. Step1~4\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net \nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n\nfor epoc in range(4900):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 5000 epochs')\n\nText(0.5, 1.0, 'after 5000 epochs')"
  },
  {
    "objectID": "posts/03wk-2.html#a.-시각화를-위한-준비",
    "href": "posts/03wk-2.html#a.-시각화를-위한-준비",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 시각화를 위한 준비",
    "text": "A. 시각화를 위한 준비\n\ndef plot_loss(loss_fn, ax=None, Wstar=[-1,5]):\n    w0hat,w1hat =torch.meshgrid(torch.arange(-10,3,0.1),torch.arange(-1,10,0.1),indexing='ij')\n    w0hat = w0hat.reshape(-1)\n    w1hat = w1hat.reshape(-1)\n    def l(w0hat,w1hat):\n        yhat = torch.exp(w0hat+w1hat*x)/(1+torch.exp(w0hat+w1hat*x))\n        return loss_fn(yhat,y) \n    loss = list(map(l,w0hat,w1hat))\n    #---#\n    if ax is None: \n        fig = plt.figure()\n        ax = fig.add_subplot(1,1,1,projection='3d')\n    ax.scatter(w0hat,w1hat,loss,s=0.001) \n    ax.scatter(w0hat[::20],w1hat[::20],loss[::20],s=0.1,color='C0') \n    w0star,w1star = np.array(Wstar).reshape(-1)\n    ax.scatter(w0star,w1star,l(w0star,w1star),s=200,marker='*',color='red',label=f\"W=[{w0star:.1f},{w1star:.1f}]\")\n    #---#\n    ax.elev = 15\n    ax.dist = -20\n    ax.azim = 75    \n    ax.legend()\n    ax.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax.set_xticks([-10,-5,0])  # x축 틱 간격 설정\n    ax.set_yticks([-10,0,10])  # y축 틱 간격 설정\n\n\ndef _learn_and_record(net, loss_fn, optimizr):\n    yhat_history = [] \n    loss_history = []\n    What_history = []\n    Whatgrad_history = []\n    What_history.append([net[0].bias.data.item(), net[0].weight.data.item()])\n    for epoc in range(100): \n        ## step1 \n        yhat = net(x)\n        ## step2 \n        loss = loss_fn(yhat,y)\n        ## step3\n        loss.backward() \n        ## step4 \n        optimizr.step()\n        ## record \n        if epoc % 5 ==0: \n            yhat_history.append(yhat.reshape(-1).data.tolist())\n            loss_history.append(loss.item())\n            What_history.append([net[0].bias.data.item(), net[0].weight.data.item()])\n            Whatgrad_history.append([net[0].bias.grad.item(), net[0].weight.grad.item()])\n        optimizr.zero_grad() \n        \n    return yhat_history, loss_history, What_history, Whatgrad_history\n    \ndef show_animation(net, loss_fn, optimizr):\n    yhat_history,loss_history,What_history,Whatgrad_history = _learn_and_record(net,loss_fn,optimizr)\n    \n    fig = plt.figure(figsize=(7.5,3.5))\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n    ## ax1: 왼쪽그림 \n    ax1.scatter(x,y,alpha=0.01)\n    ax1.scatter(x[0],y[0],color='C0',label=r\"observed data = $(x_i,y_i)$\")\n    ax1.plot(x,prob,'--',label=r\"prob (true) = $(x_i,\\frac{exp(-1+5x_i)}{1+exp(-1+5x_i)})$\")    \n    line, = ax1.plot(x,yhat_history[0],'--',label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$\") \n    ax1.legend()\n    ## ax2: 오른쪽그림 \n    plot_loss(loss_fn,ax2)\n    ax2.scatter(np.array(What_history)[0,0],np.array(What_history)[0,1],loss_history[0],color='blue',s=200,marker='*')    \n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        w0hat = np.array(What_history)[epoc,0]\n        w1hat = np.array(What_history)[epoc,1]\n        w0hatgrad = np.array(Whatgrad_history)[epoc,0]\n        w1hatgrad = np.array(Whatgrad_history)[epoc,1]\n        ax2.scatter(w0hat,w1hat,loss_history[epoc],color='grey')\n        ax2.set_title(f\"What.grad=[{w0hatgrad:.4f},{w1hatgrad:.4f}]\",y=0.8)\n        fig.suptitle(f\"epoch={epoc*5} // What=[{w0hat:.2f},{w1hat:.2f}] // Loss={loss_fn.__class__.__name__} // Opt={optimizr.__class__.__name__}\")\n        return line\n    ani = animation.FuncAnimation(fig, animate, frames=20)    \n    plt.close()\n    return ani\n\n\nfrom matplotlib import animation\nplt.rcParams[\"animation.html\"] = \"jshtml\"\n\n함수사용법\n\nloss_fn = torch.nn.MSELoss()\nplot_loss(loss_fn)\n\n\n\n\n\n\n\n\n\ntorch.manual_seed(42)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-2.html#b.-좋은-초기값",
    "href": "posts/03wk-2.html#b.-좋은-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 좋은 초기값",
    "text": "B. 좋은 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-2.html#c.-가능성-있는-초기값",
    "href": "posts/03wk-2.html#c.-가능성-있는-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 가능성 있는 초기값",
    "text": "C. 가능성 있는 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-2.html#d.-최악의-초기값",
    "href": "posts/03wk-2.html#d.-최악의-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 최악의 초기값",
    "text": "D. 최악의 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n해결하는 접근법:\n\n컴공스타일: 에폭을 늘려볼까?\n산공스타일: 옵티마이저를 바꿔볼까?\n통계스타일: Loss를 바꿔볼까?"
  },
  {
    "objectID": "posts/03wk-2.html#a.-bce-loss를-사용하여-학습",
    "href": "posts/03wk-2.html#a.-bce-loss를-사용하여-학습",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "A. BCE Loss를 사용하여 학습",
    "text": "A. BCE Loss를 사용하여 학습\n- BCE loss라는게 있음.\n\n\\(loss= - \\sum_{i=1}^{n} \\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\)\nhttps://en.wikipedia.org/wiki/Cross-entropy\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net \nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    #loss = torch.mean((y-yhat)**2) # loss_fn(yhat,y)\n    loss = -torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat))\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n같은 100 에폭인데 훨씬 잘맞춤..\n- loss수식을 못외우겠다면?\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net \nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) # yhat부터 써야함\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,prob,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')"
  },
  {
    "objectID": "posts/03wk-2.html#b.-loss-function-시각화",
    "href": "posts/03wk-2.html#b.-loss-function-시각화",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "B. Loss Function 시각화",
    "text": "B. Loss Function 시각화\n\nplot_loss(torch.nn.MSELoss())\n\n\n\n\n\n\n\n\n\nplot_loss(torch.nn.BCELoss())\n\n\n\n\n\n\n\n\n- 비교해보자.\n\nfig = plt.figure()\nax1 = fig.add_subplot(1,2,1,projection='3d')\nax2 = fig.add_subplot(1,2,2,projection='3d')\nplot_loss(torch.nn.MSELoss(),ax1)\nplot_loss(torch.nn.BCELoss(),ax2)"
  },
  {
    "objectID": "posts/03wk-2.html#c.-학습과정-시각화-좋은-초기값",
    "href": "posts/03wk-2.html#c.-학습과정-시각화-좋은-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 학습과정 시각화 – 좋은 초기값",
    "text": "C. 학습과정 시각화 – 좋은 초기값\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-2.html#d.-학습과정-시각화-가능성-있는-초기값",
    "href": "posts/03wk-2.html#d.-학습과정-시각화-가능성-있는-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 학습과정 시각화 – 가능성 있는 초기값",
    "text": "D. 학습과정 시각화 – 가능성 있는 초기값\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-2.html#e.-학습과정-시각화-최악의-초기값",
    "href": "posts/03wk-2.html#e.-학습과정-시각화-최악의-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "E. 학습과정 시각화 – 최악의 초기값",
    "text": "E. 학습과정 시각화 – 최악의 초기값\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-2.html#a.-학습과정-시각화-좋은-초기값",
    "href": "posts/03wk-2.html#a.-학습과정-시각화-좋은-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 학습과정 시각화 – 좋은 초기값",
    "text": "A. 학습과정 시각화 – 좋은 초기값\n- MSELoss + SGD\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8470])\nnet[0].weight.data = torch.tensor([[-0.3467]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-2.html#b.-학습과정-시각화-가능성-있는-초기값",
    "href": "posts/03wk-2.html#b.-학습과정-시각화-가능성-있는-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 학습과정 시각화 – 가능성 있는 초기값",
    "text": "B. 학습과정 시각화 – 가능성 있는 초기값\n- MSELoss + SGD\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-2.html#c.-학습과정-시각화-최악의-초기값",
    "href": "posts/03wk-2.html#c.-학습과정-시각화-최악의-초기값",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 학습과정 시각화 – 최악의 초기값",
    "text": "C. 학습과정 시각화 – 최악의 초기값\n- MSELoss + SGD\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-2.html#d.-참고자료",
    "href": "posts/03wk-2.html#d.-참고자료",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 참고자료",
    "text": "D. 참고자료\nhttps://www.youtube.com/watch?v=MD2fYip6QsQ\n\n11:50 – Momentum\n12:30 – RMSprop\n15:55 – Adam"
  },
  {
    "objectID": "posts/03wk-2.html#a.-신문기사-데이터의-모티브",
    "href": "posts/03wk-2.html#a.-신문기사-데이터의-모티브",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 신문기사 (데이터의 모티브)",
    "text": "A. 신문기사 (데이터의 모티브)\n- 스펙이 높아도 취업이 안된다고 합니다..\n중소·지방 기업 “뽑아봤자 그만두니까”\n중소기업 관계자들은 고스펙 지원자를 꺼리는 이유로 높은 퇴직률을 꼽는다. 여건이 좋은 대기업으로 이직하거나 회사를 관두는 경우가 많다는 하소연이다. 고용정보원이 지난 3일 공개한 자료에 따르면 중소기업 청년취업자 가운데 49.5%가 2년 내에 회사를 그만두는 것으로 나타났다.\n중소 IT업체 관계자는 “기업 입장에서 가장 뼈아픈 게 신입사원이 그만둬서 새로 뽑는 일”이라며 “명문대 나온 스펙 좋은 지원자를 뽑아놔도 1년을 채우지 않고 그만두는 사원이 대부분이라 우리도 눈을 낮춰 사람을 뽑는다”고 말했다."
  },
  {
    "objectID": "posts/03wk-2.html#b.-가짜데이터-스펙의-역설",
    "href": "posts/03wk-2.html#b.-가짜데이터-스펙의-역설",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 가짜데이터 – 스펙의 역설",
    "text": "B. 가짜데이터 – 스펙의 역설\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2025/main/posts/ironyofspec.csv\")\ndf\n\n\n\n\n\n\n\n\nx\nprob\ny\n\n\n\n\n0\n-1.000000\n0.000045\n0.0\n\n\n1\n-0.998999\n0.000046\n0.0\n\n\n2\n-0.997999\n0.000047\n0.0\n\n\n3\n-0.996998\n0.000047\n0.0\n\n\n4\n-0.995998\n0.000048\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n0.995998\n0.505002\n0.0\n\n\n1996\n0.996998\n0.503752\n0.0\n\n\n1997\n0.997999\n0.502501\n0.0\n\n\n1998\n0.998999\n0.501251\n1.0\n\n\n1999\n1.000000\n0.500000\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.legend()"
  },
  {
    "objectID": "posts/03wk-2.html#c.-로지스틱으로-적합",
    "href": "posts/03wk-2.html#c.-로지스틱으로-적합",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 로지스틱으로 적합",
    "text": "C. 로지스틱으로 적합\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---# \nfor epoc in range(5000):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.plot(x,net(x).data, '--', label= r\"prob (estimated) = $(x_i,\\hat{y}_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- Epoch을 10억번으로 설정해도 이건 못 맞출것 같음."
  },
  {
    "objectID": "posts/03wk-2.html#d.-로지스틱-한계극복-아이디어만",
    "href": "posts/03wk-2.html#d.-로지스틱-한계극복-아이디어만",
    "title": "03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 로지스틱 한계극복 – 아이디어만",
    "text": "D. 로지스틱 한계극복 – 아이디어만\n- sigmoid를 넣기 전의 상태가 직선이 아니라 꺽이는 직선이야 한다.\n\na = torch.nn.Sigmoid()\n\n\nfig,ax = plt.subplots(4,2,figsize=(8,8))\nu1 = torch.tensor([-6,-4,-2,0,2,4,6])\nu2 = torch.tensor([6,4,2,0,-2,-4,-6])\nu3 = torch.tensor([-6,-2,2,6,2,-2,-6])\nu4 = torch.tensor([-6,-2,2,6,4,2,0])\nax[0,0].plot(u1,'--o',color='C0',label = r\"$u_1$\")\nax[0,0].legend()\nax[0,1].plot(a(u1),'--o',color='C0',label = r\"$a(u_1)=\\frac{exp(u_1)}{exp(u_1)+1}$\")\nax[0,1].legend()\nax[1,0].plot(u2,'--o',color='C1',label = r\"$u_2$\")\nax[1,0].legend()\nax[1,1].plot(a(u2),'--o',color='C1',label = r\"$a(u_2)=\\frac{exp(u_2)}{exp(u_2)+1}$\")\nax[1,1].legend()\nax[2,0].plot(u3,'--o',color='C2', label = r\"$u_3$\")\nax[2,0].legend()\nax[2,1].plot(a(u3),'--o',color='C2', label = r\"$a(u_3)=\\frac{exp(u_3)}{exp(u_3)+1}$\")\nax[2,1].legend()\nax[3,0].plot(u4,'--o',color='C3', label = r\"$u_4$\")\nax[3,0].legend()\nax[3,1].plot(a(u4),'--o',color='C3', label = r\"$a(u_4)=\\frac{exp(u_4)}{exp(u_4)+1}$\")\nax[3,1].legend()"
  },
  {
    "objectID": "posts/09wk-2.html#a.-잡썰",
    "href": "posts/09wk-2.html#a.-잡썰",
    "title": "09wk-2: (생성모형) – Generative Adversarial Network (GAN)",
    "section": "A. 잡썰",
    "text": "A. 잡썰\n- 저자: 이안굿펠로우\n\n천재임\n지도교수가 요수아 벤지오\n\n- 저는 아래의 논문 읽고 소름돋았어요..\n\nhttps://arxiv.org/abs/1406.2661\n\n- 최근 10년간 머신러닝 분야에서 가장 혁신적인 아이디어이다. (얀르쿤, 2014년 시점..)\n- 야사와 만화로 배우는 인공지능\n\nhttps://wedatalab.tistory.com/125"
  },
  {
    "objectID": "posts/09wk-2.html#b.-gan의-원리",
    "href": "posts/09wk-2.html#b.-gan의-원리",
    "title": "09wk-2: (생성모형) – Generative Adversarial Network (GAN)",
    "section": "B. GAN의 원리",
    "text": "B. GAN의 원리\n- GAN의 원리는 경찰과 위조지폐범이 서로 선의의(?) 경쟁을 통하여 서로 발전하는 모형으로 설명할 수 있다.\n\nThe generative model can be thought of as analogous to a team of fakers, trying to produce fake currency and use it without detection, while the discriminative model is analogous to the police, trying to detect the counterfeit currency. Competition in this game drives both teams to improve their methods until the counterfeits are indistiguishable from the genuine articles.\n\n- 서로 적대적인(adversarial) 네트워크(network)를 동시에 학습시켜 가짜이미지를 만든다(generate)\n- 무식한 상황극..\n\n위조범: 가짜돈을 만들어서 부자가 되어야지! (가짜돈을 그림)\n경찰: (위조범이 만든 돈을 보고) 이건 가짜다!\n위조범: 걸렸군.. 더 정교하게 만들어야지..\n경찰: (깜빡 속으며) 이건 진짠가?… –&gt; 상사에게 혼남 –&gt; 판별능력 업그레이드 –&gt; 이건 가짜다!!\n위조범: 더 정교하게 만들자..\n경찰: 더 판별능력을 업그레이드 하자!\n반복..\n\n- 굉장히 우수한 경찰조차도 진짜와 가짜를 구분하지 못할때(=진짜 이미지를 0.5의 확률로만 진짜라고 말할때 = 가짜 이미지를 0.5의 확률로만 가짜라고 말할때) 학습을 멈춘다."
  },
  {
    "objectID": "posts/09wk-2.html#c.-생성모형이란-쉬운-설명",
    "href": "posts/09wk-2.html#c.-생성모형이란-쉬운-설명",
    "title": "09wk-2: (생성모형) – Generative Adversarial Network (GAN)",
    "section": "C. 생성모형이란? (쉬운 설명)",
    "text": "C. 생성모형이란? (쉬운 설명)\n- 사진속에 들어있는 동물이 개인지 고양이인지 맞출수 있는 기계와 개와 고양이를 그릴수 있는 기계중 어떤것이 더 시각적보에 대한 이해가 깊다고 볼 수 있는가?\n- 진정으로 인공지능이 이미지자료를 이해했다면, 이미지를 만들수도 있어야 한다. \\(\\to\\) 이미지를 생성하는 모형을 만들어보자 \\(\\to\\) 성공\n\n- 뭘 분류하려는 목적을 가진게 판별모형이면 뭘 만들려는 목적을 가진게 생성모형이고 생성모형이 더 우수하다.\n\n명언: 만들수 없다면 이해하지 못한 것이다, 리처드 파인만 (천재 물리학자)"
  },
  {
    "objectID": "posts/09wk-2.html#d.-생성모형이란-통계학과-버전의-설명",
    "href": "posts/09wk-2.html#d.-생성모형이란-통계학과-버전의-설명",
    "title": "09wk-2: (생성모형) – Generative Adversarial Network (GAN)",
    "section": "D. 생성모형이란? 통계학과 버전의 설명",
    "text": "D. 생성모형이란? 통계학과 버전의 설명\n- 이미지 \\(\\boldsymbol{X}\\) 가 주어졌을 경우 라벨을 \\(y\\) 라고 하자.\n- 이미지를 보고 라벨을 맞추는 일은 \\(p(y| \\boldsymbol{X})\\)에 관심이 있다고 볼 수 있다. – 판별모형\n- 이미지를 생성하는 일은 \\(p(\\boldsymbol{X},y)\\)에 관심이 있는것이다. – 생성모형\n- 데이터의 생성확률 \\(p(\\boldsymbol{X},y)\\)을 알면 클래스의 사후확률 \\(p(y|\\boldsymbol{X})\\)를 알 수 있음. (아래의 수식 참고) 하지만 역은 불가능\n\\[p(y|{\\boldsymbol X}) = \\frac{p({\\boldsymbol X},y)}{p({\\boldsymbol X})} = \\frac{p({\\boldsymbol X},y)}{\\sum_{y}p({\\boldsymbol X},y)}\\]\n\n즉 이미지를 생성하는일은 분류문제보다 더 어려운 일이라 해석가능"
  },
  {
    "objectID": "posts/09wk-2.html#e.-철학의-차이",
    "href": "posts/09wk-2.html#e.-철학의-차이",
    "title": "09wk-2: (생성모형) – Generative Adversarial Network (GAN)",
    "section": "E. 철학의 차이",
    "text": "E. 철학의 차이\n\n명언: 제한된 정보만으로 어떤 문제를 풀 때, 그 과정에서 원래의 문제보다 일반적인 문제를 풀지 말고 (=문제를 괜히 어렵게 만들어서 풀지 말고), 가능한 원래의 문제를 직접 풀어야한다. 배프닉 (SVM 창시자)\n\n- 따라서 배프닉의 원리에 의하면 일반적인 분류문제를 해결할때 “판별모형이 생성모형보다 더 바람직한 접근법”이라 할 수 있음. 즉 개와 고양이를 구분할 때, 그려진 개와 고양이 사진을 잘 구분하면 되는 것이지 굳이 개와 고양이를 그릴줄 알아야하는건 아니라는 의미.\n* 예전에는 머신러닝의 응용분야가 “분류/회귀”에 한정된 느낌이었는데 요즘은 생성모형도 인기있음.\n\n마인드가 되게 달라요"
  },
  {
    "objectID": "posts/09wk-2.html#a.-data",
    "href": "posts/09wk-2.html#a.-data",
    "title": "09wk-2: (생성모형) – Generative Adversarial Network (GAN)",
    "section": "A. Data",
    "text": "A. Data\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\nto_tensor = torchvision.transforms.ToTensor()\nX_real = torch.stack([to_tensor(Xi) for Xi, yi in train_dataset if yi==3])\n\n\nplt.imshow(X_real[0].squeeze(),cmap=\"gray\")"
  },
  {
    "objectID": "posts/09wk-2.html#b.-페이커-생성",
    "href": "posts/09wk-2.html#b.-페이커-생성",
    "title": "09wk-2: (생성모형) – Generative Adversarial Network (GAN)",
    "section": "B. 페이커 생성",
    "text": "B. 페이커 생성\n\n“net_faker: noise \\(\\to\\) 가짜이미지” 를 만들자.\n\n- 네트워크의 입력: (n,??) 인 랜덤으로 뽑은 숫자.\n\ntorch.randn(1,4) # 이게 입력으로 온다고 상상하자. \n\ntensor([[-0.9855,  1.0043, -0.4022, -0.0478]])\n\n\n- 네트워크의 출력: (n,1,28,28)의 텐서\n\nclass FlattenToImage(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,X):\n        return X.reshape(-1,1,28,28)\nnet_facker = torch.nn.Sequential(\n    torch.nn.Linear(4,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,784),\n    torch.nn.Sigmoid(), # 출력을 0~1로 눌러주기 위한 레이어 // 저한테는 일종의 문화충격\n    FlattenToImage()\n)\n\n\nnet_facker(torch.randn(1,4)).shape\n\ntorch.Size([1, 1, 28, 28])"
  },
  {
    "objectID": "posts/09wk-2.html#c.-경찰-생성",
    "href": "posts/09wk-2.html#c.-경찰-생성",
    "title": "09wk-2: (생성모형) – Generative Adversarial Network (GAN)",
    "section": "C. 경찰 생성",
    "text": "C. 경찰 생성\n\nnet_police: 진짜이미지 \\(\\to\\) 0 // 가짜이미지 \\(\\to\\) 1 와 같은 네트워크를 설계하자.\n\n- 네트워크의 입력: (n,1,28,28) 인 이미지\n- 네트워크의 출력: 0,1\n\nnet_police = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,30),\n    torch.nn.ReLU(),\n    torch.nn.Linear(30,1),\n    torch.nn.Sigmoid()\n)"
  },
  {
    "objectID": "posts/09wk-2.html#d.-바보경찰-바보페이커",
    "href": "posts/09wk-2.html#d.-바보경찰-바보페이커",
    "title": "09wk-2: (생성모형) – Generative Adversarial Network (GAN)",
    "section": "D. 바보경찰, 바보페이커",
    "text": "D. 바보경찰, 바보페이커\n- 데이터\n\nreal_image = X_real[[0]]  # 진짜이미지\nfake_image = net_facker(torch.randn(1,4)).data # 가짜이미지\n\n- 경찰네트워크가 가짜이미지를 봤을때 어떤 판단을 하는지, 진짜 이미지를 봤을떄 어떤 판단을 하는지 살펴보자.\n&lt;경찰이 진짜이미지를 봤다면&gt;\n\nnet_police(real_image)\n\ntensor([[0.4764]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n&lt;경찰이 가짜이미지를 봤다면&gt;\n\nnet_police(fake_image)\n\ntensor([[0.4968]], grad_fn=&lt;SigmoidBackward0&gt;)"
  },
  {
    "objectID": "posts/09wk-2.html#e.-똑똑해진-경찰",
    "href": "posts/09wk-2.html#e.-똑똑해진-경찰",
    "title": "09wk-2: (생성모형) – Generative Adversarial Network (GAN)",
    "section": "E. 똑똑해진 경찰",
    "text": "E. 똑똑해진 경찰\n- 데이터를 정리\n\n원래 \\(n=6131\\)개의 이미지자료가 있었음. 이를 \\({\\bf X}_{real}\\) 로 저장했었음.\n\\({\\bf X}_{fake}\\)는 net_facker의 output으로 생성하고 꼬리표 제거.\n\\({\\bf X}_{real}\\)에 대응하는 \\({\\bf y}_{real}\\) 생성. 진짜이미지는 라벨을 0으로 정함.\n\\({\\bf X}_{faker}\\)에 대응하는 \\({\\bf y}_{fake}\\) 생성. 가짜이미지는 라벨을 1로 정함.\n\n\nX_fake = net_facker(torch.randn(6131,4)).data\ny_real = torch.zeros((6131,1))\ny_fake = torch.ones((6131,1))\n\n- step1: X_real, X_fake를 보고 각각 yhat_real, yhat_fake를 만드는 과정\n\nyhat_real = net_police(X_real)\nyhat_fake = net_police(X_fake)\n\n- step2: 경찰의 미덕은 (1) 가짜이미지를 가짜라고 하고 (2) 진짜이미지를 진짜라고 해야함. 즉 yhat_real 은 거의 0의 값으로, 그리고 yhat_fake는 1이 되도록 설계해야함. (yhat_real \\(\\approx\\) y_real 이고 yhat_fake \\(\\approx\\) y_fake 이어야 함) 이러면 경찰이 잘하는것.\n\nbce = torch.nn.BCELoss()\n\n\nloss_police = bce(yhat_real,y_real) + bce(yhat_fake,y_fake) \nloss_police\n\ntensor(1.3961, grad_fn=&lt;AddBackward0&gt;)\n\n\n- step3~4\n\n# net_police = torch.nn.Sequential(\n#     torch.nn.Flatten(),\n#     torch.nn.Linear(784,30),\n#     torch.nn.ReLU(),\n#     torch.nn.Linear(30,1),\n#     torch.nn.Sigmoid()\n# )\nbce = torch.nn.BCELoss()\noptimizr_police = torch.optim.Adam(net_police.parameters())\nfor epoc in range(30):\n    X_fake = net_facker(torch.randn(6131,4)).data\n    # step1 -- yhat을 얻음\n    yhat_real = net_police(X_real)\n    yhat_fake = net_police(X_fake)\n    # step2  -- loss를 계산\n    loss_police = bce(yhat_real,y_real) + bce(yhat_fake,y_fake)\n    # step3  -- 미분 \n    loss_police.backward()\n    # step4 -- update \n    optimizr_police.step()\n    optimizr_police.zero_grad()\n\n- 경찰의 실력향상을 감상해보자.\n\nnet_police(X_real) # 거의 0으로 \n\ntensor([[0.0145],\n        [0.0247],\n        [0.0160],\n        ...,\n        [0.0240],\n        [0.1189],\n        [0.0379]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\nnet_police(net_facker(torch.randn(6131,4)).data) # 거의 1로\n\ntensor([[0.9924],\n        [0.9922],\n        [0.9924],\n        ...,\n        [0.9924],\n        [0.9923],\n        [0.9923]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n- 꽤 우수한 경찰이 되었음.\n\nfig, ax = plt.subplots(1,2)\nax[0].imshow(X_fake[[2]].squeeze(),cmap=\"gray\")\nax[0].set_title(f\"police output = {net_police(X_fake[[2]]).item():.4f}\")\nax[1].imshow(X_real[[-1]].squeeze(),cmap=\"gray\")\nax[1].set_title(f\"police output = {net_police(X_real[[-1]]).item():.4f}\")\n\nText(0.5, 1.0, 'police output = 0.0379')"
  },
  {
    "objectID": "posts/09wk-2.html#f.-더-똑똑해지는-페이커",
    "href": "posts/09wk-2.html#f.-더-똑똑해지는-페이커",
    "title": "09wk-2: (생성모형) – Generative Adversarial Network (GAN)",
    "section": "F. 더 똑똑해지는 페이커",
    "text": "F. 더 똑똑해지는 페이커\n- step1: noise \\(\\to\\) X_fake\n\nX_fake = net_facker(torch.randn(6131,4))\n# 여기서는 X_fake가 데이터가 아니고 네트워크 출력이므로 꼬리표를 제거하지 말아야함\n\n- step2: 손실함수 - 페이커의 미덕 (잘 훈련된) 경찰이 가짜이미지를 진짜라고 판단하는 것. 즉 yhat_fake \\(\\approx\\) y_real 이어야 페이커의 실력이 우수하다고 볼 수 있음.\n\nyhat_fake = net_police(X_fake)\nloss_faker = bce(yhat_fake, y_real) \n# 가짜이미지를 보고 잘 훈련된 경찰도  \n# 진짜 이미지라고 깜빡 속으면 \n# 위조범의 실력이 좋다고 볼 수 있다는 의미\n\n- step3~4:\n\nclass FlattenToImage(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,X):\n        return X.reshape(-1,1,28,28)\nnet_facker = torch.nn.Sequential(\n    torch.nn.Linear(4,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,784),\n    torch.nn.Sigmoid(), # 출력을 0~1로 눌러주기 위한 레이어 // 저한테는 일종의 문화충격\n    FlattenToImage()\n)\nbce = torch.nn.BCELoss()\noptimizr_facker = torch.optim.Adam(net_facker.parameters())\n\n\nfor epoc in range(1):\n    # step1 -- yhat을 얻음\n    X_fake = net_facker(torch.randn(6131,4))\n    # step2  -- loss를 계산\n    yhat_fake = net_police(X_fake)\n    loss_faker = bce(yhat_fake,y_real)\n    # step3  -- 미분 \n    loss_faker.backward()\n    # step4 -- update \n    optimizr_facker.step()\n    optimizr_facker.zero_grad()\n\n- 위조범의 실력향상을 감상해보자.\n\nplt.imshow(X_fake[[0]].squeeze().data,cmap=\"gray\")"
  },
  {
    "objectID": "posts/09wk-2.html#g.-경쟁학습",
    "href": "posts/09wk-2.html#g.-경쟁학습",
    "title": "09wk-2: (생성모형) – Generative Adversarial Network (GAN)",
    "section": "G. 경쟁학습",
    "text": "G. 경쟁학습\n\n두 적대적인 네트워크를 경쟁시키자!\n\n\ntorch.manual_seed(43052)\nnet_police = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(784,30),\n    torch.nn.ReLU(),\n    torch.nn.Linear(30,1),\n    torch.nn.Sigmoid()\n)\nclass FlattenToImage(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,X):\n        return X.reshape(-1,1,28,28)\nnet_facker = torch.nn.Sequential(\n    torch.nn.Linear(4,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,64),\n    torch.nn.ReLU(),\n    torch.nn.Linear(64,784),\n    torch.nn.Sigmoid(), # 출력을 0~1로 눌러주기 위한 레이어 // 저한테는 일종의 문화충격\n    FlattenToImage()\n)\nbce = torch.nn.BCELoss()\noptimizr_police = torch.optim.Adam(net_police.parameters(),lr=0.001, betas=(0.5,0.999))\noptimizr_facker = torch.optim.Adam(net_facker.parameters(),lr=0.0002, betas=(0.5,0.999))\n\n\nfor epoc in range(1000):\n    #--- net_police 를 훈련 \n    #step1\n    X_fake = net_facker(torch.randn(6131,4)).data # 여기에서 X_fake는 data를 의미\n    yhat_real = net_police(X_real)\n    yhat_fake = net_police(X_fake)\n    #step2\n    loss_police = bce(yhat_real,y_real) + bce(yhat_fake,y_fake)\n    #step3\n    loss_police.backward()\n    #step4\n    optimizr_police.step()\n    optimizr_police.zero_grad()\n    #--- net_faker 를 훈련 \n    #step1\n    X_fake = net_facker(torch.randn(6131,4)) # 이때 X_fake는 net의 out을 의미 \n    #step2\n    yhat_fake = net_police(X_fake)\n    loss_facker = bce(yhat_fake, y_real)\n    #step3\n    loss_facker.backward()\n    #step4\n    optimizr_facker.step()\n    optimizr_facker.zero_grad()\n\n\nfig, ax  = plt.subplots(2,5,figsize=(10,4))\nk=0\nfor i in range(2):\n    for j in range(5):\n        ax[i][j].imshow(X_fake[[k]].data.squeeze(),cmap=\"gray\")\n        ax[i][j].set_title(f\"police out = {net_police(X_fake[[k]]).item():.4f}\")\n        k= k+1\nfig.tight_layout()"
  },
  {
    "objectID": "posts/14wk-2.html#a.-미래보상",
    "href": "posts/14wk-2.html#a.-미래보상",
    "title": "14wk-2: (강화학습) – 4x4 Grid World q_table, Appedix B",
    "section": "A. 미래보상",
    "text": "A. 미래보상\n- 언뜻생각하면 4x4 문제에서 q_table은 아래와 같이 생각하는게 합리적인듯 보인다.\n\nq[s1,s2,a] = 상태 (s1,s2)에서 행동 a를 했을 경우 얻게되는 보상의 평균\n\\(q(s,a) = r(s,a) = \\mathbb{E}[\\text{Reward} | \\text{State}=s, \\text{Action}=a]\\)\n\n그렇지만 아래와 같이 생각하는게 더 합리적이다.\n\nq[s1,s2,a] = 상태 (s1,s2)에서 행동 a를 했을 경우 얻게되는 보상의 평균 + 미래에 얻게되리라 기대하는 보상\n\\(q(s,a) = r(s,a) + r_{\\text{future}}\\)\n\n\n단, 여기에서 미래에 얻게되리라 기대하는 보상은 최선의 선택을 한다는 전제하에 계산\n\n- 미래에 얻게되리라 기대하는 보상은 어떻게 정의할 수 있을까?\n\n# 예제1 – 상태 (2,2) 에서 “action=down” 을 했을때\n\n즉시 얻게되는 보상과\n미래에 얻게되리라 기대하는 보상\n\n은 무엇인가? 이것을 바탕으로 \\(s=(2,1)\\), \\(a=\\text{down}\\) 의 품질(Quality)는 어떻게 평가할 수 있는가?\n(풀이?)\n즉시 얻을 수 있다고 생각되는 보상은-1 이고 미래에 얻으리라 기대되는 보상은 100 점이다. 따라서 99점으로 평가하는게 합리적인듯하다. 수식으로 쓰면\n\\[q(s,a)=q(s_1,s_2,a)=q(2,2, \\text{down}) = -1 + 100 = r(2,2,\\text{down}) + \\max_{a'}q(3,2,a')\\]\n와 같이 쓸 수 있겠다.\n#\n# 예제2 – 상태 (1,2) 에서 “action=down” 을 했을때\n\n즉시 얻게되는 보상과\n미래에 얻게되리라 기대하는 보상\n\n은 무엇인가? 이것을 바탕으로 \\(s=(1,2)\\), \\(a=\\text{down}\\) 의 품질(Quality)는 어떻게 평가할 수 있는가?\n(풀이?)\n즉시 얻을 수 있다고 생각되는 보상은-1 이고 미래에 얻으리라 기대되는 보상은 99점이다. 따라서 98점으로 평가하는게 합리적인듯하다. 수식으로 쓰면\n\\[q(s,a)=q(s_1,s_2,a)=q(1,2, \\text{down}) = -1 + 99 = r(1,2,\\text{down}) + \\max_{a'}q(2,2,a')\\]\n와 같이 쓸 수 있겠다.\n#\n# 예제3 – 상태 (0,1) 에서 “action=right” 을 했을때\n\n즉시 얻게되는 보상과\n미래에 얻게되리라 기대하는 보상\n\n은 무엇인가? 이것을 바탕으로 \\(s=(0,1)\\), \\(a=\\text{right}\\) 의 품질(Quality)는 어떻게 평가할 수 있는가?\n(풀이?)\n앞의 예제들을 일반화하면 아래와 같은 수식을 쓸 수 있다.\n\\[q(0,1, \\text{right}) = r(0,1,\\text{right}) + \\max_{a'}q(0,2,a')\\]\n따라서 만약에 \\(\\max_{a}q(0,2,a)\\)의 값을 알고 있다면 이를 구할 수 있다.\n#\n- (아직 부족한) 깨달음: 모든 \\((s,a)\\)에 대하여 \\(q(s,a)\\)의 값은 아래와 같이 정의할 수 있겠다.\n\\[q(s,a) = r(s,a) + \\max_{a'}q(s',a')\\]"
  },
  {
    "objectID": "posts/14wk-2.html#b.-감가율",
    "href": "posts/14wk-2.html#b.-감가율",
    "title": "14wk-2: (강화학습) – 4x4 Grid World q_table, Appedix B",
    "section": "B. 감가율",
    "text": "B. 감가율\n# 예제1 – 당신은 지금 아무것도 쓰여 있지 않은 빈 종이 한 장을 가지고 있습니다. 이 종이에 쓸 수 있는 숫자는 오직 두 가지, 0 또는 1입니다. 어떤 숫자를 쓰느냐에 따라 보상이 달라지는데, 수많은 실험을 통해 0을 쓰면 아무 보상도 없고, 1을 쓰면 10만 원을 받을 수 있다는 사실이 확인되었습니다. 이 사실이 확인된 이후 이 빈 종이의 가치는 얼마일까요?\n(1) 0원이다.\n(2) 10만원이다.\n(3) 5만원이다.\n(4) 모르겠다.\n#\n# 예제2 – 당신 앞에는 빨간색 종이 한 장이 있습니다. 이 종이에는 0 또는 1 중 하나의 숫자를 쓸 수 있습니다. 만약 1을 쓰면 다음 단계인 주황색 종이 한 장을 받게 됩니다. 주황색 종이에도 똑같이 0 또는 1을 쓸 수 있고, 여기에 1을 쓰면 노란색 종이, 그다음은 초록색 종이, 그 다음은 파란색 종이, 그 다음은 남색 종이, 마지막으로는 보라색 종이를 순서대로 받습니다. 총 7단계(빨강 → 주황 → 노랑 → 초록 → 파랑 → 남색 → 보라색)를 거친 후, 보라색 종이에 1을 쓰면 비로소 10만 원의 현금 보상을 받을 수 있습니다. 단, 어느 단계에서든 0을 쓰면 아무 일도 일어나지 않고 그 즉시 게임이 종료됩니다. 즉, 그 이후로는 종이도 받을 수 없고 보상도 없습니다. 이 사실이 알려진 이후, 지금 당신이 들고 있는 ’빨간색 종이’의 가치는 얼마일까요?\n(1) 0원이다.\n(2) 10만 원이다.\n(3) \\(\\frac{1}{2^6}\\) x 10만원이다.\n(4) 모르겠다.\n#\n- 직관: 아무리 보장된 보상이라고 해도, 미래에 주어지는 보상은 현재의 보상과 동급취급할 수 없다.\n- 진짜 깨달음: 모든 \\((s,a)\\)에 대하여 \\(q(s,a)\\)의 값은 아래와 같이 정의하는게 합리적이다.\n\\[q(s,a) = r(s,a) + \\gamma \\max_{a'}q(s',a')\\]\n여기에서 \\(\\gamma\\)는 0과 1사이의 값이며 감가율(discout factor)이라 부른다."
  },
  {
    "objectID": "posts/14wk-2.html#c.-q_table-update",
    "href": "posts/14wk-2.html#c.-q_table-update",
    "title": "14wk-2: (강화학습) – 4x4 Grid World q_table, Appedix B",
    "section": "C. q_table update",
    "text": "C. q_table update\n- 지난시간코드\n\nclass GridWorld:\n    def __init__(self):\n        self.a2d = {\n            0: np.array([0,1]), # →\n            1: np.array([0,-1]), # ←  \n            2: np.array([1,0]),  # ↓\n            3: np.array([-1,0])  # ↑\n        }\n        self.state_space = gym.spaces.MultiDiscrete([4,4])\n        self.state = np.array([0,0])\n        self.reward = None\n        self.terminated = False\n    def step(self,action):\n        self.state = self.state + self.a2d[action]\n        s1,s2 = self.state\n        if (s1==3) and (s2==3):\n            self.reward = 100 \n            self.terminated = True\n        elif self.state in self.state_space:\n            self.reward = -1 \n            self.terminated = False\n        else:\n            self.reward = -10\n            self.terminated = True\n        # print(\n        #     f\"action = {action}\\t\"\n        #     f\"state = {self.state - self.a2d[action]} -&gt; {self.state}\\t\"\n        #     f\"reward = {self.reward}\\t\"\n        #     f\"termiated = {self.terminated}\"\n        # )            \n        return self.state, self.reward, self.terminated\n    def reset(self):\n        self.state = np.array([0,0])\n        self.terminated = False\n        return self.state\nclass RandomAgent:\n    def __init__(self):\n        self.state = np.array([0,0]) \n        self.action = None \n        self.reward = None \n        self.next_state = None\n        self.terminated = None\n        #---#\n        self.states = collections.deque(maxlen=500000)\n        self.actions = collections.deque(maxlen=500000)\n        self.rewards = collections.deque(maxlen=500000)\n        self.next_states = collections.deque(maxlen=500000)\n        self.terminations = collections.deque(maxlen=500000)\n        #---#\n        self.action_space = gym.spaces.Discrete(4)\n        self.n_experience = 0\n    def act(self):\n        self.action = self.action_space.sample()\n    def save_experience(self):\n        self.states.append(self.state)\n        self.actions.append(self.action)\n        self.rewards.append(self.reward)\n        self.next_states.append(self.next_state)\n        self.terminations.append(self.terminated)\n        self.n_experience = self.n_experience + 1\n    def learn(self):\n        pass\n\n\nplayer = RandomAgent()\nenv = GridWorld()\nscores = [] \nscore = 0 \n#\nfor e in range(1,100000):\n    #---에피소드시작---#\n    while True:\n        # step1 -- 액션선택\n        player.act()\n        # step2 -- 환경반응 \n        player.next_state, player.reward, player.terminated = env.step(player.action)\n        # step3 -- 경험기록 & 학습 \n        player.save_experience()\n        player.learn()\n        # step4 --종료 조건 체크 & 후속 처리\n        if env.terminated:\n            score = score + player.reward\n            scores.append(score)\n            score = 0 \n            player.state = env.reset() \n            break\n        else: \n            score = score + player.reward         \n            player.state = player.next_state\n\n\n\n\n\n\n\nImportant\n\n\n\n강의노트 수정 2025-06-12\n노규호학생의 도움으로 예전강의의 오류를 발견하여 수정하였습니다.\n# 수정전\n...\n        if env.terminated:\n            ...\n        else: \n            score = score + player.reward\n            scores.append(score)            \n            player.state = player.next_state\n            \n# 수정후\n        if env.terminated:\n            ...\n        else: \n            score = score + player.reward\n#            scores.append(score)            ### &lt;--- 여기를 주석처리해야함!! \n            player.state = player.next_state\n\n\n- 상황: player가 경험은 있는데, q_table을 만들줄 모름 (데이터는 있음, 학습이 안된상태)\n\nplayer.n_experience\n\n328330\n\n\n- 저번시간에 배운 q_table\n\nq_table = np.zeros((4,4,4))\nmemory = zip(player.states, player.actions, player.rewards)\nfor (s1,s2), a, r in memory:\n    qhat = q_table[s1,s2,a] # 내가 생각했던갓\n    q = r # 실제값\n    diff = q-qhat # 차이\n    q_table[s1,s2,a] = q_table[s1,s2,a]  + 0.01*diff# update\n\n\nfor a in [0,1,2,3]: \n    print(f\"action = {a}\")\n    print(f\"q[...,{a}] = {q_table[...,a].round(3)}\")\n    print(\"---\")\n\naction = 0\nq[...,0] = [[ -1.     -1.     -1.    -10.   ]\n [ -1.     -1.     -1.    -10.   ]\n [ -1.     -1.     -1.     -9.999]\n [ -1.     -1.     99.991   0.   ]]\n---\naction = 1\nq[...,1] = [[-10.  -1.  -1.  -1.]\n [-10.  -1.  -1.  -1.]\n [-10.  -1.  -1.  -1.]\n [-10.  -1.  -1.   0.]]\n---\naction = 2\nq[...,2] = [[ -1.     -1.     -1.     -1.   ]\n [ -1.     -1.     -1.     -1.   ]\n [ -1.     -1.     -1.     99.993]\n [-10.    -10.     -9.999   0.   ]]\n---\naction = 3\nq[...,3] = [[-10. -10. -10. -10.]\n [ -1.  -1.  -1.  -1.]\n [ -1.  -1.  -1.  -1.]\n [ -1.  -1.  -1.   0.]]\n---\n\n\n- 이번시간에 배운 q_table: 아래를 이용한다.\n\\[q(s,a) = r(s,a) + \\gamma \\max_{a'}q(s',a')\\]\n\n\n\n\n\n\nNote\n\n\n\n사실 좀 더 실용적으로는(=코딩친화적으로는) 아래의 수식을 쓰는게 좋다.\n\\[q(s,a) = \\begin{cases} r(s,a) & \\text{if terminated} \\\\ r(s,a) + \\gamma \\max_{a'}q(s',a') & \\text{else} \\end{cases}\\]\n\n\n\nq_table = np.zeros((4,4,4))\nmemory = zip(player.states, player.actions, player.rewards, player.next_states, player.terminations)\nfor (s1,s2), a, r, (ss1,ss2), tmd  in memory:\n    qhat = q_table[s1,s2,a] # 내가 생각했던값\n    if tmd: \n        q = r # 실제값\n    else: \n        future = q_table[ss1,ss2,:].max()\n        q = r + 0.95 * future\n    diff = q-qhat # 차이\n    q_table[s1,s2,a] = q_table[s1,s2,a]  + 0.01*diff# update\n\n\nfor a in [0,1,2,3]: \n    print(f\"action = {a}\")\n    print(f\"q[...,{a}] = {q_table[...,a].round(3)}\")\n    print(\"---\")\n\naction = 0\nq[...,0] = [[ 72.838  77.721  82.807 -10.   ]\n [ 77.725  82.87   88.276 -10.   ]\n [ 82.867  88.285  93.989  -9.999]\n [ 88.229  93.978  99.991   0.   ]]\n---\naction = 1\nq[...,1] = [[-10.     68.195  72.833  77.683]\n [-10.     72.836  77.721  82.849]\n [-10.     77.717  82.862  88.186]\n [-10.     82.723  88.128   0.   ]]\n---\naction = 2\nq[...,2] = [[ 72.838  77.724  82.867  88.241]\n [ 77.721  82.869  88.286  93.982]\n [ 82.801  88.272  93.985  99.993]\n [-10.    -10.     -9.999   0.   ]]\n---\naction = 3\nq[...,3] = [[-10.    -10.    -10.    -10.   ]\n [ 68.195  72.835  77.718  82.734]\n [ 72.832  77.721  82.863  88.122]\n [ 77.678  82.845  88.216   0.   ]]\n---\n\n\n\nplayer.q_table = q_table\n\n- 이제 플레이어의 행동은?\n\nplayer.q_table\n\narray([[[ 72.83771663, -10.        ,  72.83771538, -10.        ],\n        [ 77.72139771,  68.19454652,  77.72442966, -10.        ],\n        [ 82.80747929,  72.83310558,  82.86672465, -10.        ],\n        [ -9.99998197,  77.6827334 ,  88.24107054,  -9.99998511]],\n\n       [[ 77.72454812, -10.        ,  77.72127368,  68.19457346],\n        [ 82.86950596,  72.83600446,  82.86912699,  72.83541752],\n        [ 88.27585546,  77.72068451,  88.28563001,  77.71797997],\n        [ -9.99999683,  82.84920596,  93.98163671,  82.73393175]],\n\n       [[ 82.8669733 , -10.        ,  82.8012108 ,  72.83236834],\n        [ 88.28521264,  77.71722413,  88.27171754,  77.72136508],\n        [ 93.9886205 ,  82.86197892,  93.98461924,  82.86278052],\n        [ -9.99904498,  88.18588483,  99.99321405,  88.12228859]],\n\n       [[ 88.22883855,  -9.9999832 ,  -9.99997635,  77.67756866],\n        [ 93.97813902,  82.72305248,  -9.99999792,  82.84474465],\n        [ 99.99082608,  88.12798376,  -9.99917862,  88.21551322],\n        [  0.        ,   0.        ,   0.        ,   0.        ]]])\n\n\n\ndef act(player,s1,s2):\n    action = player.q_table[s1,s2,:].argmax()\n    return action\n\n\nact(player,0,0)\n\n0\n\n\n\nplayer.q_table[0,0,:]\n\narray([ 72.83771663, -10.        ,  72.83771538, -10.        ])"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "딥러닝 (2025)",
    "section": "",
    "text": "질문하는 방법\n\n이메일: guebin@jbnu.ac.kr\n직접방문: 자연과학대학 본관 205호\nZoom: 이메일로 미리 시간을 정할 것\n카카오톡: http://pf.kakao.com/_txeIFG/chat\n\n오늘의 강의노트\n\n코랩사용자서버사용자\n\n\n아래의 링크 클릭\n\n\n\n주피터에서 아래를 실행 (주소 오류 수정했음!)\n!wget https://raw.githubusercontent.com/guebin/DL2025/refs/heads/main/posts/lecture.ipynb\n\n\n\n강의노트\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\n \n\n\n \n\n\n \n\n\n\n\nJun 14, 2025\n\n\n15wk-1: (강화학습) – LunarLander\n\n\n최규빈 \n\n\n\n\nJun 9, 2025\n\n\n14wk-2: (강화학습) – 4x4 Grid World q_table, Appedix B\n\n\n최규빈 \n\n\n\n\nJun 4, 2025\n\n\n14wk-1: (강화학습) – 4x4 Grid World 환경의 이해\n\n\n최규빈 \n\n\n\n\nJun 2, 2025\n\n\n13wk-2: (강화학습) – Bandit 환경 설계 및 풀이, 4x4 Grid World 게임설명, 환경구현, 에이전트(랜덤)구현\n\n\n최규빈 \n\n\n\n\nMay 28, 2025\n\n\n13wk-1: (강화학습) – 강화학습 Intro, Bandit 게임 설명, Bandit 환경 설계 및 풀이\n\n\n최규빈 \n\n\n\n\nMay 26, 2025\n\n\n12wk-2: (순환신경망) – RNNCell, RNN, LSTM, Appedix A\n\n\n최규빈 \n\n\n\n\nMay 21, 2025\n\n\n12wk-1: (순환신경망) – 겹장(덧장), rNNCell\n\n\n최규빈 \n\n\n\n\nMay 19, 2025\n\n\n11wk-2: (순환신경망) – abc, abcd, 임베딩 공간의 이해, AbAcAd, 겹장(덧장)\n\n\n최규빈 \n\n\n\n\nMay 14, 2025\n\n\n11wk-1: (추천시스템) – Embedding 레이어, 사용자정의 네트워크, MF-based 추천시스템을 넘어서\n\n\n최규빈 \n\n\n\n\nMay 12, 2025\n\n\n10wk-2: (추천시스템) – optimizer 사용 고급, 모델링 전략, MF-based 추천시스템\n\n\n최규빈 \n\n\n\n\nMay 7, 2025\n\n\n10wk-1: 중간고사\n\n\n최규빈 \n\n\n\n\nMay 5, 2025\n\n\n09wk-2: (생성모형) – Generative Adversarial Network (GAN)\n\n\n최규빈 \n\n\n\n\nApr 28, 2025\n\n\n08wk-2, 09wk-1: (XAI, 설명가능한 인공지능) – Class Activation Map\n\n\n최규빈 \n\n\n\n\nApr 23, 2025\n\n\n08wk-1: (합성곱신경망) – MNIST, CIFAR10, XAI란?\n\n\n최규빈 \n\n\n\n\nApr 21, 2025\n\n\n07wk-2: (합성곱신경망) – CNN 핵심레이어, CNN의 학습원리, FashionMNIST\n\n\n최규빈 \n\n\n\n\nApr 16, 2025\n\n\n07wk-1: (합성곱신경망) – CNN 자랑, CNN 핵심레이어\n\n\n최규빈 \n\n\n\n\nApr 14, 2025\n\n\n06wk-2: (신경망) – 다항분류, FashionMNIST\n\n\n최규빈 \n\n\n\n\nApr 9, 2025\n\n\n06wk-1: (신경망) – 데이터분석 코딩패턴\n\n\n최규빈 \n\n\n\n\nApr 7, 2025\n\n\n05wk-2: (신경망) – 신경망의 표현, GPU사용법, 확률적경사하강법\n\n\n최규빈 \n\n\n\n\nApr 2, 2025\n\n\n05wk-1: (신경망) – 예측, 시벤코정리의 이면, 드랍아웃\n\n\n최규빈 \n\n\n\n\nMar 31, 2025\n\n\n04wk-2: (신경망) – 꺽인그래프의 한계(?), 시벤코정리, MNIST\n\n\n최규빈 \n\n\n\n\nMar 26, 2025\n\n\n04wk-1: (신경망) – 로지스틱의 한계 극복\n\n\n최규빈 \n\n\n\n\nMar 24, 2025\n\n\n03wk-2: (로지스틱) – sig(linr(x)), BCELoss, Adam, 로지스틱의 한계\n\n\n최규빈 \n\n\n\n\nMar 19, 2025\n\n\n03wk-1: (회귀, 로지스틱) – 파이토치식 코딩패턴 (2), 로지스틱 모형\n\n\n최규빈 \n\n\n\n\nMar 17, 2025\n\n\n02wk-2: (회귀) – 파라메터의 학습과정 음미, MSE, 파이토치식 코딩패턴 (1)\n\n\n최규빈 \n\n\n\n\nMar 10, 2025\n\n\n01wk-2, 02wk-1: (회귀) – 회귀모형, 손실함수, 파이토치를 이용한 추정\n\n\n최규빈 \n\n\n\n\nMar 5, 2025\n\n\n01wk-1: (토치) – 강의소개, 파이토치 기본\n\n\n최규빈 \n\n\n\n\nJan 1, 2025\n\n\nA1: Exercise – ver. 0505-1\n\n\n최규빈 \n\n\n\n\nJan 1, 2025\n\n\nA2: Exam Guidelines\n\n\n최규빈 \n\n\n\n\n\nNo matching items"
  }
]