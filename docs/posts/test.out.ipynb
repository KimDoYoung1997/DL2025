{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#"
      ],
      "id": "21d2bd77-8229-40f5-ac81-860f7c9b1818"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "#!apt-get install swig\n",
        "#!pip install gymnasium[box2d]\n",
        "import gymnasium as gym\n",
        "#--#\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import IPython\n",
        "#--#\n",
        "import collections\n",
        "import random\n",
        "#--#\n",
        "import torch"
      ],
      "id": "aa9ae58c-5b5a-4167-be2b-245da5017e20"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "def show(ims,jump=10):\n",
        "    ims = ims[::jump]\n",
        "    fig = plt.Figure()\n",
        "    ax = fig.subplots()\n",
        "    def update(i):\n",
        "        ax.imshow(ims[i])\n",
        "    ani = FuncAnimation(fig,update,frames=len(ims))\n",
        "    display(IPython.display.HTML(ani.to_jshtml()))"
      ],
      "id": "5df7ccd3-d6ef-4e43-8ef4-26c2bfe66a7a"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "class AgentRandom: \n",
        "    def __init__(self):\n",
        "        #--# define spaces \n",
        "        self.action_space = gym.spaces.Discrete(4)\n",
        "        #\n",
        "        self.state =  None    ## 길이가 8인 np.array        \n",
        "        self.action = None            ## int, 0,1,2,3 중 하나\n",
        "        self.reward = None            ## float  \n",
        "        self.next_state =  None       ## np.array\n",
        "        self.terminated = None        ## bool \n",
        "        #\n",
        "        self.buffer_size = 5000\n",
        "        self.states = collections.deque(maxlen=self.buffer_size) # 원소는 텐서         \n",
        "        self.actions = collections.deque(maxlen=self.buffer_size) # 원소는 텐서 \n",
        "        self.rewards = collections.deque(maxlen=self.buffer_size) # 원소는 텐서\n",
        "        self.next_states = collections.deque(maxlen=self.buffer_size) # 원소는 텐서 \n",
        "        self.terminations = collections.deque(maxlen=self.buffer_size) # 원소는 텐서 \n",
        "        #\n",
        "        self.n_experiences = 0 \n",
        "    def act(self):\n",
        "        self.action = self.action_space.sample()\n",
        "    def learn(self):\n",
        "        pass \n",
        "    def save_experience(self):\n",
        "        self.states.append(torch.tensor(self.state))\n",
        "        self.actions.append(torch.tensor(self.action))\n",
        "        self.rewards.append(torch.tensor(self.reward))\n",
        "        self.next_states.append(torch.tensor(self.next_state))\n",
        "        self.terminations.append(torch.tensor(self.terminated))           \n",
        "        #--#\n",
        "        self.n_experiences = self.n_experiences + 1 "
      ],
      "id": "33a9fa2b-effa-488f-966b-3308d6afebdf"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Agent(AgentRandom):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.eps = 0 \n",
        "        self.q_net = torch.nn.Sequential(\n",
        "            torch.nn.Linear(8,256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256,128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128,64),\n",
        "            torch.nn.ReLU(),    \n",
        "            torch.nn.Linear(64,4)\n",
        "        )\n",
        "        self.optimizr = torch.optim.Adam(self.q_net.parameters(),lr=0.0001)\n",
        "        self.batch_size = 64\n",
        "    def act(self):\n",
        "        if random.random() < self.eps: \n",
        "            self.action = self.action_space.sample()\n",
        "        else: \n",
        "            s = torch.tensor(self.state)\n",
        "            self.action = self.q_net(s).argmax().item() \n",
        "    def learn(self):\n",
        "        if self.n_experiences < self.batch_size:\n",
        "            pass \n",
        "        else: \n",
        "            for epoc in range(1):\n",
        "                memory = list(zip(\n",
        "                    self.states,\n",
        "                    self.actions,\n",
        "                    self.rewards,\n",
        "                    self.next_states,\n",
        "                    self.terminations\n",
        "                ))\n",
        "                minibatch = random.sample(memory,self.batch_size)\n",
        "                ## step 1~2 \n",
        "                loss = 0 \n",
        "                for s,a,r,ss,tmd in minibatch:\n",
        "                    # step1: q_hat \n",
        "                    q_hat = self.q_net(s)[a]        \n",
        "                    # step2: loss를 계산한다. \n",
        "                    if self.terminated:\n",
        "                        q = r\n",
        "                    else:\n",
        "                        future = self.q_net(ss).max().data\n",
        "                        q = r + 0.99 * future\n",
        "                    loss = loss + (q_hat-q)**2 \n",
        "                loss = loss / self.batch_size \n",
        "                # step3 \n",
        "                loss.backward()\n",
        "                # step4 \n",
        "                self.optimizr.step()\n",
        "                self.optimizr.zero_grad() "
      ],
      "id": "ca4eb4f9-d094-4d09-8943-85d15b6dc34a"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "env = gym.make(\"LunarLander-v3\",render_mode = 'rgb_array')\n",
        "player_dummy = Agent() \n",
        "#player_dummy.q_net = player.q_net # 비법전수 \n",
        "player_dummy.q_net.load_state_dict(torch.load(\"2025q_net_600.pth\"))\n",
        "player_dummy.state, _ = env.reset()\n",
        "score = 0 \n",
        "ims = [] \n",
        "ims.append(env.render())\n",
        "for t in range(1001):\n",
        "    player_dummy.act() \n",
        "    player_dummy.next_state, player_dummy.reward, player_dummy.terminated, player_dummy.truncated, _  = env.step(player_dummy.action)\n",
        "    score = score + player_dummy.reward\n",
        "    ims.append(env.render())\n",
        "    player_dummy.state = player_dummy.next_state\n",
        "    if player_dummy.terminated or player_dummy.truncated: \n",
        "        break "
      ],
      "id": "57f20666-6207-41c5-a600-bb62a89d1e6d"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "show(ims)"
      ],
      "id": "940561d1-2d28-4b35-9fda-bc322ca4c5c1"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "score"
      ],
      "id": "6438dbe8-beef-4b16-a2a1-4ac1c25cdb21"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  }
}