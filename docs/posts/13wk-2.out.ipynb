{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 13wk-2: (강화학습) – Bandit 환경 설계 및 풀이\n",
        "\n",
        "최규빈  \n",
        "2025-06-02\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/guebin/DL2025/blob/main/posts/13wk-2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n",
        "\n",
        "# 1. 강의영상"
      ],
      "id": "1104db5f-a7dd-4cef-8bef-45b157918d2e"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# {{<video https://youtu.be/playlist?list=PLQqh36zP38-zEjn2m8H8hMCHsQK8udE27&si=Sy-lnw4Kq56SRggu >}}"
      ],
      "id": "9c489bd1-72a5-415b-8b4c-1b1aeeb655b4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Imports"
      ],
      "id": "916cde8f-d595-42b4-9c7e-7cabef3cc7de"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "#---#\n",
        "import numpy as np\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import IPython"
      ],
      "id": "65bee054-2b1d-4345-b495-cbf5b8cc44e4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Bandit 환경 설계 및 풀이\n",
        "\n",
        "## A. 대충 개념만 실습"
      ],
      "id": "7180a0f8-41f9-4a09-9585-475001d1579a"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "action_space = [0,1] \n",
        "actions_deque = collections.deque(maxlen=200)\n",
        "rewards_deque = collections.deque(maxlen=200)\n",
        "#---#\n",
        "for _ in range(10):\n",
        "    action = np.random.choice(action_space)\n",
        "    if action ==0: \n",
        "        reward = 1\n",
        "    else:\n",
        "        reward = 10\n",
        "    actions_deque.append(action)\n",
        "    rewards_deque.append(reward)"
      ],
      "id": "9f8adb2a-06ec-4b0f-9db9-2e0706f7bd80"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "actions_deque"
      ],
      "id": "11aebaed-c9b1-428f-966a-578daccb6589"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "rewards_deque"
      ],
      "id": "d55c010d-92dd-4ed7-92b8-eea2c541c7d1"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "actions_numpy = np.array(actions_deque)\n",
        "rewards_numpy = np.array(rewards_deque)"
      ],
      "id": "6efc5703-1720-4844-91fb-af83798878a6"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "q0 = rewards_numpy[actions_numpy==0].mean()\n",
        "q1 = rewards_numpy[actions_numpy==1].mean()\n",
        "q_table = np.array([q0,q1])\n",
        "q_table"
      ],
      "id": "5fcd2731-34a2-425e-a4fb-1a1791a70d2a"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#---#\n",
        "for _ in range(5):\n",
        "    #action = np.random.choice(action_space)\n",
        "    action = q_table.argmax()\n",
        "    if action ==0: \n",
        "        reward = 1\n",
        "    else:\n",
        "        reward = 10\n",
        "    actions_deque.append(action)\n",
        "    rewards_deque.append(reward)\n",
        "    actions_numpy = np.array(actions_deque)\n",
        "    rewards_numpy = np.array(rewards_deque)\n",
        "    q0 = rewards_numpy[actions_numpy==0].mean()\n",
        "    q1 = rewards_numpy[actions_numpy==1].mean()\n",
        "    q_table = np.array([q0,q1])\n",
        "    q_table"
      ],
      "id": "ef3ea891-0397-4743-9406-f88e92946260"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GameClear"
          ]
        }
      ],
      "source": [
        "if rewards_numpy[-5:].mean() > 9:\n",
        "    print(\"GameClear\")"
      ],
      "id": "9e5f0f9e-ea53-4e98-8348-3fc4ee709569"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B. 클래스를 이용한 설계 및 풀이"
      ],
      "id": "96706c84-302b-4748-8984-8b59c00a7537"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Batdit():\n",
        "    def __init__(self):\n",
        "        self.reward = None \n",
        "    def step(self,action):\n",
        "        if action == 0:\n",
        "            self.reward = 1\n",
        "        elif action == 1:\n",
        "            self.reward = 10\n",
        "        return self.reward"
      ],
      "id": "88c607ca-440f-45ea-aeef-98c1c6132f8a"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Agent():\n",
        "    def __init__(self):\n",
        "        self.n_experiences = 0 \n",
        "        self.action_space = [0,1]\n",
        "        self.action = None \n",
        "        self.actions_deque = collections.deque(maxlen=500)\n",
        "        self.actions_numpy = np.array(self.actions_deque)\n",
        "        self.reward = None \n",
        "        self.rewards_deque = collections.deque(maxlen=500)\n",
        "        self.rewards_numpy = np.array(self.rewards_deque)\n",
        "        self.q_table = None\n",
        "    def act(self):\n",
        "        if self.n_experiences < 20:\n",
        "            self.action = np.random.choice(self.action_space)\n",
        "        else: \n",
        "            self.action = self.q_table.argmax()\n",
        "        print(f\"버튼{self.action}누름\")\n",
        "    def save_experience(self):\n",
        "        self.n_experiences = self.n_experiences + 1\n",
        "        self.actions_deque.append(self.action)\n",
        "        self.rewards_deque.append(self.reward)\n",
        "        self.actions_numpy = np.array(self.actions_deque)\n",
        "        self.rewards_numpy = np.array(self.rewards_deque)\n",
        "    def learn(self):\n",
        "        if self.n_experiences < 20:\n",
        "            pass\n",
        "        else: \n",
        "            q0 = self.rewards_numpy[self.actions_numpy == 0].mean()\n",
        "            q1 = self.rewards_numpy[self.actions_numpy == 1].mean()\n",
        "            self.q_table = np.array([q0,q1])"
      ],
      "id": "2b39d73c-99c0-42b1-aead-a34adb0e464a"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = Batdit()\n",
        "agent = Agent()"
      ],
      "id": "eeb82c8c-3c5f-4580-9c50-17e5bf412dd7"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "버튼1누름"
          ]
        }
      ],
      "source": [
        "agent.act()"
      ],
      "id": "22ab0226-0c40-4e75-a24c-1e8995dd4fcc"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "버튼1누름\n",
            "버튼1누름\n",
            "버튼0누름\n",
            "버튼0누름\n",
            "버튼1누름\n",
            "버튼0누름\n",
            "버튼1누름\n",
            "버튼1누름\n",
            "버튼0누름\n",
            "버튼0누름\n",
            "버튼0누름\n",
            "버튼1누름\n",
            "버튼0누름\n",
            "버튼0누름\n",
            "버튼1누름\n",
            "버튼1누름\n",
            "버튼0누름\n",
            "버튼1누름\n",
            "버튼1누름\n",
            "버튼1누름\n",
            "버튼1누름\n",
            "버튼1누름\n",
            "버튼1누름\n",
            "버튼1누름\n",
            "버튼1누름\n",
            "버튼1누름\n",
            "버튼1누름\n",
            "버튼1누름\n",
            "버튼1누름\n",
            "버튼1누름\n",
            "버튼1누름\n",
            "버튼1누름\n",
            "버튼1누름\n",
            "게임클리어"
          ]
        }
      ],
      "source": [
        "for _ in range(100):\n",
        "    #1. 행동\n",
        "    agent.act()\n",
        "    #2. 보상\n",
        "    agent.reward = env.step(agent.action)\n",
        "    #3. 저장 & 학습 \n",
        "    agent.save_experience()\n",
        "    agent.learn()\n",
        "    #---#\n",
        "    if (agent.n_experiences > 20) and (agent.rewards_numpy[-20:].mean() >9):\n",
        "        print(\"게임클리어\")\n",
        "        break"
      ],
      "id": "acf857e9-68ca-45d6-8afa-faa8f24a4c1d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. 예비학습: `gym.spaces`\n",
        "\n",
        "ref: <https://gymnasium.farama.org/>\n",
        "\n",
        "`-` 예시1"
      ],
      "id": "2bea6609-713a-4f37-87a4-8c60cc3f6c7d"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "action_space = gym.spaces.Discrete(4) \n",
        "action_space "
      ],
      "id": "bdac58cc-8df3-4cc1-8882-54794e7073c8"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "[action_space.sample() for _ in range(5)]"
      ],
      "id": "7196b186-1145-41d8-af76-ddde21041914"
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "0 in action_space"
      ],
      "id": "06ae77d5-a345-4342-a847-8192203b7935"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "4 in action_space"
      ],
      "id": "2781db94-0b7b-44d8-8d74-536a82a78a43"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 예시2"
      ],
      "id": "476eb644-e209-4b70-9385-35030b0eae7a"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "state_space = gym.spaces.MultiDiscrete([4,4])\n",
        "state_space"
      ],
      "id": "8bda01e5-7217-4fec-b070-033adae5f0c5"
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "[state_space.sample() for _ in range(5)]"
      ],
      "id": "fa6744c9-f7ae-43ec-aa00-9f2765bfeb65"
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.array([0,1]) in state_space"
      ],
      "id": "f2ac40cf-8501-4f70-b56b-8d14e45aa853"
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "np.array([3,3]) in state_space"
      ],
      "id": "dd1adffb-8ef4-416a-9c20-b1bb31d3584e"
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "np.array([3,4]) in state_space"
      ],
      "id": "69252eb9-096c-4151-afd1-eff7be67c3cd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. 4x4 Grid World 게임 설명\n",
        "\n",
        "## A. 게임설명\n",
        "\n",
        "`-` 문제설명: 4x4 그리드월드에서 상하좌우로 움직이는 에이전트가 목표점에\n",
        "도달하도록 학습하는 방법\n",
        "\n",
        "`-` GridWorld에서 사용되는 주요변수\n",
        "\n",
        "1.  **`State`**: 각 격자 셀이 하나의 상태이며, 에이전트는 이러한 상태 중\n",
        "    하나에 있을 수 있음.\n",
        "2.  **`Action`**: 에이전트는 현재상태에서 다음상태로 이동하기 위해\n",
        "    상,하,좌,우 중 하나의 행동을 취할 수 있음.\n",
        "3.  **`Reward`**: 에이전트가 현재상태에서 특정 action을 하면 얻어지는\n",
        "    보상.\n",
        "4.  **`Terminated`**: 하나의 에피소드가 종료되었음을 나타내는 상태.\n",
        "\n",
        "## B. 시각화"
      ],
      "id": "d2133e83-830a-4641-87cd-a9e8f6c74698"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "def show(states):\n",
        "    fig = plt.Figure()\n",
        "    ax = fig.subplots()\n",
        "    ax.matshow(np.zeros([4,4]), cmap='bwr',alpha=0.0)\n",
        "    sc = ax.scatter(0, 0, color='red', s=500)  \n",
        "    ax.text(0, 0, 'start', ha='center', va='center')\n",
        "    ax.text(3, 3, 'end', ha='center', va='center')\n",
        "    # Adding grid lines to the plot\n",
        "    ax.set_xticks(np.arange(-.5, 4, 1), minor=True)\n",
        "    ax.set_yticks(np.arange(-.5, 4, 1), minor=True)\n",
        "    ax.grid(which='minor', color='black', linestyle='-', linewidth=2)\n",
        "    state_space = gym.spaces.MultiDiscrete([4,4])\n",
        "    def update(t):\n",
        "        if states[t] in state_space:\n",
        "            s1,s2 = states[t]\n",
        "            states[t] = [s2,s1]\n",
        "            sc.set_offsets(states[t])\n",
        "        else:\n",
        "            s1,s2 = states[t]\n",
        "            s1 = s1 + 0.5 if s1 < 0 else (s1 - 0.5 if s1 > 3 else s1)\n",
        "            s2 = s2 + 0.5 if s2 < 0 else (s2 - 0.5 if s2 > 3 else s2)\n",
        "            states[t] = [s2,s1]       \n",
        "            sc.set_offsets(states[t])\n",
        "    ani = FuncAnimation(fig,update,frames=len(states))\n",
        "    display(IPython.display.HTML(ani.to_jshtml()))"
      ],
      "id": "21be108a-a98c-4c45-aad7-f00e89da6f63"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "show([[0,0],[1,0],[2,0],[3,0],[4,0]])"
      ],
      "id": "8e002dc1-14aa-4621-9670-f239b609a505"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. 4x4 Grid World 환경 구현"
      ],
      "id": "92fd967c-90e3-4271-9124-826f23c22dff"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "class GridWorld:\n",
        "    def __init__(self):\n",
        "        self.state_space = gym.spaces.MultiDiscrete([4,4])\n",
        "        self.action_space = gym.spaces.Discrete(4) \n",
        "        self._action_to_direction = {\n",
        "            0 : np.array([1, 0]), # row+, down\n",
        "            1 : np.array([0, 1]), # col+, right\n",
        "            2 : np.array([-1 ,0]), # row-, up\n",
        "            3 : np.array([0, -1]) # col-, left\n",
        "        }\n",
        "        self.reset()\n",
        "        self.state = None \n",
        "        self.reward = None \n",
        "        self.termiated = None\n",
        "    def step(self,action):\n",
        "        direction = self._action_to_direction[action]\n",
        "        self.state = self.state + direction\n",
        "        if np.array_equal(self.state,np.array([3,3])): \n",
        "            self.reward = 100 \n",
        "            self.terminated = True\n",
        "        elif self.state not in self.state_space:\n",
        "            self.reward = -10\n",
        "            self.terminated = True\n",
        "        else:\n",
        "            self.reward = -1 \n",
        "        return self.state, self.reward, self.terminated\n",
        "    def reset(self):\n",
        "        self.state = np.array([0,0])\n",
        "        self.terminated = False   \n",
        "        return self.state "
      ],
      "id": "26a6dd60-8c82-49b2-b54c-d52e67194908"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = GridWorld()\n",
        "state = env.reset()\n",
        "states = [] \n",
        "states.append(state)\n",
        "for t in range(50):\n",
        "    action = env.action_space.sample() \n",
        "    state,reward,terminated = env.step(action)\n",
        "    states.append(state)\n",
        "    if terminated: break "
      ],
      "id": "0b92cc09-d13f-4bda-95a8-b49a5b5b2f1e"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "show(states)"
      ],
      "id": "d8f27703-3648-437d-8e49-4da0b9672315"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   처음에 바로 죽는 경우가 많아 몇번 시도하고 위의 애니메이션을 얻음\n",
        "\n",
        "# 6. `AgentRandom` 구현하여 환경과 상호작용\n",
        "\n",
        "## A. 에이전트 클래스 설계\n",
        "\n",
        "`-` 우리가 구현하고 싶은 기능\n",
        "\n",
        "-   `.act()`: 액션을 결정 –\\> 여기서는 그냥 랜덤액션\n",
        "-   `.save_experience()`: 데이터를 저장 –\\> 여기에 일단 초점을 맞추자\n",
        "-   `.learn()`: 데이터로에서 학습 –\\> 패스"
      ],
      "id": "89ed4a10-a64f-4d83-af10-515c0db1e2c6"
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AgentRandom: \n",
        "    def __init__(self,env):\n",
        "        #--# define spaces \n",
        "        self.action_space = env.action_space\n",
        "        self.state_space = env.state_space\n",
        "        #--# replay buffer \n",
        "        self.action = None \n",
        "        self.actions = collections.deque(maxlen=500)\n",
        "        self.current_state =  None \n",
        "        self.current_states = collections.deque(maxlen=500)\n",
        "        self.reward = None \n",
        "        self.rewards = collections.deque(maxlen=500)\n",
        "        self.next_state =  None \n",
        "        self.next_states = collections.deque(maxlen=500)\n",
        "        self.terminated = None \n",
        "        self.terminations = collections.deque(maxlen=500)\n",
        "        #--# other information\n",
        "        self.n_episodes = 0         \n",
        "        self.n_experiences = 0\n",
        "        self.score = 0        \n",
        "        self.scores = collections.deque(maxlen=500)        \n",
        "    def act(self):\n",
        "        self.action = self.action_space.sample()\n",
        "    def learn(self):\n",
        "        pass \n",
        "    def save_experience(self):\n",
        "        self.current_states.append(self.current_state)        \n",
        "        self.actions.append(self.action)\n",
        "        self.rewards.append(self.reward)  \n",
        "        self.next_states.append(self.next_state)\n",
        "        self.terminations.append(self.terminated)\n",
        "        #--#\n",
        "        self.n_experiences = self.n_experiences + 1 \n",
        "        self.score = self.score + self.reward"
      ],
      "id": "8efcf916-1e5b-4ee3-a423-f5c2fabfb22c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B. 환경과 상호작용"
      ],
      "id": "f0b17524-a407-4acc-a1f8-3db2cd15cc66"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에피소드: 1     점수(에피소드): -14   경험수: 5\n",
            "에피소드: 2     점수(에피소드): -10   경험수: 6\n",
            "에피소드: 3     점수(에피소드): -11   경험수: 8\n",
            "에피소드: 4     점수(에피소드): -13   경험수: 12\n",
            "에피소드: 5     점수(에피소드): -10   경험수: 13\n",
            "에피소드: 6     점수(에피소드): -10   경험수: 14\n",
            "에피소드: 7     점수(에피소드): -13   경험수: 18\n",
            "에피소드: 8     점수(에피소드): -12   경험수: 21\n",
            "에피소드: 9     점수(에피소드): -16   경험수: 28\n",
            "에피소드: 10    점수(에피소드): -10   경험수: 29\n",
            "에피소드: 11    점수(에피소드): -15   경험수: 35\n",
            "에피소드: 12    점수(에피소드): -10   경험수: 36\n",
            "에피소드: 13    점수(에피소드): -10   경험수: 37\n",
            "에피소드: 14    점수(에피소드): -11   경험수: 39\n",
            "에피소드: 15    점수(에피소드): -12   경험수: 42\n",
            "에피소드: 16    점수(에피소드): -12   경험수: 45\n",
            "에피소드: 17    점수(에피소드): -10   경험수: 46\n",
            "에피소드: 18    점수(에피소드): -10   경험수: 47\n",
            "에피소드: 19    점수(에피소드): -11   경험수: 49\n",
            "에피소드: 20    점수(에피소드): -10   경험수: 50\n",
            "에피소드: 21    점수(에피소드): -12   경험수: 53\n",
            "에피소드: 22    점수(에피소드): -10   경험수: 54\n",
            "에피소드: 23    점수(에피소드): -10   경험수: 55\n",
            "에피소드: 24    점수(에피소드): -12   경험수: 58\n",
            "에피소드: 25    점수(에피소드): -12   경험수: 61\n",
            "에피소드: 26    점수(에피소드): -10   경험수: 62\n",
            "에피소드: 27    점수(에피소드): -10   경험수: 63\n",
            "에피소드: 28    점수(에피소드): -11   경험수: 65\n",
            "에피소드: 29    점수(에피소드): -10   경험수: 66\n",
            "에피소드: 30    점수(에피소드): -17   경험수: 74\n",
            "에피소드: 31    점수(에피소드): -10   경험수: 75\n",
            "에피소드: 32    점수(에피소드): -13   경험수: 79\n",
            "에피소드: 33    점수(에피소드): -10   경험수: 80\n",
            "에피소드: 34    점수(에피소드): -13   경험수: 84\n",
            "에피소드: 35    점수(에피소드): -11   경험수: 86\n",
            "에피소드: 36    점수(에피소드): -10   경험수: 87\n",
            "에피소드: 37    점수(에피소드): 87    경험수: 101\n",
            "에피소드: 38    점수(에피소드): -11   경험수: 103\n",
            "에피소드: 39    점수(에피소드): -11   경험수: 105\n",
            "에피소드: 40    점수(에피소드): -10   경험수: 106\n",
            "에피소드: 41    점수(에피소드): -11   경험수: 108\n",
            "에피소드: 42    점수(에피소드): -10   경험수: 109\n",
            "에피소드: 43    점수(에피소드): -10   경험수: 110\n",
            "에피소드: 44    점수(에피소드): -14   경험수: 115\n",
            "에피소드: 45    점수(에피소드): -11   경험수: 117\n",
            "에피소드: 46    점수(에피소드): -13   경험수: 121\n",
            "에피소드: 47    점수(에피소드): -10   경험수: 122\n",
            "에피소드: 48    점수(에피소드): -13   경험수: 126\n",
            "에피소드: 49    점수(에피소드): -20   경험수: 137\n",
            "에피소드: 50    점수(에피소드): -10   경험수: 138"
          ]
        }
      ],
      "source": [
        "env = GridWorld()\n",
        "agent = AgentRandom(env)\n",
        "#--#\n",
        "for _ in range(50):\n",
        "    agent.current_state = env.reset()\n",
        "    agent.score = 0 \n",
        "    for t in range(100):\n",
        "        # step1: 행동\n",
        "        agent.act()\n",
        "        # step2: 보상\n",
        "        agent.next_state, agent.reward, agent.terminated = env.step(agent.action)\n",
        "        # step3: 저장 & 학습\n",
        "        agent.save_experience()\n",
        "        agent.learn()\n",
        "        # step4: \n",
        "        agent.current_state = agent.next_state\n",
        "        if agent.terminated: break\n",
        "    agent.scores.append(agent.score) \n",
        "    agent.n_episodes = agent.n_episodes + 1 \n",
        "    #---#\n",
        "    print(\n",
        "        f\"에피소드: {agent.n_episodes} \\t\"\n",
        "        f\"점수(에피소드): {agent.scores[-1]} \\t\" \n",
        "        f\"경험수: {agent.n_experiences}\"\n",
        "    )"
      ],
      "id": "af2f37ce-cdbe-4f06-ae8b-422d84464f70"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C. 상호작용결과 시각화"
      ],
      "id": "1fb16964-ea6c-411a-8a9d-60843b1e9af7"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "[np.array([0,0])] + list(agent.next_states)[134:140]"
      ],
      "id": "e98cd24d-9a57-4a85-9acb-f4808359e9c2"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "show([np.array([0,0])] + list(agent.next_states)[134:140])"
      ],
      "id": "5b9d9805-d0c0-428e-bc24-9386b7c01b3c"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  }
}