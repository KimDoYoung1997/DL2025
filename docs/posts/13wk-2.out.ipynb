{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 13wk-2: (강화학습) – Bandit 환경 설계 및 풀이, 4x4 Grid World\n",
        "\n",
        "게임설명, 환경구현, 에이전트(랜덤)구현\n",
        "\n",
        "최규빈  \n",
        "2025-06-02\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/guebin/DL2025/blob/main/posts/13wk-2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n",
        "\n",
        "# 1. 강의영상\n",
        "\n",
        "<https://youtu.be/playlist?list=PLQqh36zP38-xRfokRN58uC0Mr4NGrJiWX&si=PhVcbmFUN0x3TLfN>\n",
        "\n",
        "# 2. Imports"
      ],
      "id": "c3a8d916-a4cd-48d0-88b2-4918e0f04c3d"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "#---#\n",
        "import numpy as np\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import IPython"
      ],
      "id": "3857ad14-f8de-4973-ae86-7adb7fd1af6f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Bandit 환경 설계 및 풀이\n",
        "\n",
        "## A. 대충 개념만 실습"
      ],
      "id": "b6ed15bd-a561-435c-91e6-678714f5abdd"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "action_space = [0,1] \n",
        "actions_deque = collections.deque(maxlen=500)\n",
        "rewards_deque =  collections.deque(maxlen=500)\n",
        "#---#"
      ],
      "id": "f58ccc61-bdef-4708-aabb-ff427cd89d99"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(10):\n",
        "    action = np.random.choice(action_space)\n",
        "    if action == 1:\n",
        "        reward = 10 \n",
        "    else:\n",
        "        reward = 1\n",
        "    actions_deque.append(action)\n",
        "    rewards_deque.append(reward)"
      ],
      "id": "4d6ab7a7-f7b1-48ef-adf0-072459dec4cf"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "actions_deque"
      ],
      "id": "4908cf64-ea61-4430-a526-5154fbca0b50"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "rewards_deque"
      ],
      "id": "0de137ca-a78b-4522-a56c-d391d0bc37b5"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "actions_numpy = np.array(actions_deque)\n",
        "rewards_numpy = np.array(rewards_deque)"
      ],
      "id": "1cfb5c3a-5c72-42a0-86a0-e48e9ad8f537"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "q0 = rewards_numpy[actions_numpy == 0].mean()\n",
        "q1 = rewards_numpy[actions_numpy == 1].mean()\n",
        "q_table = np.array([q0,q1])\n",
        "q_table"
      ],
      "id": "0fcadb60-bf36-4c5d-8f08-dcf890f26ff6"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "action = q_table.argmax()"
      ],
      "id": "3ba6499e-e137-45b6-8318-9f647c889585"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(5):\n",
        "    action = q_table.argmax()\n",
        "    if action == 1:\n",
        "        reward = 10 \n",
        "    else:\n",
        "        reward = 1\n",
        "    actions_deque.append(action)\n",
        "    rewards_deque.append(reward)\n",
        "    actions_numpy = np.array(actions_deque)\n",
        "    rewards_numpy = np.array(rewards_deque)    \n",
        "    q0 = rewards_numpy[actions_numpy == 0].mean()\n",
        "    q1 = rewards_numpy[actions_numpy == 1].mean()\n",
        "    q_table = np.array([q0,q1])"
      ],
      "id": "0ca81468-2ff7-454a-9fd9-c90abcfb30ed"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "actions_numpy"
      ],
      "id": "32e2d548-1c32-4aa2-b201-ac7b3ac6f9bd"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "rewards_numpy"
      ],
      "id": "6322c32b-dda3-4f74-bfc4-3f938eb78aa3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B. 클래스를 이용한 구현"
      ],
      "id": "3176b888-e0b6-48e7-a629-f3e80beccc19"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Bandit:\n",
        "    def __init__(self):\n",
        "        self.reward = None \n",
        "    def step(self,action):\n",
        "        if action == 0:\n",
        "            self.reward = 1\n",
        "        else: \n",
        "            self.reward = 10 \n",
        "        return self.reward "
      ],
      "id": "ecadad99-7cb3-468f-9fd1-f7a1c90d6198"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    def __init__(self):\n",
        "        pass \n",
        "    def act(self):\n",
        "        # 만약에 경험이 20보다 작음 --> 랜덤액션 \n",
        "        # 경험이 20보다 크면 --> action = q_tabel.argmax()\n",
        "        pass \n",
        "    def save_experience(self):\n",
        "        # 데이터 저장 \n",
        "        pass \n",
        "    def learn(self):\n",
        "        # q_table 을 업데이트하는 과정 \n",
        "        pass"
      ],
      "id": "ab591669-92e9-40c6-8831-ed5cd9481b33"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------"
      ],
      "id": "4eb15883-a324-414a-ae04-8c5c815b01a9"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    def __init__(self):\n",
        "        self.action = None \n",
        "        self.reward = None \n",
        "        self.actions = collections.deque(maxlen=500)\n",
        "        self.rewards = collections.deque(maxlen=500)\n",
        "        self.action_space = [0,1] \n",
        "        self.q_table = None \n",
        "        self.n_experience = 0\n",
        "    def act(self):\n",
        "        if self.n_experience < 20:\n",
        "            self.action = np.random.choice(self.action_space)\n",
        "        else: \n",
        "            self.action = self.q_table.argmax()\n",
        "        print(f\"버튼{self.action}누름!\")\n",
        "    def save_experience(self):\n",
        "        self.actions.append(self.action)\n",
        "        self.rewards.append(self.reward)\n",
        "        self.n_experience = self.n_experience + 1\n",
        "    def learn(self):\n",
        "        if self.n_experience < 20:\n",
        "            pass\n",
        "        else:\n",
        "            # q_table 을 업데이트하는 과정 \n",
        "            actions = np.array(self.actions)\n",
        "            rewards = np.array(self.rewards)\n",
        "            q0 = rewards[actions == 0].mean() # 행동0을했을때 얻는 보상의 평균값\n",
        "            q1 = rewards[actions == 1].mean()# 행동1을했을때 얻는 보상의 평균값\n",
        "            self.q_table = np.array([q0,q1])"
      ],
      "id": "38e775f8-dfa9-4d8b-b1b5-80638bca1b7c"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "버튼0누름!\n",
            "버튼0누름!\n",
            "버튼0누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼0누름!\n",
            "버튼1누름!\n",
            "버튼0누름!\n",
            "버튼1누름!\n",
            "버튼0누름!\n",
            "버튼0누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼0누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "---게임클리어---"
          ]
        }
      ],
      "source": [
        "env = Bandit()\n",
        "player = Agent()\n",
        "for _ in range(100):\n",
        "    # step1: agent action \n",
        "    player.act()\n",
        "    # step2: action --> state, reward\n",
        "    player.reward = env.step(player.action)\n",
        "    # step3: agent가 데이터를 축적하고 학습\n",
        "    player.save_experience() # 데이터를 저장\n",
        "    player.learn() #저장된 데이터를 학습 \n",
        "    #---강화학습의 종료를 결정--#\n",
        "    if player.n_experience < 20:\n",
        "        pass \n",
        "    else: \n",
        "        if np.array(player.rewards)[-20:].mean() > 9.5:\n",
        "            print(\"---게임클리어---\")\n",
        "            break"
      ],
      "id": "5e0ffc59-7f4d-4810-8a25-23ace21ad927"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. 예비학습: `gym.spaces`\n",
        "\n",
        "ref: <https://gymnasium.farama.org/>\n",
        "\n",
        "`-` 예시1"
      ],
      "id": "b2455bb5-2788-4bc8-8507-14c886e13e4c"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "action_space = gym.spaces.Discrete(4) \n",
        "action_space "
      ],
      "id": "abfd14a1-2b01-49ac-afb1-f0ad3a9167f4"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "[action_space.sample() for _ in range(5)]"
      ],
      "id": "930613b6-38d6-41b5-b2a9-23f9e30d8933"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "0 in action_space"
      ],
      "id": "8a9f7303-533f-4ea4-a1d8-680f56bae51f"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "4 in action_space"
      ],
      "id": "78592488-f2d1-44a2-8c1e-c36e6cf71f64"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 예시2"
      ],
      "id": "365f3359-f6c9-4786-b878-aec5a8df8868"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "state_space = gym.spaces.MultiDiscrete([4,4])\n",
        "state_space"
      ],
      "id": "7877707a-8153-4ce7-8105-1fd2f9eeade7"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "[state_space.sample() for _ in range(5)]"
      ],
      "id": "709ed7f9-0e09-4ad6-900a-2272b9d902e3"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.array([0,1]) in state_space"
      ],
      "id": "85bde880-6ede-4a03-8d72-2ace4764a0cf"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "np.array([3,3]) in state_space"
      ],
      "id": "54c52c0b-1974-455d-83fc-9e051f5d3658"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "np.array([3,4]) in state_space"
      ],
      "id": "58c2d1f4-4d59-4d63-ae60-2637505b6460"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. 4x4 Grid World 게임 설명\n",
        "\n",
        "## A. 게임설명\n",
        "\n",
        "`-` 문제설명: 4x4 그리드월드에서 상하좌우로 움직이는 에이전트가 목표점에\n",
        "도달하도록 하는 게임\n",
        "\n",
        "-   백문이 불여일견:\n",
        "    <https://claude.ai/public/artifacts/76e13820-2b51-4e7e-a514-00190de17c45>\n",
        "    (출처: 클로드)\n",
        "\n",
        "`-` GridWorld에서 사용되는 주요변수\n",
        "\n",
        "1.  **`State`**: 각 격자 셀이 하나의 상태이며, 에이전트는 이러한 상태 중\n",
        "    하나에 있을 수 있음.\n",
        "2.  **`Action`**: 에이전트는 현재상태에서 다음상태로 이동하기 위해\n",
        "    상,하,좌,우 중 하나의 행동을 취할 수 있음.\n",
        "3.  **`Reward`**: 에이전트가 현재상태에서 특정 action을 하면 얻어지는\n",
        "    보상.\n",
        "4.  **`Terminated`**: 하나의 에피소드가 종료되었음을 나타내는 상태.\n",
        "\n",
        "## B. 시각화"
      ],
      "id": "90c6d18b-86ad-4d93-859e-d8db71a86023"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "def show(states):\n",
        "    fig = plt.Figure()\n",
        "    ax = fig.subplots()\n",
        "    ax.matshow(np.zeros([4,4]), cmap='bwr',alpha=0.0)\n",
        "    sc = ax.scatter(0, 0, color='red', s=500)  \n",
        "    ax.text(0, 0, 'start', ha='center', va='center')\n",
        "    ax.text(3, 3, 'end', ha='center', va='center')\n",
        "    # Adding grid lines to the plot\n",
        "    ax.set_xticks(np.arange(-.5, 4, 1), minor=True)\n",
        "    ax.set_yticks(np.arange(-.5, 4, 1), minor=True)\n",
        "    ax.grid(which='minor', color='black', linestyle='-', linewidth=2)\n",
        "    state_space = gym.spaces.MultiDiscrete([4,4])\n",
        "    def update(t):\n",
        "        if states[t] in state_space:\n",
        "            s1,s2 = states[t]\n",
        "            states[t] = [s2,s1]\n",
        "            sc.set_offsets(states[t])\n",
        "        else:\n",
        "            s1,s2 = states[t]\n",
        "            s1 = s1 + 0.5 if s1 < 0 else (s1 - 0.5 if s1 > 3 else s1)\n",
        "            s2 = s2 + 0.5 if s2 < 0 else (s2 - 0.5 if s2 > 3 else s2)\n",
        "            states[t] = [s2,s1]       \n",
        "            sc.set_offsets(states[t])\n",
        "    ani = FuncAnimation(fig,update,frames=len(states))\n",
        "    display(IPython.display.HTML(ani.to_jshtml()))"
      ],
      "id": "a5cf9f1a-6eb4-4f1c-8db3-8110e99acb2b"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "show([[0,0],[1,0],[2,0],[3,0],[4,0]]) # show 사용방법"
      ],
      "id": "828d00d6-81b1-4b26-9a8d-3456f080ad28"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. 4x4 Grid World 환경 구현"
      ],
      "id": "2d960627-fff6-4517-bc88-0461282520d2"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GridWorld:\n",
        "    def __init__(self):\n",
        "        self.a2d = {\n",
        "            0: np.array([0,1]), # →\n",
        "            1: np.array([0,-1]), # ←  \n",
        "            2: np.array([1,0]),  # ↓\n",
        "            3: np.array([-1,0])  # ↑\n",
        "        }\n",
        "        self.state_space = gym.spaces.MultiDiscrete([4,4])\n",
        "        self.state = np.array([0,0])\n",
        "        self.reward = None\n",
        "        self.terminated = False\n",
        "    def step(self,action):\n",
        "        self.state = self.state + self.a2d[action]\n",
        "        s1,s2 = self.state\n",
        "        if (s1==3) and (s2==3):\n",
        "            self.reward = 100 \n",
        "            self.terminated = True\n",
        "        elif self.state in self.state_space:\n",
        "            self.reward = -1 \n",
        "            self.terminated = False\n",
        "        else:\n",
        "            self.reward = -10\n",
        "            self.terminated = True\n",
        "        print(\n",
        "            f\"action = {action}\\t\"\n",
        "            f\"state = {self.state - self.a2d[action]} -> {self.state}\\t\"\n",
        "            f\"reward = {self.reward}\\t\"\n",
        "            f\"termiated = {self.terminated}\"\n",
        "        )            \n",
        "        return self.state, self.reward, self.terminated\n",
        "    def reset(self):\n",
        "        self.state = np.array([0,0])\n",
        "        self.terminated = False\n",
        "        return self.state"
      ],
      "id": "55b4d592-274b-40d5-99be-ba8a9e904814"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = GridWorld()"
      ],
      "id": "b88cd40a-3e6a-4a32-857d-127326b387c9"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True"
          ]
        }
      ],
      "source": [
        "action_space = gym.spaces.Discrete(4)\n",
        "for _ in range(50):\n",
        "    action = action_space.sample()\n",
        "    env.step(action)\n",
        "    if env.terminated == True:\n",
        "        env.reset()\n",
        "        break"
      ],
      "id": "9bf58668-7d83-446f-8626-cc6bfdd30261"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7. “에이전트 $\\Leftrightarrow$ 환경” 상호작용 구현\n",
        "\n",
        "`-` 우리가 구현하고 싶은 기능\n",
        "\n",
        "-   `.act()`: 액션을 결정 –\\> 여기서는 그냥 랜덤액션\n",
        "-   `.save_experience()`: 데이터를 저장 –\\> 여기에 일단 초점을 맞추자\n",
        "-   `.learn()`: 데이터로에서 학습 –\\> 패스"
      ],
      "id": "075e41a5-9646-45d6-a17d-fc4fa32f1d33"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RandomAgent:\n",
        "    def __init__(self):\n",
        "        self.state = None \n",
        "        self.action = None \n",
        "        self.reward = None \n",
        "        self.next_state = None\n",
        "        self.terminated = None\n",
        "        #---#\n",
        "        self.states = collections.deque(maxlen=500)\n",
        "        self.actions = collections.deque(maxlen=500)\n",
        "        self.rewards = collections.deque(maxlen=500)\n",
        "        self.next_states = collections.deque(maxlen=500)\n",
        "        self.terminations = collections.deque(maxlen=500)\n",
        "        #---#\n",
        "        self.action_space = gym.spaces.Discrete(4)\n",
        "        self.n_experience = 0\n",
        "    def act(self):\n",
        "        self.action = self.action_space.sample()\n",
        "    def save_experience(self):\n",
        "        self.states.append(self.state)\n",
        "        self.actions.append(self.action)\n",
        "        self.rewards.append(self.reward)\n",
        "        self.next_states.append(self.next_state)\n",
        "        self.terminations.append(self.terminated)\n",
        "        self.n_experience = self.n_experience + 1\n",
        "    def learn(self):\n",
        "        pass "
      ],
      "id": "ad0ef1e7-2cde-46bc-9fa8-d3737679f539"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "player = RandomAgent()\n",
        "env = GridWorld()"
      ],
      "id": "1de109e4-c35a-4578-a688-287ac60afbee"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 1  state = [2 0] -> [ 2 -1]    reward = -10    termiated = True"
          ]
        }
      ],
      "source": [
        "for t in range(50):\n",
        "    # step1 -- 에이전트가 action을 함 \n",
        "    player.act()\n",
        "    # step2 -- 환경이 에이전트의 action을 보고 next_state, reward, terminated \n",
        "    player.next_state, player.reward, player.terminated = env.step(player.action)\n",
        "    # step3 -- 에이전트가 save & learn\n",
        "    player.save_experience()\n",
        "    player.learn()\n",
        "    # step4 -- next iteration \n",
        "    player.state = player.next_state\n",
        "    if env.terminated:\n",
        "        player.state = env.reset()\n",
        "        break"
      ],
      "id": "249a50e2-3259-454b-9bcc-16fc58d32261"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action = 0  state = [-1  0] -> [-1  1]  reward = -10    termiated = True\n",
            "---에피소드1종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 3  state = [0 1] -> [-1  1]    reward = -10    termiated = True\n",
            "---에피소드2종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드3종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 0  state = [0 1] -> [0 2]  reward = -1 termiated = False\n",
            "action = 2  state = [0 2] -> [1 2]  reward = -1 termiated = False\n",
            "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 3  state = [1 2] -> [0 2]  reward = -1 termiated = False\n",
            "action = 1  state = [0 2] -> [0 1]  reward = -1 termiated = False\n",
            "action = 0  state = [0 1] -> [0 2]  reward = -1 termiated = False\n",
            "action = 1  state = [0 2] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드4종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드5종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 0  state = [0 1] -> [0 2]  reward = -1 termiated = False\n",
            "action = 2  state = [0 2] -> [1 2]  reward = -1 termiated = False\n",
            "action = 2  state = [1 2] -> [2 2]  reward = -1 termiated = False\n",
            "action = 3  state = [2 2] -> [1 2]  reward = -1 termiated = False\n",
            "action = 3  state = [1 2] -> [0 2]  reward = -1 termiated = False\n",
            "action = 2  state = [0 2] -> [1 2]  reward = -1 termiated = False\n",
            "action = 2  state = [1 2] -> [2 2]  reward = -1 termiated = False\n",
            "action = 1  state = [2 2] -> [2 1]  reward = -1 termiated = False\n",
            "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
            "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
            "action = 3  state = [2 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
            "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드6종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 0  state = [0 1] -> [0 2]  reward = -1 termiated = False\n",
            "action = 2  state = [0 2] -> [1 2]  reward = -1 termiated = False\n",
            "action = 0  state = [1 2] -> [1 3]  reward = -1 termiated = False\n",
            "action = 0  state = [1 3] -> [1 4]  reward = -10    termiated = True\n",
            "---에피소드7종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드8종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드9종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 1  state = [1 0] -> [ 1 -1]    reward = -10    termiated = True\n",
            "---에피소드10종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드11종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 3  state = [1 2] -> [0 2]  reward = -1 termiated = False\n",
            "action = 0  state = [0 2] -> [0 3]  reward = -1 termiated = False\n",
            "action = 1  state = [0 3] -> [0 2]  reward = -1 termiated = False\n",
            "action = 2  state = [0 2] -> [1 2]  reward = -1 termiated = False\n",
            "action = 2  state = [1 2] -> [2 2]  reward = -1 termiated = False\n",
            "action = 1  state = [2 2] -> [2 1]  reward = -1 termiated = False\n",
            "action = 0  state = [2 1] -> [2 2]  reward = -1 termiated = False\n",
            "action = 0  state = [2 2] -> [2 3]  reward = -1 termiated = False\n",
            "action = 0  state = [2 3] -> [2 4]  reward = -10    termiated = True\n",
            "---에피소드12종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드13종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드14종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드15종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드16종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 0  state = [1 2] -> [1 3]  reward = -1 termiated = False\n",
            "action = 0  state = [1 3] -> [1 4]  reward = -10    termiated = True\n",
            "---에피소드17종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드18종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 1  state = [1 0] -> [ 1 -1]    reward = -10    termiated = True\n",
            "---에피소드19종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드20종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 1  state = [1 0] -> [ 1 -1]    reward = -10    termiated = True\n",
            "---에피소드21종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 0  state = [0 1] -> [0 2]  reward = -1 termiated = False\n",
            "action = 0  state = [0 2] -> [0 3]  reward = -1 termiated = False\n",
            "action = 1  state = [0 3] -> [0 2]  reward = -1 termiated = False\n",
            "action = 3  state = [0 2] -> [-1  2]    reward = -10    termiated = True\n",
            "---에피소드22종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드23종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 0  state = [0 1] -> [0 2]  reward = -1 termiated = False\n",
            "action = 0  state = [0 2] -> [0 3]  reward = -1 termiated = False\n",
            "action = 2  state = [0 3] -> [1 3]  reward = -1 termiated = False\n",
            "action = 3  state = [1 3] -> [0 3]  reward = -1 termiated = False\n",
            "action = 3  state = [0 3] -> [-1  3]    reward = -10    termiated = True\n",
            "---에피소드24종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
            "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
            "action = 2  state = [2 0] -> [3 0]  reward = -1 termiated = False\n",
            "action = 2  state = [3 0] -> [4 0]  reward = -10    termiated = True\n",
            "---에피소드25종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드26종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드27종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 1  state = [2 0] -> [ 2 -1]    reward = -10    termiated = True\n",
            "---에피소드28종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
            "action = 3  state = [2 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
            "action = 0  state = [2 1] -> [2 2]  reward = -1 termiated = False\n",
            "action = 3  state = [2 2] -> [1 2]  reward = -1 termiated = False\n",
            "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 2  state = [1 2] -> [2 2]  reward = -1 termiated = False\n",
            "action = 0  state = [2 2] -> [2 3]  reward = -1 termiated = False\n",
            "action = 1  state = [2 3] -> [2 2]  reward = -1 termiated = False\n",
            "action = 2  state = [2 2] -> [3 2]  reward = -1 termiated = False\n",
            "action = 1  state = [3 2] -> [3 1]  reward = -1 termiated = False\n",
            "action = 3  state = [3 1] -> [2 1]  reward = -1 termiated = False\n",
            "action = 3  state = [2 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 3  state = [1 2] -> [0 2]  reward = -1 termiated = False\n",
            "action = 2  state = [0 2] -> [1 2]  reward = -1 termiated = False\n",
            "action = 2  state = [1 2] -> [2 2]  reward = -1 termiated = False\n",
            "action = 0  state = [2 2] -> [2 3]  reward = -1 termiated = False\n",
            "action = 1  state = [2 3] -> [2 2]  reward = -1 termiated = False\n",
            "action = 2  state = [2 2] -> [3 2]  reward = -1 termiated = False\n",
            "action = 3  state = [3 2] -> [2 2]  reward = -1 termiated = False\n",
            "action = 0  state = [2 2] -> [2 3]  reward = -1 termiated = False\n",
            "action = 1  state = [2 3] -> [2 2]  reward = -1 termiated = False\n",
            "action = 0  state = [2 2] -> [2 3]  reward = -1 termiated = False\n",
            "action = 2  state = [2 3] -> [3 3]  reward = 100    termiated = True\n",
            "---에피소드29종료---"
          ]
        }
      ],
      "source": [
        "scores = [] \n",
        "score = 0 \n",
        "for e in range(1,100):\n",
        "    #---에피소드시작---#\n",
        "    while True:\n",
        "        # step1 -- 에이전트가 action을 함 \n",
        "        player.act()\n",
        "        # step2 -- 환경이 에이전트의 action을 보고 next_state, reward, terminated 을 return\n",
        "        player.next_state, player.reward, player.terminated = env.step(player.action)\n",
        "        # step3 -- 에이전트가 save & learn\n",
        "        player.save_experience()\n",
        "        player.learn()\n",
        "        # step4 -- next iteration \n",
        "        if env.terminated:\n",
        "            score = score + player.reward\n",
        "            scores.append(score)\n",
        "            score = 0 \n",
        "            player.state = env.reset() \n",
        "            print(f\"---에피소드{e}종료---\")\n",
        "            break\n",
        "        else: \n",
        "            score = score + player.reward\n",
        "            scores.append(score)            \n",
        "            player.state = player.next_state\n",
        "    #---에피소드끝---#\n",
        "    if scores[-1] > 0:\n",
        "        break"
      ],
      "id": "90366133-7154-4232-a50a-4503055ea144"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "paths = [np.array([0,0])]+ list(player.next_states)[-28:]\n",
        "show(paths)"
      ],
      "id": "2702da36-edeb-42f7-9338-f032502c11c4"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  }
}