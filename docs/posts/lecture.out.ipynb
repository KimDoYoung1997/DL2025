{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# lecture\n",
        "\n",
        "최규빈  \n",
        "2025-05-19\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/guebin/DL2025/blob/main/posts/09wk-2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n",
        "\n",
        "# 1. 강의영상"
      ],
      "id": "2318e79f-7c3d-4c7e-8f82-ce02ac4fefc2"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "#{{<video https://youtu.be/playlist?list=PLQqh36zP38-zuDZdouFCc1D5qJe36M2S0&si=kOtJ2iFWNwqIU4R6 >}}"
      ],
      "id": "05948607-43ef-4979-a3df-27cb3c9e3959"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Imports"
      ],
      "id": "fb957b0b-7449-4abb-b7d4-649f447b9135"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "c9b95da2-8bbd-4870-b631-6825e2f4fc4b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. 예비학습\n",
        "\n",
        "## A. 파이토치의 유연성\n",
        "\n",
        "`-` 아래는 엄밀한 의미에서는 계산불가능하지만 파이토치는 그냥 해준다.\n",
        "\n",
        "`-` 이와 유사하게 아래도 엄밀한 의미에서는 계산불가능하지만 파이토치는\n",
        "그냥 해준다.\n",
        "\n",
        "## B. loss를 계산하는 다른방식\n",
        "\n",
        "`-` 아래를 가정하자.\n",
        "\n",
        "`-` loss를 계산하는 방법1\n",
        "\n",
        "`-` loss를 계산하는 방법2\n",
        "\n",
        "# 4. 겹장(덧장)\n",
        "\n",
        "***(생각1) ${\\boldsymbol h}$에 대한 이해***\n",
        "\n",
        "`-` ${\\boldsymbol h}$는 사실 문자열 “abc, abcd”들을 숫자로 바꾼 표현이라\n",
        "해석할 수 있음. 즉 원핫인코딩과 다른 또 다른 형태의 숫자표현이라 해석할\n",
        "수 있다.\n",
        "\n",
        "`-` 사실 ${\\boldsymbol h}$는 원핫인코딩보다 약간 더 (1) 액기스만 남은\n",
        "느낌 + (2) 숙성된 느낌을 준다\n",
        "\n",
        "-   (why1) ${\\boldsymbol h}$는 ${\\boldsymbol x}$ 보다\n",
        "    ${\\boldsymbol y}$를 예측함에 좀 더 직접적인 역할을 한다. 즉\n",
        "    ${\\boldsymbol x}$ 숫자보다 ${\\boldsymbol h}$ 숫자가 잘 정리되어 있고\n",
        "    (차원이 낮고) 입력의 특징을 잘 정리한 (추천시스템의 MBTI처럼)\n",
        "    의미있는 숫자이다.\n",
        "-   (why2) ${\\boldsymbol x}$는 학습없이 그냥 얻어지는 숫자표현이지만,\n",
        "    ${\\boldsymbol h}$는 학습을 통하여 고치고 고치고 고친 숫자표현이다.\n",
        "\n",
        "결론: 사실 ${\\boldsymbol h}$는 잘 숙성되어있는 입력정보\n",
        "${\\boldsymbol x}$ 그 자체로 해석 할 수 있다.\n",
        "\n",
        "***(생각2) [수백년전통을 이어가는\n",
        "방법](https://www.joongang.co.kr/article/24087690#home)***\n",
        "\n",
        "    “1리터에 500만원에 낙찰된 적 있습니다.”\n",
        "    “2kg에 1억원 정도 추산됩니다.”\n",
        "    “20여 종 종자장을 블렌딩해 100ml에 5000만원씩 분양 예정입니다.”\n",
        "\n",
        "    모두 씨간장(종자장) 가격에 관한 실제 일화다.\n",
        "\n",
        "    (중략...)\n",
        "\n",
        "    위스키나 와인처럼 블렌딩을 하기도 한다. \n",
        "    새로 담근 간장에 씨간장을 넣거나, 씨간장독에 햇간장을 넣어 맛을 유지하기도 한다. \n",
        "    이를 겹장(또는 덧장)이라 한다. \n",
        "    몇몇 종갓집에선 씨간장 잇기를 몇백 년째 해오고 있다. \n",
        "    매년 새로 간장을 담가야 이어갈 수 있으니 불씨 꺼트리지 않는 것처럼 굉장히 어려운 일이다.\n",
        "    이렇게 하는 이유는 집집마다 내려오는 고유 장맛을 잃지 않기 위함이다. \n",
        "    씨간장이란 그만큼 소중한 주방의 자산이며 정체성이다.\n",
        "\n",
        "덧장: 새로운간장을 만들때, 옛날간장을 섞어서 만듦\n",
        "\n",
        "`*` 기존방식 -\n",
        "$\\text{콩물} \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}$\n",
        "\n",
        "`*` 수백년 전통의 간장맛을 유지하는 방식\n",
        "\n",
        "-   $\\text{콩물}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1$\n",
        "-   $\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2$\n",
        "-   $\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3$\n",
        "\n",
        "`*` 수백년 전통의 간장맛을 유지하면서 조리를 한다면?\n",
        "\n",
        "-   $\\text{콩물}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_1$\n",
        "-   $\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_2$\n",
        "-   $\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_3$\n",
        "\n",
        "점점 맛있는 간장계란밥이 탄생함\n",
        "\n",
        "`*` 알고리즘의 편의상 아래와 같이 생각해도 무방\n",
        "\n",
        "-   $\\text{콩물}_1, \\text{간장}_0 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_1$,\n",
        "    $\\text{간장}_0=\\text{맹물}$\n",
        "-   $\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_2$\n",
        "-   $\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_3$\n",
        "\n",
        "***아이디어***\n",
        "\n",
        "`*` 수백년 전통의 간장맛을 유지하면서 조리하는 과정을 수식으로? (콩물을\n",
        "$x$로, 간장을 $h$로!!)\n",
        "\n",
        "-   $\\boldsymbol{x}_1, \\boldsymbol{h}_0 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_1 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_1$\n",
        "-   $\\boldsymbol{x}_2, \\boldsymbol{h}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_2 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_2$\n",
        "-   $\\boldsymbol{x}_3, \\boldsymbol{h}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_3 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_3$\n",
        "\n",
        "이제 우리가 배울것은 (1) “$\\text{콩물}_{t}$”와 “$\\text{간장}_{t-1}$”로\n",
        "“$\\text{간장}_t$”를 `숙성`하는 방법 (2) “$\\text{간장}_t$”로\n",
        "“$\\text{간장계란밥}_t$를 `조리`하는 방법이다\n",
        "\n",
        "즉 `숙성`담당 네트워크와 `조리`담당 네트워크를 각각 만들어 학습하면\n",
        "된다.\n",
        "\n",
        "# 5. RNNCell\n",
        "\n",
        "## A. 차원의 정리\n",
        "\n",
        "`-` 기본버전\n",
        "\n",
        "-   X.shape = $(L, H_{in})$\n",
        "-   h.shape = $(L, H_{out})$\n",
        "-   y.shape = $(L, Q)$\n",
        "-   Xt.shape = $(H_{in}, )$\n",
        "-   ht.shape = $(H_{out},)$\n",
        "-   yt.shape = $(Q,)$\n",
        "\n",
        "`-` `AbAcAd`를 2차원공간에 임베딩하려고 할 경우.\n",
        "\n",
        "-   X.shape = $(L, H_{in})$ = $(L,4)$\n",
        "-   h.shape = $(L, H_{out})$ = $(L,2)$\n",
        "-   y.shape = $(L, Q)$ = $(L,4)$\n",
        "-   Xt.shape = $(H_{in}, )$ = $(4,)$\n",
        "-   ht.shape = $(H_{out},)$ = $(2,)$\n",
        "-   yt.shape = $(Q,)$ = $(4,)$\n",
        "\n",
        "## B. 순환신경망 알고리즘\n",
        "\n",
        "***`# 버전1`***\n",
        "\n",
        "**step 1**: 일단 $\\text{간장}_0(={\\boldsymbol h}_0)$을 맹물로 초기화\n",
        "한다. 즉 아래를 수행한다.\n",
        "\n",
        "$${\\boldsymbol h}_0 = [0,0]$$\n",
        "\n",
        "**step 2**: $\\text{콩물}_1(={\\boldsymbol x}_1)$,\n",
        "$\\text{간장}_0(={\\boldsymbol h}_0)$ 을 이용하여\n",
        "$\\text{간장}_1(={\\boldsymbol h}_1)$을 숙성한다. 즉 아래를 수행한다. (즉\n",
        "콩물과 오래된 간장을 합친뒤 숙성)\n",
        "\n",
        "$${\\boldsymbol h}_1= \\tanh({\\boldsymbol x}_1{\\bf W}_{ih}+{\\boldsymbol h}_0{\\bf W}_{hh}+{\\boldsymbol b}_{ih}+{\\boldsymbol b}_{hh})$$\n",
        "\n",
        "> **Note**\n",
        ">\n",
        "> 아래의 식이 성립함을 관찰하자.\n",
        ">\n",
        "> $$\\begin{bmatrix} {\\boldsymbol x}_1 & {\\boldsymbol h}_{0} \\end{bmatrix}\\begin{bmatrix} {\\bf W}_{ih} \\\\ {\\bf W}_{hh}\\end{bmatrix}={\\boldsymbol x}_1{\\bf W}_{ih}+{\\boldsymbol h}_0{\\bf W}_{hh}$$\n",
        "\n",
        "**step 3:** $\\text{간장}_1$을 이용하여 $\\text{간장계란밥}_1$을 만든다.\n",
        "그리고 $\\hat{\\boldsymbol y}_1$을 만든다.\n",
        "\n",
        "$${\\boldsymbol o}_1= {\\bf W}_{ho}{\\boldsymbol h}_1+{\\boldsymbol b}_{ho}$$\n",
        "\n",
        "$$\\hat{\\boldsymbol y}_1 = \\text{soft}({\\boldsymbol o}_1)$$\n",
        "\n",
        "**step 4**: $t=2,3,4,5,\\dots,L$ 에 대하여 step2-3을 반복한다.\n",
        "\n",
        "`#`\n",
        "\n",
        "***`# 버전2`***\n",
        "\n",
        "init $\\boldsymbol{h}_0$\n",
        "\n",
        "for $t$ in $1:L$\n",
        "\n",
        "-   ${\\boldsymbol h}_t= \\tanh({\\boldsymbol x}_t{\\bf W}_{ih}+{\\boldsymbol h}_{t-1}{\\bf W}_{hh}+{\\boldsymbol b}_{ih}+{\\boldsymbol b}_{hh})$\n",
        "-   ${\\boldsymbol o}_t= {\\bf W}_{ho}{\\boldsymbol h}_1+{\\boldsymbol b}_{ho}$\n",
        "-   $\\hat{\\boldsymbol y}_t = \\text{soft}({\\boldsymbol o}_t)$\n",
        "\n",
        "`#`\n",
        "\n",
        "***`# 버전3`***\n",
        "\n",
        "``` python\n",
        "ht = [0,0]\n",
        "for t in 1:T \n",
        "    ht = tanh(linr(xt)+linr(ht))\n",
        "    ot = linr(ht)\n",
        "    yt_hat = soft(ot)\n",
        "```\n",
        "\n",
        "-   코드상으로는 $h_t$와 $h_{t-1}$의 구분이 교모하게 사라진다. (그래서\n",
        "    오히려 좋아)\n",
        "\n",
        "`#`\n",
        "\n",
        "`-` 따라서 실질적인 전체코드는 아래와 같은 방식으로 구현할 수 있다.\n",
        "\n",
        "## C. 구현1 – rNNCell\n",
        "\n",
        "`-` 데이터정리"
      ],
      "id": "db0e3418-b3b0-484a-a5ed-83055ee06f29"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "txt = list('AbAcAd'*50)\n",
        "txt[:10]"
      ],
      "id": "b098579e-e218-4151-b10d-f89c85faf49d"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_train = pd.DataFrame({'x':txt[:-1], 'y':txt[1:]})\n",
        "df_train[:5]"
      ],
      "id": "68cf665f-9f1e-4b71-93ce-d5b8bbac9269"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "x = torch.tensor(df_train.x.map({'A':0,'b':1,'c':2,'d':3}))\n",
        "y = torch.tensor(df_train.y.map({'A':0,'b':1,'c':2,'d':3}))\n",
        "X = torch.nn.functional.one_hot(x).float()\n",
        "y = torch.nn.functional.one_hot(y).float()"
      ],
      "id": "9a747a88-b1e5-433e-9581-8c9e1954922f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 순환신경망으로 적합\n",
        "\n",
        "`-` 결과 확인 및 시각화\n",
        "\n",
        "`-` yhat 값 분석\n",
        "\n",
        "-   미세하지만 뒤로갈수록 좀 더 성능이 좋다.\n",
        "\n",
        "`-` h1,h2 분석 (= 임베딩스페이스 분석)\n",
        "\n",
        "## D. 구현2 – RNNCell\n",
        "\n",
        "ref: <https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html>\n",
        "\n",
        "`-` 데이터정리"
      ],
      "id": "7ebe97e4-2958-4f8f-a0b8-b7ab4bc7f8fe"
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "x = torch.tensor(df_train.x.map({'A':0,'b':1,'c':2,'d':3}))\n",
        "y = torch.tensor(df_train.y.map({'A':0,'b':1,'c':2,'d':3}))\n",
        "X = torch.nn.functional.one_hot(x).float()\n",
        "y = torch.nn.functional.one_hot(y).float()"
      ],
      "id": "18dc3588-7f19-4483-8e39-2dab307c56da"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` Net설계 및 가중치 설정 (구현1과 동일하도록 가중치 초기화)\n",
        "\n",
        "`-` 손실함수 및 옵티마이저 설정\n",
        "\n",
        "`-` 학습\n",
        "\n",
        "`-` 결과확인\n",
        "\n",
        "-   구현1과 같은 결과"
      ],
      "id": "6c5847e0-e934-4b08-9495-79d08751a16b"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  }
}