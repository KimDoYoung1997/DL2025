{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# lecture\n",
        "\n",
        "최규빈  \n",
        "2025-05-19\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/guebin/DL2025/blob/main/posts/09wk-2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n",
        "\n",
        "# 1. 강의영상"
      ],
      "id": "06a25e95-d75d-48f2-86c7-ae4efdb48795"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# {{<video https://youtu.be/playlist?list=PLQqh36zP38-zEjn2m8H8hMCHsQK8udE27&si=Sy-lnw4Kq56SRggu >}}"
      ],
      "id": "89a8a3c8-183e-4b68-b40a-04d0bfca8ce1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Imports"
      ],
      "id": "85017c4b-ae7c-4621-a334-558a68f46367"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "#---#\n",
        "import numpy as np\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import IPython"
      ],
      "id": "be280b13-39ac-4e0c-a67c-bbc942b53917"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Bandit 환경 설계 및 풀이\n",
        "\n",
        "## A. 대충 개념만 실습"
      ],
      "id": "8c0fb060-5ae7-431f-9ea5-41ce5512caf1"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "action_space = [0,1] \n",
        "actions_deque = collections.deque(maxlen=500)\n",
        "rewards_deque =  collections.deque(maxlen=500)\n",
        "#---#"
      ],
      "id": "ffbafc7b-76fd-4e05-b2fa-f823f1f4dea3"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(10):\n",
        "    action = np.random.choice(action_space)\n",
        "    if action == 1:\n",
        "        reward = 10 \n",
        "    else:\n",
        "        reward = 1\n",
        "    actions_deque.append(action)\n",
        "    rewards_deque.append(reward)"
      ],
      "id": "ca352fd1-388f-4090-a68a-b93f139e254f"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "actions_deque"
      ],
      "id": "df532254-b43e-4058-bd38-624e493c9507"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "rewards_deque"
      ],
      "id": "1cf5ad96-cfbb-44a9-80dd-6f7510d9b2f9"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "actions_numpy = np.array(actions_deque)\n",
        "rewards_numpy = np.array(rewards_deque)"
      ],
      "id": "9ad85645-23fc-49fe-80bc-10fe667421f5"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "q0 = rewards_numpy[actions_numpy == 0].mean()\n",
        "q1 = rewards_numpy[actions_numpy == 1].mean()\n",
        "q_table = np.array([q0,q1])\n",
        "q_table"
      ],
      "id": "33963107-d98d-438a-9597-8b74f89af408"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "action = q_table.argmax()"
      ],
      "id": "6662715d-e316-43b7-b281-db49f3da4b97"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(5):\n",
        "    action = q_table.argmax()\n",
        "    if action == 1:\n",
        "        reward = 10 \n",
        "    else:\n",
        "        reward = 1\n",
        "    actions_deque.append(action)\n",
        "    rewards_deque.append(reward)\n",
        "    actions_numpy = np.array(actions_deque)\n",
        "    rewards_numpy = np.array(rewards_deque)    \n",
        "    q0 = rewards_numpy[actions_numpy == 0].mean()\n",
        "    q1 = rewards_numpy[actions_numpy == 1].mean()\n",
        "    q_table = np.array([q0,q1])"
      ],
      "id": "46532b57-252e-4fdd-948e-7e328a4f2296"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "actions_numpy"
      ],
      "id": "aa3829b3-32ba-467a-bfe8-1f3284e00bbd"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "rewards_numpy"
      ],
      "id": "c52ba635-b54c-45e4-853a-73e3acc60b73"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B. 클래스를 이용한 구현"
      ],
      "id": "41160d4f-5f1b-4c5c-83d7-cbd9d33b8e1c"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Bandit:\n",
        "    def __init__(self):\n",
        "        self.reward = None \n",
        "    def step(self,action):\n",
        "        if action == 0:\n",
        "            self.reward = 1\n",
        "        else: \n",
        "            self.reward = 10 \n",
        "        return self.reward "
      ],
      "id": "4d42cf9b-0ce1-4222-9177-3f495752779f"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    def __init__(self):\n",
        "        pass \n",
        "    def act(self):\n",
        "        # 만약에 경험이 20보다 작음 --> 랜덤액션 \n",
        "        # 경험이 20보다 크면 --> action = q_tabel.argmax()\n",
        "        pass \n",
        "    def save_experience(self):\n",
        "        # 데이터 저장 \n",
        "        pass \n",
        "    def learn(self):\n",
        "        # q_table 을 업데이트하는 과정 \n",
        "        pass"
      ],
      "id": "25a472e9-738c-4205-8ff9-e856aceaade3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------"
      ],
      "id": "e61140ef-5b0d-4238-ac37-f2752b3fad20"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    def __init__(self):\n",
        "        self.n_experiences = 0 \n",
        "        self.action_space = [0,1]\n",
        "        self.action = None\n",
        "        self.reward = None \n",
        "        self.q_table = None \n",
        "        self.actions = collections.deque(maxlen=500)\n",
        "        self.rewards = collections.deque(maxlen=500)\n",
        "    def act(self):\n",
        "        if self.n_experiences < 20:\n",
        "            self.action = np.random.choice(self.action_space)\n",
        "        else: \n",
        "            self.action = self.q_table.argmax()\n",
        "        print(f\"버튼{self.action}누름!\")\n",
        "    def save_experience(self):\n",
        "        self.actions.append(self.action)\n",
        "        self.rewards.append(self.reward)\n",
        "        self.n_experiences = self.n_experiences + 1 \n",
        "    def learn(self):\n",
        "        if self.n_experiences < 20:\n",
        "            pass\n",
        "        else: \n",
        "            actions = np.array(self.actions)\n",
        "            rewards = np.array(self.rewards)\n",
        "            q0 = rewards[actions==0].mean()\n",
        "            q1 = rewards[actions==1].mean()\n",
        "            self.q_table = np.array([q0,q1])"
      ],
      "id": "f7632ae5-bff9-4c13-842e-be6cec2c8ebf"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = Bandit()\n",
        "player = Agent()"
      ],
      "id": "bd8eb055-858d-4431-a7a3-5273f744a410"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼0누름!\n",
            "버튼1누름!\n",
            "버튼0누름!\n",
            "버튼1누름!\n",
            "버튼0누름!\n",
            "버튼1누름!\n",
            "버튼0누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼0누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼0누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼0누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "버튼1누름!\n",
            "---\n",
            "36번만에 게임클리어"
          ]
        }
      ],
      "source": [
        "for _ in range(50):\n",
        "    # step1 : agent --> env \n",
        "    player.act()\n",
        "    # step2: agnet <-- env \n",
        "    player.reward = env.step(player.action)\n",
        "    # step3: agent: update (save + learn) \n",
        "    player.save_experience() \n",
        "    player.learn()\n",
        "    #----#\n",
        "    if player.n_experiences < 20: \n",
        "        pass \n",
        "    else: \n",
        "        recent_rewards = np.array(player.rewards)[-20:]\n",
        "        if recent_rewards.mean() > 9.5:\n",
        "            print(\"---\")\n",
        "            print(f\"{player.n_experiences}번만에 게임클리어\")\n",
        "            break "
      ],
      "id": "f82ed4ee-293c-4896-8dbb-93031469444f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. 예비학습: `gym.spaces`\n",
        "\n",
        "ref: <https://gymnasium.farama.org/>\n",
        "\n",
        "`-` 예시1"
      ],
      "id": "51285415-726f-4dc1-93fe-ea04053aa333"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "action_space = gym.spaces.Discrete(4) \n",
        "action_space "
      ],
      "id": "2aa20310-25dd-4771-82ff-3c5efb508c96"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "[action_space.sample() for _ in range(5)]"
      ],
      "id": "33509be6-286c-4d34-948f-7b6928c46558"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "0 in action_space"
      ],
      "id": "1c5825aa-d6e0-4308-a23d-8a603e238afd"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "4 in action_space"
      ],
      "id": "20347c21-9e42-4e3c-b172-e3e7a69fc12a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 예시2"
      ],
      "id": "ccfb2fdd-f2f8-459e-81a3-464f406379f2"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "state_space = gym.spaces.MultiDiscrete([4,4])\n",
        "state_space"
      ],
      "id": "16b3a23b-52c7-426a-b3e2-769fe723591d"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "[state_space.sample() for _ in range(5)]"
      ],
      "id": "d3e2dc47-e353-48fc-b61b-a93b0935215d"
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.array([0,1]) in state_space"
      ],
      "id": "5eadf302-2503-4f66-8049-795adce7f475"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "np.array([3,3]) in state_space"
      ],
      "id": "b54b803f-5100-4ced-8d05-2b831a8c5e8a"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "np.array([3,4]) in state_space"
      ],
      "id": "8ea21007-44be-45d3-a8c8-eb134100bcc7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. 4x4 Grid World 게임 설명\n",
        "\n",
        "## A. 게임설명\n",
        "\n",
        "`-` 문제설명: 4x4 그리드월드에서 상하좌우로 움직이는 에이전트가 목표점에\n",
        "도달하도록 하는 게임\n",
        "\n",
        "-   백문이 불여일견:\n",
        "    <https://claude.ai/public/artifacts/76e13820-2b51-4e7e-a514-00190de17c45>\n",
        "    (출처: 클로드)\n",
        "\n",
        "`-` GridWorld에서 사용되는 주요변수\n",
        "\n",
        "1.  **`State`**: 각 격자 셀이 하나의 상태이며, 에이전트는 이러한 상태 중\n",
        "    하나에 있을 수 있음.\n",
        "2.  **`Action`**: 에이전트는 현재상태에서 다음상태로 이동하기 위해\n",
        "    상,하,좌,우 중 하나의 행동을 취할 수 있음.\n",
        "3.  **`Reward`**: 에이전트가 현재상태에서 특정 action을 하면 얻어지는\n",
        "    보상.\n",
        "4.  **`Terminated`**: 하나의 에피소드가 종료되었음을 나타내는 상태.\n",
        "\n",
        "## B. 시각화"
      ],
      "id": "92258169-a663-4e2c-ac87-e31ae00bdbed"
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "def show(states):\n",
        "    fig = plt.Figure()\n",
        "    ax = fig.subplots()\n",
        "    ax.matshow(np.zeros([4,4]), cmap='bwr',alpha=0.0)\n",
        "    sc = ax.scatter(0, 0, color='red', s=500)  \n",
        "    ax.text(0, 0, 'start', ha='center', va='center')\n",
        "    ax.text(3, 3, 'end', ha='center', va='center')\n",
        "    # Adding grid lines to the plot\n",
        "    ax.set_xticks(np.arange(-.5, 4, 1), minor=True)\n",
        "    ax.set_yticks(np.arange(-.5, 4, 1), minor=True)\n",
        "    ax.grid(which='minor', color='black', linestyle='-', linewidth=2)\n",
        "    state_space = gym.spaces.MultiDiscrete([4,4])\n",
        "    def update(t):\n",
        "        if states[t] in state_space:\n",
        "            s1,s2 = states[t]\n",
        "            states[t] = [s2,s1]\n",
        "            sc.set_offsets(states[t])\n",
        "        else:\n",
        "            s1,s2 = states[t]\n",
        "            s1 = s1 + 0.5 if s1 < 0 else (s1 - 0.5 if s1 > 3 else s1)\n",
        "            s2 = s2 + 0.5 if s2 < 0 else (s2 - 0.5 if s2 > 3 else s2)\n",
        "            states[t] = [s2,s1]       \n",
        "            sc.set_offsets(states[t])\n",
        "    ani = FuncAnimation(fig,update,frames=len(states))\n",
        "    display(IPython.display.HTML(ani.to_jshtml()))"
      ],
      "id": "68bfce29-e8df-4cd1-bdec-d3da2f51821b"
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "show([[0,0],[1,0],[2,0],[3,0],[4,0]]) # show 사용방법"
      ],
      "id": "af6d2912-d0bc-4a8f-978b-2f5e55b86569"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. 4x4 Grid World 환경 구현"
      ],
      "id": "eaa17f32-dbec-4a4c-b0cf-d729ba71aa52"
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GridWorld:\n",
        "    def __init__(self):\n",
        "        self.a2d = {\n",
        "            0: np.array([0,1]), # →\n",
        "            1: np.array([0,-1]), # ←  \n",
        "            2: np.array([1,0]),  # ↓\n",
        "            3: np.array([-1,0])  # ↑\n",
        "        }\n",
        "        self.state = np.array([0,0])\n",
        "        self.state_space = gym.spaces.MultiDiscrete([4,4])\n",
        "        self.terminated = False \n",
        "        self.reward = None \n",
        "    def reset(self):\n",
        "        self.state = np.array([0,0])\n",
        "        self.reward = None \n",
        "        self.terminated = False\n",
        "    def step(self,action):\n",
        "        self.state = self.state + self.a2d[action]\n",
        "        s1,s2 = self.state \n",
        "        if (s1==3) and (s2==3):\n",
        "            self.reward = 100\n",
        "            self.terminated = True \n",
        "        elif self.state in self.state_space:\n",
        "            self.reward = -1 \n",
        "            self.terminated = False\n",
        "        else: \n",
        "            self.reward = -10 \n",
        "            self.terminated = True \n",
        "        print(\n",
        "            f\"action = {action}\\t\"\n",
        "            f\"state = {self.state - self.a2d[action]} -> {self.state}\\t\"\n",
        "            f\"reward = {self.reward}\\t\"\n",
        "            f\"termiated = {self.terminated}\"\n",
        "        )\n",
        "        return self.state, self.reward, self.terminated\n",
        "    def reset(self):\n",
        "        self.terminated = False \n",
        "        self.state = np.array([0,0])\n",
        "        return self.state"
      ],
      "id": "47a40eb0-4f11-441a-911f-6c94acc21122"
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = GridWorld()"
      ],
      "id": "f51febbc-69bc-4cc2-a13b-d47c2564f90a"
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 1  state = [1 0] -> [ 1 -1]    reward = -10    termiated = True\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 3  state = [1 1] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
            "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False"
          ]
        }
      ],
      "source": [
        "for t in range(10):\n",
        "    action = action_space.sample()\n",
        "    env.step(action)\n",
        "    if env.terminated:\n",
        "        env.state = env.reset()"
      ],
      "id": "457030e8-fbbc-4490-8a84-d82f377fae68"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. “에이전트 $\\Leftrightarrow$ 환경” 상호작용 구현\n",
        "\n",
        "`-` 우리가 구현하고 싶은 기능\n",
        "\n",
        "-   `.act()`: 액션을 결정 –\\> 여기서는 그냥 랜덤액션\n",
        "-   `.save_experience()`: 데이터를 저장 –\\> 여기에 일단 초점을 맞추자\n",
        "-   `.learn()`: 데이터로에서 학습 –\\> 패스"
      ],
      "id": "df3e7eff-6db2-4972-98c3-6ab92a51dd51"
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RandomAgent:\n",
        "    def __init__(self):\n",
        "        self.n_experiences = 0 \n",
        "        self.action_space = gym.spaces.Discrete(4)\n",
        "        #---#\n",
        "        self.state = None \n",
        "        self.action = None\n",
        "        self.reward = None \n",
        "        self.next_state = None \n",
        "        self.termiated = None\n",
        "        #---#\n",
        "        self.states = collections.deque(maxlen=500)\n",
        "        self.actions = collections.deque(maxlen=500)\n",
        "        self.rewards = collections.deque(maxlen=500)\n",
        "        self.next_states = collections.deque(maxlen=500)\n",
        "        self.terminations = collections.deque(maxlen=500)\n",
        "        #---#\n",
        "        #self.q_table = None \n",
        "    def act(self):\n",
        "        self.action = self.action_space.sample()\n",
        "    def save_experience(self):\n",
        "        self.states.append(self.state)\n",
        "        self.actions.append(self.action)        \n",
        "        self.rewards.append(self.reward)\n",
        "        self.next_states.append(self.next_state)\n",
        "        self.terminations.append(self.termiated)\n",
        "        self.n_experiences = self.n_experiences + 1 \n",
        "    def learn(self):\n",
        "        pass"
      ],
      "id": "a77562c9-1205-4c43-a6c3-083cecd0b162"
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {},
      "outputs": [],
      "source": [
        "player = RandomAgent()\n",
        "env = GridWorld()"
      ],
      "id": "42ad0d4d-d005-41c4-bf7b-d45a8b87fd19"
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 1  state = [1 0] -> [ 1 -1]    reward = -10    termiated = True"
          ]
        }
      ],
      "source": [
        "for _ in range(50):\n",
        "    # step1 : agent --> env \n",
        "    player.act()\n",
        "    # step2: agnet <-- env \n",
        "    player.next_state, player.reward, player.terminated = env.step(player.action)\n",
        "    # step3: agent: update (save + learn) \n",
        "    player.save_experience() \n",
        "    player.learn()\n",
        "    # step4: prepare next iterations \n",
        "    player.state = player.next_state\n",
        "    if env.terminated:\n",
        "        player.state = env.reset()\n",
        "        break"
      ],
      "id": "82d26399-1ea2-42f8-a3bc-31d17d38d946"
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드1종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
            "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
            "action = 1  state = [1 0] -> [ 1 -1]    reward = -10    termiated = True\n",
            "---에피소드2종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드3종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드4종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 1  state = [1 0] -> [ 1 -1]    reward = -10    termiated = True\n",
            "---에피소드5종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드6종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드7종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 3  state = [1 1] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
            "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 1  state = [2 0] -> [ 2 -1]    reward = -10    termiated = True\n",
            "---에피소드8종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드9종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 0  state = [0 1] -> [0 2]  reward = -1 termiated = False\n",
            "action = 3  state = [0 2] -> [-1  2]    reward = -10    termiated = True\n",
            "---에피소드10종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 3  state = [1 1] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
            "action = 2  state = [2 1] -> [3 1]  reward = -1 termiated = False\n",
            "action = 1  state = [3 1] -> [3 0]  reward = -1 termiated = False\n",
            "action = 3  state = [3 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
            "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
            "action = 3  state = [2 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
            "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
            "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 2  state = [2 0] -> [3 0]  reward = -1 termiated = False\n",
            "action = 3  state = [3 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
            "action = 3  state = [2 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 2  state = [1 2] -> [2 2]  reward = -1 termiated = False\n",
            "action = 1  state = [2 2] -> [2 1]  reward = -1 termiated = False\n",
            "action = 3  state = [2 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
            "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
            "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
            "action = 3  state = [2 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 3  state = [1 1] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 3  state = [1 1] -> [0 1]  reward = -1 termiated = False\n",
            "action = 3  state = [0 1] -> [-1  1]    reward = -10    termiated = True\n",
            "---에피소드11종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드12종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 0  state = [0 1] -> [0 2]  reward = -1 termiated = False\n",
            "action = 0  state = [0 2] -> [0 3]  reward = -1 termiated = False\n",
            "action = 1  state = [0 3] -> [0 2]  reward = -1 termiated = False\n",
            "action = 1  state = [0 2] -> [0 1]  reward = -1 termiated = False\n",
            "action = 0  state = [0 1] -> [0 2]  reward = -1 termiated = False\n",
            "action = 1  state = [0 2] -> [0 1]  reward = -1 termiated = False\n",
            "action = 3  state = [0 1] -> [-1  1]    reward = -10    termiated = True\n",
            "---에피소드13종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
            "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
            "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
            "action = 3  state = [2 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
            "action = 0  state = [2 1] -> [2 2]  reward = -1 termiated = False\n",
            "action = 1  state = [2 2] -> [2 1]  reward = -1 termiated = False\n",
            "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
            "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
            "action = 2  state = [2 1] -> [3 1]  reward = -1 termiated = False\n",
            "action = 1  state = [3 1] -> [3 0]  reward = -1 termiated = False\n",
            "action = 2  state = [3 0] -> [4 0]  reward = -10    termiated = True\n",
            "---에피소드14종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
            "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
            "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
            "action = 2  state = [2 1] -> [3 1]  reward = -1 termiated = False\n",
            "action = 3  state = [3 1] -> [2 1]  reward = -1 termiated = False\n",
            "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
            "action = 2  state = [2 0] -> [3 0]  reward = -1 termiated = False\n",
            "action = 1  state = [3 0] -> [ 3 -1]    reward = -10    termiated = True\n",
            "---에피소드15종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드16종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드17종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
            "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
            "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
            "action = 1  state = [2 1] -> [2 0]  reward = -1 termiated = False\n",
            "action = 0  state = [2 0] -> [2 1]  reward = -1 termiated = False\n",
            "action = 2  state = [2 1] -> [3 1]  reward = -1 termiated = False\n",
            "action = 0  state = [3 1] -> [3 2]  reward = -1 termiated = False\n",
            "action = 2  state = [3 2] -> [4 2]  reward = -10    termiated = True\n",
            "---에피소드18종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드19종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드20종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
            "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
            "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
            "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
            "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
            "action = 0  state = [2 1] -> [2 2]  reward = -1 termiated = False\n",
            "action = 1  state = [2 2] -> [2 1]  reward = -1 termiated = False\n",
            "action = 0  state = [2 1] -> [2 2]  reward = -1 termiated = False\n",
            "action = 1  state = [2 2] -> [2 1]  reward = -1 termiated = False\n",
            "action = 0  state = [2 1] -> [2 2]  reward = -1 termiated = False\n",
            "action = 1  state = [2 2] -> [2 1]  reward = -1 termiated = False\n",
            "action = 2  state = [2 1] -> [3 1]  reward = -1 termiated = False\n",
            "action = 1  state = [3 1] -> [3 0]  reward = -1 termiated = False\n",
            "action = 0  state = [3 0] -> [3 1]  reward = -1 termiated = False\n",
            "action = 2  state = [3 1] -> [4 1]  reward = -10    termiated = True\n",
            "---에피소드21종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 3  state = [0 1] -> [-1  1]    reward = -10    termiated = True\n",
            "---에피소드22종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 3  state = [0 1] -> [-1  1]    reward = -10    termiated = True\n",
            "---에피소드23종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드24종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드25종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드26종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 2  state = [2 0] -> [3 0]  reward = -1 termiated = False\n",
            "action = 1  state = [3 0] -> [ 3 -1]    reward = -10    termiated = True\n",
            "---에피소드27종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 3  state = [2 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
            "action = 1  state = [1 1] -> [1 0]  reward = -1 termiated = False\n",
            "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드28종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드29종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 0  state = [0 1] -> [0 2]  reward = -1 termiated = False\n",
            "action = 1  state = [0 2] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 3  state = [1 1] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 2  state = [1 1] -> [2 1]  reward = -1 termiated = False\n",
            "action = 0  state = [2 1] -> [2 2]  reward = -1 termiated = False\n",
            "action = 0  state = [2 2] -> [2 3]  reward = -1 termiated = False\n",
            "action = 3  state = [2 3] -> [1 3]  reward = -1 termiated = False\n",
            "action = 0  state = [1 3] -> [1 4]  reward = -10    termiated = True\n",
            "---에피소드30종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드31종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드32종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드33종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드34종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드35종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 0  state = [1 2] -> [1 3]  reward = -1 termiated = False\n",
            "action = 3  state = [1 3] -> [0 3]  reward = -1 termiated = False\n",
            "action = 1  state = [0 3] -> [0 2]  reward = -1 termiated = False\n",
            "action = 3  state = [0 2] -> [-1  2]    reward = -10    termiated = True\n",
            "---에피소드36종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드37종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드38종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드39종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 0  state = [1 0] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 2  state = [1 2] -> [2 2]  reward = -1 termiated = False\n",
            "action = 3  state = [2 2] -> [1 2]  reward = -1 termiated = False\n",
            "action = 1  state = [1 2] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 3  state = [1 2] -> [0 2]  reward = -1 termiated = False\n",
            "action = 1  state = [0 2] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드40종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드41종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 1  state = [0 1] -> [0 0]  reward = -1 termiated = False\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드42종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 2  state = [1 0] -> [2 0]  reward = -1 termiated = False\n",
            "action = 3  state = [2 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 3  state = [1 0] -> [0 0]  reward = -1 termiated = False\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드43종료---\n",
            "action = 2  state = [0 0] -> [1 0]  reward = -1 termiated = False\n",
            "action = 1  state = [1 0] -> [ 1 -1]    reward = -10    termiated = True\n",
            "---에피소드44종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 0  state = [0 1] -> [0 2]  reward = -1 termiated = False\n",
            "action = 0  state = [0 2] -> [0 3]  reward = -1 termiated = False\n",
            "action = 3  state = [0 3] -> [-1  3]    reward = -10    termiated = True\n",
            "---에피소드45종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드46종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드47종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드48종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드49종료---\n",
            "action = 3  state = [0 0] -> [-1  0]    reward = -10    termiated = True\n",
            "---에피소드50종료---\n",
            "action = 1  state = [0 0] -> [ 0 -1]    reward = -10    termiated = True\n",
            "---에피소드51종료---\n",
            "action = 0  state = [0 0] -> [0 1]  reward = -1 termiated = False\n",
            "action = 2  state = [0 1] -> [1 1]  reward = -1 termiated = False\n",
            "action = 0  state = [1 1] -> [1 2]  reward = -1 termiated = False\n",
            "action = 0  state = [1 2] -> [1 3]  reward = -1 termiated = False\n",
            "action = 3  state = [1 3] -> [0 3]  reward = -1 termiated = False\n",
            "action = 1  state = [0 3] -> [0 2]  reward = -1 termiated = False\n",
            "action = 0  state = [0 2] -> [0 3]  reward = -1 termiated = False\n",
            "action = 2  state = [0 3] -> [1 3]  reward = -1 termiated = False\n",
            "action = 3  state = [1 3] -> [0 3]  reward = -1 termiated = False\n",
            "action = 2  state = [0 3] -> [1 3]  reward = -1 termiated = False\n",
            "action = 2  state = [1 3] -> [2 3]  reward = -1 termiated = False\n",
            "action = 1  state = [2 3] -> [2 2]  reward = -1 termiated = False\n",
            "action = 2  state = [2 2] -> [3 2]  reward = -1 termiated = False\n",
            "action = 3  state = [3 2] -> [2 2]  reward = -1 termiated = False\n",
            "action = 1  state = [2 2] -> [2 1]  reward = -1 termiated = False\n",
            "action = 2  state = [2 1] -> [3 1]  reward = -1 termiated = False\n",
            "action = 0  state = [3 1] -> [3 2]  reward = -1 termiated = False\n",
            "action = 3  state = [3 2] -> [2 2]  reward = -1 termiated = False\n",
            "action = 2  state = [2 2] -> [3 2]  reward = -1 termiated = False\n",
            "action = 0  state = [3 2] -> [3 3]  reward = 100    termiated = True\n",
            "---에피소드52종료---"
          ]
        }
      ],
      "source": [
        "scores = [] \n",
        "playtimes = []\n",
        "for e in range(1,1000):\n",
        "    player.state = env.reset()\n",
        "    score = 0 \n",
        "    #---#\n",
        "    for playtime in range(1,50):\n",
        "        # step1 : agent --> env \n",
        "        player.act()\n",
        "        # step2: agnet <-- env \n",
        "        player.next_state, player.reward, player.terminated = env.step(player.action)\n",
        "        # step3: agent: update (save + learn) \n",
        "        player.save_experience() \n",
        "        player.learn()\n",
        "        # step4: prepare next iterations \n",
        "        player.state = player.next_state\n",
        "        score = score + player.reward\n",
        "        if env.terminated:\n",
        "            print(f\"---에피소드{e}종료---\")\n",
        "            break\n",
        "    #---#\n",
        "    scores.append(score)\n",
        "    if scores[-1] > 0:\n",
        "        break"
      ],
      "id": "5288b78f-99df-4241-94f6-cc6b7e17a96a"
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores[-1]"
      ],
      "id": "e093459a-5b8d-47fb-9d39-50d822c19b28"
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "metadata": {},
      "outputs": [],
      "source": [
        "paths = [np.array([0,0])]+ list(player.next_states)[-20:]\n",
        "show(paths)"
      ],
      "id": "b22928bd-a76b-4ac8-b3e7-d93295df8565"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  }
}