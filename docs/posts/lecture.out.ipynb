{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 08wk-1: (합성곱신경망) XXX\n",
        "\n",
        "최규빈  \n",
        "2025-01-01\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/guebin/DL2025/blob/main/posts/05wk-2\n",
        "    .ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n",
        "\n",
        "# 1. 강의영상"
      ],
      "id": "b50e6c7d-c4a7-4c91-8294-b5a4fb393f29"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "#{{<video https://youtu.be/playlist?list=PLQqh36zP38-z7s7FppJtYXFUnJzw88qWg&si=3TuaJ7IiiIG6QT7X>}}"
      ],
      "id": "b3c6adf5-5a25-47f9-8d86-13f7237bd9a8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Imports"
      ],
      "id": "51ad9ba4-8df8-44a3-9955-6a1d584b23d0"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "2e39f442-4cd6-403e-bf9c-15071c4dd634"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = (4.5, 3.0)"
      ],
      "id": "3fbf745c-bb6e-42b0-91ec-1385fe1b5d49"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. MNIST"
      ],
      "id": "3f3b2f7f-8540-496d-b06f-2cac9ed8f337"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True,transform=torchvision.transforms.ToTensor())\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True,transform=torchvision.transforms.ToTensor())\n",
        "X,y = next(iter(torch.utils.data.DataLoader(train_dataset,batch_size=6000,shuffle=True)))\n",
        "XX,yy = next(iter(torch.utils.data.DataLoader(train_dataset,batch_size=1000,shuffle=True)))"
      ],
      "id": "cbd52b2e-2878-4886-bead-1b3fa9192a3b"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(1,32,kernel_size=5),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.MaxPool2d(kernel_size=2), # (n,32,?,?)\n",
        "    torch.nn.Conv2d(32,32,kernel_size=3),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Flatten(), # (n,???)\n",
        "    torch.nn.Linear(3200,10)\n",
        ")\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(net.parameters())\n",
        "#---#\n",
        "X = X.to(\"cuda:0\")\n",
        "XX = XX.to(\"cuda:0\")\n",
        "y = y.to(\"cuda:0\")\n",
        "yy = yy.to(\"cuda:0\")\n",
        "net.to(\"cuda:0\")\n",
        "#---#\n",
        "for epoc in range(100):\n",
        "    #1\n",
        "    netout = net(X)\n",
        "    #2\n",
        "    loss = loss_fn(netout,y)\n",
        "    #3\n",
        "    loss.backward()\n",
        "    #4 \n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "31f8e607-9b9e-408d-ba92-88e0a28a1034"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "(net(X).argmax(axis=1) == y).float().mean()"
      ],
      "id": "9295ffe3-4056-4553-8609-f7a1d63a004d"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "(net(XX).argmax(axis=1) == yy).float().mean()"
      ],
      "id": "b84f7fc4-ab5a-46ee-81da-5d7eed660101"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "id": "4aae567a-b592-4a87-8857-d7247cae3d47"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. CIFAR10"
      ],
      "id": "aa4416fd-b02f-4c86-8fbd-847c98b02cf3"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True,transform=torchvision.transforms.ToTensor())\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True,transform=torchvision.transforms.ToTensor())\n",
        "X,y = next(iter(torch.utils.data.DataLoader(train_dataset,batch_size=10000,shuffle=True)))\n",
        "XX,yy = next(iter(torch.utils.data.DataLoader(train_dataset,batch_size=2000,shuffle=True)))"
      ],
      "id": "db9918e5-30d4-434a-b8bd-efcadf0d3a19"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A. 직접설계"
      ],
      "id": "49498204-c9d2-4871-9ec5-216dbaf69251"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(3,32,kernel_size=5),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.MaxPool2d(kernel_size=2), # (n,32,?,?)\n",
        "    torch.nn.Conv2d(32,32,kernel_size=3),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Flatten(), # (n,???)\n",
        "    torch.nn.Linear(4608,10)\n",
        ")\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizr = torch.optim.Adam(net.parameters())\n",
        "#---#\n",
        "X = X.to(\"cuda:0\")\n",
        "XX = XX.to(\"cuda:0\")\n",
        "y = y.to(\"cuda:0\")\n",
        "yy = yy.to(\"cuda:0\")\n",
        "net.to(\"cuda:0\")\n",
        "#---#\n",
        "for epoc in range(100):\n",
        "    #1\n",
        "    netout = net(X)\n",
        "    #2\n",
        "    loss = loss_fn(netout,y)\n",
        "    #3\n",
        "    loss.backward()\n",
        "    #4 \n",
        "    optimizr.step()\n",
        "    optimizr.zero_grad()"
      ],
      "id": "3ee97e5f-689f-440f-b8b8-b6d324a16678"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "(net(X).argmax(axis=1) == y).float().mean()"
      ],
      "id": "37ffc4af-9b5a-4329-8790-628a855852e3"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "(net(XX).argmax(axis=1) == yy).float().mean()"
      ],
      "id": "681cce2d-02e4-49dc-923b-38cf6beca2aa"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "id": "a306c3e4-56e9-4b2e-bd33-84b51b7f5f56"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B. 알렉스넷?\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Comparison_image_neural_networks.svg/960px-Comparison_image_neural_networks.svg.png)"
      ],
      "id": "d8c52276-1b20-443e-96d2-e462cb22b0ab"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "img = torch.randn([1,3,224,224])"
      ],
      "id": "109cea97-2bc6-4e79-8927-0774b213754a"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(3,96,kernel_size=(11,11),stride=4),\n",
        "    torch.nn.ReLU(),    \n",
        "    torch.nn.MaxPool2d((3,3),stride=2), # default stride는 3\n",
        "    torch.nn.Conv2d(96,256,kernel_size=(5,5),padding=2),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.MaxPool2d((3,3),stride=2), # default stride는 3\n",
        "    torch.nn.Conv2d(256,384,kernel_size=(3,3),padding=1),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Conv2d(384,384,kernel_size=(3,3),padding=1),\n",
        "    torch.nn.ReLU(),    \n",
        "    torch.nn.Conv2d(384,256,kernel_size=(3,3),padding=1),\n",
        "    torch.nn.ReLU(),    \n",
        "    torch.nn.MaxPool2d((3,3),stride=2),\n",
        "    torch.nn.Flatten(),\n",
        "    torch.nn.Linear(6400,4096),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Dropout(0.5),\n",
        "    torch.nn.Linear(4096,4096),        \n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Dropout(0.5),    \n",
        "    torch.nn.Linear(4096,1000),\n",
        ")"
      ],
      "id": "4289fe86-0cae-4ece-8e08-bd0f49dd6ce6"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "net[:3](img).shape"
      ],
      "id": "24459589-a5cb-4847-82da-9ee1494e4422"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C. 알렉스넷으로 ImageNet 적합"
      ],
      "id": "12a81832-fb4a-42c5-8912-71399b68f0b7"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "net[-1] = torch.nn.Linear(4096,10)"
      ],
      "id": "29796977-7e3c-4ee1-93b6-8192d39c6b1f"
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "img = torch.randn(1,3,32,32)"
      ],
      "id": "bfb899aa-bcc1-4ea2-a6b4-396c1d16b847"
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "net(img)"
      ],
      "id": "ab05928a-17bc-4dc3-a90b-1968e5210522"
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "net[:5](img).shape"
      ],
      "id": "3daf2cbb-0403-4e62-9fbb-694676a17cae"
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "net[5](net[:5](img))"
      ],
      "id": "83543838-0b4e-458b-a997-4a5a56ca270a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## D. renset18\n",
        "\n",
        "`-` res: <https://arxiv.org/pdf/1512.03385>"
      ],
      "id": "d4889f3b-36ac-41e8-836b-dbd0defcc43d"
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = torchvision.models.resnet18()\n",
        "net.fc = torch.nn.Linear(512,10)"
      ],
      "id": "cd5d4b7c-9dea-4a0a-8518-513af0f36088"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## E. resnet18, pretrained=True\n",
        "\n",
        "# 5. XAI 란?\n",
        "\n",
        "<https://brunch.co.kr/@hvnpoet/140>"
      ],
      "id": "4a27a6f9-5d21-48dc-b8b9-bcc6590da665"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  }
}